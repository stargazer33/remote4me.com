{
 "items": [
  {
    "id": "FLnx55NfS92T1L1M1vOwNA",
    "url": "https://remote.co/job/coding-specialist-11/",
    "title": "Coding Specialist",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=1, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "nThrive",
      "sameAs": "https://www.nthrive.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 29, 2019 5:29:53 PM",
    "validThrough": "Sep 5, 2019 5:29:53 PM",
    "crawled": "Aug 29, 2019 6:24:02 PM",
    "content": "<h3>Coding Specialist at <span>nThrive</span></h3><div><span><i></i> Remote</span>        </div><div>            <p><strong>Job ID: </strong>2019-26531</p><p><strong>Employment Type: </strong><strong>Full Time</strong></p><p><strong>Hours Per Week: </strong>40 hours</p><p><strong>Onsite Work Schedule Details: </strong><strong>M-F 8-4:30pm should be flexible to work weekends and holidays as needed</strong></p><p><strong>City: </strong><strong>Remote</strong></p><p><strong>Overview</strong></p><p>The Coding Specialist will work closely with HIM and other support departments to reimburse healthcare claims. This individual will utilize specialized medical classification software to assign procedure and diagnosis codes for insurance billing as well as review claims data to ensure that assigned codes meet required legal and insurance rules and that required signatures and authorizations are in place before submission.</p><p><strong>Responsibilities</strong></p><ul><li>Selects and sequences ICD-10, and/or CPT/HCPCS codes for designated patient types which may include but are not limited to: Ancillary (Diagnostic)/ Recurring; Hospital, Clinic; Physician Pro Fee; Technical Fee or Evaluation and Management.</li><li>Reviews and analyzes clinical records to ensure that APC assignments accurately reflect the diagnoses/procedures documented in the clinical record.</li><li>Abstracts clinical data from the record after documentation review to ensure that it is adequate and appropriate to support diagnoses, procedures and discharge disposition is selected.</li><li>May act as a resource with client staff for data integrity, clarification and assistance in understanding and determining appropriate and compliant coding practices including provider queries.</li><li>Maintains strict patient and provider confidentiality in compliance with all federal, state, and hospital laws and guidelines for release of information.</li><li>Maintain current working knowledge of ICD-10 and/or CPT/HCPCS and coding guidelines, government regulations, protocols and third-party requirements regarding coding and/or billing.</li><li>Participate in continuing education activities to enhance knowledge, skills, and maintain current credentials.</li><li>Supports nThrive’s Compliance Program by adhering to policies and procedures pertaining to HIPAA, FDCPA, FCRA, and other laws applicable to nThrive’s business practices. This includes: becoming familiar with nThrive’s Code of Ethics, attending training as required, notifying management or nThrive’s Helpline when there is a compliance concern or incident, HIPAA-compliant handling of patient information, and demonstrable awareness of confidentiality obligations.</li></ul><p><strong>Qualifications</strong></p><ul><li><strong>Active RHIA, RHIT, CCS</strong></li><li>3+ years of recent and relevant hands-on coding experience including active production coding</li><li>Ability to consistently code at 95% threshold for both accuracy and quality while maintaining client-specific and nThrive production standards</li><li>Proficient computer knowledge including MS Office (Outlook, Word, Excel, Power Point)</li><li>Must display excellent interpersonal and problem-solving skills with all levels of internal and external customers</li><li>Candidates must successfully pass pre-employment coding test</li><li>Cable or DSL high-speed, wired Internet Connection</li></ul><p><strong>About nThrive</strong></p><p><strong>Be Inspired. Ignite Change. Transform Health Care.</strong><br>From Patient-to-Payment, nThrive provides all the technology, advisory expertise, services, analytics and education programs health care organizations need to thrive in the communities they serve. Our colleagues share a united passion to help health care organizations strengthen their financial position, which translates to accessible, quality care for all. This passion fuels our drive to innovate and participate in community outreach through the nThrive CARES program. Our colleagues are encouraged to think differently and empowered to make a lasting impact that ensures our health care providers, and our world, are healthy and productive.</p>        </div><div>        <a href='https://careers-nthrive.icims.com/jobs/26531/coding-specialist/job' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SDmblLl3QbaNm6su6qwOTw",
    "url": "https://stackoverflow.com/jobs/265031/data-platform-engineer-heetch?a=1qSKVWcse6xq",
    "title": "Data Platform Engineer at Heetch  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:avro/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=11, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Heetch",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 29, 2019 1:06:24 PM",
    "validThrough": "Sep 5, 2019 1:06:24 PM",
    "crawled": "Aug 29, 2019 1:06:24 PM",
    "content": "<h3><span>Data Platform Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>System Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Carsharing, Marketplace, Transportation</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Heetch | No office location<br></div><h4>Technologies</h4><div></div><div>kafka</div><div>prestodb</div><div>apache-spark</div><div>airflow</div><div>amazon-redshift</div>                <h4>Job description</h4>                <div><p><strong>⚠️<u>Read before applying:</u></strong></p><p>We're a young company iterating over our remote culture so for now, we're only working with people in locations where the time zone is:&nbsp;<strong>-3 hours &gt; Paris time zone&nbsp;&lt;&nbsp;+3 hours</strong></p><p><strong>Data Engineering Team @Heetch</strong></p><p>Our team's mission is to help the company generate confident insights, make better decisions and build data-driven products. We believe the data platform is the digital nervous system of Heetch and that empowering everyone in the company with data access is critical to our business success. As a new sub-team within Data Engineering, the Data Infrastructure team is dedicated to designing, building and scaling our data platform and the underlying data infrastructure.</p><p><strong>What will be your role?</strong></p><p>You will enable Data Scientists, Data Analysts, and Operations teams, tailor the data platform to their needs and empower them to solve challenging ML and analytics problems. If you're experienced, passionate and interested in leading the transformation of our data infrastructure, we would love to talk to you!</p><p><strong>Does it sound like you?</strong></p><ul><li>You've architected, built, scaled, tuned and maintained large-scale distributed systems in a production environment, specifically on top of AWS.</li><li>You've got proven experience working with data technologies that power data platforms (e.g.: Spark, Presto, Kafka, Airflow, Avro, Redshift, ElasticSearch, etc.).</li><li>You've led DevOps topics such as CI/CD, containerization, monitoring, etc. in a data ecosystem.</li><li>You display strong coding skills in Python and Scala with a focus on maintainability, scale, and automation.</li><li>You love to work autonomously and take on unconstrained problems.</li><li>You can drive a vision, estimate the associated tasks and plan from development to delivery.</li><li>You take pride in sharing and gathering knowledge through documentation, advocacy and getting soaked in stakeholders use cases.</li></ul><p><strong>What will you do?</strong></p><ul><li>Build frameworks, libraries, and abstractions to enable easy and reliable data processing, ingestion and exposition</li><li>Automate data pipeline and services deployment and configuration management</li><li>Support, manage and handle operations on cloud-based data technologies (e.g., clusters, serverless applications, APIs, databases)</li><li>Monitor the health of the data platform through automation</li><li>Handle periodic on-call rotations</li><li>Allow data engineering and data science to execute their pipelines through workflow management</li></ul><p><strong>What will be your challenges?</strong></p><ul><li>Build the next generation of our data platform using open source big data technologies such as Kafka, Kafka Streams, Airflow, Spark, Metacat and Kubernetes</li><li>Enable data scientists to test and productionize various ML models to enhance the performance of our marketplace</li><li>Craft robust infrastructure foundations to support API-based data access including finatra microservices and AWS Lambda functions</li><li>Support, manage and handle operations on our MPP databases (Redshift, Presto)</li><li>Design change data capture from PostgreSQL databases to feed the data lake</li><li>Simplify data integration with Apache Gobblin</li><li>Enable dataset discovery, metadata exploration, and change notification</li><li>Unlock acceptance testing with Airflow, Spark, and Cucumber</li></ul><p><strong>What's next?</strong></p><p>If your application is selected, the process will be composed of 4 steps:</p><ol><li>Non-technical interview with the Engineering Manager of your potential team (1h30)</li><li>Take home assignment (~5 days deadline)</li><li>Interview with your future teammates (1h)</li><li>Day on site (Paris) to meet your future stakeholders</li></ol><p>Check out our<a href='https://eng.heetch.com/' rel='nofollow'>&nbsp;Engineering Blog</a>&nbsp;and follow our&nbsp;<a href='https://twitter.com/heetcheng' rel='nofollow'>twitter</a>&nbsp;:) You can also have a look at our open-source projects and contributions&nbsp;<a href='https://oss.heetch.com/' rel='nofollow'>here</a></p>                </div>            <div>        <a href='https://jobs.lever.co/heetch/707af0c6-48ff-4426-8caa-5faa8ef9e9ae?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Heetch</h4>            <div><p>Heetch is a mobility app with a simple mission: We want people to enjoy going out.<br>Every night and every day, our drivers are doing their best to make their rides unforgettable and friendly! We are focused on young people's expectations and are competing within a fast-paced market.</p><p>The service launched in Paris in September 2013 has been growing ever since, with thousands of daily rides in France, Belgium, and Morocco. With more than 1 million users in Europe, we are proud to be one of the fastest growing French startups!</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Full remote and flexible ways of working</span>                            </li>                            <li>                                <span></span>                                <span>Paid conferences attendance/travel</span>                            </li>                            <li>                                <span></span>                                <span>Code Retreat</span>                            </li>                            <li>                                <span></span>                                <span>2 company seminars</span>                            </li>                            <li>                                <span></span>                                <span>Travel budget to visit your co-workers</span>                            </li>                            <li>                                <span></span>                                <span>Heetch Credits</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LYttcGq0Rt6k-sZD90LnTQ",
    "url": "https://jobmote.com/job/66472/remote-python-data-engineer/",
    "title": "Remote Python Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/10",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 401000,
      "maxValue": 401000,
      "info": "",
      "unit": "DAY",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 401k /Day"
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:36 PM",
    "validThrough": "Aug 31, 2019 10:07:36 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>AWS, Kinesis, Lambda, Snowflake, Python 3.6/3.7, S3, Data Management, Data Ingestion, Data Processing, IOT<br><br>If you are a Remote Python Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>Previous experience providing robust and reliable data management techniques; massaging, optimizations for aggregating/reading performantly.<br>Familiar with developing solutions that scale to meet scenarios of high-velocity data ingestion and processing.<br>Be a core player in collaborations with the team(s) to identify new and useful ways to package and present data to clients<br>A deep understanding of distributed programming concepts and are able to identify the patterns necessary for a scalable, robust, and reliable service.<br>Ability to reason about performance benefits and tradeoffs in software and infrastructure design decisions as they relate to preventing data loss and recovering from failure.<br>Comfortable with contributing to a collaborative development environment both within the team and across the organization. We are true full stack since we are from silicon to the cloud, so there are several teams with which to interact and collaborate.<br>Create and communicate tests that need to exist to prevent regressions and find performance bottlenecks.<br>Know what metrics need to be created or monitored to alert on abnormal operation and to aid in capacity/scale planning.<br>Desire to automate processes to keep the team moving efficiently and safely.<br><br>Tech Stack:<br><br>Modern Python (3.6/3.7) and Go<br>AWS primitives for an event based architecture<br>CI/CD, automation for infrastructure and code, and observability/instrumentation are first class citizens<br><br>What's In It for You<br><br>Full Remote! <br>Monthly hack days<br>Health, Dental, and Vision benefits<br>21 days PTO + separate sick day quota<br>401K plan<br>Amazingly talented team!So, if you are a Remote Python Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "uDjEPJNdS_KRStI5DzcJBw",
    "url": "https://jobmote.com/job/66466/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:36 PM",
    "validThrough": "Aug 31, 2019 10:07:36 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ckaBQ6BGTC6kpevAkIJVUA",
    "url": "https://jobmote.com/job/66450/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:35 PM",
    "validThrough": "Aug 31, 2019 10:07:35 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0HPnOrrvSQ6mLCho93p6aw",
    "url": "https://jobmote.com/job/66449/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:35 PM",
    "validThrough": "Aug 31, 2019 10:07:35 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xXyA0yeoTMGWh0yus9689g",
    "url": "https://remoteok.io/jobs/74767",
    "title": "Data Engineer Attribution",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Security Scorecard - We are revolutionizing the cybersecurity industry",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 8:00:40 PM",
    "validThrough": "Sep 4, 2019 8:00:40 PM",
    "crawled": "Aug 28, 2019 8:30:29 PM",
    "content": "<span></span> <span><h4>Security Scorecard - We are revolutionizing the cybersecurity industry</h4></span> <br> <h3>Data Engineer Attribution</h3> <div>  <div>   \\nAbout The Role\\n\\nThe Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.\\n\\n&nbsp;Requirements:\\n\\n\\n* 3+ years of experience with:\\n\\n\\n* Scala or Python, both preferred\\n\\n* Distributed systems (e.g. Spark, Hadoop)\\n\\n\\n\\n\\n\\n* Database systems (e.g. Postgres, MySQL)\\n\\n* Experience with the following is preferred:\\n\\n\\n* IP (v4/v6) allocation and addressing conventions\\n\\n* DNS conventions and best practices\\n\\n* Anti-abuse investigations\\n\\n\\n\\n\\n\\n* Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)\\n\\n\\n\\n\\nTraits\\n\\n\\n* Comfortable working as part of a distributed team\\n\\n* Excellent communication and teamwork skills\\n\\n* Ability to make data driven decisions\\n\\n* Ability to do independent research\\n\\n\\n\\n\\nInterview Process\\n\\n\\n* Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.\\n\\n* Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.\\n\\n* 1-2 technical interviews with data engineer and data science team members via video or in person. 1-1.5 hours for both.\\n\\n* Final meeting with engineering leadership via video or in person. 1 hour.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "sKKzedE6RSy9unM7O3LTXw",
    "url": "http://workinstartups.com/job-board/job/83721/go-backend-developer-london-uk-at-tabeo/",
    "title": "Go Backend Developer - London, UK",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/9",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=9, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "Tabeo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 1:38:04 PM",
    "validThrough": "Aug 30, 2019 1:38:04 PM",
    "crawled": "Aug 28, 2019 2:06:35 PM",
    "content": "<p>About Tabeo</p><br /><p>Our mission is to make healthcare more accessible and affordable. Tabeo builds payments and business tools for medical professionals. We&rsquo;re helping independent dental practices and large hospital groups create new, digital patient experiences.</p><br /><p>In the last 12 months, we&rsquo;ve grown the number of our partners delivering care from 30 to 600 in the UK. Our team plans to expand its network to 2,000 in the next 12 months. By December, our revenue will be 50x higher than for the same period last year.&nbsp;</p><br /><p><br />What will you do</p><br /><p>You will work on important parts of our back-end. This will include (but not limited to) our TabeoSprint CQRS/ES architecture framework as well as several microservices that utilise it. Your input will be valuable to enhancing and improving the framework and existing microservices as well as designing and developing new microservices.</p><br /><p>You will wear many hats, have lots of challenges, and if you're the type that loves grokking and learning on a dime, then you'll love the scope of what you can contribute to on a daily basis. You will be expected to come up with great ideas to push our code to the next level and we&rsquo;ll give you the opportunity to do so.</p><br /><p>You&rsquo;ll work closely with</p><br /><p>Hisham, Marcin and Peter. You will be expected to be based and work in the office in London with Hisham who will introduce you to the existing codebase.</p><br /><p><br />How we work</p><br /><p>We&rsquo;re using agile methodology through SCRUM based on 2 week sprints. Our team is completely international and so at work we speak only English. Our team is also partly distributed so you must be comfortable working with remote colleagues.</p><br /><p>How you&rsquo;ll fit in</p><br /><p>You have 2-4 years of programming experience in at least one popular programming language.<br />You have experience working with Go or willing to learn it.<br />You are familiar with cloud services (GCP, AWS).<br />You know how to use Docker.<br />You know how to use Git.<br />You have a good understanding of SQL.<br />You have good experience creating RESTful APIs.<br />You know design patterns.<br />You&rsquo;re a quick learner.<br />You speak and write good English.<br />You&lsquo;re a team player with a good sense of humour.<br />You love researching new topics and ways of doing things.<br />You love passing on your knowledge to your colleagues.</p><br /><p>Our stack that you&rsquo;ll be working with</p><br /><p>Go<br />Google Cloud Platform<br />Docker<br />Kubernetes<br />PostgreSQL<br />Apache Kafka<br />... and many others</p><br /><p><br />What we offer</p><br /><p>Competitive salary (based on experience)<br />Work with awesome people<br />Competitive vacation policy<br />Flexible working, at home, away or in office<br />Private health insurance<br />Life insurance and disability benefits<br />Regular team events<br />Free coffee, drinks, fruits, muesli and snacks<br />&pound;2,000 budget per year for your personal development<br />Start date: next 3 months</p><br /><p>If you&rsquo;re interested, please send us an email to jobs@tabeo.co.uk with your CV and a short intro.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "b6C0XpRfQ_a076vGnkVjoQ",
    "url": "https://jobmote.com/job/66369/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GLnmbS2cT9CqGMen4J0Cug",
    "url": "https://jobmote.com/job/66368/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "A2ckNrvERiqqF8Gdbs_L1g",
    "url": "https://jobmote.com/job/66367/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "7F38o8pqRnmtFqBs-OI5KQ",
    "url": "https://jobmote.com/job/66366/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZJXg6zEfRZuLEC_Kjm_GeQ",
    "url": "https://remoteok.io/jobs/74747",
    "title": "Senior Data Engineer",
    "tags": [
      "DBG:surround``2N(remot,work) 3W OR(encourag, avail, environ)",
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "50% remote",
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 11:03:34 PM",
    "validThrough": "Sep 3, 2019 11:03:34 PM",
    "crawled": "Aug 27, 2019 11:30:30 PM",
    "content": "<span></span> <span><h4>Creative Commons</h4></span> <br> <h3>Senior Data Engineer</h3> <span></span> <span>verified</span> <br> <span>From Pacific time zones to Eastern time zones</span> <div>  <div>   \\nCreative Commons is building a “front door” to the growing universe of openly licensed and public domain content through CC Search and the CC Catalog API. The Senior Data Engineer reports to the Director of Engineering and is responsible for CC Catalog, the open source catalog that powers those products. This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners.\\n\\n**Diversity &amp; inclusion**\\n\\nWe believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.\\n\\n**Work environment and location**\\n\\nCreative Commons is a fully-distributed organization - we have no central office. This position is available to applicants working in the range of the Eastern to Pacific time zones, in a remote working environment. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.\\n\\n\\n\\n# Responsibilities\\n **Primary responsibilities**\\nArchitect, build, and maintain the existing CC Catalog, including:\\n* Ingesting content from new and existing sources of CC-licensed and public domain works.\\n* Scaling the catalog to support billions of records and various media types.\\n* Implementing resilient, distributed data solutions that operate robustly at web scale.\\n* Automating data pipelines and workflows.\\n* Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.\\n\\nAugment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.\\n\\nBuild an open source community around the CC Catalog, including:\\n* Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.\\n* Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor. \\n* Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.\\n\\nCollaborate with other outside communities, companies, and institutions to further Creative Commons’ mission. \\n\\n# Requirements\\n\\n* Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization\\n* Proficiency with Python\\n* Proficiency with Apache Spark\\n* Experience with cloud computing platforms such as AWS\\n* Experience with Apache Airflow or other workflow management software\\n* Experience with machine learning or interest in picking it up\\n* Fluent in English\\n* Excellent written and verbal communication skills\\n* Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure\\n* Curiosity and a desire to keep learning\\n* Commitment to consumer privacy and security\\n\\nNice to have (but not required):\\n* Experience with contributing to or maintaining open source software\\n* Experience with web crawling\\n* Experience with Docker\\n \\n\\n#Salary\\n100000 -120000\\n \\n\\n#Location\\n- From Pacific time zones to Eastern time zones   <br>  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pzqZKamwQMGx7bkZQ4tIXA",
    "url": "https://remote.co/job/senior-data-analyst-2/",
    "title": "Senior Data Analyst",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:vba/dotnet/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=0, go=3, nodejs=1, bigdata-ml=50, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Bill.com",
      "sameAs": "https://www.bill.com/"
    },
    "salary": {
      "currency": "USD",
      "minValue": 25,
      "maxValue": 50,
      "info": "",
      "unit": "HOUR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 25 - 50 /Hour"
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 6:58:25 PM",
    "validThrough": "Sep 3, 2019 6:58:25 PM",
    "crawled": "Aug 27, 2019 7:31:37 PM",
    "content": "<h3>Senior Data Analyst at <span>Bill.com</span></h3><div><span><i></i> Remote</span>         | <span> Freelance </span></div><div>            <ul><li><strong>(Contract / Remote)</strong></li><li><strong>REMOTE-USA</strong></li><li><strong>PRODUCT &amp; UX – PRODUCT MANAGEMENT</strong></li><li><strong>TEMPORARY / CONTRACTOR</strong></li></ul><p><strong>About Bill.com</strong></p><p>Bill.com is a leader in financial process automation for small businesses and mid-size companies. Making it simple to connect and do business, the Bill.com Back Office Cloud digitizes, automates and simplifies legacy payment and financial processes. With an integrated, end-to-end platform, Bill.com leverages artificial intelligence to reduce manual work, and provides a cloud workspace to help run your business anytime, anywhere. The company partners with many of the largest U.S. financial institutions, more than 70% of the top 100 U.S. accounting firms, and major accounting software providers. Bill.com manages more than $70B in annual payment volume across ACH, virtual cards, checks, and international payments. The company has offices in Palo Alto, California and Houston, Texas.</p><p><strong>Mission:</strong></p><p>The Sr. Growth Analyst reports into the growth team with responsibilities around coming up with data-driven insights, helping develop hypotheses, and measuring experiments. Part of this role is tactical; you’ll be responsible for finding data and putting it into a reportable format for the team. The other part is strategic; you’ll be a thought partner in establishing the direction for our experimentation. Additionally, this role supports the product organization, so finding and reporting on product performance will be an important part of this job.</p><p><strong>This is a remote, contract role. Pay rate is $25 – $50 per hour dependent on experience and location.</strong></p><p><strong>Responsibilities:</strong></p><ul><li>Data discovery: You’ll be responsible for finding the data we need to evaluate product performance. This data spans our analytics tools, CRM databases, backend databases, and support tools.</li><li>Analysis: You’ll identify, analyze, and interpret trends or patterns in complex data sets</li><li>Document: You’ll fill in our documentation gaps as you discover missing documentation around data sources, column descriptions, etc.</li><li>Thought partner: You’ll use your insights to help provide direction for our growth strategy.</li></ul><p><strong>Professional Experience/Background to be successful in this role:</strong></p><ul><li>Experienced: You have experience finding data and producing reports. Lots of it. And you enjoy the technical challenges of getting the data. SQL is a second language for you. You can debate the merits of Excel’s more esoteric functions. You have a minimum of 5 years of experience in a related field.</li><li>Curious: But you are also relentlessly inquisitive about the data. Creating a report inspires new questions that you itch to answer. For you, there’s always another question that leads to another insight. You love getting caught in this cycle.</li><li>Careful: You know how easy it is for data to mislead you so you’ve developed an instinct for double-checking and triangulating against suspicious results.</li><li>Communication: You are an excellent communicator, both verbally and in written form. You can make an analytical argument, and you can present complex data in an understandable way.</li><li><strong>Bachelor’s Degree:</strong>&nbsp;<strong>Relevant subjects include statistics, economics, data science, computer science, business.</strong></li></ul><p><strong>Extra points if you…</strong></p><ul><li>Stats: Have experience with R and multivariate regressions</li><li>Data Science: Have spent time with Matlab / Octave</li><li>Data pipeline experience: Have experience moving data around (e.g., ETL) and auditing data pipelines.</li><li>Programming: Have a working knowledge of Python, VBA, or Javascript.</li><li><strong>Masters Degree:</strong>&nbsp;<strong>Have a masters degree in statistics, data science, computer science, or business.</strong></li></ul><p><strong>Expected Outcomes in 3 months:</strong></p><ul><li>Learn Bill.com’s data models. Become fluent with our schemas. Understand our analytics tools. Know where to go to get the data we need.</li><li>Build high-level reports for each of our growth metrics (e.g., acquisition, activation, retention, etc).</li><li>Run 5-10 drill-down analyses in key areas.</li><li>Contribute meaningfully in discussions around growth hypotheses.</li></ul><p><strong>Outcomes expected in 6 months:</strong></p><ul><li>Become a data authority for at least one analytics area (e.g., activation).</li><li>Actively propose data-driven growth hypotheses on an ongoing basis</li></ul><p><strong>Bill.com Culture:</strong></p><ul><li>Humble – No ego</li><li>Fun – Celebrate the moments</li><li>Authentic – We are who we are</li><li>Passionate – Love what you do</li><li>Dedicated – To each other and the customer</li></ul>        </div><div>        <a href='https://jobs.lever.co/bill/98e7f172-4b47-48f1-abad-ae4ff791d30b' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IYSgzebBRH-5gzzz-m5ISw",
    "url": "https://remote.co/job/software-engineer-computer-vision/",
    "title": "Software Engineer, Computer Vision",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/32",
      "DBG_TECH1:k/t/w:cuda/bigdata-ml/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:opencv/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=12, other=0, dotnet=0, c=13, mobile=0, go=0, nodejs=0, bigdata-ml=67, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/West"
    ],
    "tagsNames1": [
      "US Pacific time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Williams-Sonoma",
      "sameAs": "https://www.williams-sonomainc.com"
    },
    "salary": {
      "currency": "USD",
      "minValue": 12,
      "maxValue": 16,
      "info": "",
      "unit": "WEEK",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 12 - 16 /Week"
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 5:38:25 PM",
    "validThrough": "Sep 3, 2019 5:38:25 PM",
    "crawled": "Aug 27, 2019 6:24:08 PM",
    "content": "<h3>Software Engineer, Computer Vision at <span>Williams-Sonoma</span></h3><div><span><i></i> Remote</span>         | <span> Entry-level </span> | <span> Freelance </span> | <span> Part-time </span></div><div>            <p><strong>Requisition Number:</strong> SS-16507<br><strong>Area of Interest:</strong> Information Technology<br><strong>Organization:</strong> Corporate<br><strong>Brand/Division:</strong> Shared Services<br><strong>Position Type: Part-time</strong></p><p><strong>JOB DESCRIPTION</strong><br><strong>Location: San Jose, CA (Non-California Residents can work Remote from anywhere within the United States)</strong></p><p><strong>Terms: 12-16-week contract on a Williams-Sonoma, Inc. W2 (Non-exempt)</strong></p><p><strong>Hours:</strong><br>Monday — Friday; 20-hours max per week (part-time)<br><strong>Work hours: anytime between 8 AM — 7 PM Pacific Time; up to 8 paid hours max per day; 20 paid hours max per week</strong></p><p><strong>About Outward, Inc.</strong><br>Outward, Inc. HQ is based in San Jose, CA and is a wholly-owned subsidiary of Williams Sonoma, Inc.</p><p>At Outward Inc. our vision is to ‘lower the friction’ with regards to all aspects of the customer journey for our parent company and our retail customers. We do this by offering new technology solutions that enable new experiences and top-notch visualizations of their products. We are continuously pushing the boundaries of how 3D and AR/ VR technologies will drive the next generation shopping experience. Through our portfolio of premium lifestyle brands — our mission is to deepen consumer connections with the products that matter and deliver an innovative experience.</p><p><strong>Summary:</strong><br>We’re looking for talented software engineer to work part-time (20-hours max per week) for our applied Research &amp; Development Group located in San Jose, CA. The best candidate will assist us in making new visual experiences through research and software engineering. The R&amp;D group works on problems in imaging, computer vision, graphics, and machine learning. Some areas of interest are:</p><ul><li>Computer Vision: multiple view geometry, point cloud reconstruction</li><li>Deep Learning</li><li>Physically based rendering, global illumination</li><li>Graphics pipelines</li><li>Machine learning, DNNs</li></ul><p><strong>REQUIREMENTS AND QUALIFICATIONS</strong><br><strong>We will like to meet you because…</strong></p><ul><li><strong>You have a BSc Degree in CS, EE, Applied Math or similar field</strong></li><li>You have skills in design and implementation of algorithms</li><li>You have strong software engineering skills in Python or C++</li><li>You have experience with scientific libraries such as NumPy, scikit-learn, image manipulation libraries like OpenCV, Machine learning frameworks like Tensorflow, PyTorch</li><li>You have strong communication skills</li><li>You have GPGPU programming knowledge – OpenGL, CUDA, etc.</li><li>You have practical experience with modern CNN architectures</li></ul><p><strong>Estimated Start date(s) &amp; additional Information:</strong><br>September 9, 2019 (or sooner) through December 20, 2019 (up to 16-weeks max)<br>If you work more than 5-hours per day, you are required by the state of California to take a 30-minute lunch break</p><p>This position Will Not offer Visa Sponsorship or relocation assistance.</p><p>Outward, Inc. is an Equal Opportunity Employer.<br>Outward, Inc. will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the California Fair Employment Act (AB 1008), or other applicable state or local laws and ordinances.</p><p>Williams-Sonoma, Inc. is an Equal Opportunity Employer.</p><p>Williams-Sonoma, Inc. will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance, or other applicable state or local laws and ordinances.</p>        </div><div>        <a href='https://careers.williams-sonomainc.com/williams-sonoma-inc/job/San-Jose-Temporary-Software-Engineer-Computer-Vision-(Outward,-Inc_)-CA-95101/586135500/?&amp;utm_source=remote.co' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "K-VUBdWkT2G7v68W7C2QyA",
    "url": "https://jobmote.com/job/66196/senior-data-etl-engineer-remote/",
    "title": "Senior Data ETL Engineer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jersey/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 26, 2019 10:07:37 PM",
    "validThrough": "Aug 29, 2019 10:07:37 PM",
    "crawled": "Aug 27, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>SQL, AWS, ETL<br><br>We are one of the most successful technology start-ups in the Philadelphia/New Jersey region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. <br><br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.<br><br>We need a Senior ETL Data Engineer to help us transform how consumers interact with real estate data.<br><br>What You Will Be Doing<br><br>- Recommend and implement data processing tools and technologies<br>- Extract, transform and load data pipelines from end to end<br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info<br>- Create, develop and document data mapping rules from multiple sources<br>- Develop continuous process movements<br><br>What You Need for this Position<br><br>- 5+ yrs experience<br>- ETL<br>- SQL / PostgreSQL<br>- AWS<br>- BSCS or related degree<br><br>What's In It for You<br><br>- Competitive Pay<br>- FULL REMOTE!So if you are a Senior Data ETL Engineer with relevant experience, please apply today! Interviews are occurring this week!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YbCzoZaUQUO2fR9wD0f8zw",
    "url": "https://jobmote.com/job/66173/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 26, 2019 10:07:37 PM",
    "validThrough": "Aug 29, 2019 10:07:37 PM",
    "crawled": "Aug 27, 2019 3:06:24 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XSMpkAVyQXi6w4-b20XjLg",
    "url": "https://jobmote.com/job/65021/aws-big-data-cloud-engineer-remote-flexibility-philadelphia/",
    "title": "AWS Big Data Cloud Engineer - Remote Flexibility - Philadelphia",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b>AWS Big Data Cloud Engineer - REMOTE FLEXIBILITY - Philadelphia - Full Time - Negotiable Salary</b><br><br>My client is an AWS advanced consulting partner that is certified in big data, machine learning, artificial intelligence, education competencies, and DevOps. They are a U.S. based company that is in the process of building out their Canadian team, so the opportunity to grow into a directing position is now! In this role, you will be designing big data, mobile, and web solutions for premier brands worldwide. As well as, providing valuable insights and solutions to customers based on their needs and requirements.<br> They are offering a competitive base salary, performance based bonuses, the opportunity to work with the latest technologies and tooling's of your choice, and the ability to learn and grow directly from former Amazon Directors!<br> The ideal candidate for this role is some who has strong cloud computing experience on AWS, willing to travel, and has great people skills.<br><br><b>Qualifications/Requirements</b>:<ul><li>Demonstrated hands on experience in building Distributed Big Data Solutions (ingesting, processing, caching, logging, monitoring)</li><li>Strong development experience in Big Data processing engines (preference: Spark on EMR)</li><li>Demonstrated expertise in Cloud Computing on AWS (EC2, EMR, Redshift, Data Pipeline)</li><li>Expertise in NoSQL and SQL</li><li>Strong experience in altering ETL processes</li><li>Strong written and oral communication skills</li><li>Ability to travel up to 50%</li><li>Ability to meet tight deadlines in high pressured environments</li></ul><b>Benefits</b>:<ul><li>Competitive Base Salary</li><li>Performance based bonuses</li><li>REMOTE FLEXIBILITY</li><li>Ability to work with the latest technologies of your choice</li><li>Clear opportunities to grow</li><li>Learn side by side from former AWS Directors</li><li>Ability to receive AWS Certifications</li><li>Never focused on one technology or tooling</li><li>Excellent company culture</li><li>Premium Healthcare</li><li>UNLIMITED PTO</li><li>Transportation Reimbursement</li><li>FAST HIRING PROCESS</li></ul> Interviews are now underway and the process is moving extremely fast! If you or someone you may know could be interested in this opportunity APPLY NOW! For guaranteed IMMEDIATE consideration!<br> To apply, contact me via email: [Click Here to Email Your Resum?] ; phone: (212)- ; or LinkedIn message. Upon conversation, please be able to provide an updated CV.<br> Jefferson Frank is the global leader in Amazon Web Services recruiting. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.<br> At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Wwra45h_QzqVF5O1meBe0g",
    "url": "https://jobmote.com/job/64989/hadoop-developer-remote/",
    "title": "Hadoop Developer - REMOTE",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:k/t/w:mahout/java/5",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Skiltrek LLC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b> ****Location: Jacksonville Beach FL or Remote**** </b><br><br><b> Job Title: Hadoop Developer </b><br><br><b> Long Term Contract ? 12 months + </b><b><br><br><b> W2 only - (No C2C) </b></b><br><br><b> Sign On Bonus! </b><br><br><b>Work Auth: USC / GC / GC EAD only</b><br><br><b> ****Location: Jacksonville Beach FL or Remote**** </b><b><br><br><b> Change your lifestyle move near the beach! Jacksonville voted in the top 3 most affordable cities in the US! Cost of living calculator: </b></b><br><br><b> Job Description: </b><br> We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.<br><br><b> Responsibilities </b><br><br>? Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities<br> ? Implementing ETL process using APACHE NIFI<br> ? Monitoring performance and advising any necessary infrastructure changes<br> ? Defining data retention policies<br> ? Proficient with Spark and SparkR.<br><br><b> Skills and Qualifications: </b><br> ? Proficient understanding of distributed computing principles.<br> ? Proficiency with ETL infrastructure such as Nifi, Talend.<br> ? Management of Hadoop cluster, with all included services such as Hive,HBase,mapReduce and Sqoop<br> ? Ability to solve any ongoing issues with operating the cluster and identifying performance bottlenecks.<br> ? Proficiency with Hadoop v2, MapReduce, HDFS<br> ? Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.<br> ? Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala<br> ? Experience with Spark and SparkR<br> ? Experience with integration of data from multiple data sources<br> ? Experience with NoSQL databases, such as HBase, Cassandra, MongoDB<br> ? Knowledge of various ETL techniques and frameworks, such as Flume<br> ? Experience with various messaging systems, such as Kafka.<br> ? Experience with Big Data Client toolkits, such as Mahout, SparkML, or H2O<br> ? Good understanding of Lambda Architecture, along with its advantages and drawbacks<br> ? Experience with Cloudera/MapR/Hortonworks</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tFvCNDPRTj-Qro-O4MLaFg",
    "url": "https://jobmote.com/job/64988/hadoop-developer-remote/",
    "title": "Hadoop Developer - REMOTE",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:k/t/w:mahout/java/5",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Skiltrek LLC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b> ****Location: Jacksonville Beach FL or Remote**** </b><br><br><b> Job Title: Hadoop Developer </b><br><br><b> Long Term Contract ? 12 months + </b><b><br><br><b> W2 only - (No C2C) </b></b><br><br><b> Sign On Bonus! </b><br><br><b>Work Auth: USC / GC / GC EAD only</b><br><br><b> ****Location: Jacksonville Beach FL or Remote**** </b><b><br><br><b> Change your lifestyle move near the beach! Jacksonville voted in the top 3 most affordable cities in the US! Cost of living calculator: </b></b><br><br><b> Job Description: </b><br> We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.<br><br><b> Responsibilities </b><br><br>? Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities<br> ? Implementing ETL process using APACHE NIFI<br> ? Monitoring performance and advising any necessary infrastructure changes<br> ? Defining data retention policies<br> ? Proficient with Spark and SparkR.<br><br><b> Skills and Qualifications: </b><br> ? Proficient understanding of distributed computing principles.<br> ? Proficiency with ETL infrastructure such as Nifi, Talend.<br> ? Management of Hadoop cluster, with all included services such as Hive,HBase,mapReduce and Sqoop<br> ? Ability to solve any ongoing issues with operating the cluster and identifying performance bottlenecks.<br> ? Proficiency with Hadoop v2, MapReduce, HDFS<br> ? Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.<br> ? Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala<br> ? Experience with Spark and SparkR<br> ? Experience with integration of data from multiple data sources<br> ? Experience with NoSQL databases, such as HBase, Cassandra, MongoDB<br> ? Knowledge of various ETL techniques and frameworks, such as Flume<br> ? Experience with various messaging systems, such as Kafka.<br> ? Experience with Big Data Client toolkits, such as Mahout, SparkML, or H2O<br> ? Good understanding of Lambda Architecture, along with its advantages and drawbacks<br> ? Experience with Cloudera/MapR/Hortonworks</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "jkHsHSW4QV-jv2E8YL5GFA",
    "url": "https://jobmote.com/job/64980/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:28 PM",
    "validThrough": "Aug 28, 2019 10:07:28 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rLmIy81lT96La8xNVHlEJg",
    "url": "https://remoteok.io/jobs/74708",
    "title": "Data Engineer Productionize Statistical Models",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SecurityScorecard",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 9:16:15 AM",
    "validThrough": "Sep 1, 2019 9:16:15 AM",
    "crawled": "Aug 25, 2019 10:06:28 AM",
    "content": "<span></span> <span><h4>SecurityScorecard</h4></span> <br> <h3>Data Engineer Productionize Statistical Models</h3> <div>  <div>   \\nAbout The Role\\n\\nThe Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.\\n\\nThis position is&nbsp;either in our HQ in NYC or remote in North America.\\n\\nTechnical Skills and Experience\\n\\n\\n* 3+ years of experience with:\\n\\n\\n* Scala or Python, both preferred\\n\\n* Distributed systems (e.g. Spark, Hadoop)\\n\\n\\n\\n\\n\\n* Database systems (e.g. Postgres, MySQL)\\n\\n* Experience with the following is preferred:\\n\\n\\n* IP (v4/v6) allocation and addressing conventions\\n\\n* DNS conventions and best practices\\n\\n* Anti-abuse investigations\\n\\n\\n\\n\\n\\n* Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)\\n\\n\\n\\n\\nTraits&nbsp;\\n\\n\\n* Comfortable working as part of a distributed team\\n\\n* Excellent communication and teamwork skills\\n\\n* Ability to make data driven decisions\\n\\n* Ability to do independent research\\n\\n\\n\\n\\nInterview Process\\n\\n\\n* Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.\\n\\n* Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.\\n\\n* 1-2 technical interviews with data engineer and data science team members via video or in person.&nbsp;45 minutes each.\\n\\n* Final meeting with engineering leadership via video or in person. 1 hour.\\n\\n\\n\\n\\n&nbsp;About SecurityScorecard\\n\\nAt SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.\\n\\nBacked by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Yka_Pd9GRvKhw0eJ5xtkyw",
    "url": "https://stackoverflow.com/jobs/290942/data-engineer-productionize-statistical-models-securityscorecard?a=1zzwjFzYHPyM",
    "title": "Data Engineer: productionize statistical models at SecurityScorecard (New York, NY) ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SecurityScorecard",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 4:06:24 AM",
    "validThrough": "Sep 1, 2019 4:06:24 AM",
    "crawled": "Aug 25, 2019 4:06:24 AM",
    "content": "<h3><span>Data Engineer: productionize statistical models</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Cybersecurity, SaaS</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: SecurityScorecard | New York, NY<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time +/- 4 hours</span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>New York, NY.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                    </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>postgresql</div><div>apache-spark</div><div>scala</div><div>networking</div>                <h4>Job description</h4>                <div><p><strong>About The Role</strong></p><p>The Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.</p><p>This position is&nbsp;either in our HQ in NYC or remote in North America.</p><p><strong>Technical Skills and Experience</strong></p><ul><li>3+ years of experience with:<ul><li>Scala or Python, both preferred</li><li>Distributed systems (e.g. Spark, Hadoop)</li></ul></li><li>Database systems (e.g. Postgres, MySQL)</li><li>Experience with the following is preferred:<ul><li>IP (v4/v6) allocation and addressing conventions</li><li>DNS conventions and best practices</li><li>Anti-abuse investigations</li></ul></li><li>Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)</li></ul><p><strong>Traits&nbsp;</strong></p><ul><li>Comfortable working as part of a distributed team</li><li>Excellent communication and teamwork skills</li><li>Ability to make data driven decisions</li><li>Ability to do independent research</li></ul><p><strong>Interview Process</strong></p><ul><li>Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.</li><li>Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.</li><li>1-2 technical interviews with data engineer and data science team members via video or in person.&nbsp;45 minutes each.</li><li>Final meeting with engineering leadership via video or in person. 1 hour.</li></ul><p>&nbsp;<strong>About SecurityScorecard</strong></p><p>At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.</p><p>Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.</p>                </div>            <div>        <a href='https://grnh.se/b15dc2e61' rel='nofollow'>                        Apply now        </a></div>            <h4>About SecurityScorecard</h4>            <div><p><strong>About SSC</strong></p><p>At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.</p><p>Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Unlimited PTO</span>                            </li>                            <li>                                <span></span>                                <span>Health Benefits Starting Day One</span>                            </li>                            <li>                                <span></span>                                <span>401k</span>                            </li>                            <li>                                <span></span>                                <span>Education Stipend</span>                            </li>                            <li>                                <span></span>                                <span>Learning and Development</span>                            </li>                            <li>                                <span></span>                                <span>Stocked Kitchen</span>                            </li>                            <li>                                <span></span>                                <span>Remote Work Options</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "mjoCf5KVSC-swz8w0TArwQ",
    "url": "https://jobmote.com/job/64940/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "yOsAdJokTdahVwR25TDVDQ",
    "url": "https://jobmote.com/job/64923/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "stBIIgNdQQC0CWsPJTsXsw",
    "url": "https://jobmote.com/job/64920/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "k-Q0W8eRRzSOYfWDuih8zg",
    "url": "https://jobmote.com/job/64919/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "QKvFNuG2QjW9eOrwebJuGQ",
    "url": "https://jobmote.com/job/64819/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 10:07:37 PM",
    "validThrough": "Aug 26, 2019 10:07:37 PM",
    "crawled": "Aug 24, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "iNstO8tSTcCfbhemy1whUg",
    "url": "https://stackoverflow.com/jobs/290839/senior-data-scientist-remote-global-wallethub?a=1zxnx6wxdfxu",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=84, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 6:23:00 PM",
    "validThrough": "Aug 30, 2019 6:23:00 PM",
    "crawled": "Aug 23, 2019 6:23:00 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div><div>artificial-intelligence</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>Although we appreciate your interest in working with us, due to the high number of applications we receive, we will only be able to respond to successful applicants.</strong></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/290839?reset=False&amp;ra=1zxnx6wxdfxu&amp;oqs=a%3D1zxnx6wxdfxu' rel='nofollow'>Apply now</a></div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-KlB0J-IQdm7qZdcc5AJqw",
    "url": "https://www.remoteage.com/remote-jobs/big-data-engineer-data-scientist/",
    "title": "Big Data Engineer/ Data Scientist",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=64, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Natsoft",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 11:06:59 AM",
    "validThrough": "Aug 30, 2019 11:06:59 AM",
    "crawled": "Aug 23, 2019 11:07:34 AM",
    "content": "<h3>            Big Data Engineer/ Data Scientist        </h3><div>United States, Indiana</div><div>Company: Natsoft<p></p></div><div>                    <h4>Overview</h4>                    <p>Greeting, </p><p></p><p>I represent Natsoft Corporation, a leading IT staffing organization. I am part of a team responsible for servicing a major client of ours that is a world leader in IT services.</p><p></p><p>Job Title<strong>: </strong><strong>Big Data Engineer/ Data Scientist</strong></p><p>Location: Dallas, TX </p><p>Duration : Long Term</p><p></p><p><strong>Experience in </strong>HDP/CDH Hadoop Admin, Data Scientist, Sqoop, Oozie, Hive, Pig Latin, Spark, Sql, Stored Procs, Hive, Impala</p><p></p><p>Let me know for any further information.</p><p><strong> </strong></p><p><strong> </strong></p><p><strong>Thanks &amp; Regards,</strong></p><p><strong>Amit</strong></p><p><strong>Sr.US IT Recruiter </strong></p><p>Natsoft Corporation | 27 Worlds Fair Dr,Somerset,NJ 08873</p><p>Phone: | Email: | |</p><p></p><p>NATSOFT CORPORATION is a certified Minority Business Enterprise (MBE) Global Software Consulting, Application Development, Staffing and Remote Infrastructure Company. MBE certified by the States of NJ, PA &amp; City of Houston.</p><p></p><p> – provided by Dice</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?%2fSJhHUD47wcM9lAoX82EPgg' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "BtbARtvtQemE9yBve-KGsQ",
    "url": "https://remoteok.io/jobs/74683",
    "title": "Software Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 5:00:46 AM",
    "validThrough": "Aug 30, 2019 5:00:46 AM",
    "crawled": "Aug 23, 2019 5:06:31 AM",
    "content": "<span></span> <span><h4>Rho AI</h4></span> <br> <h3>Software Engineer</h3> <div>  <div>   \\nRho AI’s data-driven products &amp; services are used in a wide range of industries,&nbsp;with a growing focus on sustainable systems (e.g. energy, water, climate,&nbsp;waste). We value pragmatic solutions and have cultivated a modern technology&nbsp;stack that combines software development (python microservices, react&nbsp;frontends), infrastructure automation (docker, kubernetes), and machine&nbsp;learning (scikit-learn, pytorch) into a developer-friendly CICD flow.\\n\\nAs a member of the software engineering team, you will:\\n\\n\\n* Develop products and services for advanced machine learning applications in interesting and important problem spaces.\\n\\n* Join a group of talented and congenial team members where you will be respected in your software design decisions and take ownership of the systems that you build.\\n\\n* Learn from and collaborate with senior engineers and co-founders.\\n\\n* Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.\\n\\n\\n\\n\\nSound interesting? We are hiring for a variety of experience levels, so all are welcome to apply. We are&nbsp; interested in hearing from candidates who have publicly available open-source and/or technical writing examples and are looking to&nbsp;take their next step in their professional careers.&nbsp; Please reach out if:\\n\\nYou have:\\n\\n\\n* (Must) Good communication skills for technical and non-technical audiences.\\n\\n* (Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.\\n\\n* (Must) Proficient on all backend layers - databases, services and APIs.\\n\\n* (Must) A collaborative attitude oriented around craftsmanship and team success.\\n\\n* (Should) An interest in systems thinking &amp; enjoy stitching components together.\\n\\n* (Should) Have experience working within a microservices oriented architecture.\\n\\n* (Nice) Built systems that process large amounts of data and/or traffic.\\n\\n* (Nice) Strong computer science principles, and/or algorithmic skills.\\n\\n* (Nice) Experience with machine learning applications.\\n\\n\\n\\n\\n&nbsp;You would like these perks:\\n\\n\\n* Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.\\n\\n* Work with a highly engaged team, learn together, and make decisions that impact the whole company.\\n\\n* Benefits, including health insurance and 401k.\\n\\n\\n\\n\\n&nbsp;You meet these criteria:\\n\\n\\n* You are seeking a full-time job.\\n\\n* You reside in the United States.\\n\\n* You are authorized / eligible to work for any company in the United States.\\n\\n* You are in a continental US time zone, or willing to align your schedule.\\n\\n\\n\\n\\nTo get an interview, you must supply:\\n\\n\\n* A cover letter that explains why you are 1) specifically interested in Rho AI as a company and 2) a good fit for this particular position.\\n\\n* A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "CizYbGStR8qwCgy03cHxyg",
    "url": "https://jobmote.com/job/64515/staff-software-engineer-backend-remote-sensing-raster-pipelines/",
    "title": "Staff Software Engineer, Backend (Remote Sensing / Raster Pipelines)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "The Climate Corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 10:07:32 PM",
    "validThrough": "Aug 25, 2019 10:07:32 PM",
    "crawled": "Aug 23, 2019 3:06:27 AM",
    "content": "<div>The Climate Corporation is revolutionizing the agriculture industry with a platform and products that are helping the world's farmers sustainably increase productivity with digital tools. As the industry leader, we're working to ensure we're the most connected platform in Agriculture. Through our partnerships, farmers can exchange data between the Climate FieldView™ platform and our partner connected solutions in just minutes. <br><br> We have an opportunity for a Staff Engineer position in our Geospatial Algorithms Engineering Group to work with a team of highly experienced computer vision and remote sensing software engineers to help us enhance and expand our satellite and drone imagery processing systems. We ingest, archive and process vast amounts of multi-spectral space-borne, air-borne, and unmanned imagery along with vector data that help our customers manage farming activities at a global scale. As a Staff Engineer in our team, you will be tasked with the design and implementation of high-performance satellite image processing systems and the operationalization of remote sensing algorithms. The core of this work is to expand our back-end capabilities and to build out systems to generate on-demand, analysis-ready datasets. Your contributions will help the team deliver high-quality, near-real-time actionable information to our customers and help them make data-driven decisions. If you are passionate about innovation and excited about helping us transform agriculture and develop a platform that helps farmers sustainably increase their productivity,. we would love to talk to you! <br><br><strong>What You Will Do:</strong> <ul><li>Benchmark, analyze, and deploy raster and vector based algorithms built on remotely sensed datasets</li><li>Drive the development of raster processing pipelines with a focus on data provenance, validation, traceability, and error propagation</li><li>Analyze system and product requirements to design optimal and scalable system architectures</li><li>Participate and support the verification and validation of production algorithms</li><li>Document architectural designs, changes, and configuration control processes</li><li>Perform technical risk management and mitigation.</li> <li>Coach and mentor junior team members in data-intensive system design.</li> <li>Drive collaboration and coordination of across-teams work</li><li>Improve our software engineering processes towards the continuous improvement of reliability, scalability, and maintainability of all our systems</li> </ul><strong>Basic Qualifications:</strong> <ul><li>At least 8 years of demonstrable experience in building highly-reliable production software systems.</li><li>Solid understanding of functional programming, object-oriented design, data structures, complexity analysis, design, verification, and validation techniques.</li><li>Solid understanding of computer science and computer vision fundamentals.</li> </ul><strong>Additional Preferred Qualifications:</strong> <ul><li>Experience working with AWS-based systems in production</li><li>Experience using Scrum best practices in software development projects</li><li>Experience writing reliable and maintainable code in Scala and/or Java</li><li>Experience in operationalizing algorithms at large scale against large data stores</li><li>Experience working with and contributing to the open source software community for geospatial software and analysis</li><li>Excellent leadership skills with high integrity, work ethics, humility, and self-awareness.</li><li>Excellent ability to present complex technical information in a clear and concise manner.</li><li>Ability to handle multiple, competing priorities in a fast-paced development environment.</li><li>Passion for computer vision, raster data processing, geospatial engineering, and derivation of information rich data products.</li> <li>Experience working with systems processing and manipulating petabytes of imagery data.</li> </ul><strong>What We Offer:</strong> <br><br> Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers. <br><br> We provide competitive salaries and some of the best perks in the industry, including: <ul><li>Superb medical, dental, vision, life, disability benefits, and a 401k matching program</li><li>A stocked kitchen with a large assortment of snacks &amp; drinks to get you through the day</li><li>Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used</li><li>We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hack-a-thons to encourage participation and growth in both community involvement and career development</li> </ul> We also hinge our cultural DNA on these five values: <ul><li>Inspire one another</li><li>Innovate in all we do</li><li>Leave a mark on the world</li><li>Find the possible in the impossible</li><li>Be direct and transparent</li> </ul> Learn more about our team and our mission: <br><br> The Climate Corporation - The Technology Behind Making A Difference <br><br> or visit <br><br><strong>As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. If you need assistance or accommodation due to a disability, you may contact us at</strong> <strong></strong> <br><br><strong>#LI-DR1</strong></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Am5IDqKoQpSK0lKCyuIFtg",
    "url": "http://workinstartups.com/job-board/job/83711/computer-vision-engineer-at-disperseio/",
    "title": "Computer Vision Engineer",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=88, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Disperse.io",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 50000,
      "maxValue": 65000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 50k - 65k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 10:26:40 PM",
    "validThrough": "Aug 29, 2019 10:26:40 PM",
    "crawled": "Aug 22, 2019 11:30:31 PM",
    "content": "<section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>DESCRIPTION</h2><br /><p><strong>About us</strong></p><br /><p>Disperse is a VC-backed artificial intelligence construction startup focused on improving on-site productivity with the help of computer vision. Our goal is to ultimately re-imagine the way building projects are planned, delivered and operated.</p><br /><p>We're currently working on some of the largest building projects in London (e.g. Renzo Piano&rsquo;s Shard Place, Wood Wharf) and have grown from 5 to 35 people over the past year. We have ambitions to expand significantly, which means that we are looking for passionate and enthusiastic talent to join the team.</p><br /><p>We move at a high speed, and will provide you with immense opportunities for initiative, creativity and leadership.&nbsp;<strong><a class=&quot;external&quot; href='https://workable.com/nr?l=http%3A%2F%2Fwww.disperse.io%2Fteam%2F' rel='nofollow noreferrer noopener'>Our proudly diverse, international team is based in London, Sarajevo and Yerevan</a></strong>, and has a wealth of experience from construction management to computer vision and robotics.</p><br /><p><strong>Your role</strong></p><br /><p>We are looking for a highly motivated and passionate Computer Vision Engineer to join our growing team. Someone who is excited at the prospect of applying deep knowledge and expertise to shape the future of the construction industry and to have a direct impact on productivity.</p><br /><p>As part of your role, you will collaborate with our Computer Vision scientists and the wider Engineering team to both use and craft state-of-the-art deep learning algorithms to creatively solve real-world problems in the construction sector. You will be given lots of responsibility, driving projects which could involve implementing cutting edge algorithms and integrating these into our workflows and core software.</p><br /><p>If you&rsquo;re eager to apply Computer Vision and Machine Learning to real-world problems and would like to work with a world-class team of researchers and engineers, this role is a superb opportunity for you.</p><br /><p><strong>Our culture</strong></p><br /><p>Ask anyone at Disperse what they love most about working here, and they'll probably tell you &quot;it's the people!&quot;, &quot;the team, of course&quot;, &quot;the people and the Hedwig owls in the offices&quot;.</p><br /><p>As clich&eacute;d as it may sound, we're very proud of the people we have and the close-knit, family culture we've built across London, Sarajevo and Yerevan. Despite the distances, we're united through the passion with which we approach our goals and the fun that we have along the way. We always look out for each other, no matter what. The following should give you a good idea what type of culture you'd be joining:</p><br /><ul><br /><li>We encourage proactivity and taking full ownership of problems and initiatives. We don't believe in micromanagement. Instead, we let you pave your own path and give you the space to continuously learn and grow even if it means taking a few detours.</li><br /><li>We support each other. If a process breaks or if you're struggling, you can always count on the people around you and the people far away from you, to help you get back on track.</li><br /><li>We run on feedback: direct and transparent praise and constructive criticism, communicated with the best of intentions. There is no other way to learn!</li><br /><li>Ideas and approaches are always judged on merit rather than source. We welcome discussions and challenges. This way everyone makes a tremendous impact no matter the role.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>REQUIREMENTS</h2><br /><p>You should apply if:</p><br /><ul><br /><li>You have a MSc degree or PhD in Machine Learning, Computer Vision, Computer Science, or a related quantitative field</li><br /></ul><br /><ul><br /><li>You have hands on experience using machine learning and computer vision.</li><br /><li>You have good coding skills in Python with experience using one of: Tensorflow, PyTorch, or similar.</li><br /><li>You have experience in managing projects with large datasets</li><br /><li>You have experience of working in an autonomous team</li><br /><li>You have strong communication skills - you can summarise the complex, liaise with your fellow Computer Vision engineers, and explain your work in simple terms to your other colleagues.</li><br /><li>You're a problem solver and analytical thinker; you don&rsquo;t accept the status quo and are always looking for creative solutions.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>BENEFITS</h2><br /><ul><br /><li>Pro rata salary of &pound;50,000 - &pound;65,000 per annum plus generous option package</li><br /><li>Friendly, open and transparent culture.</li><br /><li>You'll get to join a passionate startup with proven traction on its scaling journey.</li><br /><li>Flexible working hours / ability to work from home.</li><br /><li>Regular mentoring and feedback.</li><br /><li>Awesome start-up office in&nbsp;<a class=&quot;external&quot; href='https://workable.com/nr?l=https%3A%2F%2Fwww.theofficegroup.co.uk%2Foffice%2F2-stephen-street%2F' rel='nofollow noreferrer noopener'>Central London, Fitzrovia</a></li><br /><li>25 days' holiday plus all bank holidays.</li><br /><li>Free coffee.</li><br /><li>Regular socials and team retreats to exotic destinations (Tibilisi, Sarajevo,...Where next?)</li><br /></ul><br /><p>&nbsp;</p><br /><p><strong>The process</strong></p><br /><p>The interview process will involve:</p><br /><ol><br /><li>A review of your application;</li><br /><li>A 20-minute chat where we both can learn more about each other;</li><br /><li>Homework assignment for us to get a sense of how you tackle problems;</li><br /><li>Two rounds of on-site technical and cultural chats with the team. If you are not currently based in London, we would be happy to speak with you over video chat;</li><br /><li>Final round to iron out any remaining questions you may have.</li><br /></ol><br /><p>This process should take around two weeks, depending on diaries.</p><br /></section>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "e_kxDViWRgyjw76_5zGK7g",
    "url": "https://stackoverflow.com/jobs/290564/software-engineer-rho-ai?a=1zrF0Xcvrji0",
    "title": "Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/22",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=54, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 11:30:24 PM",
    "validThrough": "Aug 29, 2019 11:30:24 PM",
    "crawled": "Aug 22, 2019 11:30:24 PM",
    "content": "<h3><span>Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Rho AI | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>python</div><div>single-page-application</div><div>sql</div><div>nosql</div><div>docker</div>                <h4>Job description</h4>                <div><p>Rho AI’s data-driven products &amp; services are used in a wide range of industries,&nbsp;with a growing focus on sustainable systems (e.g. energy, water, climate,&nbsp;waste). We value pragmatic solutions and have cultivated a modern technology&nbsp;stack that combines software development (python microservices, react&nbsp;frontends), infrastructure automation (docker, kubernetes), and machine&nbsp;learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p><p>As a member of the software engineering team, you will:</p><ul><li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li><li>Join a group of talented and congenial team members where you will be respected in your software design decisions and take ownership of the systems that you build.</li><li>Learn from and collaborate with senior engineers and co-founders.</li><li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li></ul><p>Sound interesting? We are hiring for a variety of experience levels, so all are welcome to apply. We are&nbsp; interested in hearing from candidates who have publicly available open-source and/or technical writing examples and are looking to&nbsp;take their next step in their professional careers.&nbsp; Please reach out if:</p><p><strong>You have:</strong></p><ul><li>(Must) Good communication skills for technical and non-technical audiences.</li><li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li><li>(Must) Proficient on all backend layers - databases, services and APIs.</li><li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li><li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li><li>(Should) Have experience working within a microservices oriented architecture.</li><li>(Nice) Built systems that process large amounts of data and/or traffic.</li><li>(Nice) Strong computer science principles, and/or algorithmic skills.</li><li>(Nice) Experience with machine learning applications.</li></ul><p>&nbsp;<strong>You would like these perks:</strong></p><ul><li>Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.</li><li>Work with a highly engaged team, learn together, and make decisions that impact the whole company.</li><li>Benefits, including health insurance and 401k.</li></ul><p>&nbsp;<strong>You meet these criteria:</strong></p><ul><li>You are seeking a full-time job.</li><li>You reside in the United States.</li><li>You are authorized / eligible to work for any company in the United States.</li><li>You are in a continental US time zone, or willing to align your schedule.</li></ul><p><strong>To get an interview, you must supply:</strong></p><ul><li>A cover letter that explains why you are 1) <em>specifically interested</em> in Rho AI as a company and 2) a <em>good fit</em> for this particular position.</li><li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/290564?reset=False&amp;ra=1zrF0Xcvrji0&amp;oqs=a%3D1zrF0Xcvrji0' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Rho AI</h4>            <div><p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p><p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p><p><strong>Work at Rho AI</strong></p><p>Rho AI is a remote-first organization, where you will work with a talented group of data scientists, engineers and thought leaders&nbsp;to harness the power of data science to propel projects with a positive world impact. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p><p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ugYHfLiiRC284ohrXYVVIA",
    "url": "https://www.remoteage.com/remote-jobs/data-lead-software-developer-remote-considered-3/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 9:22:37 AM",
    "validThrough": "Aug 29, 2019 9:22:37 AM",
    "crawled": "Aug 22, 2019 10:07:24 AM",
    "content": "<h3>            Data Lead Software Developer-remote considered        </h3><div>United States, Connecticut</div><div>Company: Travelers Insurance<p></p></div><div>                    <h4>Overview</h4>                    <p>Company Information<br>Solid reputation, passionate people and endless opportunities. That’s Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers – and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br></p><ul> <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul> <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others’ views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p><p></p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?Epk0ZMC5PtRX7kTbNMCTdAz' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MaY0cOzlS9ipKYJcwvNTCg",
    "url": "https://remote.co/job/chatbot-a-i-developer/",
    "title": "Chatbot A.I. Developer",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR( australia, japan, newzealand)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(europ, european, europeanunion)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Asia"
    ],
    "tagsNames1": [
      "Asia time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Day Translations",
      "sameAs": "https://www.daytranslations.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 21, 2019 6:30:55 PM",
    "validThrough": "Aug 28, 2019 6:30:55 PM",
    "crawled": "Aug 21, 2019 7:31:22 PM",
    "content": "<h3>Chatbot A.I. Developer at <span>Day Translations</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>Category:</strong>&nbsp;<strong>Software Development<br>Job Type: Full-Time</strong></p><p>Day Translations is a global translation and interpreting company. We help improve worldwide communication through accurate, localized translations, interpretation and outsourcing services, and a wide variety of tailored language solutions for individuals, organizations, and businesses of all sizes.</p><p><strong>About the Chatbot AI developer position</strong></p><p><strong>Location</strong>:<strong>&nbsp;Remote (America, Europe, Middle East, Australia, and Asia)</strong></p><p><strong>Reports to</strong>: DevOps Manager</p><p>Day Translations seeks a qualified Chatbot AI developer. This position provides a great opportunity for an individual who has knowledge and experience working with Chatbot AI-enabled implementations. Day Translations is on a journey to transform its technology landscape from an older to newer, cutting edge conversational bot. We are looking for a Developer who can build bot which communicates clearly in multiple languages and in a more human approach with users in creative ways. Unlike the traditional bots being just concentrated on the business services, it should communicate by understanding the context through NLP or other good approaches.</p><p>You will code, test, and debug new and existing implementations. If you enjoy the challenge of working in a fast-paced, dynamic environment and have a passion for software development and engineering, this is the place for you.</p><p><strong>Job duties and responsibilities:</strong></p><ul><li>Chatbot and web services design, development, testing and maintenance</li><li>Design, development and unit testing prior to delivering the final product to the Lead Manager</li><li>Delivery of solutions aligned with expectations, on time, within budget, and with anticipated business value</li><li>Work as a member of our Agile Scrum team and technical experts, including programmers, UX designers, and project managers to design new products, or scale existing solutions</li><li>Design and develop plug and play cross-platform solutions along with API across multiple channels</li></ul><p><strong>Requirements:</strong></p><ul><li>Proven prior experience with good portfolio in developing AI-based Chatbots and other applications is must</li><li>Ability to effectively communicate technical information to non-technical team members.</li><li>Ability to effectively communicate written and verbally with customers, peers, and management.</li><li>Must be able to work cooperatively and effectively in an agile team environment.</li><li>Experience developing and implementing Bots</li><li>Experience in Conversational AI platforms/frameworks like IBM Watson, Tensorflow, Pandorabots, Dialogflow etc. for enterprises using ML and Deep Learning</li><li>Experience with bot text to speech and vice versa transformation incorporation</li><li>Experience with bot multi-lingual utilization (preferred)</li><li>Knowledgeable of Cloud services, methodologies and best practices (Amazon and Google preferred)</li></ul><p><strong>Candidates should be prepared to take additional tests/interviews.</strong></p>        </div><div>        <a href='https://day-translations.breezy.hr/p/2025b48dfbf4?source=remote.co' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j5PqydDBQZCl3Ot6ehLxWw",
    "url": "https://jobmote.com/job/64201/enterprise-architect-london-or-remote-70k-100k-bonus-benfits/",
    "title": "Enterprise Architect-LONDON or REMOTE-£70K-£100K+Bonus+Benfits",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:embedded/c/1",
      "DBG_TECH1:k/t/w:embedded/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=1, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/embedded",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "embedded"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 70000,
      "maxValue": 100000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 70k - 100k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 20, 2019 10:07:31 PM",
    "validThrough": "Aug 23, 2019 10:07:31 PM",
    "crawled": "Aug 21, 2019 3:06:24 AM",
    "content": "<div>Job Title: Enterprise Architect <br><br>Location: London OR Remote<br><br>Salary: Up to £70,000 - £100,000 - Flexible Dependent on experience + Benefits (Including 20% bonus)<br><br>Position: Permanent <br><br>Our client is a multinational leader in the managed services sector specifically related to the Telecom and Technology sectors. They work with some of the largest and most successful companies out there, so this is a great opportunity to work among industry experts.<br><br>You will be joining the IT Services division focused on global and managed services including enterprise networking, cloud networking, wireless, communications and workplace services. Being a modern and forward-thinking company, my client offer flexible hours, remote working as well as an excellent salary and benefits package. The division you will be joining is growing rapidly so this is a great time to join the teams.<br><br>This is a customer facing role, so we are looking for someone that ideally has customer facing experience in a global or regional service ideally including presales, managed service frameworks, commercial and contract experience. <br><br>Your key skills should include the following:<br><br>Essential<br><br>Customer facing experience<br>Experience working on large strategic customer accounts as an architect<br>Good understanding of cloud and digital concepts<br>Experience working with virtual teams including service architects, project management, engineers and service management<br>Strong understanding of managed services, global service desks, and ITIL concepts<br>Experience with large deals and contract negotiation (Ideally £10 Million+)<br>Experience building complex cost models<br>Comfortable delivering presentations to customers at a senior level<br>Experience working with PS subject matter experts<br>Experience working and designing multinational / global servicesDesirable <br><br>Some experience working with major clients in the retail and / or hospitality industries<br>Technical or operations background<br>ITIL3 foundation or similar<br>May have one or more other industry certification such as Prince2, PMP and /or technical accreditations e.g Cisco or similarThis role would suit someone from a similar background such as a service management consultant, senior service designer, senior service architect or enterprise architect for manager services / service management.<br><br>How to APPLY:-<br><br>If you are interested in finding out more about this opportunity, please submit your CV via the link provided and I will contact you shortly for a confidential discussion.<br><br>Cubiq Recruitment is recognised as a trusted supplier of permanent, contract and interim recruitment services to the technology and manufacturing sectors.<br><br>Our teams of specialist recruiters operate across the following engineering and commercial disciplines; mechanical engineering, electrical engineering, controls &amp; instrumentation, embedded software &amp; electronics, quality &amp; manufacturing, product design and project, programme &amp; operations management</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "at1O9cneQ-yv6mUnMPfakw",
    "url": "https://jobmote.com/job/63917/principal-data-scientist-100-remote-or-chesterbrook-pa-or-cambridge/",
    "title": "Principal Data Scientist (100% Remote or Chesterbrook, PA or Cambridge",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=0, go=0, nodejs=0, bigdata-ml=30, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Dell Technologies",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 10:07:32 PM",
    "validThrough": "Aug 22, 2019 10:07:32 PM",
    "crawled": "Aug 20, 2019 3:06:25 AM",
    "content": "<div>Are you in need of a one-of-a-kind opportunity? How about the challenge of uncovering hidden insights to drive new business value for customers from one of world's largest, and growing, store of meta-data created from a cloud integration platform? Dell Boomi is the first and still the industry's 1 Integration Platform as-a Service that enables customers to develop and execute data integrations that access, transform, and move data between clouds, between clouds and on-premise applications, and between on-premise applications.Meta-data is continually being generated as users develop new application integrations, capturing the relationships for every application being accessed, the data mapping definitions created, as well as meta-data being generated that captures every aspect of the execution of the integration. Dell Boomi already offers value-add to its users today where some of this meta-data is what we call crowd-sourced. But we know that there is so much more to unleash from this meta-data, developer behaviors, execution characteristics, correlations of common integrations across our customer-base world-wide.We are looking for data scientists to work on machine learning, data mining, and statistical modeling for predictive and prescriptive enterprise analytics. Successful candidates will be expected to understand and investigate state of the art techniques in advanced machine learning and statistical modeling, and also design, develop, and deploy state-of-art, scalable systems for innovative analytics applications. Applicants will be expected to work with a diverse, large set of data sources sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights.ResponsibilitiesResearch, design, prototype and deliver robust and scalable models based on machine learning, data mining, and statistical modeling to answer key business problems, to improve the product, to increase and optimize customer experiences, and other business outcomesAssess the effectiveness and accuracy of new data sources and data gathering techniquesDevelop custom data models and algorithms to apply to data setsBuild cost effective tools and support structures needed to analyze data, perform elements of data cleaning, feature selection and feature engineering and organize experiments in conjunction with best practicesWork with development teams &amp; business groups to ensure models can be implemented as part of a delivered solution replicable across many clientsPresent findings to stakeholders to drive improvements and solutions from concept through to deliveryKeep abreast of the latest developments in the field by continuous learning and proactively champion promising new methods relevant to the problems at handCollaborate closely with university partners and other scientists and engineers in a multidisciplinary work environmentPreferred Qualifications:Master's in computer science with 5 years of experience in related field.Demonstrated history of driving and delivering analytics models and solutionsDeep knowledge of fundamentals of machine learning, data mining and statistical predictive modeling, and extensive experience applying these methods to real world problemsStrong problem-solving skills with an emphasis on product development.Experience working with and creating data architectures.Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacksStrong skills in software prototyping and engineering with expertise in applicable programming and analytics languages (Python, R, C/C++) and various open source machine learning and analytics packages to generate deliverable modules and prototype demonstrations of their workDesired interdisciplinary skills include big data technologies, ETL, statistics and causal inference, Deep Learning, modeling and simulationBreadth of skills and experience in machine learning - diverse types of data and sources, different types of learning models, diverse learning settingsAbility and inclination to work in multi-disciplinary environments, and a passion for ideas realized in practiceDemonstrated ability to propose novel solutions to problems, performing experiments to show feasibility of their solutions, and working to refine the solutions into a real-world contextStrong analytical, written, and verbal communication skillsBenefits We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities - all to create a compelling and rewarding work environment.Apply now Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.&quot;LI Priority&quot;&quot;DCAM1&quot;Full time<p>by Jobble</p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "cOUpqD7hSiOK9hTHTty6aA",
    "url": "https://remoteok.io/jobs/74594",
    "title": "Data Science Curriculum Writer",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=100, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 9:41:35 PM",
    "validThrough": "Aug 26, 2019 9:41:35 PM",
    "crawled": "Aug 19, 2019 10:30:31 PM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Curriculum Writer</h3> <div>  <div>   \\nPlease Apply Here\\n\\nEducation | Remote, USA | Contract\\n\\nWho We Are Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;thinkful.com. Job Description Thinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp; Responsibilities\\n\\n\\n* Consistently deliver content that meets spec and is on time to support our program launch roadmap\\n\\n* Create daily lesson plans consisting of&nbsp;\\n\\n* Presentation decks that instructors use to lecture students on a given learning objective\\n\\n* Instructor notes that instructors use alongside&nbsp;\\n\\n* Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture\\n\\n* Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform\\n\\n* Creates code assets to support lesson plans, student activities, and written curriculum content\\n\\n* Iterates on deliverables based on user feedback\\n\\n\\n\\n\\nRequirements\\n\\n\\n* 3+ years of hands-on Data Science industry experience&nbsp;\\n\\n* Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning\\n\\n* Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)\\n\\n* Collaborative.You enjoy partnering with people and have excellent project management skills and follow through\\n\\n* Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations\\n\\n\\n\\n\\nCompensation and Benefit\\n\\n\\n* Contract position with a collaborative team\\n\\n* Ability to work remotely with flexible hours&nbsp;\\n\\n* Access to all available course curriculum for personal use\\n\\n* Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry\\n\\n* At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\n\\n\\n\\n\\nApply Here:\\n\\nhttps://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_MB6GpF6S1evdfbpKztX3g",
    "url": "http://workinstartups.com/job-board/job/83539/aimachine-learning-lead-at-digitalbridge/",
    "title": "AI/Machine Learning Lead",
    "tags": [
      "DBG:surround``OR(employe,develop,engin) 4W 4N(OR(&quot;not&quot;,no,doesn't),matter,OR(countri,locat,live,resid))",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/56",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:layout/frontend/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=1, bigdata-ml=84, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=6}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalBridge",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 2:27:22 PM",
    "validThrough": "Aug 26, 2019 2:27:22 PM",
    "crawled": "Aug 19, 2019 4:06:32 PM",
    "content": "<section class=&quot;section section--text&quot;><br /><p>DigitalBridge is seeking a lead for the AI/Machine Learning team to lead the company&rsquo;s research and development efforts. At DigitalBridge, we are developing a platform that guides consumers in developing beautiful living spaces, no matter how little design experience they have. We are using cutting-edge computer vision and machine learning technology to enhance our software and make it as smart as possible. We are active in the area of recommendation systems, optimisation for layout planning and computer vision for scene understanding.</p><br /><p>The role includes a mixture of people management and tech lead responsibilities. We are looking for someone who has experience managing small teams in a fast-paced environment. At the same time, we are looking for someone who has deep technical knowledge of machine learning and computer vision techniques and is able to give direction as well as guidance.</p><br /></section><br /><section class=&quot;section section--text&quot;><br /><p><strong>What does the opportunity look like day-to-day?</strong></p><br /><ul><br /><li>Align the business&rsquo;s R&amp;D efforts with business and product objectives.</li><br /><li>Management of the research team to define and deliver research objectives.</li><br /><li>Deliver robust, working technology that solves computer vision and machine learning problems.</li><br /><li>Represent the company&rsquo;s technological development to external clients and the public.</li><br /></ul><br /><p><strong>What you will bring to the team:</strong></p><br /><ul><br /><li>PhD in an area related to computer vision and machine learning.</li><br /><li>Proven background in developing and productising robust solutions to computer vision and machine learning problems.</li><br /><li>Deep knowledge in deep learning and convolutional neural networks.</li><br /><li>Some experience in leading a machine learning/computer vision team.</li><br /><li>Some experience with Python and/or C++.</li><br /><li>Excellent verbal and written communication skills.</li><br /><li>A positive attitude, self-motivation and strive to improve constantly.</li><br /></ul><br /><p><strong>It would be great if you also have:</strong></p><br /><ul><br /><li>Experience in presenting your work to a large audience.</li><br /><li>Experience in writing patents and scientific papers.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><p><strong>We offer:</strong></p><br /><ul><br /><li>Great offices!</li><br /><li>A relaxed and informal working environment</li><br /><li>Central Manchester location (Manchester Science Park)</li><br /><li>Working with a diverse, talented team</li><br /><li>Competitive Salary</li><br /><li>Open holidays</li><br /><li>Pension scheme</li><br /><li>Health insurance</li><br /><li>Share options</li><br /><li>Flexible working</li><br /><li>Kitchen with free coffee, drinks, cereal and fruit</li><br /><li>Great social activities</li><br /></ul><br /></section>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LbpdJdYcSpmIf8LEc3ycBA",
    "url": "https://jobmote.com/job/62653/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 18, 2019 10:07:27 PM",
    "validThrough": "Aug 21, 2019 10:07:27 PM",
    "crawled": "Aug 19, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SA7Dn9-ZStWwWvXeaYiwuA",
    "url": "https://jobmote.com/job/62652/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 18, 2019 10:07:27 PM",
    "validThrough": "Aug 21, 2019 10:07:27 PM",
    "crawled": "Aug 19, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NLTuK688TcCRrTSrkpWu1Q",
    "url": "https://jobmote.com/job/62587/remote-data-analyst/",
    "title": "REMOTE Data Analyst",
    "tags": [
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Advance Search",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:33 PM",
    "validThrough": "Aug 20, 2019 10:07:33 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>Our client is a fast growing provider of messaging and commerce solutions for automotive dealers and is looking for passionate and creative developers to join our team to build the next generation of automotive commerce technology. You will work directly with our wonderful development team to support our existing technology and build the future of automotive.</p> <p> </p> <p> <br>This is a full-time position. Very fun work environment with a team that is passionate about learning and delivering great software products. It s important that you fit with the team and culture, as we work closely together on a daily basis.</p> <p> </p> <p> <br>You will use our data set to look for insights that will help make a material impact for our business and our customers. Additionally you will work with other developers and business units to build reports and solve problems by analyzing relevant data and producing actionable insights.</p> <p> </p> <p>We expect to see:</p> <p> </p> <p> </p> <ul><li><ul><li>Understanding of descriptive statistics</li></ul></li></ul><p> </p> <ul><li><ul><li>Understanding of web technologies</li></ul></li></ul><p> </p> <ul><li><ul><li>Data visualization skills</li></ul></li></ul><p> </p> <ul><li><ul><li>Some experience with SQL</li></ul></li></ul><p> </p> <ul><li><ul><li>Experience with R or Python is a big plus</li></ul></li></ul><p> </p> <ul><li><ul><li>Passion for numbers ;)</li></ul></li></ul><p> </p> <p> </p> <p> <br>What we offer</p> <p> </p> <p> </p> <ul><li><ul><li>Work remotely from home</li></ul></li></ul><p> </p> <ul><li><ul><li>Competitive salary</li></ul></li></ul><p> </p> <ul><li><ul><li>Working with a passionate team</li></ul></li></ul><p> </p> <ul><li>Autonomy and responsibility in a fast moving company</li></ul> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ztvkx50iSq-bnjlrh1miLQ",
    "url": "https://jobmote.com/job/62636/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:34 PM",
    "validThrough": "Aug 20, 2019 10:07:34 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IPW0_B_0QBaQFZfH5AiFuw",
    "url": "https://jobmote.com/job/62635/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:34 PM",
    "validThrough": "Aug 20, 2019 10:07:34 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_f7mFbtwTn2GsxWzeV-fYA",
    "url": "https://stackoverflow.com/jobs/284120/data-analyst-amida-technology-solutions?a=1xhFG5jNbocw",
    "title": "Data Analyst at Amida Technology Solutions (Washington, DC) ",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Amida Technology Solutions",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:24 PM",
    "validThrough": "Aug 24, 2019 1:06:24 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Data Analyst</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                    </div>                <div>Company: Amida Technology Solutions | Washington, DC<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Washington, DC.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div>scientist</div>                <h4>Job description</h4>                <div><p>Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact.</p><p>Our team is comprised of creative, forward thinkers who are passionate about using cutting edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high growth environment that values fresh ideas, candid conversations, and authentic teamwork.</p><p>Amida is currently looking for a Data Analyst to join our team in Washington DC or from a remote location within the continental US. In this role you will work across our client engagements, providing expertise in data collection, data analysis, data mapping, data profiling, data mining and data modeling.&nbsp; You will be responsible for inspecting, cleansing, transforming and modeling data and will address issues related to data completeness and quality, as well as contribute to and produce technical and data process documentation.&nbsp;</p><p>What you will be doing:</p><ul><li>Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions</li><li>Apply analytical methodologies and principles to&nbsp;meet client needs.</li><li>Prepare forecast&nbsp;and analyze&nbsp;trends, develops and analyzes metrics, and prepares reports and recommendations related to management.</li><li>You will also be responsible&nbsp;for focusing on&nbsp;business performance, project analysis, internal control, risk assessment, and support of project objectives.</li></ul><p>What we are looking for:</p><ul><li>B.S. and/or M.S. in a quantitative field such as Computer Science, Statistics, or Mathematics</li><li>Minimum 3-5 year of recent professional experience in data science, data mining and/or data analysis</li><li>Experience in data migration to include data mapping and data profiling</li><li>Prior experience working with Healthcare data, or in the Healthcare field</li><li>Ability to conduct data profiling and predictive analysis using a variety of standard tools</li><li>Programming proficiency in a subset of Python</li><li>Experience with data visualization tools and methodologies</li><li>Ability to communicate concisely and effectively with software engineers and clients</li><li>Ability to obtain a Public Trust security clearance</li></ul><p>Preferred Skills</p><ul><li>Exposure to Amazon Web Services (AWS) and cloud-based systems</li><li>Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA)</li><li>Prior experience with metadata management to include meta tagging</li><li>Previous experience working in an Agile Team setting and using Agile management tools such as Jira</li><li>Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods</li></ul>                </div>            <div>        <a href='https://amida.applytojob.com/apply/L0IbEdxyOX/Data-Analyst?source=STCK' rel='nofollow'>                        Apply now        </a></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "E5T566WmT9CagyDiQ7h8qw",
    "url": "https://stackoverflow.com/jobs/282115/data-engineer-activestate-software?a=1wBYUO4wS9PO",
    "title": "Data Engineer at ActiveState Software (Vancouver, BC, Canada) ",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:golang/go/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:maven/java/13",
      "DBG_TECH1:k/t/w:npm/nodejs/5",
      "DBG_TECH1:k/t/w:perl/other/25",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:rubygems/ruby/8",
      "DBG_TECH1:techWeightMap:{python=12, other=25, dotnet=0, c=0, mobile=1, go=16, nodejs=7, bigdata-ml=40, ruby=10, apple=0, java=23, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/West"
    ],
    "tagsNames1": [
      "US Pacific time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "ActiveState Software",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:24 PM",
    "validThrough": "Aug 24, 2019 1:06:24 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Computer Software, SaaS, Software Development / Engineering</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: ActiveState Software | Vancouver, BC, Canada<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-08:00) Pacific Time </span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>Vancouver, BC, Canada.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>docker</div><div>kafka</div><div>hadoop</div><div>microservices</div>                <h4>Job description</h4>                <div><p>ActiveState Platform - made by developers for developers! We are reinventing build engineering with an on-demand SaaS Platform and CLI tool that lets developers automate the building of any runtime environment using any open source language ecosystem on any platform. In Beta right now, we support Python and Perl and we're hiring to add more languages and packages! We’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!</p><p><strong>This position is open to full-time telecommuters anywhere in North America</strong>. You can also choose to work from our headquarters in beautiful Vancouver, BC.</p><p><strong>This position is open to both junior (including fresh out of school) and senior applicants. The salary for this position will be commensurate with your experience.</strong></p><p><strong>What You’ll be Doing</strong></p><p>As a Data Engineer, you will create and maintain a data processing pipeline to feed our automated build systems with information about various open source languages and package updates. This work includes automating processing of open source package update feeds from language repositories including PyPI (Python), CPAN (Perl), Maven (Java), NPM (JavaScript), RubyGems. You will also be creating web crawlers for eco-systems without well defined APIs.</p><p>Our day to day work practices are centered around GitHub, pull requests, code review, CI for testing, and agile development with Pivotal Tracker as our project management tool. We’re always looking to improve our practices and we expect you to help us to do so.</p><p>We’re a polyglot company building our system using Golang, Python, Elm, Javascript, Perl, Docker, Kubernetes, DCOS, CircleCI, and other modern tools. Quality is as important as speed. We’re building for the long run, so you’ll need to enjoy writing tests and documentation too.</p><p>Our team is scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Highfive for video calls and screen sharing, Pivotal Tracker, and Google Drive.</p><p>We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code.</p><p><strong>What’s in it for You</strong></p><ul><li>Working for a stable and growing company that offers the environment and personal growth potential of a start-up.</li><li>The chance to work with a smart, passionate team of people.</li><li>The chance to work on a project that will change the work lives of developers around the world.</li><li>Competitive salary, bonus, and stock option plan.</li><li>Comprehensive benefits package and health/wellness credit program.</li></ul><p><strong>Requirements</strong></p><ul><li>Experience creating and maintaining complex software systems along with the ability to design non-trivial applications and components from scratch.</li><li>The ability to write clean, well-tested code with clear documentation.</li><li>Deep experience with at least one programming language, and shallow experience with several.</li><li>Excellent written and spoken skills, both technical and non-technical. You’ll need to work closely with your developer teammates, as well as be able to have coherent conversations with people from QA, sales, marketing, and other parts of the company.</li><li>A willingness to engage in the process of defining our work through conversations with product management, other engineering teams, and the rest of the company.</li><li>The ability to help others on the team become better at their jobs through mentoring, thoughtful code reviews, and generally being a team player.</li></ul><p><strong>Assets</strong></p><p>If you have experience with any of the following please make sure to highlight it in your cover letter:</p><ul><li>Data processing technologies, including but not limited to Kafka, Hadoop, Hive, Presto, Luigi, Airflow, Storm, etc.</li><li>Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI.</li><li>Golang code, especially large code bases.</li><li>Microservices and message queues.</li><li>Docker and Kubernetes.</li><li>Perl, Python, Tcl, or Ruby, especially an understanding of their respective language communities and toolchains.</li></ul><p><strong>Working at ActiveState</strong></p><p>ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all of us.</p><p>Our company is a team of 40+ and growing, with 2/3rds of the positions in technical roles&nbsp; including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events.</p><p>Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches.</p><p><a href='https://platform.activestate.com/create-account?utm_source=stackoverflow.com&amp;utm_medium=referral&amp;utm_content=company-page&amp;utm_campaign=create-account' rel='nofollow'>Try out our Platform for free and see for yourself what we are doing!&nbsp;</a></p>                </div>            <div>        <a href='https://grnh.se/9b3144282' rel='nofollow'>                        Apply now        </a></div>            <h4>About ActiveState Software</h4>            <div><p>If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Weekly meals: Friday lunches and Monday breakfasts</span>                            </li>                            <li>                                <span></span>                                <span>Stocked kitchen: snacks, DIY lunch options, drinks and treats!</span>                            </li>                            <li>                                <span></span>                                <span>Healthy Lifestyle credit: for your and our planet's health &amp; wellness</span>                            </li>                            <li>                                <span></span>                                <span>Bonus program: annual bonus, and cash incentives for meeting goals</span>                            </li>                            <li>                                <span></span>                                <span>Benefits package: medical, dental, extended health, vision coverage</span>                            </li>                            <li>                                <span></span>                                <span>Friday games: board games, puzzles, Xbox, poker or whatever you choose</span>                            </li>                            <li>                                <span></span>                                <span>ActiveVentures: fun quarterly staff outings in and around Vancouver</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DzMfw4uUQz-NI2ZQpwKl2A",
    "url": "https://stackoverflow.com/jobs/287205/senior-data-engineer-security-scorecard-we-are?a=1yjOJpmp6XUA",
    "title": "Senior Data Engineer at Security Scorecard - We are revolutionizing the cybersecurity industry  ",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/24",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Security Scorecard - We are revolutionizing the cybersecurity industry via Source-Code Recruitment Ltd",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Senior Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                            </div>                    </div>                <div>Company: Security Scorecard - We are revolutionizing the cybersecurity industry via Source-Code Recruitment Ltd | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>hadoop</div><div>apache-spark</div><div>scala</div><div>amazon-web-services</div><div>docker</div>                <h4>Job description</h4>                <div><p><strong>Why SecurityScorecard</strong></p><p>SecurityScorecard is revolutionizing the cybersecurity industry with our platform, data, and insights. We’ve built a new category of enterprise software, which enables companies to rate and understand the security risk of any company. Our customers span a variety of sectors and use cases, including compliance, cyber insurance, and vendor risk management. We are proud to be backed by Sequoia, Google Ventures, and Moody's.</p><p>SecurityScorecard is growing tremendously and targeting talent who can contribute to the next phase in our company's development. A successful Scorecarder exemplifies our S(CORE) values: Solutions Focused, Customer Centric, operate as One Team, Resilience and Embody #SecurityDNA. Your interest in making an impact in our organization and alignment with these values are as important as your skills.</p><p><strong>Opportunity</strong></p><p>The Senior Data Analytics Engineer will build meaningful analytics that inform companies of security risk. You will be working closely with our Data Science team, implementing algorithms and managing the analytic pipeline. We have over 1 PB of data, so the ideal candidate will have experience processing and querying large amounts of data.</p><p>We prefer this person to work from our NYC headquarters, but will consider remote applicants in other geographic areas.</p><p><strong>Responsibilities:</strong></p><ul><li>Manage the analytic pipeline using Spark, Hadoop, etc.</li><li>Leverage cutting-edge technologies to support new and existing and services and processes.</li><li>Quickly and efficiently design and implement in an agile environment</li><li>Work with other team members to implement consistent architecture</li><li>Drive projects through all stages of development</li><li>Actively share knowledge and responsibility with other team members and teams</li><li>Improve the effective output of the engineering team by managing quality, and identifying inconsistencies.</li></ul><p><strong>Requirements:</strong></p><ul><li>Bachelor's degree (CS, EE or Math preferred) or equivalent work experience as well as interest in a fast paced, complex environment.</li><li>5+ years of experience Scala or another functional language experience in a commercial environment (highly preferred)</li><li>3+ Experience with Spark, and the Hadoop ecosystem and similar frameworks</li><li>Familiarity with various tools such as AWS and Docker and an instinct for automation</li><li>Expert in SQL</li><li>Strong understanding of Software Architecture principles and patterns.</li><li>Experience working with 3rd party software and libraries, including open source</li><li>Experience with Postgres</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/287205?reset=False&amp;ra=1yjOJpmp6XUA&amp;oqs=a%3D1yjOJpmp6XUA' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Security Scorecard - We are revolutionizing the cybersecurity industry</h4>            <div><p>SecurityScorecard is revolutionizing the cybersecurity industry with our platform, data, and insights. We’ve built a new category of enterprise software, which enables companies to rate and understand the security risk of any company. Our customers span a variety of sectors and use cases, including compliance, cyber insurance, and vendor risk management. We are proud to be backed by Sequoia, Google Ventures, and Moody's.</p><p>SecurityScorecard is growing tremendously and targeting talent who can contribute to the next phase in our company's development. A successful Scorecarder exemplifies our S(CORE) values: Solutions Focused, Customer Centric, operate as One Team, Resilience and Embody #SecurityDNA. Your interest in making an impact in our organization and alignment with these values are as important as your skills.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "I5_DbnA0Q_CW89QszCFLtA",
    "url": "https://stackoverflow.com/jobs/283906/sr-software-engineer-rho-ai?a=1xddNx0BcRuU",
    "title": "Sr. Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/20",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=60, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Sr. Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Data Science, Software Development / Engineering</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Rho AI | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>single-page-application</div><div>sql</div><div>nosql</div><div>docker</div>                <h4>Job description</h4>                <div><p>Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste). We value pragmatic solutions and have cultivated a modern technology stack that combines software development (python microservices, react frontends), infrastructure automation (docker, kubernetes), and machine learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p><p>As a member of the software engineering team, you will:</p><ul><li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li><li>Join a group of talented and congenial team members in an experienced individual contributor role (mix of architecting / building / mentoring), with future people management opportunities (if you like).</li><li>Lead engineering projects by collaborating with team members and customers, facilitating technology architecture decisions, driving forward work streams, and releasing high quality software.</li><li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li></ul><p><strong>You have</strong>:</p><ul><li>(Must) Been the tech lead of a project that uses a Python based stack.</li><li>(Must) Good communication skills for technical and non-technical audiences.</li><li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li><li>(Must) Worked on all layers of the stack - databases, services, and frontends.</li><li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li><li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li><li>(Should) Have experience working within a microservices oriented architecture.</li><li>(Nice) Built systems that process large amounts of data and/or traffic.</li><li>(Nice) Strong computer science principles, and/or algorithmic skills.</li><li>(Nice) Experience with machine learning applications.</li></ul><p><strong>You meet these criteria</strong>:</p><ul><li>You are seeking a full-time job.</li><li>You reside in the United States.</li><li>You are&nbsp;authorized / eligible to work for any company in the United States.</li><li>You are in a continental US time zone, or willing to align your schedule.</li></ul><p><strong>To get an interview, you must supply:<br></strong></p><ul><li>A cover letter that explains why you are 1)&nbsp;<em>specifically interested</em>&nbsp;in Rho AI as a company and 2) a&nbsp;<em>good fit</em>&nbsp;for this particular position.</li><li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/283906?reset=False&amp;ra=1xddNx0BcRuU&amp;oqs=a%3D1xddNx0BcRuU' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Rho AI</h4>            <div><p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p><p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p><p><strong>Work at Rho AI</strong></p><p>At Rho AI, you will work with a talented group of data scientists, engineers and thought leaders&nbsp;to harness the power of data science to propel projects with a positive world impact. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p><p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Work from anywhere in the world with flexible work schedules.</span>                            </li>                            <li>                                <span></span>                                <span>Health insurance &amp; FSA accounts</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salaries along with 401k</span>                            </li>                            <li>                                <span></span>                                <span>4 weeks of PTO</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "h_U7GMkmSzaN72n8Pe2Faw",
    "url": "https://stackoverflow.com/jobs/159704/remote-sr-big-data-openings-aws-hadoop-python-surge?a=RyHKuqqkVIQ",
    "title": "REMOTE Sr. Big Data Openings- AWS, Hadoop, Python at Surge  ",
    "tags": [
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Surge",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>REMOTE Sr. Big Data Openings- AWS, Hadoop, Python</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Surge | No office location<br></div><h4>Technologies</h4><div></div><div>data-analysis</div><div>python</div><div>apache-spark</div><div>amazon-web-services</div><div>bigdata</div>                <h4>Job description</h4>                <div><p>SURGE is looking for smart, self-motivated, experienced, senior automated test engineers&nbsp;who enjoy the freedom of telecommuting and flexible schedules, to work as long-term, consistent&nbsp;(40 hrs/week) independent contractors (no W2)&nbsp;on a variety of software development projects.</p><p>Experience Required:&nbsp;</p><p>Senior Big Data, Data Analysis and Data Science Openings</p><p><strong>Must be located in the US or Canada to be considered for this role. Sorry, No Visas.</strong></p><p>For immediate consideration, email resume with tech stack under each job and include your full name, cell phone number, email address and start date to: <a href='mailto:jobs@surgeforward.com' rel='nofollow'>jobs@surgeforward.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/159704?reset=False&amp;ra=RyHKuqqkVIQ&amp;oqs=a%3DRyHKuqqkVIQ' rel='nofollow'>Apply now</a></div>            <h4>About Surge</h4>            <div><p>Surge is an onshore provider of custom web, cloud, mobile, digital, and desktop software development and consulting services to clients in every industry, from hot startups to Fortune 500 companies.<br><br>Founded in 2007, and listed on the Inc. 5000 list of America’s fastest growing companies for five straight years, Surge has successfully delivered hundreds of software products, apps, and solutions to its clients using a proven agile/scrum development process combined with an elite group of North American software professionals.<br><br>Simply put, Surge offers America’s best software engineers, on demand, at rates 30-50% less than the competition.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Great Pay</span>                            </li>                            <li>                                <span></span>                                <span>Choose Your Hours</span>                            </li>                            <li>                                <span></span>                                <span>Work From Home</span>                            </li>                            <li>                                <span></span>                                <span>Work With Happy People</span>                            </li>                            <li>                                <span></span>                                <span>Zero Commute</span>                            </li>                            <li>                                <span></span>                                <span>See Your Family More</span>                            </li>                            <li>                                <span></span>                                <span>Travel While You Work</span>                            </li>                            <li>                                <span></span>                                <span>Software Provided</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "PWI0a0ffRSSVR2csuuQsOw",
    "url": "https://jobmote.com/job/62494/senior-data-etl-engineer-remote/",
    "title": "Senior Data ETL Engineer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jersey/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>SQL, AWS, ETL<br><br>We are one of the most successful technology start-ups in the Philadelphia/New Jersey region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. <br><br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.<br><br>We need a Senior ETL Data Engineer to help us transform how consumers interact with real estate data.<br><br>What You Will Be Doing<br><br>- Recommend and implement data processing tools and technologies<br>- Extract, transform and load data pipelines from end to end<br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info<br>- Create, develop and document data mapping rules from multiple sources<br>- Develop continuous process movements<br><br>What You Need for this Position<br><br>- 5+ yrs experience<br>- ETL<br>- SQL / PostgreSQL<br>- AWS<br>- BSCS or related degree<br><br>What's In It for You<br><br>- Competitive Pay<br>- FULL REMOTE!So if you are a Senior Data ETL Engineer with relevant experience, please apply today! Interviews are occurring this week!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O33bqfH4Tt2ngOXxrahqhg",
    "url": "https://jobmote.com/job/62489/data-scientist-remote/",
    "title": "Data Scientist - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:css/frontend/6",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>DOMO, R, SQL, JavaScript, CSS, HTML, Python<br><br>If you are a Data Scientist - Remote with experience, please read on!<br><br>What You Will Be Doing<br><br>You will be responsible for helping digital businesses succeed by introducing them to BI insights that they can rely on:<br>- You will use pre-built API connections, SQL, and Domo's other ETL tools to access various databases and prepare data to be imported into Domo<br>- Develop and manage client CRM portfolios <br>- Analyze customer data to improve customer experience <br>- Assist in the preparation of sales forecasts, quotes or negotiations<br><br>What You Need for this Position<br><br>At Least 2 Years of experience and knowledge of:<br><br>- Domo**<br>- Data Analysis <br>- Data Science <br>- KPI Creation <br>- Python, R, JavaScript, HTML, and CSS<br>- API, SQL and other ETL tools<br><br>What's In It for You<br><br>- Competitive pay <br>- Flexible Schedule <br>- FULLY REMOTE*So, if you are a Data Scientist - Remote with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-eccFMG1QMmkqEOw11N8Iw",
    "url": "https://jobmote.com/job/62472/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "VjF8uLQCSuqsWmcPYGnlFA",
    "url": "https://jobmote.com/job/62465/nlu-nlp-architect-or-engineer-remote/",
    "title": "NLU NLP Architect or Engineer REMOTE",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Collabera",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Position/REQ ID: ? NLP Architect <br>Location: RTP or SJ areas, can be remote <br>Duration: 11 Months <br>? <br>MUST HAVES <br>Strong knowledge of the Machine Learning techniques around natural language<br>Experience implementing enterprise scale NLU based IVR solution(s).<br>Strong knowledge IVR based application development and Conversational IVR.<br>Experience in Dialogflow OR other NLP engine models such as<br>Good knowledge on building conversational IVR (Interactive Voice Response) flows using Dialog flow<br>Experience with machine learning techniques within NLP such as tokenization, parts of speech tagging, stemming, lemmatization, named entity recognition, sentiment analysis, TF-IDF, topic modeling, bag of words, word vectors, language modeling, seq2seq, LSTMs, Transformers <br>? <br>PLUSSES <br>Programming experience in Node JS, Python, SQL, NoSQL, Java, Graph Databases a plus<br>Strong knowledge of applicable methodologies, tools, standards, and procedures.<br>Experience in Big Data platform handling large volumes of data and have experience in data processing and storage. <br>DAY-TO-DAY <br>Implement NLU/NLP solutions to extract value from Install Base data.<br>Be the in-house NLP expert, lead NLP initiatives, review the deliverables and set standards and guideline<br>Develop design principle for developing new dialog flows.<br>Help cultivate organization-wide best practices for NLP and Coach and Mentor other members of the team<br>Deconstruct customer-agent conversations to programmatically extract concepts and relationships between concepts in various conversation scenarios.<br>Work with various business lines like? Sales and Marketing to identify opportunities for NLP and recommend them into actionable data science projects.<br>Guide the data engineers to design data pipelines to effectively store, normalize and access text data. <br>?<br><br>NLP,NLU,IVR, Dialogflow<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qltAN9MnTRytFqxPNVMv3A",
    "url": "https://jobmote.com/job/62461/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9DL46nmFSQWSr3miuD9_2Q",
    "url": "https://www.remoteage.com/remote-jobs/senior-software-engineer-385/",
    "title": "Senior Software Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DeepIntent",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 6:21:49 AM",
    "validThrough": "Aug 23, 2019 6:21:49 AM",
    "crawled": "Aug 16, 2019 7:08:25 AM",
    "content": "<h3>            Senior Software Engineer        </h3><div>United States, New York</div><div>Company: DeepIntent<p></p></div><div>                    <h4>Overview</h4>                    <p>Our CompanyDeepIntent is a marketing technology company that helps healthcare brands strengthen communication with patients and healthcare professionals by enabling highly effective and performant digital advertising campaigns. Our healthcare technology platform, MarketMatch™, connects advertisers, data providers, and publishers to operate the first unified, programmatic marketplace for healthcare marketers. The platform’s built-in identity solution matches digital IDs with clinical, behavioral, and contextual data in real-time so marketers can qualify 1.6M+ verified HCPs and 225M+ patients to find their most clinically-relevant audiences, and message them on a one-to-one basis in a privacy compliant way. Healthcare marketers use MarketMatch to plan, activate, and measure digital campaigns in ways that best suit their business, from managed service engagements to technical integration or self-service solutions. DeepIntent was founded by Memorial Sloan Kettering alumni in 2015 and acquired by Propel Media, Inc. in 2017. We proudly serve major pharmaceutical and Fortune 500 companies out of our offices in New York, California, and India. Learn more about what we do on our website; learn about our company and culture on Glassdoor. The TeamDeepIntent’s founding team is composed of data scientists from advertising, healthcare and finance and are still actively involved in R&amp;D projects at the company. Our simple mission: create the next generation of cutting edge analytics for marketers. You will be a core asset in our pursuit of achieving this mission. The Role- Design, develop, test, deploy, maintain and improve our core bidding software.- Work closely with the Data Science, Engineering, and Product teams to implement new algorithms and optimize the code base for speed and performance.- Manage individual project priorities, deadlines and deliverables.- Work with business units on product development. Non-Technical Requirements- An enthusiastic learner who is able to keep up with various technologies.- Strong mathematical and logical skills.- A strong collaborator in small, cross-domain, distributed team environments.- 1-2+ years of advertising experience considered a plus, but not required. Technical Requirements- Bachelor’s degree in Computer Science, similar technical field of study or equivalent practical experience.- 4-7 years of experience in software development- Experience with distributed and parallel systems, developing large software systems.- Experience with one or more general purpose languages including Java, C++.- Interest and ability to learn other coding languages.- Experience performance tuning and writing low latency software.- Experience with cloud computing platforms (AWS and/or Google Cloud Platform)- Machine Learning experience is a plus, but not required.</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?Nr6wnfaWjnnyA08qisOb3As' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ut99_sPnTBmjehM-dZ_yAg",
    "url": "https://jobmote.com/job/62289/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 10:07:38 PM",
    "validThrough": "Aug 18, 2019 10:07:38 PM",
    "crawled": "Aug 16, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ps907LhhSdWlc2MBh-gZOg",
    "url": "https://jobmote.com/job/62288/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 10:07:38 PM",
    "validThrough": "Aug 18, 2019 10:07:38 PM",
    "crawled": "Aug 16, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "h6NoVN0HR3yexBvEs3nsbw",
    "url": "https://www.remoteage.com/remote-jobs/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 5:34:44 PM",
    "validThrough": "Aug 22, 2019 5:34:44 PM",
    "crawled": "Aug 15, 2019 6:23:53 PM",
    "content": "<h3>            Data Lead Software Developer-remote considered        </h3><div>United States, Connecticut</div><div>Company: Travelers Insurance<p></p></div><div>                    <h4>Overview</h4>                    <p>Company Information<br>Solid reputation, passionate people and endless opportunities. That’s Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers – and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.</p><p>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.</p><p>Primary Job Duties &amp; Responsibilities</p><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li><li>Analyze latest Big Data Analytic technologies and their innovative applications in both business intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li><li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li><li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li><li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li><li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li><li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li><li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li><li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li><li>This position is open for candidates to work remotely.</li></ul><p>Minimum Qualifications<br>A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.</p><p>Education, Work Experience &amp; Knowledge</p><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li><li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (e.g. Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li><li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li><li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li><li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li><li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li><li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li><li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li><li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li><li>Experience building microservices and real-time APIs</li><li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li><li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li><li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li><li>Experience with BI tools and reporting software (e.g. Microstrategy, Cognos, Tableau etc.)</li><li>Agile project management experience, including use of agile project management tools (i.e. JIRA, Git, etc.)</li><li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li><li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li><li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li><li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li><li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li><li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li><li>Advanced IT process improvement, and problem-solving skills</li><li>Comfortable presenting to senior management</li></ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others’ views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th</p><p>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.</p><p>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.</p><p>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe</p><p>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br>To apply for this position please <b>CLICK HERE</b> </p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?isOoGJzBLh3T%2fZh8sJuFCgm' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zfq28vo9Th6OnSETshh84w",
    "url": "https://jobmote.com/job/62024/software-engineering-manager-work-from-home/",
    "title": "Software Engineering Manager (Work From Home)",
    "tags": [
      "DBG:surround``work 2W from 2W home 4W OR(staff,cowork,offic,posit)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:dotnet/dotnet/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/8",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=8, c=13, mobile=1, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "Kforce Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 12:21:16 PM",
    "validThrough": "Aug 18, 2019 12:21:16 PM",
    "crawled": "Aug 15, 2019 5:06:26 PM",
    "content": "<div>Kforce has been retained by one of our digital and software solutions clients based in Reston, Virginia (VA) to assist them in hiring a Software Engineering Manager to joint their team. This is a full-time, salaried position with a competitive base salary and a comprehensive benefits package. It is also a Work from Home/Remote position given the dispersed locations of their engineering, product and leadership teams.Summary:Reporting directly into the CIO, this Engineering Manager will direct a team that is responsible for development and enhancement of their flagship product that leverages social technology, artificial intelligence and real-time analytics to provide solutions to their customers.<br><br>* The ideal candidate will have prior experience as a developer<br><br>* Current experience as a manager<br><br>* Experience delivering customer-facing, commercial, enterprise software products to a B2B audience<br><br>* Well-rounded SDLC expertise in an Agile environment<br><br>Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.*Compensation Type:*Years <br> Associated topics: .net, application, c c++, develop, devops, java, matlab, perl, software engineer, software programmer</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GIx3rOKUTUKFG2yUEAw2aw",
    "url": "http://workinstartups.com/job-board/job/82589/data-analyst-manager-at-hubble/",
    "title": "Data Analyst Manager",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hubble",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 1:35:01 PM",
    "validThrough": "Jul 29, 2019 1:35:01 PM",
    "crawled": "Aug 15, 2019 2:06:34 PM",
    "content": "<p><strong>DESCRIPTION </strong></p><br /><p>Hubble is the UK&rsquo;s leading PropTech scale up; changing the face of commercial property. Our mission is to find the perfect home for every company and we&rsquo;ve built an online platform to help businesses rent, manage and share office space in London. We&rsquo;ve raised over &pound;6m in venture funding from the most respected investors in technology and real estate to make this mission a reality.</p><br /><p>As a Data Analyst you will be working closely with Data Science, Engineering and Business Operations to support all teams with day to day reporting, problem solving and using data to provide key company insights. You will work across a range of areas such as our acquisition strategies, product funnels, supply and demand dynamics, sales performance and more.</p><br /><p><strong>RESPONSIBILITIES </strong></p><br /><ul><br /><li>Own the data request process from prioritisation through to delivery.</li><br /><li>Support all departments through report creation, ad-hoc data analysis and providing key business insights and solutions.</li><br /><li>Empower all teams with the right tools to understand the data and make decisions quickly</li><br /><li>End-to-end ownership of data quality in our core datasets and data pipelines.</li><br /><li>Experiment with new tools and technologies to meet business requirements regarding performance, scaling, and data quality.</li><br /><li>Work on automating key areas of data for scale</li><br /></ul><br /><p><strong>REQUIREMENTS</strong></p><br /><ul><br /><li>Strong SQL knowledge and experience. You will need to comfortably create multiple complex queries from scratch, have knowledge of databases, Vlookups, Pivot tables, advanced Excel</li><br /><li>Excellent problem solving skills - ability to see beyond the numbers and think logically. You should have commercial understanding to come up with appropriate solutions for key areas in the business.</li><br /><li>Previous experience in a similar role, ideally in a startup environment</li><br /><li>Experience solving real problems using data analysis techniques and statistical rigour.</li><br /><li>Excellent communication skills; the ability to convey complex analysis results clearly.</li><br /></ul><br /><h3><strong>PROGRESSION</strong></h3><br /><ul><br /><li>We give an incredible amount of opportunity to take ownership and autonomy</li><br /><li>If you do well, there are opportunities to expand your role and be involved with data science and how we grow our product</li><br /><li>You will have the opportunity to learn new languages such as Python and R.</li><br /></ul><br /><p><strong>BENEFITS </strong></p><br /><p>We make sure everyone in the team is comfortable and has the best environment for them. We offer flexible hours, remote working and have a relaxed attitude to taking holiday - focusing only on whether work gets done. Benefits can be tweaked on an individual basis depending on what makes you most productive. Here are some of the things we offer:</p><br /><ul><br /><li>Remuneration competitive with industry and level of experience.</li><br /><li>Macbook, peripherals and standing desk.</li><br /><li>Expense budget &amp; travel.</li><br /><li>Noise-cancelling headphones.</li><br /><li>Spotify Premium or Apple Music.</li><br /><li>Kindle Unlimited + free technical books.</li><br /><li>Health &amp; Pension.</li><br /><li>Cycle to Work scheme.</li><br /></ul><br /><p>We truly value our people and company culture. Want to know more about why Hubble is a great place to work? Check out this<a href='https://workable.com/nr?l=https%3A%2F%2Fhubblehq.com%2Fblog%2Fhubble-best-places-to-work' rel='nofollow noreferrer noopener'>&nbsp;recent blog post</a>.</p><br /><p>Hubble is an equal opportunities employer. We are a diverse bunch of people who are committed to maintaining a welcoming culture of inclusion and equality. We encourage applications from anyone that meets the requirements for the role.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ncH4ZTBZRqmfNZqIM14rqw",
    "url": "https://jobmote.com/job/61006/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:33 PM",
    "validThrough": "Aug 17, 2019 10:07:33 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ing20FV-RI6BUQBtJ9liGg",
    "url": "https://jobmote.com/job/61041/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ADLoDrTjRtGaZTrb0RgdpA",
    "url": "https://jobmote.com/job/61040/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Bu19rQqKSSKMqTuK3qlVeg",
    "url": "https://jobmote.com/job/61027/sap-data-analyst-consultant-remote/",
    "title": "SAP Data Analyst - Consultant (REMOTE)",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "RPartners",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p> <strong>SAP Data Analyst / Architect</strong></p> <p> <strong>REMOTE / WORK FROM HOME / TELECOMMUTE options available</strong></p> <p>Our client has a product that allows their customers to access business-critical data that may be stored in many systems. Their product allows the customer to connect and combine from all of their systems into the product and have delivered, actionable, insights within seconds.</p> <p> </p> <p>They are currently starting a new initiative that entails a large scale extraction and migration of customer data that currently resides within an SAP ECC 6.0 running on DB2.</p> <p> </p> <p>This initiative has generated the need for Sr. Data Analysts / Architects with experience supporting the extraction and migration of data from an ECC 6.0 / DB2 environment.</p> <p> </p> <p>Strong experience with SAP LT Replication, ABAP and SAP Data Services (BODS) is required. Experience supporting Logistics / Distribution / Operations modules within ECC is a plus.</p> <p> </p> <p>Excellent communication skills and the ability to effectively bridge the layer between the end customers data structure(s) resident within ECC / DB2 and the Clients Development teams is critical.</p> <p> </p> <p>This is projected to be a 3-6 month initiative with the strong possibility of follow-on extension as the project scope increases.</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DHiIMxn1TeGM6uT5WDzJMg",
    "url": "https://remoteok.io/jobs/74510",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Catch Co.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 11:52:43 PM",
    "validThrough": "Aug 21, 2019 11:52:43 PM",
    "crawled": "Aug 15, 2019 12:06:30 AM",
    "content": "<span></span> <span><h4>Catch Co.</h4></span> <br> <h3>Data Engineer</h3> <span></span> <br> <span>US-only</span> <div>  <div>   **Position Overview:**\\n\\n\\nThe Catch Company is looking for a Data Engineer to support our Analytics team. The Analytics team is looking to grow and improve our analytics tech stack to enable smarter and faster business decisions, automated processes, and personalized customer experiences.\\n\\nIn this role, you will own the development and maintenance of our analytics tech stack and will be instrumental in identifying and implementing new technologies and tools to support our goals. While we already have a robust analytics / business intelligence ecosystem in place, we believe the right Data Engineer can push our team to become industry leaders in enabling smarter decision-making and personalizing our customer experience via new technologies and approaches. Our current tech stack includes: Redshift (warehouse), Fivetran/Stitch Data/custom pipelines (ETL), dbt (transformation), Looker (visualization), and a variety of other services that support one-off tools (e.g., Jupyter notebooks, Amazon EC2, etc.).\\n\\nAdditionally, we welcome both local (Chicago) and remote candidates for this role! Our analytics team is partially remote and our engineering team is fully remote.\\n\\n\\n**What makes this a special opportunity:**\\n\\nYou will have broad freedom to change and improve the way we do things as the only Data Engineer on the team\\nYou will have the opportunity to be a thought leader when it comes to selecting new technologies; you will be responsible for identifying and implementing new tools and technologies\\nYou will work with people who are eager to use data to improve our product offerings, our customer experience, and other key components of the business\\nWe place a premium on building a great culture made up of great people\\nYou will work with and learn from experienced leaders who have a track record of building successful companies\\nWe are based in Chicago’s West Loop (one of the best restaurant neighborhoods in the world), with easy access to all major public transportation systems\\n\\n\\n**Benefits:**\\n\\n&quot;Take what you need&quot; PTO Policy\\n4 additional paid days off specifically to enjoy the outdoors\\nFlexible working schedule\\nAbility to work from home if there is a need\\nMedical, Dental and Vision Insurance - We cover 85% of your premium and 50% for dependents\\nHealth Savings Account\\n401(K) plan\\nPre-Tax Commuter Benefits\\nUnlimited fruit snacks\\n\\n# Responsibilities\\n **What you will do:**\\n\\nOwn the maintenance and development of our analytics tech stack, including identifying and implementing new tools, managing utilization, and improving performance\\nModel and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it\\nRe-structure our processes for ingesting and analyzing website event data to a) Capture more usable, relevant data and b) Use technologies like Spark that allow for faster data transformation\\nBuild custom data pipelines that reliably provide clean, ready-to-analyze data and develop systems that monitor those pipelines to ensure their health\\nWork closely with our software engineers to identify new opportunities for data collection (with a focus on personalization/recommendation systems) and build the processes to make that data available in our data warehouse\\nIdentify use cases for real-time/streaming analytics and select and implement tools to support those use cases\\nResearch and surface new ideas and approaches, whether new technologies, tools, frameworks, or process improvements for the team \\n\\n# Requirements\\n**What experience you need:**\\n\\nExperience working in data engineering, data architecture, or another similar field\\nExtensive experience manipulating data using SQL\\nExperience using Git to version/manage code\\nFluency in one or more programming languages such as Python, Java, Go, etc.\\nExperience working with relational databases/data warehouses\\nFamiliarity with ETL tools\\nFamiliarity with business intelligence/visualization tools\\n[Optional/Preferred]: Experience building custom data pipelines\\n[Optional/Preferred]: Experience structuring and analyzing high volumes of website event data (e.g., impressions, views, clicks, etc.)\\nYou must be eligible to work in the United States; visa sponsorship is not available\\n\\n**What will make you successful:**\\n\\nCuriosity: Always seeking to understand “why”, always looking to make things better.\\nPassion: You are driven by a love for what you do\\nOptimism: The ability to bounce back quickly when something doesn’t work\\nAction: Knowing when to shift from planning to doing\\nHonesty: Transparency with customers, partners and teammates\\nEntrepreneurial spirit\\nData-driven mindset\\nAn interest in / passion for the outdoors (fishing knowledge not required!)\\n \\n\\n#Location\\n- US-only   <br>  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "3clwT_bPSp-ihMD6vbjEWQ",
    "url": "https://weworkremotely.com/remote-jobs/creative-commons-data-engineer",
    "title": "Creative Commons: Data Engineer",
    "tags": [
      "DBG:surround``2N(remot,work) 3W OR(encourag, avail, environ)",
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "50% remote",
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "https://creativecommons.org/"
    },
    "salary": {
      "currency": "USD",
      "minValue": 80000,
      "maxValue": 100000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 80k - 100k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:04:25 PM",
    "validThrough": "Aug 21, 2019 10:04:25 PM",
    "crawled": "Aug 14, 2019 10:30:23 PM",
    "content": "<h3> Data Engineer </h3><div><div><b><span>About this position</span></b></div><div><br></div><div><span>Creative Commons is building a “front door” to the growing universe of openly licensed and public domain content through </span><a href='https://search.creativecommons.org/' rel='nofollow'><span>CC Search</span></a><span> and the </span><a href='https://api.creativecommons.engineering/' rel='nofollow'><span>CC Catalog API</span></a><span>. The Data Engineer reports to the Director of Engineering and is responsible for </span><a href='https://github.com/creativecommons/cccatalog' rel='nofollow'><span>CC Catalog</span></a><span>, the open source catalog that powers those products. This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners.</span></div><div><br></div><div><b><span>Primary responsibilities</span></b></div><div><br></div><ul><li><span>Architect, build, and maintain the existing CC Catalog, including:</span><br><br></li><li><span>Ingesting content from new and existing sources of CC-licensed and public domain works.</span><br><br></li><li><span>Scaling the catalog to support billions of records and various media types.</span><br><br></li><li><span>Implementing resilient, distributed data solutions that operate robustly at web scale.</span><br><br></li><li><span>Automating data pipelines and workflows.</span><br><br></li><li><span>Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.</span><br><br></li></ul><div><li></li></div><div><span>Augment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.</span></div><div><br></div><div><li></li></div><div><span>Build an open source community around the CC Catalog, including:</span></div><div><br></div><ul><li><span>Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.</span><br><br></li><li><span>Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor.</span><br><br></li><li><span>Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.</span><br><br></li></ul><div><li></li></div><div><span>Collaborate with other outside communities, companies, and institutions to further Creative Commons’ mission.</span></div><div><br></div><div><b><span>Qualifications and requirements</span></b></div><div><br></div><ul><li><span>Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization</span><br><br></li><li><span>Proficiency with Python</span><br><br></li><li><span>Proficiency with Apache Spark</span><br><br></li><li><span>Experience with cloud computing platforms such as AWS</span><br><br></li><li><span>Experience with Apache Airflow or other workflow management software</span><br><br></li><li><span>Experience with machine learning or interest in picking it up</span><br><br></li><li><span>Fluent in English</span><br><br></li><li><span>Excellent written and verbal communication skills</span><br><br></li><li><span>Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure</span><br><br></li><li><span>Curiosity and a desire to keep learning</span><br><br></li><li><span>Commitment to consumer privacy and security</span><br><br></li><li><span>Nice to have (but not required):</span><br><br></li><li><span>Experience with contributing to or maintaining open source software</span><br><br></li><li><span>Experience with web crawling</span><br><br></li><li><span>Experience with Docker</span><br></li></ul><div><br></div><div><b><span>Diversity &amp; inclusion</span></b></div><div><br></div><div><span>We believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.</span></div><div><b><br></b></div><div><b><span>Work environment and location</span></b></div><div><br></div><div><span>Creative Commons is a fully-distributed organization — we have no central office. This position is available to applicants working in the range of the Eastern to Pacific time zones, in a remote working environment. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.</span></div><div><br></div><div><b><span>Salary and benefits</span></b></div><div><br></div><div><span>Creative Commons is a leading non-profit employer, offering competitive salaries and benefits, including health and wellness plans, annual retirement contributions, and a positive, supportive work environment. We offer competitive salary in the range for this position from $80,000 to $100,000 USD, </span><span>commensurate with relevant skills, experience, and location.</span></div><div><br></div><div><b><span>How to apply</span></b></div><div><br></div><div><span>Please email your cover letter and resume as a single PDF to “jobs@creativecommons.org” with the subject heading of “Data Engineer / [Last Name].” Phone calls and messages will not be returned.</span></div><div><br></div></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "nr4Ne-_OSgSh1B7RluQeRA",
    "url": "http://workinstartups.com/job-board/job/83435/aiimage-search-at-tba/",
    "title": "AI/Image search",
    "tags": [
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``OR(oper,collabor) 2W remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TBA",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 5:45:20 PM",
    "validThrough": "Aug 21, 2019 5:45:20 PM",
    "crawled": "Aug 14, 2019 7:30:31 PM",
    "content": "<p>*********************************************************************************************************</p><br /><p>No agencies or job seekers.</p><br /><p>Entrepreneurs seeking a developer with experience of image search and machine learning.&nbsp; Innovative and unique brand marketing platform.&nbsp; Working with CEO and CTO (full-stack engineer with 20 years experience) to shape and implement key functionality to showcase to investors. Collaborative, flexible, remote working. Ideally based near London but not essential. Contact us for an exploratory chat.&nbsp;</p><br /><p>Founders: Serial entrepreneurs/tech/marketing/publishing/academic with 25 year track record and over $250m Sales and $5m in Venture Fundraising.&nbsp;</p><br /><p>*********************************************************************************************************</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "viiFpAK4SJuNTN8shtpIdQ",
    "url": "https://www.remotepython.com/jobs/19f9a17c0f8b4e63a84421a1dde5c407/",
    "title": "Machine Learning Scientist at DigitalMR",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:caffe/bigdata-ml/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/24",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:theano/bigdata-ml/8",
      "DBG_TECH1:k/t/w:torch/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=1, go=0, nodejs=0, bigdata-ml=88, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalMR",
      "sameAs": "https://www.digital-mr.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 6:23:57 PM",
    "validThrough": "Aug 21, 2019 6:23:57 PM",
    "crawled": "Aug 14, 2019 6:23:57 PM",
    "content": "<h3>Machine Learning Scientist</h3>London, United Kingdom<br>Company: DigitalMR<br>Job Type:&nbsp;Full-time<div>                              <div>                      </div>                    <p></p><p>Applications are invited for a Machine Learning Scientist who will use existing IP developed and implemented to deliver projects to DigitalMR clients. DigitalMR is a tech company with proprietary solutions for market research. Our young and diverse team uniquely combines the skill-sets of software engineers, data scientists and market researchers.  They create commercial tools and applications that collect data in smart ways, which are then turned into business actionable insights for some of the world’s most demanding clients. We are a growing company that can offer a lot of encouragement and support, looking for the right candidate to join our team.<br><br>DigitalMR is a remote-first company, with team members in various countries around the world. The successful candidate will work remotely. Occasional travel to meet collaborators and client visits may be required.</p><p><strong>Role and Responsibilities</strong></p><ul><li>Implement and evaluate models and software prototypes of machine learning processing</li><li>Train, validate and systematically test algorithms with large text and image data sets</li><li>Meet accuracy targets for sentiment and semantic analysis</li><li>Maintain relationships with relevant external collaborators and realise knowledge transfer</li><li>Work closely with a dynamic team of software engineers and market researchers to realise applications that may include sentiment, emotions, topics, and trends extraction, social propagation, and social influence</li><li>Arrange integration of tested algorithms with the company’s platforms and data systems</li><li>Document system performance and incorporate customer feedback</li><li>Other tasks assigned by the CTO/CEO</li></ul><p><strong>Qualifications, Experience &amp; Skills:</strong></p><ul><li>Masters, PhD, or equivalent experience in a quantitative field (Machine learning, Computer vision, Computer Science, Applied Mathematics, Engineering, etc.)</li><li>Track record in machine learning techniques</li><li>Familiarity with deep learning libraries such as Torch, Theano, Caffe, or PyBrain</li><li>Hands-on experience coding in one of the following: C/C++, Java, Python</li><li>Positive attitude and good interpersonal, communication and teamwork skills; a great fit with the <a href='http://www.digital-mr.com/mission-values' rel='nofollow'>company's values</a></li><li>Ability to solve complex problems in a fast-­paced environment with limited guidance</li></ul><p><strong>Desirable Skills:</strong></p><ul><li>Digital image processing / computer vision experience</li><li>Amazon EC2 familiarity</li><li>­Organisational skills both in management of time and software code in an agile framework.</li><li>Hadoop ecosystem experience</li><li>Methods for learning imbalanced datasets</li></ul><p><strong>The above role offers:</strong></p><ul><li>Employment with an award winning ­growing international company</li><li>Be a key part of very forward-thinking projects in social media analytics</li><li>­Flat structure, no bureaucracy, no red tape</li><li>Competitive salary and performance bonus</li><li>Company share options</li></ul><p></p>                      <h4>Desired Skills</h4>            <ul>                              <li><span>Artificial Intelligence</span></li>                              <li><span>Big Data</span></li>                              <li><span>Data Science</span></li>                              <li><span>Machine Learning</span></li>                          </ul>                                <h4>How to Apply</h4>            <p></p><p>Please send a copy of your CV to recruitment@digital-mr.com and click on the 'Apply' button to fill out a short application form.</p><p></p>                                <h4>Contact Info</h4>            <ul>              <li><strong>Contact Name:</strong> Brathep</li>              <li><strong>Contact Email:</strong> <a href='mailto:recruitment@digital-mr.com' rel='nofollow'>recruitment@digital-mr.com</a></li>              <li><strong>Company Website:</strong> <a href='https://www.digital-mr.com/' rel='nofollow'>https://www.digital-mr.com/</a></li>            </ul>                  </div><a href='https://forms.gle/7WAMhhZcB6kP3pF7A' rel='nofollow'>Apply</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vHwbuyU5S6yw9s3GJNjMeQ",
    "url": "https://weworkremotely.com/remote-jobs/catch-co-data-engineer",
    "title": "Catch Co: Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Catch Co",
      "sameAs": "http://www.catchco.com"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 6:22:13 PM",
    "validThrough": "Aug 21, 2019 6:22:13 PM",
    "crawled": "Aug 14, 2019 6:23:04 PM",
    "content": "<h3> Data Engineer </h3><div><div><h4>DESCRIPTION</h4></div><div><strong>Position Overview:</strong><br></div><div>The Catch Company is looking for a Data Engineer to support our Analytics team. The Analytics team is looking to grow and improve our analytics tech stack to enable smarter and faster business decisions, automated processes, and personalized customer experiences.<br></div><div>In this role, you will own the development and maintenance of our analytics tech stack and will be instrumental in identifying and implementing new technologies and tools to support our goals. While we already have a robust analytics / business intelligence ecosystem in place, we believe the right Data Engineer can push our team to become industry leaders in enabling smarter decision-making and personalizing our customer experience via new technologies and approaches. Our current tech stack includes:&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Faws.amazon.com%2Fredshift%2F' rel='nofollow'>Redshift</a>&nbsp;(warehouse),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Ffivetran.com%2F' rel='nofollow'>Fivetran</a>/<a href='https://workable.com/nr?l=https%3A%2F%2Fwww.stitchdata.com%2F' rel='nofollow'>Stitch Data</a>/custom pipelines (ETL),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Fwww.getdbt.com%2F' rel='nofollow'>dbt</a>&nbsp;(transformation),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Flooker.com%2F' rel='nofollow'>Looker</a>&nbsp;(visualization), and a variety of other services that support one-off tools (e.g., Jupyter notebooks, Amazon EC2, etc.).<br></div><div>Additionally, we welcome both local (Chicago) and remote candidates for this role! Our analytics team is partially remote and our engineering team is fully remote.</div><div><br></div><div><strong>What makes this a special opportunity:</strong><br></div><ul><li>You will have broad freedom to change and improve the way we do things as the only Data Engineer on the team</li><li>You will have the opportunity to be a thought leader when it comes to selecting new technologies; you will be responsible for identifying and implementing new tools and technologies</li><li>You will work with people who are eager to use data to improve our product offerings, our customer experience, and other key components of the business</li><li>We place a premium on building a great culture made up of great people</li><li>You will work with and learn from experienced leaders who have a track record of building successful companies</li><li>We are based in Chicago’s West Loop (one of the best restaurant neighborhoods in the world), with easy access to all major public transportation systems</li></ul><div><span><br></span></div><div><strong>What you will do:</strong><br></div><ul><li>Own the maintenance and development of our analytics tech stack, including identifying and implementing new tools, managing utilization, and improving performance</li><li>Model and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it</li><li>Re-structure our processes for ingesting and analyzing website event data to a) Capture more usable, relevant data and b) Use technologies like Spark that allow for faster data transformation</li><li>Build custom data pipelines that reliably provide clean, ready-to-analyze data and develop systems that monitor those pipelines to ensure their health</li><li>Work closely with our software engineers to identify new opportunities for data collection (with a focus on personalization/recommendation systems) and build the processes to make that data available in our data warehouse</li><li>Identify use cases for real-time/streaming analytics and select and implement tools to support those use cases</li><li>Research and surface new ideas and approaches, whether new technologies, tools, frameworks, or process improvements for the team</li></ul><div><h4>REQUIREMENTS</h4></div><div><strong>What experience you need:</strong><br></div><ul><li>Experience working in data engineering, data architecture, or another similar field</li><li>Extensive experience manipulating data using SQL</li><li>Experience using Git to version/manage code</li><li>Fluency in one or more programming languages such as Python, Java, Go, etc.</li><li>Experience working with relational databases/data warehouses</li><li>Familiarity with ETL tools</li><li>Familiarity with business intelligence/visualization tools</li><li>[Optional/Preferred]: Experience building custom data pipelines</li><li>[Optional/Preferred]: Experience structuring and analyzing high volumes of website event data (e.g., impressions, views, clicks, etc.)</li><li>You must be eligible to work in the United States; visa sponsorship is not available</li></ul><div><span><br></span></div><div><strong>What will make you successful:</strong><br></div><ul><li><strong>Curiosity</strong>: Always seeking to understand “why”, always looking to make things better.</li><li><strong>Passion</strong>: You are driven by a love for what you do</li><li><strong>Optimism</strong>: The ability to bounce back quickly when something doesn’t work</li><li><strong>Action</strong>: Knowing when to shift from planning to doing</li><li><strong>Honesty</strong>: Transparency with customers, partners and teammates</li><li>Entrepreneurial spirit</li><li>Data-driven mindset</li><li>An interest in / passion for the outdoors (fishing knowledge not required!)</li></ul><div><h4>BENEFITS</h4></div><ul><li>&quot;Take what you need&quot; PTO Policy</li><li>4 additional paid days off specifically to enjoy the outdoors</li><li>Flexible working schedule</li><li>Ability to work from home if there is a need</li><li>Medical, Dental and Vision Insurance - We cover 85% of your premium and 50% for dependents</li><li>Health Savings Account</li><li>401(K) plan</li><li>Pre-Tax Commuter Benefits</li><li>Unlimited fruit snacks</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "FJMEMfJVRhSmyp3uIJ7_Yg",
    "url": "https://jobmote.com/job/60844/machine-learning-scientist-remote-any-country/",
    "title": "Machine Learning Scientist - REMOTE, ANY COUNTRY",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:caffe/bigdata-ml/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:express/nodejs/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:theano/bigdata-ml/8",
      "DBG_TECH1:k/t/w:torch/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=1, go=0, nodejs=8, bigdata-ml=66, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalMR",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 13, 2019 10:07:32 PM",
    "validThrough": "Aug 16, 2019 10:07:32 PM",
    "crawled": "Aug 14, 2019 3:06:25 AM",
    "content": "<div>Applications are invited for a Machine Learning Scientist who will use existing IP developed and implemented to deliver projects to DigitalMR clients.<p><strong>DigitalMR is a remote-first company, with team members in various countries around the world. The successful candidate will work remotely in the country they are currently based.</strong> Occasional travel to meet collaborators and client visits may be required.<br><br></p> <p><strong>Role and Responsibilities</strong></p> <ul><li>Implement and evaluate models and software prototypes of machine learning processing</li> <li>Train, validate and systematically test algorithms with large text and image data sets</li> <li>Meet accuracy targets for sentiment and semantic analysis</li> <li>Maintain relationships with relevant external collaborators and realise knowledge transfer</li> <li>Work closely with a dynamic team of software engineers and market researchers to realise applications that may include sentiment, emotions, topics, and trends extraction, social propagation, and social influence</li> <li>Arrange integration of tested algorithms with the company's platforms and data systems</li> <li>Document system performance and incorporate customer feedback</li> <li>Other tasks assigned by the CTO/CEO<br><br></li> </ul><p><strong>The above role offers:</strong> </p> <ul><li>Employment with an award winning ­growing international company</li> <li>Be a key part of very forward-thinking projects in social media analytics</li> <li>­Flat structure, no bureaucracy, no red tape</li> <li>Competitive salary and performance bonus</li> <li>Company share options</li> </ul><p><strong>Qualifications, Experience &amp; Skills:</strong></p> <ul><li>Masters, PhD, or equivalent experience in a quantitative field (Machine learning, Computer vision, Computer Science, Applied Mathematics, Engineering, etc.)</li> <li>Track record in machine learning techniques</li> <li>Familiarity with deep learning libraries such as Torch, Theano, Caffe, or PyBrain</li> <li>Hands-on experience coding in one of the following: C/C++, Java, Python</li> <li>Positive attitude and good interpersonal, communication and teamwork skills; a great fit with the company's values </li> <li>Ability to solve complex problems in a fast-­paced environment with limited guidance</li> </ul><p><strong><br>Desirable Skills:</strong></p> <ul><li>Digital image processing / computer vision experience</li> <li>Amazon EC2 familiarity</li> <li>­Organisational skills both in management of time and software code in an agile framework.</li> <li>Hadoop ecosystem experience</li> <li>Methods for learning imbalanced datasets</li> </ul><p><strong>To express your interest in this role, please click on the 'Apply' button below, and fill out this short application form .</strong></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YeTRPbaOQGWm_9r5d7QC_g",
    "url": "https://jobmote.com/job/60827/remote-machine-learning-engineer-retail-domain/",
    "title": "REMOTE - Machine Learning Engineer - Retail Domain",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/18",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 13, 2019 10:07:31 PM",
    "validThrough": "Aug 16, 2019 10:07:31 PM",
    "crawled": "Aug 14, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Machine Learning/Data Science, retail domain experience, Python, R, Inventory Optimization, Deep Neural Networks (DNN), TensowFlow, Machine Learning Algorithms, Order Management/fulfillment systems, Cloud Platforms: AWS/GCP/Azure<br><br>If you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please read on!<br><br>Top Reasons to Work with Us<br><br>We are a technology consulting firm specializing in delivering High Performing Omni Channel Fulfillment solutions to the retail vertical. We are passionate about building best of breed enterprise applications, keen on bringing top-notch technical insight to solving business problems that is focused on customer's success by operating with integrity and building a long term relationship. Our consultants are seasoned battle-tested engineers with many years of real-world experience.<br><br>What You Will Be Doing<br><br>You will be working remote to help build and scale our internal omni-channel fulfillment platform. This will involve utilizing machine learning algorithms and standing up machine learning platforms in the cloud. We are looking for someone who can both be hands on and be involved in over-arching architectural decisions.<br><br>What You Need for this Position<br><br>MUST HAVE:<br>- BS in related field<br>- 3+ years of machine learning/data science experience<br>- Strong Retail/E-Commerce industry experience<br>- Deep Neural Networks (DNN)<br>- Tensorflow<br>- Python/R<br>- Experience with machine learning algorithms<br>- Cloud services: AWS, GCP, or Azure<br>- Order Management/fulfillment systems or Inventory Optimization<br><br>What's In It for You<br><br>- Competitive Salary DOE<br>- Comprehensive Benefits Package<br>- Generous PTO<br>- 401k with match<br>- REMOTE WORK!So, if you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6CjYnE3zRA20bgsmgjsD_Q",
    "url": "https://remoteok.io/jobs/74477",
    "title": "Senior Backend Developer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angularjs/frontend/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "java"
    ],
    "hiringOrganization": {
      "name": "gomo video",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 12:10:24 AM",
    "validThrough": "Aug 21, 2019 12:10:24 AM",
    "crawled": "Aug 14, 2019 1:06:30 AM",
    "content": "<span></span> <span><h4>gomo video</h4></span> <br> <h3>Senior Backend Developer</h3> <div>  <div>   \\nWe are looking for an experienced back-end or full-stack developer to join our remote UK team.\\n\\n\\n\\nTell me about Instilled!\\n\\nInstilled is a new learning experience platform (LXP), meaning it is the very latest breed of learning delivery tools. Despite being new to the market, Instilled is built on a mature product with a solid client base and consolidates a wealth of experience and technology from our parent group. We are a small, agile team in a much larger learning technology business that is successful and passionate about creating outstanding learning tools.\\n\\nWhat Instilled provides is a YouTube like experience for learners to discover content and progress at their own pace—it was originally a video platform, so included are a host of video features such as auto-captioning, auto-translation and commenting etc.\\n\\nWe are still in the early stages of this products transformation but we have huge aspirations and want developers that relish the opportunity to create industry-leading products.\\n\\nHow will I know this is for me?\\n\\nFirst, this is a UK-specific role.&nbsp;Candidates must be eligible to work in the UK.&nbsp;Our team does have a US component, but we are not currently hiring for&nbsp;any US roles.\\n\\nOur ideal candidate is friendly, enthusiastic and just as passionate about technology as we are. The team spans multiple offices and time-zones so a self-starter attitude and excellent communication skills are key. We know not everyone has experience of the learning industry but that’s fine, we want people that understand code. Our current tech stack is comprised of Java, Spring, PostgreSQL, AngularJS, and others. These things change though, so whilst prior experience is advantageous, the key is being able to adapt to whatever technology the task demands. We look for developers that have an opinion about how technology can be applied, but remain equally open minded about new or different approaches. Working well in a team is vital as this role will be fundamental in shaping our product architecture - clearly articulating a concept and nurturing other team members is hugely important.\\n\\nOk, sounds great! What do I do?\\n\\nThis is a unique opportunity to join a dynamic product team that is taking an impressive client list in to a whole new world of learning. If this sounds like a good fit then we would like to hear from you. Please send over a cover letter explaining why and attach your CV. Feel free to outline any achievements you are particularly proud of and include a link to code you can share. Extra points for your best joke!  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ycO0VbbyTDuohVINZMH7aQ",
    "url": "https://jobmote.com/job/60694/remote-or-on-site-reference-data-analyst-mdm-right-to-hire/",
    "title": "REMOTE or ON SITE - REFERENCE DATA ANALYST (MDM) - RIGHT TO HIRE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SANS",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 12, 2019 10:07:28 PM",
    "validThrough": "Aug 15, 2019 10:07:28 PM",
    "crawled": "Aug 13, 2019 3:06:25 AM",
    "content": "<div><p>A Try &amp; Buy position at Major player in retirement finance. </p><p> Pay Options: IC - Self Incorporated or w2 . </p><p> Contact Susan Andaluz . call / ext.162 or email with the Job Code SA33532 or Click the Apply Now button (Sorry, NO 3rd Party (Subcontract) for this position!) . </p><p> Location: Remote or On Site (Windsor, CT - Braintree, MA - Atlanta, GA - Minneapolis, MN) </p><p> Skills required for the position: REFERENCE DATA, SQL, TIBCO EBX, ORCHESTRA NETWORK </p><p> Detailed Info: The Reference Data Analyst is a key role responsible for Enterprise Reference Data Management (RDM). </p><p> Act as business solution owner of the firms Reference Data Management (RDM) ecosystem, including tool configuration and operating processes </p><p> Working with Data Governance team to define Enterprise Reference Data Values </p><p> Map Source System Reference Data Values to the Enterprise Data Values </p><p> Act as the owner of enterprise reference data hierarchies (transaction taxonomies, industries, etc) </p><p> Accountable for data quality controls, measurement, and issue resolution </p><p> Partner with key roles, e.g. application analysts, data integration team, database administrators team, infrastructure team, and business constituents to maintain a robust and sustainable RDM system </p><p> Define detailed RDM processes, workflow tasks, data flows, and dependencies </p><p> Development/Computing Environment: For remote position, hands-on experience with Orchestra network or Tibco EBX is a must </p><p> Candidate should have good understanding of data management concepts (data governance, data modeling, data quality, data lineage, master data management, metadata management, data analytics, etc) </p><p> Strong business and technical background in the area of Master &amp; Reference Data Management </p><p> SQL proficiency </p><p> Proficiency in creating source-to-target mapping, including handling complex taxonomies </p><p> Background in finance (ideally in insurance or retirement services) </p><p> For on site position, hands-on experience with Enterprise MDM tools like Informatica, IBM, Talend, Orchestra network, Tibco EBX, etc is a plus </p><br><p> . </p><p> The position offers competitive rate for a contract and an opportunity for full scale compensation package for F/T empoyee position. </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "hrszm0zTRHe58oUEu1UYEg",
    "url": "https://jobmote.com/job/60659/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 12, 2019 10:07:27 PM",
    "validThrough": "Aug 15, 2019 10:07:27 PM",
    "crawled": "Aug 13, 2019 3:06:25 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IKY57wiYTUac5TRlJ_sKhw",
    "url": "https://jobmote.com/job/59526/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>Azure Big Data Engineer (Remote Flexibility)<br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.<br> *AZURE EXPERIENCE REQUIRED<br> Skills:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience with data pipeline and workflow management tools</li></ul>Benefits:<ul><li>Medical</li><li>Dental</li><li>Vision</li><li>Family leave</li><li>PTO</li><li>Retirement Plan</li><li>Remote options</li></ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br><br><b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZL0Zu53lQP2FBnrJui_FsA",
    "url": "https://jobmote.com/job/59525/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TNrx0oWNT0KRufsggJdQvQ",
    "url": "https://jobmote.com/job/59506/aws-data-engineer-150k-remote/",
    "title": "AWS Data Engineer- $150K- REMOTE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:21 PM",
    "validThrough": "Aug 14, 2019 10:07:21 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><b>AWS Big Data Engineer</b><br> As an AWS Big Data Engineer, you will be responsible to design and develop data pipelines using AWS Big Data tools and other modern technologies. You will play a crucial role in shaping the future of the big data and analytic initiatives for many of their clients. As an AWS Big Data Engineer, you will be helping organizations migrate to the cloud, transform their business and optimize their technical investment. You will also be responsible for developing products where you see gaps in client technologies and in the market! <br><b>Location:</b> Remote<br><b>Travel</b>: 25-30%<br><b>Salary:</b> $150-180K(based on experience)<br><b>Roles and Responsibilities:</b><ul><li>Work on large-scale Data projects</li><li>Build data pipelines using AWS Cloud services</li><li>Develop Python programming to streamline processes for the data ingestion</li><li>Recommend ways to improve data quality and reliability </li><li>Build data lakes and construct data pipelines for clients</li><li>Gather client requirements </li><li>Manipulate data using Python, SQL, NoSQL, and other standard tools and methods</li></ul><b>Skills and Qualifications:</b><ul><li>Bachelor's degree in Computer Science or equivalent</li><li>Skilled in data and analytic technologies</li><li>Extensive experience with Python, Scala, or Java programming</li><li>Must have experience with SQL and NoSQL environments</li><li>Extensive knowledge and hands-on experience with Big Data platforms (Hadoop, Kafka, Spark, NiFi, HBase, etc.)</li><li>Hands on experience with AWS Cloud Services (Redshift, EC2, EMR, Kinesis, etc.)</li><li>Proficient in creating data pipelines</li><li>AWS Big Data speciality or Solutions Architect Professional Cert- a plus! </li></ul><b>Company Rewards:</b><ul><li>Competitive base salary</li><li>Health, Dental, and Vision plans</li><li>Paid vacation and holidays</li><li>Work/life Balance</li></ul><b>Contact Details:</b> Looking to fill this position immediately. If interested, please contact [Click Here to Email Your Resum?] or call .<br> Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professional on the planet. Back by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.<br> At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivaled customer experience. Work with us and you'll get the personalized experience you deserve- one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "4jJZhKU6Qveelvz-s3qSRQ",
    "url": "https://jobmote.com/job/59529/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UQHuaQWGSGy94AxCxZ6iAg",
    "url": "https://jobmote.com/job/59523/nlu-nlp-architect-or-engineer-remote/",
    "title": "NLU NLP Architect or Engineer REMOTE",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Collabera",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>Position/REQ ID: ? NLP Architect <br>Location: RTP or SJ areas, can be remote <br>Duration: 11 Months <br>? <br>MUST HAVES <br>Strong knowledge of the Machine Learning techniques around natural language<br>Experience implementing enterprise scale NLU based IVR solution(s).<br>Strong knowledge IVR based application development and Conversational IVR.<br>Experience in Dialogflow OR other NLP engine models such as<br>Good knowledge on building conversational IVR (Interactive Voice Response) flows using Dialog flow<br>Experience with machine learning techniques within NLP such as tokenization, parts of speech tagging, stemming, lemmatization, named entity recognition, sentiment analysis, TF-IDF, topic modeling, bag of words, word vectors, language modeling, seq2seq, LSTMs, Transformers <br>? <br>PLUSSES <br>Programming experience in Node JS, Python, SQL, NoSQL, Java, Graph Databases a plus<br>Strong knowledge of applicable methodologies, tools, standards, and procedures.<br>Experience in Big Data platform handling large volumes of data and have experience in data processing and storage. <br>DAY-TO-DAY <br>Implement NLU/NLP solutions to extract value from Install Base data.<br>Be the in-house NLP expert, lead NLP initiatives, review the deliverables and set standards and guideline<br>Develop design principle for developing new dialog flows.<br>Help cultivate organization-wide best practices for NLP and Coach and Mentor other members of the team<br>Deconstruct customer-agent conversations to programmatically extract concepts and relationships between concepts in various conversation scenarios.<br>Work with various business lines like? Sales and Marketing to identify opportunities for NLP and recommend them into actionable data science projects.<br>Guide the data engineers to design data pipelines to effectively store, normalize and access text data. <br>?<br><br>NLP,NLU,IVR, Dialogflow<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "x_O3qHhgTJmNXpIfnCUyOQ",
    "url": "https://jobmote.com/job/59493/sql-data-analyst-telecommute/",
    "title": "SQL Data Analyst - Telecommute",
    "tags": [
      "DBG:surround``3N(telecommut, posit) NOT fulltim",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=1, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UnitedHealth Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:21 PM",
    "validThrough": "Aug 14, 2019 10:07:21 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><br>No industry is moving faster than health care. And no organization is better positioned to lead health care forward. We need attention to every detail with an eye for the points no one has considered. The rewards for performance are significant. You'll help improve the health of millions. And you'll do your life's best work.(sm)<br><br>The primary role of the Data Analyst is to develop effective and high quality healthcare program integrity analytics that meet business requirements. Technical abilities include following team and industry coding best practices, data analysis, performance tuning, unit testing, and system testing support utilizing SQL, Python, and other similar tools.<br><br>You'll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.<br><br><b><br><b>Primary Responsibilities:</b></b><br><br>Develop healthcare payment integrity analytics <br>Write complex SQL queries to validate data <br>Understand data structure and content, perform query tuning <br>Support business analysts; translate business requirements to technical specifications<br><br><b><br><b>Required Qualifications:</b></b><br><br>5+ years of Data Analysis experience using SQL <br>2+ years of experience in health care payment integrity analytics and working with large data sets <br>Proficiency coding overpayment analytics using SQL <br>Knowledge of medical coding concepts (Claims data, Procedure codes, Diagnosis codes, Provider and Member data)<br><br><b><br><b>Preferred Qualifications:</b></b><br><br>Bachelor's degree or equivalent experience <br>Cognos/Tableau report development experience <br>Other tools/languages - Python, JavaScript, R, Spark<br>Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)<br><br>*All Telecommuters will be required to adhere to UnitedHealth Group's Telecommuter Policy.<br><br><b>Diversity creates a healthier atmosphere:</b> UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.<br><br>UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.<br><br><b>Job Keywords:</b> SQL Data Analyst, telecommute, telecommuter, remote, work from home<br><br><b>Job Title: </b> SQL Data Analyst - Telecommute <br><b>Shift: </b> Day Job <br><b>Travel: </b> No <br><b>Business: </b> Optum Ops-Transactions <br><b>Family: </b> Analytics <br><b>Telecommuter Position: </b> Yes <br><b>Job Level: </b> Individual Contributor <br><b>Overtime Status: </b> Exempt <br><b>Posted Date: </b> 8/9/2019 <br><b>City: </b> Eden Prairie <br><b>State: </b> MN <br><b>Country: </b> United States <br><b>Department: </b> Optum Ops-Shared Svcs Analytcs<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gKyvR_aPQjKo_E5gcxMttg",
    "url": "https://remote.co/job/backend-engineer-20/",
    "title": "Backend Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:node.js/nodejs/13",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:sass/frontend/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=15, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=18}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "Dotscience",
      "sameAs": "https://www.dotscience.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 8:08:24 PM",
    "validThrough": "Aug 18, 2019 8:08:24 PM",
    "crawled": "Aug 11, 2019 8:32:10 PM",
    "content": "<h3>Backend Engineer at <span>Dotscience</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>REMOTE</strong>&nbsp;London, England, United Kingdom Engineering BE-01</p><p><strong>DESCRIPTION</strong></p><p><strong>NOTE:&nbsp;This role is remote-only, and you need to be living in, and have a right to work in, one of the following countries: UK, Germany, France, Ireland or USA. We are mostly based in the UK and so the ability to co-ordinate with this timezone is needed.</strong></p><p><strong>About Dotscience</strong></p><p>Dotscience is a startup founded in 2017 and funded by DDN, the world’s largest privately-held storage company. Its mission is to build an end-to-end data science platform that holds AI accountable for its decision making.</p><p>We like to see ourselves as a very friendly and high-trust team. Because we are fully remote we are able to be flexible about parenting responsibilities and other things in life that need your attention. We co-ordinate once a day in a standup where we check in to say how things are going and tell jokes (it is part of our standup routine). The rest of the time we collaborate through GitHub, Slack, Google Hangouts and Google Docs.&nbsp;<strong>We get together in person every 6-8 weeks for a couple of days somewhere in the UK, where we socialise and build our relationships.&nbsp;</strong>We do get some work done too, but it’s mainly about face time. We try to do something fun and we mix up the venues and locations. Sometimes it’s in a WeWork, but sometimes we hire a holiday cottage and have jam sessions! We see our fair share of babies at our meetings, either in person for a visit and a cuddle, or on our video calls.</p><p>The culture in the Engineering team is very collaborative and within the company all discussions are open by default. Everyone is listened to and nobody gets a special pass to push decisions through. You would be a fit for us if you care about how and why things work, engineering quality and user value. We would be a fit for you if you want a supportive, flexible, high-trust work environment where you are encouraged to grow your role at a pace to suit you.</p><p><strong>About the role</strong></p><p>NOTE: We are looking for a number of engineers across the stack, so we’re flexible about exactly which roles we hire into regarding frontend, backend and full stack.</p><p><strong>Tech We Use</strong></p><p><strong>Front-end</strong></p><ul><li>Javascript</li><li>React</li><li>Redux</li><li>CSS</li><li>SCSS</li></ul><p><strong>Back-end</strong></p><ul><li>Go (core)</li><li>Python (knowledge of)</li><li>PostgreSQL</li><li>Javascript</li><li>Node.js</li></ul><p><strong>Infrastructure</strong></p><ul><li>Docker / Kubernetes</li><li>AWS / GCE</li><li>Gitlab / Github</li></ul><p>Aims</p><p><strong>Work with the team to:</strong></p><ul><li>Develop a product which is robust and scalable for cloud and on-premise use</li><li>Design and create services and system architecture</li><li>Ensure the product is built to deliver a good user experience</li></ul><p><strong>Responsibilities</strong></p><ul><li>Design and build our data science platform collaboratively with the team</li><li>Using tech from the list above</li><li>Collaborate through pair programming, attending meetings and being an active member in the self-organising team.</li><li>Help improve our code quality through writing unit tests, automation and performing code reviews</li><li>Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products</li><li>Work with the product and design teams to understand end-user requirements, formulate use cases, and then translate that into a pragmatic and effective technical solution</li><li>Work within the scrum framework to deliver product value to a regular cadence.</li><li>Provide support as part of a rota.</li><li>Write user documentation for the work you do.</li></ul><p><strong>REQUIREMENTS</strong></p><p><strong>Experience</strong></p><ul><li><strong>Degree-level education (or comparable experience) in STEM or another relevant area.</strong></li><li>Good understanding and plenty of practical experience in a statically typed programming language. We use Go, so we’d need you to learn it on the job if you don’t know it already.</li><li>Good understanding and plenty of practical experience in a scripting language.</li><li>Some familiarity with containers from an architectural perspective.</li></ul><p><strong>Personal skills</strong></p><ul><li>Good communication and teamwork skills.</li><li>A preference for being organised and dependable.</li><li>Keen to learn and share knowledge.</li><li>A tendency to question things, to be critical and enquiring.</li><li>Comfortable with change and pragmatic decision making.</li><li>Happy to work under time pressure occasionally.</li><li>Able to manage own time.</li><li>Know when to ask for help or input.</li><li>Know when to give feedback to others.</li></ul>        </div><div>        <a href='https://dotscience.workable.com/j/8C9F0DBB3D' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ovcQcJ0xQu2uYJok1b__tw",
    "url": "https://jobmote.com/job/59449/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "JydIJVcyQaatBSqBlfX3SA",
    "url": "https://jobmote.com/job/59447/remote-servicenow-developer/",
    "title": "Remote ServiceNow Developer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nelson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div><b>Remote ServiceNow Developer-Arlington, VA</b><br> Job Description:<br> Remote ServiceNow Developer-Arlington, VA<br> A modern fast growing digital consulting firm based in Arlington, VA is seeking a ServiceNow Developer. Voted one of the best places to work, this firm is looking for a creative individual to manage key company assets through the ServiceNow platform. You will join a team of outcome-driven ServiceNow professionals.<br> As the ServiceNow Developer you will be responsible for using the NOW platform to manage assets and having knowledge of IT Asset Management/ working with CMDB. You will be an essential technical resource to develop client solutions, track the contractual, financial, and inventory details of hardware/devices throughout the lifecycle.<br> Essential Requirements:<ul><li>3+ years' experience with ServiceNow platform</li><li>2+ years' experience with ServiceNow IT Asset Management</li><li>Knowledge of ServiceNow Discovery and CMDB</li><li>JavaScript Experience</li><li>Excellent communication skills and the ability to work within a team</li><li>Must be a U.S Citizen or Permanent Resident</li><li>Eligible for Public Trust Clearance</li><li>ServiceNow System Admin Certification / ServiceNow Implementation Specialist Certification</li></ul> This company is offering an above market rate salary and generous benefits. The firm is currently interviewing and looking to hire immediately.<br> If you think this company is a great fit for you, please send your CV to [Click Here to Email Your Resum?] and/or call . Ask for Mackenzie regarding a confidential career scanning and to further discuss the opportunity.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "iMeo1tBrTkCyoXJP-NajQQ",
    "url": "https://jobmote.com/job/59443/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UWNwpwABTt-9_xY9SgfdQA",
    "url": "https://jobmote.com/job/59442/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "hTWVNoHsTkexqIAgI-FR7g",
    "url": "https://jobmote.com/job/59431/big-data-engineer-remote/",
    "title": "Big Data Engineer(REMOTE)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/64",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:sql-server/dotnet/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=4, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=104, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Netserv-Applications Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div><b>Big Data Engineer</b><br><br>?<br><br>? 6-8 years of experience in ?data engineering with strong experience in Big Data using any Hadoop ecosystem and building Data Lakes using Hadoop<br><br>? Bachelor?s Degree in Computer Science, Engineering, and/or background in Mathematic and Statistics<br><br>? Experience on Big Data platforms (Cloudera/Horton Hadoop, Spark, HBase, Hive) , scripting using Python , Data Lakes using Hadoop<br><br>? Strong Database and Data warehousing background, Proficient with ETL tools like SSIS, Informatica and has strong SQL, PL/SQL or T-SQL skills<br><br>. Worked in data base environments like MS SQL Server, Oracle, Teradata or Netezza<br><br>. Worked in Agile project environment , good communication and leadership/team skills<br><br>. Any experience with MDM (Master Data Management) a plus<br><br>?<br><br>Location: Knoxville (REMOTE)<br><br>Start Date: Immediate<br><br>Type : Full Time<br><br>?<br><br>Visio<br><br>Technical Writing<br><br>Technical Communication<ul><li><b>Big Data Engineer</b><br><br>?<br><br>? 6-8 years of experience in ?data engineering with strong experience in Big Data using any Hadoop ecosystem and building Data Lakes using Hadoop<br><br>? Bachelor?s Degree in Computer Science, Engineering, and/or background in Mathematic and Statistics<br><br>? Experience on Big Data platforms (Cloudera/Horton Hadoop, Spark, HBase, Hive) , scripting using Python , Data Lakes using Hadoop<br><br>? Strong Database and Data warehousing background, Proficient with ETL tools like SSIS, Informatica and has strong SQL, PL/SQL or T-SQL skills<br><br>. Worked in data base environments like MS SQL Server, Oracle, Teradata or Netezza<br><br>. Worked in Agile project environment , good communication and leadership/team skills<br><br>. Any experience with MDM (Master Data Management) a plus<br><br>?<br><br>Location: Knoxville (REMOTE)<br><br>Start Date: Immediate<br><br>Type : Full Time<br><br>?</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "dr9XvYKyQKyHibwUIrDjHg",
    "url": "https://jobmote.com/job/59322/aws-data-engineer-150k-remote/",
    "title": "AWS Data Engineer- $150K- REMOTE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 10:07:32 PM",
    "validThrough": "Aug 12, 2019 10:07:32 PM",
    "crawled": "Aug 10, 2019 3:06:25 AM",
    "content": "<div><br><br><p><strong>AWS Big Data Engineer</strong></p><br><p>As an AWS Big Data Engineer, you will be responsible to design and develop data pipelines using AWS Big Data tools and other modern technologies. You will play a crucial role in shaping the future of the big data and analytic initiatives for many of their clients. As an AWS Big Data Engineer, you will be helping organizations migrate to the cloud, transform their business and optimize their technical investment. You will also be responsible for developing products where you see gaps in client technologies and in the market! </p><br><p><strong>Location:</strong> Remote</p><br><p><strong>Travel</strong>: 25-30%</p><br><p><strong>Salary:</strong> $150-180K(based on experience)</p><br><p><strong>Roles and Responsibilities:</strong></p><br><ul><li><br></li><li>Work on large-scale Data projects<br></li><li>Build data pipelines using AWS Cloud services<br></li><li>Develop Python programming to streamline processes for the data ingestion<br></li><li>Recommend ways to improve data quality and reliability <br></li><li>Build data lakes and construct data pipelines for clients<br></li><li>Gather client requirements <br></li><li>Manipulate data using Python, SQL, NoSQL, and other standard tools and methods<br></li></ul><br><p><strong>Skills and Qualifications:</strong></p><br><ul><li><br></li><li>Bachelor's degree in Computer Science or equivalent<br></li><li>Skilled in data and analytic technologies<br></li><li>Extensive experience with Python, Scala, or Java programming<br></li><li>Must have experience with SQL and NoSQL environments<br></li><li>Extensive knowledge and hands-on experience with Big Data platforms (Hadoop, Kafka, Spark, NiFi, HBase, etc.)<br></li><li>Hands on experience with AWS Cloud Services (Redshift, EC2, EMR, Kinesis, etc.)<br></li><li>Proficient in creating data pipelines<br></li><li>AWS Big Data speciality or Solutions Architect Professional Cert- a plus! <br></li></ul><br><p><strong>Company Rewards:</strong></p><br><ul><li><br></li><li>Competitive base salary<br></li><li>Health, Dental, and Vision plans<br></li><li>Paid vacation and holidays<br></li><li>Work/life Balance<br></li></ul><br><p><strong>Contact Details:</strong> Looking to fill this position immediately. If interested, please contact or call .</p><br><p>Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professional on the planet. Back by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.</p><br><p>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivaled customer experience. Work with us and you'll get the personalized experience you deserve- one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "cP8fGO7KTWiDjZ6rcKxdsw",
    "url": "https://jobmote.com/job/59309/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 10:07:32 PM",
    "validThrough": "Aug 12, 2019 10:07:32 PM",
    "crawled": "Aug 10, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MrDB_ac3Tu-TuM4D3KVj0w",
    "url": "https://stackoverflow.com/jobs/288152/software-engineer-create-devops-for-ai-dotscience?a=1yDvz3ma1BKM",
    "title": "Software Engineer | create 'DevOps for AI' platform & tools | 100% remote at Dotscience  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/32",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:go/go/15",
      "DBG_TECH1:k/t/w:golang/go/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:node.js/nodejs/65",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:shell/other/1",
      "DBG_TECH1:techWeightMap:{python=25, other=7, dotnet=0, c=0, mobile=0, go=52, nodejs=65, bigdata-ml=84, ruby=2, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "Dotscience via techfolk",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 60000,
      "maxValue": 80000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "GBP 60k - 80k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 8:30:25 PM",
    "validThrough": "Aug 16, 2019 8:30:25 PM",
    "crawled": "Aug 9, 2019 8:30:25 PM",
    "content": "<h3><span>Software Engineer | create 'DevOps for AI' platform &amp; tools | 100% remote</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>DevOps</span>                                    </div>                            </div>                    </div>                <div>Company: Dotscience via techfolk | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+00:00) London </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>go</div><div>node.js</div><div>python</div><div>docker</div>                <h4>Job description</h4>                <div><p>Dotscience is hiring remote back end software engineers to help tackle some of the considerable challenges ahead in developing AI for production use. We're mainly working in Go, plus Python and Node.js and we'll support your learning if you need to cross train.</p><p>Our end-to-end machine learning toolset helps our customers stabilise and scale their AI initiatives; from development to production, we help them track full evolution of models and metrics throughout the lifecycle. Think 'DevOps for ML'.</p><p>We're hiring someone to help architect and implement data science automation solutions and tooling. We’re building from the ground up, inheriting zero legacy code. Collaborating with our product and design teams, you'll develop a product which is robust and scalable for cloud and on-premise use. You'll also help us to integrate with, and to automate, most of the major AI/ML ecosystems as we build out our tech</p><p>We'll listen to your opinions and actively encourage you to make recommendations as to how we can improve our products.</p><p>Now is an exciting time to join us; we're hiring a range of skills across the stack and can potentially shape your role in ways that build upon your strengths.&nbsp;</p><p><strong><br>Example first projects</strong></p><ul><li>Building features on the Dotscience platform that enables data scientists to create, collaborate on and to manage their workflows</li><li>Building API’s and SDK’s to support data pipelines and model deployment</li><li>Scaling the platform to support large and complex data science workloads</li><li>Maintain an operational stack and infrastructure for back end services</li></ul><p><strong>We're looking for</strong></p><ul><li>Strong back end coding skills, using a statically typed programming language - we use mainly Go (Golang), plus Python and Node.js, and can support your transition and learning</li><li>A technical understanding of building AI/ML pipelines in research or production environments</li><li>Familiarity with Containers from an architectural perspective</li><li>Familiarity with a scripting language, such as Bash, Perl, Python, Ruby, Shell etc.</li><li>Solid understanding of Computing or AI - gained from practical application, or through education&nbsp;</li><li>Familiarity with the principles of Agile, automated testing and continuous delivery</li><li>Clear desire to learn, to improve and to share knowledge with colleagues</li><li>Considering senior to principal level remote back end jobs such as: Go Developer | Golang Developer | Python Developer | Node.js Developer | Back End Engineer | Lead Engineer | AI Tools Engineer | Machine Learning Developer | Artificial Intelligence Engineer | Data Scientist | etc.</li></ul><p><strong>Current stack - we'll welcome your influence</strong></p><p>Go (Golang) | Python | Node.js | PostgreSQL | Docker | Kubernetes | AWS | GCE | GitHub | GitLab | Tensorflow</p><p><strong>Salary and benefits</strong></p><ul><li>£60,000 to £80,000+ negotiable - we're keeping an open mind</li><li>Flexible and family friendly working environment - no core hours, work at the times that suit you</li><li>Remote workers package, including fully expensed work travel costs</li><li>25 days holiday + UK national/public holidays/local benefits | private medical cover | life cover/income protection insurance | group personal pension/contributory pension | conference involvement encouraged | open source projects include <a title=&quot;Tensorflow for Dotscience&quot; href='https://github.com/dotmesh-io/jupyterlab-tensorflow' rel='nofollow'>Tensorflow for Dotscience</a> and <a title=&quot;Jupyterlab plugins&quot; href='https://github.com/dotmesh-io/jupyterlab-plugin' rel='nofollow'>Jupyterlab plugins for Dotscience</a></li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/288152?reset=False&amp;ra=1yDvz3ma1BKM&amp;oqs=a%3D1yDvz3ma1BKM' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Dotscience</h4>            <div><p>Launched July 2019, Dotscience is funded by DDN, the world’s largest privately-held storage company. We're an innovation project being run like a start-up and we're looking for someone who cares greatly about how and why things work, about engineering quality and about user value. Our aim is to help data science and ML teams to collaborate, to build and to deploy AI models effectively. We believe that building and deploying ML models should be easy, fast and safe. Our mission is to build an end-to-end data science toolset that holds AI accountable for its decision making. An entirely distributed team, we collaborate through daily stand-ups and use tools such as GitHub, Slack, Hangouts and Google Docs. We also meet up every six-eight weeks, for example at a nice holiday cottage, to get to know each other better, to hold work sprints, to enjoy downtime together, and to discuss our mission plans. We offer a supportive, flexible, high-trust work environment, where you are encouraged to grow your role at a pace to suit you.</p><p><strong>Location:</strong> remote/work from home - within the UK, France, Germany and/or the US - please note that you need to be living in, and have the right to work in, one of these countries.</p><p><strong>Even if your CV isn't ready, please talk with Vittoria at techfolk to find out more:</strong></p><p>0117 318 2447 | <a href='mailto:hello@techfolk.co.uk' rel='nofollow'>hello@techfolk.co.uk</a> | @we_are_techfolk</p><p>RECRUITERS: <span>Dotscience has selected techfolk as its exclusive recruitment partner for this position and cold calling and speculative applications are not welcomed.</span></p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O7Zpst0tQb6yjFQVjPIewg",
    "url": "https://stackoverflow.com/jobs/288150/senior-data-scientist-remote-global-wallethub?a=1yDsZcj5hgAw",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 8:30:25 PM",
    "validThrough": "Aug 16, 2019 8:30:25 PM",
    "crawled": "Aug 9, 2019 8:30:25 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/288150?reset=False&amp;ra=1yDsZcj5hgAw&amp;oqs=a%3D1yDsZcj5hgAw' rel='nofollow'>Apply now</a></div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "va228XYgRD64DaJ2EJW1CQ",
    "url": "https://www.remoteage.com/remote-jobs/r14078-algorithms-software-engineer-r14078-ek/",
    "title": "R14078 Algorithms Software Engineer – R14078 EK",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/16",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:signal-processing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:signal-processing/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=5, dotnet=0, c=10, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "BOSE CORP wants you to send your resume to bk",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 5:37:24 PM",
    "validThrough": "Aug 16, 2019 5:37:24 PM",
    "crawled": "Aug 9, 2019 6:24:55 PM",
    "content": "<h3>            R14078 Algorithms Software Engineer – R14078 EK        </h3><div>United States, Massachusetts</div><div>Company: BOSE CORP wants you to send your resume to bk<p></p></div><div>                    <h4>Overview</h4>                    <p>R14078 ALGORITHMS SOFTWARE ENGINEER – R14078<br>Location: United States – Massachusetts – Stow</p><p>Industry: Automotive<br>Job Category: Engineering – Other Engineering<br>Algorithms Software Engineer</p><p>At Bose, we are passionate about helping people reach their fullest human potential so that they can feel more, do more, and be more. Working as a member of the Software Center of Excellence team, come astonish our Bose Automotive Division, obsessed with the details about our products, with your outstanding ability to create algorithms and software for a superlative audio experience in a car.</p><p>As an Algorithms Software Engineer, you will be part of a close-knit team within the Bose Automotive Software Center of Excellence. You will help implement cutting-edge audio processing algorithms on high-end automotive processors that lead to unique and exciting audio experiences. You will work with research teams to take acoustic concepts from prototype to implementation. You will also work with audio engineers around the world to create the best sound experiences based on these implementations.</p><p>Specific responsibilities:</p><p>Build software for algorithms related to music and voice processing in MATLAB, Simulink and C<br>Create high-level designs for software frameworks for these algorithms<br>Build comprehensive unit and system tests in software to verify functionality of these algorithms<br>Required skills and experience:</p><p>MS in Electrical or Computer Engineering with an emphasis on DSP or Communications<br>Thorough knowledge of C, Matlab and a scripting language such as Perl or Python<br>5 years of experience building signal processing software<br>Preferred skills and experience</p><p>Knowledge of the theory and implementation of adaptive filtering, sub-band filtering and other advanced filtering techniques<br>Knowledge of Simulink modeling and libraries<br>Job Location</p><p>Primary location – Stow, MA<br>Remote work capability will be considered for qualifying candidate to work remotely from the Greater Chicago (IL), Austin (TX), Washington, DC, Bloomfield Hills (MI), Esslingen (Germany), Montreal (Canada) areas</p><p>COMPENSATION<br>Base Salary – $GENEROUS ***ASK FOR WHAT YOU WANT ***<br>Full-time Benefits – Full<br>Relocation Assistance Available – Possible for ideal candidate</p><p>CANDIDATE DETAILS<br>7+ to 10 years experience<br>Seniority Level – Mid-Senior<br>Management Experience Required – No<br>Minimum Education – Bachelor’s Degree<br>Willingness to Travel – Occasionally</p><p>BOSE CORP wants you to send your resume to bk</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?t9dZgA5AE6GP%2bS8h5q584Qw' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "wCQw7zFjTXuv7lfBIopRng",
    "url": "https://news.ycombinator.com/item?id=20653780",
    "title": "Datadog | Full-time, Permanent Roles: Data Engineer | Software Engineer - Data Infra | ...",
    "tags": [
      "DBG:surround``remot 3N OR(options, avail, allow) NOT encourag",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=5, mobile=0, go=6, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 2:48:32 PM",
    "validThrough": "Aug 16, 2019 2:48:32 PM",
    "crawled": "Aug 9, 2019 4:09:08 PM",
    "content": "Datadog | Full-time, Permanent Roles: Data Engineer | Software Engineer - Data Infra | Distributed Systems Engineer (ALL AVAILABLE IN REMOTE US/NYC/BOSTON)<p>1) Data Engineer: Looking for engineers to work on realtime (Kafka + Kafka Connect + custom Go consumers) and batch systems (Spark on EMR + Dataproc + Luigi + Parquet + S3 and GCS) to process 100's of TBs daily - at times PB-scale per day. Apply here for BOSTON/NYC - <a href='https://grnh.se/f4127d5f1' rel='nofollow'>https://grnh.se/f4127d5f1</a> - if REMOTE US, email bryan.hughes@datadoghq.com.</p><p>2) Software Engineer - Data Infra: Engineers in our Data Infra team build and own all infrastructure required to transport, process and store data at scale. This team also owns the system that allows teams to schedule and execute their batch jobs on multiple cloud platforms in multiple regions. Apply here for BOSTON/NYC/REMOTE US - <a href='https://grnh.se/ef2ed6f51' rel='nofollow'>https://grnh.se/ef2ed6f51</a>.</p><p>3) Distributed Systems Engineer: Help us build the high-throughput, low-latency systems that power our product. These systems ingest, store, analyze, and query tens of millions of events per second from companies all over the globe. Looking for experience in Go and Python, with bits of C or other languages. Apply here for BOSTON/NYC - <a href='https://grnh.se/866fe22c1' rel='nofollow'>https://grnh.se/866fe22c1</a> - if REMOTE US, email bryan.hughes@datadoghq.com.</p><p>More details about Datadog here: <a href='https://www.datadoghq.com/' rel='nofollow'>https://www.datadoghq.com/</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "WeO8WCikQkuzk2wCFfy8iw",
    "url": "https://jobmote.com/job/58072/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 10:07:25 PM",
    "validThrough": "Aug 11, 2019 10:07:25 PM",
    "crawled": "Aug 9, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0DM6HDj4Q0aN7PaDN_GL2w",
    "url": "https://jobmote.com/job/58071/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 10:07:25 PM",
    "validThrough": "Aug 11, 2019 10:07:25 PM",
    "crawled": "Aug 9, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "dHV80z7xS4aghTGmerf4dA",
    "url": "https://news.ycombinator.com/item?id=20644843",
    "title": "Neuronalys | Engineers | Lille, FRANCE | Onsite or Remote, Full-Time, VISA | www.neuronalys.ai ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:cuda/bigdata-ml/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=10, mobile=0, go=0, nodejs=0, bigdata-ml=37, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 4:23:14 PM",
    "validThrough": "Aug 15, 2019 4:23:14 PM",
    "crawled": "Aug 8, 2019 6:24:50 PM",
    "content": "Neuronalys | Engineers | Lille, FRANCE | Onsite or Remote, Full-Time, VISA | www.neuronalys.ai<p>Neuronalys is a young startup, we create private SaaS deep learning solutions.</p><p>Our main product is in beta, tested with success by French law enforcement and will be released December 2019.We plan to launch an alpha for a second product in the middle of 2020. We created the specifications with companies in the energy and aeronautic fields. They are excited and waiting for this new product.</p><p>Our team is looking forward to welcoming 3 Engineers.- (2) ML/AI Engineers (computer vision) with good knowledge in Python / C- (1) ML/AI Engineer (text analysis) with good knowledge in Python / C(CUDA, video streaming, WebRTC is a bonus)</p><p>We care about people. We are constantly trying to improve the interactions in the teams and the balance between work/life. Ask us about it at jobs@neuronalys.ai</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "omunMD51Sfy2sm7TwcGhNw",
    "url": "https://remoteok.io/jobs/74390",
    "title": "Data Science Subject Matter Expert",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=100, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 4:27:36 AM",
    "validThrough": "Aug 15, 2019 4:27:36 AM",
    "crawled": "Aug 8, 2019 5:06:29 AM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Subject Matter Expert</h3> <div>  <div>   \\nPlease Apply Here\\n\\nEducation | Remote, USA | Contract\\n\\n\\nWho We Are\\nThinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;thinkful.com.\\n\\nJob Description\\nThinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp;\\n\\nResponsibilities\\n\\n\\n* Consistently deliver content that meets spec and is on time to support our program launch roadmap\\n\\n* Create daily lesson plans consisting of&nbsp;\\n\\n* Presentation decks that instructors use to lecture students on a given learning objective\\n\\n* Instructor notes that instructors use alongside&nbsp;\\n\\n* Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture\\n\\n* Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform\\n\\n* Creates code assets to support lesson plans, student activities, and written curriculum content\\n\\n* Iterates on deliverables based on user feedback\\n\\n\\n\\n\\nRequirements\\n\\n\\n* 3+ years of hands-on Data Science industry experience&nbsp;\\n\\n* Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning\\n\\n* Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)\\n\\n* Collaborative.You enjoy partnering with people and have excellent project management skills and follow through\\n\\n* Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations\\n\\n\\n\\n\\nCompensation and Benefit\\n\\n\\n* Contract position with a collaborative team\\n\\n* Ability to work remotely with flexible hours&nbsp;\\n\\n* Access to all available course curriculum for personal use\\n\\n* Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry\\n\\n* At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApply Here:\\n\\nhttps://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "APIITh3TSF6491Xsqlle8g",
    "url": "https://stackoverflow.com/jobs/287570/software-engineer-search-platform-wikimedia-foundation-inc?a=1yrph3USwgBG",
    "title": "Software Engineer, Search Platform at Wikimedia Foundation, Inc.  ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/8",
      "DBG_TECH1:k/t/w:java/mobile/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:php/php/15",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=5, mobile=4, go=0, nodejs=0, bigdata-ml=14, ruby=0, apple=0, java=11, gamedev=0, php=15, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TECH1/php",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java",
      "php"
    ],
    "hiringOrganization": {
      "name": "Wikimedia Foundation, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 1:06:24 AM",
    "validThrough": "Aug 15, 2019 1:06:24 AM",
    "crawled": "Aug 8, 2019 1:06:24 AM",
    "content": "<h3><span>Software Engineer, Search Platform</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Education Technology, eLearning, Non-Profit</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                            </div>                    </div>                <div>Company: Wikimedia Foundation, Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>java</div><div>php</div><div>machine-learning</div>                <h4>Job description</h4>                <div><p><strong>Summary</strong></p><p>Our small team is passionate about making knowledge discoverable. We are responsible for Wikidata Query Service (a graph database that allows users to run arbitrary SPARQL queries on Wikidata) and for the search engine used on Wikipedia and its sister projects.</p><p>We are looking for a software engineer to help us bring the Search Platform team to the next level.</p><p>We use open-source tools as much as possible, and always open source our own work. Java, Python, PHP, and Scala make up most of our code, but we value using the right tool for the job. Our world is vast and can be complicated, so we value communication, enthusiasm, and an eagerness to learn.</p><p><strong>You are responsible for:</strong></p><ul><li>Work and communicate clearly and effectively within a small team that spans multiple time zones</li><li>Help maintain, scale, and extend query services at the Wikimedia Foundation — this includes the Wikidata Query Service (WDQS) and our Elasticsearch-based search engine</li><li>Improve the integration of Search, Wikidata Query Service, and the MediaWiki platform</li></ul><p><strong>Skills and Experience:</strong></p><ul><li>Good working knowledge of software design principles</li><li>Good understanding of how to scale applications, in terms of load, complexity, and performance</li><li>Ability to work in a Linux server environment</li><li>Write code in Java and PHP that stands the test of time</li><li>Demonstrated experience in large-scale Java applications</li><li>Be willing to travel occasionally - sometimes internationally - for team and organizational meetings</li><li>Proficient English speaker</li></ul><p><strong>Additionally, we’d love it if you have:</strong></p><ul><li>Degree in computer science, statistics, math, physics or other quantitative discipline; equivalent experience learned hands-on on the job also works</li><li>Experience with graph databases</li><li>Experience working on open source, collaborative development projects</li><li>Understanding of free culture / free software / open source principles</li><li>Exposure to applied machine learning (ML), deep learning, or natural language processing (NLP)</li><li>Familiarity with statistics</li><li>Experience with an internet software environment operating at scale; for example, messaging platforms that process hundreds of thousands of events per second</li><li>Big thumbs ups if you are a contributor to Wikipedia</li></ul><p><em>Show us your stuff! If you have any existing open-source software that you've developed (this could be your own software or patches to other packages), please share the URLs for the source. Links to GitHub, etc. are especially useful.</em>&nbsp;&nbsp;</p><p><strong>U.S. Benefits &amp; Perks*</strong></p><ul><li>Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)</li><li>The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more</li><li>The 401(k) retirement plan offers matched contributions at 4% of annual salary</li><li>Flexible and generous time off - vacation, sick and volunteer days, plus 19 paid holidays - including the last week of the year.</li><li>Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.</li><li>For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program</li><li>Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses</li><li>Telecommuting and flexible work schedules available</li><li>Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax</li><li>Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people</li></ul><p><strong><em>*Eligible international workers' benefits are specific to their location and dependent on their employer of record</em></strong></p><p><strong>More information</strong></p><p><a href='https://wikimediafoundation.org/' rel='nofollow'><strong>WMF<br></strong></a><a href='https://wikimediafoundation.org/news/' rel='nofollow'><strong>Blog<br></strong></a><a href='https://meta.wikimedia.org/wiki/Strategy/Wikimedia_movement/2017' rel='nofollow'><strong>Wikimedia 2030<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimedia_Foundation_Medium-term_plan_2019' rel='nofollow'><strong>Wikimedia Medium Term Plan<br></strong></a><a href='https://wikimediafoundation.org/2018/08/30/diversity-inclusion-numbers/' rel='nofollow'><strong>Diversity and inclusion information for Wikimedia workers, by the numbers<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimania_2019' rel='nofollow'><strong>Wikimania 2019<br></strong></a><a href='https://annual.wikimedia.org/2017/' rel='nofollow'><strong>Annual Report - 2017</strong></a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/287570?reset=False&amp;ra=1yrph3USwgBG&amp;oqs=a%3D1yrph3USwgBG' rel='nofollow'>Apply now</a></div>            <h4>About Wikimedia Foundation, Inc.</h4>            <div><p><strong>The Wikimedia Foundation is...</strong></p><p>...the nonprofit organization that supports Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared&nbsp;knowledge,&nbsp;and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive&nbsp;<a href='https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&amp;uselang=en&amp;utm_medium=wmfWikiLink&amp;utm_source=B_FAQ&amp;utm_campaign=C_FAQ' rel='nofollow'>financial support</a>&nbsp;from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p><p><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Fully paid premiums for medical, dental &amp; vision insurance premiums</span>                            </li>                            <li>                                <span></span>                                <span>401(k) with 4% matching contribution</span>                            </li>                            <li>                                <span></span>                                <span>7-12 weeks parental leave with 100% pay + lactation room</span>                            </li>                            <li>                                <span></span>                                <span>Wellness Program ($1800 annual) to promote wellness &amp; personal growth</span>                            </li>                            <li>                                <span></span>                                <span>Pre-tax savings plans for Transportation &amp; Parking</span>                            </li>                            <li>                                <span></span>                                <span>Flexible work schedules and remote working options</span>                            </li>                            <li>                                <span></span>                                <span>Pet Friendly office</span>                            </li>                            <li>                                <span></span>                                <span>Commitment to diversity &amp; inclusion throughout the employee lifecycle</span>                            </li>                            <li>                                <span></span>                                <span>12 days vacation, 19 days holiday, 2 days volunteer work and more!</span>                            </li>                            <li>                                <span></span>                                <span>Lean more at https://wikimediafoundation.org/wiki/Work_with_us</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "p0IM97hPQ9eQxsuoHqOU9g",
    "url": "https://stackoverflow.com/jobs/287563/data-science-subject-matter-expert-thinkful-inc?a=1yrgfzf6U4wM",
    "title": "Data Science Subject Matter Expert at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/88",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:pandas/python/10",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=16, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=118, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 84000,
      "maxValue": 108000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 84k - 108k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 7, 2019 10:30:24 PM",
    "validThrough": "Aug 14, 2019 10:30:24 PM",
    "crawled": "Aug 7, 2019 10:30:24 PM",
    "content": "<h3><span>Data Science Subject Matter Expert</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>python</div><div>machine-learning</div><div>pandas</div><div>&nbsp;thinkful.com</div>                <h4>Job description</h4>                <div><p><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow' rel='nofollow'>Please Apply Here</a></p><p>Education | Remote, USA | Contract</p><strong>Who We Are</strong>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit<a href='https://www.thinkful.com/' rel='nofollow'>&nbsp;thinkful.com</a>.<strong>Job Description</strong>Thinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp;<strong>Responsibilities</strong><ul><li>Consistently deliver content that meets spec and is on time to support our program launch roadmap</li><li>Create daily lesson plans consisting of&nbsp;</li><li>Presentation decks that instructors use to lecture students on a given learning objective</li><li>Instructor notes that instructors use alongside&nbsp;</li><li>Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture</li><li>Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform</li><li>Creates code assets to support lesson plans, student activities, and written curriculum content</li><li>Iterates on deliverables based on user feedback</li></ul><strong>Requirements</strong><ul><li>3+ years of hands-on Data Science industry experience&nbsp;</li><li>Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning</li><li>Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)</li><li>Collaborative.You enjoy partnering with people and have excellent project management skills and follow through</li><li>Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations</li></ul><strong>Compensation and Benefit</strong><ul><li>Contract position with a collaborative team</li><li>Ability to work remotely with flexible hours&nbsp;</li><li>Access to all available course curriculum for personal use</li><li>Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry</li><li>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming<br><br></li></ul><p>Apply Here:</p><p>https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow</p>                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O-ZFPj2BTaiIIpSJx-ta8A",
    "url": "https://berlinstartupjobs.com/engineering/backend-developer-borg-collective-gmbh/",
    "title": "Backend Developer // Borg Collective GmbH",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``choos 5W locat",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:django/python/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=8, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "Borg Collective",
      "sameAs": "https://hive.one"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 7, 2019 10:57:10 AM",
    "validThrough": "Aug 14, 2019 10:57:10 AM",
    "crawled": "Aug 7, 2019 11:07:24 AM",
    "content": "<h3>Backend Developer // Borg Collective</h3><div> Company:  Borg Collective <br> <br></div><div> Tags:</div><div>  <p>We are a small team building algorithms analyzing social media and the cryptocurrency space. We are trying to find ways to describe groups of people mathematically. Some groups with well defined structures are easy, such as a company, government or an army. Others are hard: such as a village, academia or an online community interested in bitcoin. We are interested in the latter.</p>  <p>We believe this project can open the doors to solving the fundamental problems in decentralized systems design.</p>  <p><strong>These will be your tasks</strong></p>  <p>As a backend developer you’ll be responsible for managing things like scheduling background tasks, building API routes for our clients, and collecting and storing data from other APIs for use in our algorithms, all the while logging and fixing errors along the way. If you like working with MVC’s transforming and moving data in creative and efficient ways, this if for you.</p>  <p>We are also constantly finding new scaling challenges as we collect more data and users and need to readjust deployment on our servers. We need to manage communication between services, backups, testing, as well as resource management such as memory.</p>  <p><strong>Skills &amp; Requirements</strong></p>  <ul>   <li>Intermediate Python</li>   <li>A history of using MVC’s like Django or Rails</li>   <li>Basic MySQL</li>   <li>Docker</li>   <li>Be the type of person who is language independent and enjoys using new tech</li>   <li>Git</li>   <li>Basic crontab</li>  </ul>  <p><strong>Bonus</strong></p>  <ul>   <li>AWS</li>   <li>NGINX</li>   <li>Kubernetes</li>   <li>Github and its services</li>  </ul>  <p><strong>We’re offering these benefits</strong></p>  <ul>   <li>Work on hard &amp; fundamental problems</li>   <li>Equity options</li>   <li>Work from home or office or a cafe (whatever you prefer!)</li>   <li>Work visa sponsorship to Germany (if you wish to relocate)</li>  </ul>  <p><strong>How we work</strong></p>  <p>We are mostly a distributed team of 5 and growing. Most of the team members are located in Europe.</p>  <ul>   <li><strong>Choose your location:</strong> It would be ideal for you to work with the team in Berlin and we are happy to sponsor a German Work Visa for you. If it is not possible for you to work from Berlin we can also offer that you work remotely.</li>   <li><strong>Regular off-sites:</strong> At least every quarter we make a point for the team to meet in person and work together for a couple of days. We typically rent a big house where we live and work for several days.</li>   <li><strong>Communication:</strong> We use the following tools at work: Slack for instant messaging Asana for task management Standup Alice (Slack bot) for weekly stand-ups 1:1 calls on per need basis</li>   <li><strong>Working time:</strong> We currently do not track your hours worked (eg. Mon-Fri 9-5) however we do expect you deliver results on tasks. We do expect that you will be available on Slack in the afternoon, Central European Time (GMT+1).</li>   <li><strong>Office:</strong> Most of us currently work remotely from home, cafés etc. and you are welcome to do the same. If you work with us in Berlin you can join us in our coworking space to get more of an “office culture”.</li>  </ul>  <p><strong>Culture of Critical Thinking</strong></p>  <p>One of the biggest risks we face is that we can fool ourselves into believing that we got something to work when we in fact did not. This is because verifying accuracy of our algorithm’s outputs takes a long time and significant infrastructure. This means that an experiment that was not well-thought through enough can lead us to wasting months of work. We cannot afford that. For this reason, it is essential that we build a culture around critical thinking and closely follow the scientific method.</p>  <p>If you are not familiar with Critical Thinking &amp; the Scientific Method, we encourage you to watch the following videos before having a chat with us:</p>  <p>Critical Thinking Course</p>  <p>Richard Feynman discussing the Scientific Method</p>  <p><strong>Big no-no’s</strong></p>  <ul>   <li>Calls to authority (“I’ve been doing this for 20 years and you’re just an intern, we’ll do it my way”; “world’s top experts agree that…”)</li>   <li>Discrediting ideas based on their public perception (“If you think that you are a X, Y, Z”)</li>  </ul>  <p>Please include your GitHub account or some kind of portfolio of works within your CV/resume.</p> </div><a href='https://hive.join.com/jobs/292604-backend-developer?pid=98c1261599ca17c51388&amp;utm_source=berlinstartupjobs&amp;utm_medium=paid&amp;utm_campaign=singlepostingstandard&amp;utm_content=backenddeveloper' rel='nofollow'>Apply for this position</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zFgtA6SRRkqYy2JGFAGa_Q",
    "url": "https://jobmote.com/job/57726/remote-machine-learning-engineer-retail-domain/",
    "title": "REMOTE - Machine Learning Engineer - Retail Domain",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/18",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 10:07:24 PM",
    "validThrough": "Aug 9, 2019 10:07:24 PM",
    "crawled": "Aug 7, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Machine Learning/Data Science, retail domain experience, Python, R, Inventory Optimization, Deep Neural Networks (DNN), TensowFlow, Machine Learning Algorithms, Order Management/fulfillment systems, Cloud Platforms: AWS/GCP/Azure<br><br>If you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please read on!<br><br>Top Reasons to Work with Us<br><br>We are a technology consulting firm specializing in delivering High Performing Omni Channel Fulfillment solutions to the retail vertical. We are passionate about building best of breed enterprise applications, keen on bringing top-notch technical insight to solving business problems that is focused on customer's success by operating with integrity and building a long term relationship. Our consultants are seasoned battle-tested engineers with many years of real-world experience.<br><br>What You Will Be Doing<br><br>You will be working remote to help build and scale our internal omni-channel fulfillment platform. This will involve utilizing machine learning algorithms and standing up machine learning platforms in the cloud. We are looking for someone who can both be hands on and be involved in over-arching architectural decisions.<br><br>What You Need for this Position<br><br>MUST HAVE:<br>- BS in related field<br>- 3+ years of machine learning/data science experience<br>- Strong Retail/E-Commerce industry experience<br>- Deep Neural Networks (DNN)<br>- Tensorflow<br>- Python/R<br>- Experience with machine learning algorithms<br>- Cloud services: AWS, GCP, or Azure<br>- Order Management/fulfillment systems or Inventory Optimization<br><br>What's In It for You<br><br>- Competitive Salary DOE<br>- Comprehensive Benefits Package<br>- Generous PTO<br>- 401k with match<br>- REMOTE WORK!So, if you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SvTvvs5vRmOMIsqLmkiEhQ",
    "url": "https://jobmote.com/job/57697/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 10:07:23 PM",
    "validThrough": "Aug 9, 2019 10:07:23 PM",
    "crawled": "Aug 7, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "351fh48jRmu2TtWlHNpPxA",
    "url": "https://remoteok.io/jobs/74364",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Xapo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 9:28:52 PM",
    "validThrough": "Aug 13, 2019 9:28:52 PM",
    "crawled": "Aug 6, 2019 9:30:29 PM",
    "content": "<span></span> <span><h4>Xapo</h4></span> <br> <h3>Data Engineer</h3> <div>  <div>   BALANCE FOR BETTER&nbsp;\\nAt Xapo, we embrace our differences and actively foster an inclusive environment where we all can thrive. We’re a flexible, family-friendly environment, and we recognize that everyone has commitments outside of work. We have a goal of reaching gender parity and strongly encourage women to apply to our open positions. Diversity is not a tagline at Xapo; it is our foundation.\\n\\nRESPONSIBILITIES\\n\\n\\n\\n* Design and build data structures on MPP platform like AWS RedShift and or Druid.io.\\n\\n* Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.\\n\\n* Translate complex business requirements into scalable technical solutions.\\n\\n* Strong understanding of analytics needs.\\n\\n* Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.\\n\\n* Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.\\n\\n\\n\\n\\nREQUIREMENTS\\n\\n\\n* In-depth understanding of data structures and algorithms.\\n\\n* Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.\\n\\n* Experience in designing and developing ETL data pipelines.\\n\\n* Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.\\n\\n* Programming experience in building high-quality software. Skills with Python or Scala preferred.\\n\\n* Strong analytical and communication skills.\\n\\n\\n\\n\\nNICE TO HAVE SKILLS\\n\\n\\n* Work/project experience with big data and advanced programming languages.\\n\\n* Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.\\n\\n* Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).\\n\\n* Experience with or advanced courses on data science and machine learning.\\n\\n\\n\\nOTHER REQUIREMENTS\\n\\n\\n\\nA dedicated workspace.&nbsp;\\n\\n\\nA reliable internet connection with the fastest speed possible in your area.\\n\\n\\nDevices and other essential equipment that meet minimal technical specifications.\\n\\n\\nAlignment with Our Values.\\n\\n\\n\\nWHY WORK FOR XAPO?\\n\\n\\n\\nShape the Future:&nbsp;Improve lives through cutting-edge technology, work remotely from anywhere in the world\\n\\n\\nOwn Your Success:&nbsp;Receive attractive remuneration, enjoy an autonomous work culture and flexible hours, apply your expertise to meaningful work every day\\n\\n\\nExpect Excellence:&nbsp;Collaborate, learn, and grow with a high performance team.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kZ466qXOQFyvhdtCT0Aa2w",
    "url": "https://remote.co/job/tech-lead-senior-software-engineer/",
    "title": "Tech Lead – Senior Software Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:django/python/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=15, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=12}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Sourceress",
      "sameAs": "https://www.sourceress.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 6:31:59 PM",
    "validThrough": "Aug 13, 2019 6:31:59 PM",
    "crawled": "Aug 6, 2019 7:32:18 PM",
    "content": "<h3>Tech Lead – Senior Software Engineer at <span>Sourceress</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>REMOTE</strong></p><p><strong>ENGINEERING</strong></p><p><strong>FULL-TIME</strong></p><p><strong>About the role</strong></p><p>As a senior software engineer, you’ll focus on owning projects from end to end. We’ll work to shield you from all other responsibilities and meetings so that you can maximally focus on solving a variety of interesting technical and business challenges.</p><p>We’re planning to double in size for each of the next two years. Fast-growing companies are often constrained by their ability to find or cultivate internal leaders (both purely technical leaders and people leaders). Accordingly, you’ll have significant autonomy in determining your projects, their requirements, and their architectures.</p><p>We’re exceptionally remote-friendly: about half of our team is remote, our San Francisco office has “portals” (a large TV, high quality microphone, and webcam) in every well-trafficked room, and remote team members even participate in lunch conversations, our book clubs, and our AI research club.</p><p><strong>About Sourceress</strong></p><p>Our mission is to help people find work that matters. We believe that the world is better when people understand the opportunities available to them. Our human-assisted AI platform delivers great results to our customers (customer quote: “I’d have a panic attack if you guys stopped existing”).</p><p>Because of this, we raised $3.5M from OpenAI researchers and Lightspeed Venture Partners at one of the highest ever valuations coming out of YC. Our team has previously sold companies, published machine learning research, has Dropbox’s former Chief of Staff, and hails from MIT, Google, Airbnb, McKinsey, etc.</p><p>Help us create a world where all 7 billion people work at jobs that they love, do things that they’re great at, and work for companies that are solving meaningful problems.</p><p><strong>Responsibilities</strong></p><ul><li>Solve the most important problems facing the business (generally by writing software, but not always!)</li><li>Minimize the complexity of the software that we create and maintain.</li><li>Continually improve your own software engineering skills (whether via side projects, classes, or whatever else works for you)</li><li>Help develop our team of talented engineers by mentoring, collaborating on projects and providing detailed code / architecture reviews.</li></ul><p><strong>Sample projects</strong></p><ul><li>For detail-oriented engineers that love to build beautiful and highly correct products: we have greenfield customer-facing product work. These users depend on and love Sourceress, and are eager to help improve the product and provide feedback to your work.</li><li>For engineers that love rapid prototyping and hate CSS: we have a variety of products for our highly-trained internal contracting team. These are critical to the magical feeling of our product and often require creative solutions and complex interfaces.</li><li>For engineers who love data, systems, and infrastructure: we’re also building a distributed model training and model scoring system. Because we care about all of the candidates in the world, we run into quite interesting infrastructure scaling problems that most startups would not hit they were much larger. As a result, a relatively small number of engineers get to solve “large” infrastructure problems end-to-end.</li><li>For engineers interested in machine learning, we have a variety of interesting problems touching a huge variety of sub-fields: NLP, deep learning, interpretability, fairness, graph-based learning, entity resolution, and much more are all relevant to our work. Engineers without prior experience but interest in learning can and will be taught the relevant skills.</li><li>For those engineers who care about clean code, developer tooling and productivity: we pride ourselves on exceptional developer tooling, and are constantly investing in our internal tools. For example: we’ve created a method that that allows us to attach a debugger to any process that has encountered an unexpected exception, <em>even in production</em>. This tool (we call it the Platinum Debugger) eliminates the time-consuming and often difficult step of reproducing the bug for about 90% of our bugs, vastly improving our productivity.</li></ul><p><strong>Requirements</strong></p><ul><li>3+ years of software engineering experience.</li><li>You’re an effective executor. You understand both the value of shipping quickly and of software craftsmanship, and have the judgment to know when to apply each. You’re capable, focused, and productive.</li><li>You’re cognizant of the multi-year consequences of your decisions.</li><li>You’r dependable. You do high-quality work, on time.</li><li>You’re incredibly smart.</li></ul><p><strong>Stack</strong></p><ul><li>Typescript (react)</li><li>Type-annotated Python 3 (django, scikit-learn, pytorch)</li><li>PostgreSQL</li><li>AWS</li></ul>        </div><div>        <a href='https://jobs.lever.co/sourceress/496094d0-1cb6-4b64-b59b-c6fdf0914709' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_V5foCEWTCC7t6SOC0EjmQ",
    "url": "https://stackoverflow.com/jobs/287228/data-engineer-xapo?a=1ykinKqMHTjy",
    "title": "Data engineer at Xapo  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Xapo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 4:06:25 PM",
    "validThrough": "Aug 13, 2019 4:06:25 PM",
    "crawled": "Aug 6, 2019 4:06:25 PM",
    "content": "<h3><span>Data engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Banking, Cryptocurrency, Financial Technology</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Xapo | No office location<br></div><h4>Technologies</h4><div></div><div>sql</div><div>amazon-web-services</div><div>etl</div>                <h4>Job description</h4>                <div><span><strong><span>BALANCE FOR BETTER</span></strong></span>&nbsp;<span>At Xapo, we embrace our differences and actively foster an inclusive environment where we all can thrive. We’re a flexible, family-friendly environment, and we recognize that everyone has commitments outside of work. We have a goal of reaching gender parity and strongly encourage women to apply to our open positions. Diversity is not a tagline at Xapo; it is our foundation.</span><span><strong>RESPONSIBILITIES<br></strong></span><ul><li><span>Design and build data structures on MPP platform like AWS RedShift and or Druid.io.</span></li><li><span>Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.</span></li><li><span>Translate complex business requirements into scalable technical solutions.</span></li><li><span>Strong understanding of analytics needs.</span></li><li><span>Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.</span></li><li><span>Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.</span></li></ul><p><span><strong><span>REQUIREMENTS</span></strong></span></p><ul><li><span>In-depth understanding of data structures and algorithms.</span></li><li><span>Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.</span></li><li><span>Experience in designing and developing ETL data pipelines.</span></li><li><span>Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.</span></li><li><span>Programming experience in building high-quality software. Skills with Python or Scala preferred.</span></li><li><span>Strong analytical and communication skills.</span></li></ul><p><span><strong>NICE TO HAVE SKILLS</strong></span></p><ul><li><span>Work/project experience with big data and advanced programming languages.</span></li><li><span>Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.</span></li><li><span>Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).</span></li><li><span>Experience with or advanced courses on data science and machine learning.</span></li></ul><span><strong><span>OTHER REQUIREMENTS</span></strong></span><ul><span>A dedicated workspace.&nbsp;</span><span>A reliable internet connection with the fastest speed possible in your area.</span><span><span>Devices and other essential equipment that meet minimal technical specifications.</span></span><span><span>Alignment with Our Values.</span></span></ul><span><strong><span>WHY WORK FOR XAPO?</span></strong></span><ul><span><strong><span>Shape the Future:</span></strong><span>&nbsp;Improve lives through cutting-edge technology, work remotely from anywhere in the world</span></span><span><strong><span>Own Your Success:</span></strong><span>&nbsp;Receive attractive remuneration, enjoy an autonomous work culture and flexible hours, apply your expertise to meaningful work every day</span></span><span><span><strong>Expect Excellence:</strong>&nbsp;</span><span>Collaborate, learn, and grow with a high performance team.</span></span></ul>                </div>            <div>        <a href='https://xapo.bamboohr.com/jobs/view.php?id=69' rel='nofollow'>                        Apply now        </a></div>            <h4>About Xapo</h4>            <div><p>Xapo is a global financial technology company built on bitcoin &amp; blockchain with a mission to enable anyone, anywhere to take control of their money. Founded in 2013 by International Entrepreneur Wences Casares (CEO) &amp; Federico Murrone (COO), Xapo has made an unparalleled investment in security infrastructure, assembled a renowned advisory board, recruited a world class team, and raised $40M from top venture capital firms in Silicon Valley &amp; the world. Are you a self-starter who shares our passion for harnessing cutting-edge technologies to impact the lives of people globally? Do you dream of growing your career at a tech startup, while not sacrificing your work-life balance? Do you wish for a job that allows you to work from home, or anywhere else in the world that you need or want to be? Are you searching for a company that appreciates your individuality, and recognizes that we all have personal and family obligations outside of work? If so, Xapo may be the place for you! Xapo employs a global, remote workforce in over fifty countries. We hire great people – and in exchange, we offer autonomy, flexibility, meaningful work, a collaborative team environment, and top tier compensation. Do the best work of your career at Xapo - and still have the time to enjoy all of life’s special moments! &nbsp; We are seeking a&nbsp;Senior Growth Data Engineer&nbsp;to join our global team. This full-time position is planned to be remote, meaning you can work from anywhere!<br><strong><br>WHY WORK FOR XAPO?</strong></p><ul><li>Attractive compensation.</li><li>Work remotely from anywhere in the world.</li><li>Collaborate, learn, and grow with a diverse, global team.</li><li>Achieve balance with our autonomous work culture and flexible hours.</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Attractive compensation &amp; equity opportunities</span>                            </li>                            <li>                                <span></span>                                <span>Remote job - work from anywhere in the world!</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours</span>                            </li>                            <li>                                <span></span>                                <span>Autonomous work environment</span>                            </li>                            <li>                                <span></span>                                <span>Generous vacation plan</span>                            </li>                            <li>                                <span></span>                                <span>Paid leave for new parents</span>                            </li>                            <li>                                <span></span>                                <span>Collaborate with a global team across 50 countries!</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "RuCUxjZpTya46XCXrRAIgw",
    "url": "https://jobmote.com/job/57548/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:20 PM",
    "validThrough": "Aug 8, 2019 10:07:20 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-BOKQ-kLQgKAA7j4Q45v6g",
    "url": "https://jobmote.com/job/57560/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Tlzt8gC0R-eEhYttr8VrOg",
    "url": "https://jobmote.com/job/57559/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ApveJj95RIS5A-Qe0CiOoA",
    "url": "https://jobmote.com/job/57558/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p>&nbsp;</p> <p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pz9nb0VMQOuoiyvbusQzTA",
    "url": "https://jobmote.com/job/57557/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p>&nbsp;</p> <p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Dnrn39rlS4-TjdmWTJ2a2A",
    "url": "https://news.ycombinator.com/item?id=20612109",
    "title": "Kalepa | Software Engineers | New York City, NY | ONSITE / PARTIAL REMOTE, VISA Kalepa is a New ...",
    "tags": [
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 9:46:05 AM",
    "validThrough": "Aug 12, 2019 9:46:05 AM",
    "crawled": "Aug 5, 2019 11:07:10 AM",
    "content": "Kalepa | Software Engineers | New York City, NY | ONSITE / PARTIAL REMOTE, VISA<p>Kalepa is a New York based, VC backed, startup building software to transform and disrupt the $1T commercial insurance market.</p><p>Engineers at Kalepa will be solving interesting and challenging problems at the intersection of big data pipelines, cutting-edge machine learning models, intuitive frontend apps, and robust infrastructure. You will be working in a small team building technology from the ground up with the latest stack.</p><p>One trillion dollars are spent globally each year on commercial insurance. However, the process for estimating the risk associated with a given business across various perils is still reliant on inefficient and inaccurate forms and research. This information asymmetry leads to a broken set of incentives and a poor experience for both businesses and insurers alike. By combining cutting edge data science, enterprise software, and insurance expertise, Kalepa is delivering precision underwriting at scale. Kalepa is turning real-world data into a complete understanding of risk.</p><p>Kalepa is led by a strong team with experiences from Facebook, APT (acquired by Mastercard for $600M in 2015), the Israel Defense Forces, MIT, Berkeley, and UPenn. We are backed by IA Ventures.</p><p>More details here: <a href='https://angel.co/company/kalepa/jobs/460333-software-engineer' rel='nofollow'>https://angel.co/company/kalepa/jobs/460333-software-enginee...</a></p><p>Contact: paul.monasterio@kalepa.co</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "i_xp-LKSStq-EVLiycoO_A",
    "url": "https://jobmote.com/job/56486/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:23 PM",
    "validThrough": "Aug 7, 2019 10:07:23 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XxXdP7T-RjqxMODCEDKBsA",
    "url": "https://jobmote.com/job/56467/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Eliassen Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out the foundation platform around Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><b>Responsibilities/Skills:</b><br><ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li> <li>Build Back end applications using Java, Spark/Scala, Python</li> <li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li> <li>Work on performance optimizations on Hbase and Solr</li> <li>Work on Performance optimization on Spark Jobs and MapReduce jobs</li> <li>Ability to debug complex production scenarios</li> <li>Master?s degree in Computer Science, Management Information Systems #eg1989</li> </ul> For immediate consideration, email your updated resume to Dan Malta at [Click Here to Email Your Resum?] <br> Job ID: 321205<br><b>About Eliassen Group:</b><br> Eliassen Group provides strategic talent solutions to drive our clients? innovation and business results. Leveraging over 30 years of success, our expertise in IT staffing, Agile consulting, creative services, managed services, and life sciences enables us to partner with our clients to execute their business strategy and scale effectively. Headquartered in Reading, MA and with offices from coast to coast, Eliassen Group offers local community presence, deep networks, as well as national reach. For more information, visit .<br> Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.<br> Don?t miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a <b><em> $1,000 referral check !</em></b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j1C6VL4oR3KPcdgZbVXY8w",
    "url": "https://jobmote.com/job/56468/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TCCX4f3tToWrOc-Md4oy5g",
    "url": "https://jobmote.com/job/56449/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented. If the successful candidate prefers to be onsite, that is also welcomed. The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure. IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day. The company has a history of promoting from within.<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em>any</em></b> of the following:<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LTKZjw6gR1yxd98M7y4lLw",
    "url": "https://jobmote.com/job/56412/budget-business-data-analyst-remote-offsite/",
    "title": "Budget- Business Data Analyst-Remote (Offsite)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "US Information Technologies Corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:24 PM",
    "validThrough": "Aug 6, 2019 10:07:24 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div>Budget- Business Data Analyst-Remote (Offsite) Location: <b>Chantilly, VA </b> Job Code: <b>899 </b> # of openings: <b>5 </b> Description<br><br>POSITION: Remote Budget - Business Data Analyst- (Offsite) Cleared<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Full-Time (40 hours per week)<br><br>Location: Remote (Offsite) Preference will be given to candidates close to the DC area.<br><br>Fully Funded Position<br><br>Length: 3 years<br><br>Required:<br><br>Active Secret or NACLC -CLEARANCE Required<br><br>Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Education: BA or BS Degree<br><br>Descriptive Job Title: Candidate Experience Level:<br><br>Business Data Analyst I (Off-Site) Entry to Mid-Level 1 to 5 years experience)<br><br>2 years experience requested.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Enterprise Business Financial Support Services- Business Data Analyst- DLA<br><br>Enterprise Systems<br><br>Government Agency, collecting and organizing information user manuals, training materials, installation guides, proposals, and reports.<br><br>Edits functional descriptions, system specifications, user manuals, special reports, performing financial and administrative tasks. preparing and/or maintaining systems, programming, and operations documentation, procedures and methods.<br><br>Maintains a current internal documentation library. Provides or coordinates special documentation services as required.<br><br>Position:<br><br>Provides support in collecting and organizing information required for preparation of user manuals, training materials, installation guides, proposals, and reports. Edits functional descriptions, system specifications, user manuals, special reports, or any other customer deliverables and documents. Provides support in performing financial and administrative tasks. Under general supervision, is responsible for preparing and/or maintaining systems, programming, and operations documentation, procedures and methods. Maintains a current internal documentation library. Provides or coordinates special documentation services as required.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><b>Must have experience in working with DOD Lifecycle management, DOD 5000.1, 5000.2, DODI 5000.02, and Guidebook. Must be in your Resume </b><br> Two (2) years experience in similar taskings.<br> Specialized experience in assembling technical documents and providing a detailed analysis of various business system functions.<br> Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Must have experience with the following programs:<br> MS Suite<br> Word<br> Excel<br> Access<br> Project Management<br> PowerPoint<br><br>Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Active Secret or NACLC Required<br><br>1. Collecting and organizing information<br><br>2. Prepares User manuals, training materials, installation guides, proposals, and reports.<br><br>3. Edits functional descriptions, system specifications, user manuals, special reports,<br><br>4. Performing financial and administrative tasks.<br><br>5. Preparing and/or maintaining systems, programming, and operations documentation, procedures and methods.<br><br>6. Maintains a current internal documentation library.<br><br>7. Provides or coordinates special documentation services as required.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Active Secret or NACLC -CLEARANCE Required<br><br>USIT values celebrates and enacts diversity in the workplace. USIT takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans and other protected veterans. EOE/AA/M/F/Veteran/Disability <br> USIT is an Equal Opportunity Employer (EOE). USIT provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran or disabled status. <br><b>USIT participates in E-Verify. </b><br><br>#DICE <br> #indeed <br> #CJ<br><br>USIT is an Equal Opportunity Employer (EOE). USIT provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran or disabled status. Previous Applicants: Email: Password:<br><br>If you do not remember your password click here .<br><br>Back to Search Results<br><br>New Search<br><br>- provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tdI551QKQzyowkSbfbEttQ",
    "url": "https://jobmote.com/job/56407/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "INuZJpkMRvaI6vpx-u9KJA",
    "url": "https://jobmote.com/job/56389/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "3mkmxyhSSyG2qsOs1Lt5Lg",
    "url": "https://jobmote.com/job/56386/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented. If the successful candidate prefers to be onsite, that is also welcomed. The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure. IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day. The company has a history of promoting from within.<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection </li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience</li><li>Strong ability to talk through findings and algorithms </li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em>any</em></b> of the following:<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6zhiqTveSG6IHbAIRZLTcg",
    "url": "https://jobmote.com/job/56255/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 10:07:26 PM",
    "validThrough": "Aug 5, 2019 10:07:26 PM",
    "crawled": "Aug 3, 2019 3:06:26 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tMy9wgcLRPidltjZsJ0QRg",
    "url": "https://jobmote.com/job/56243/hadoop-administrator-l2-engineer-role-100-remote/",
    "title": "Hadoop administrator ( L2 engineer role )100% Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/120",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=2, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=120, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Everest Consulting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 10:07:26 PM",
    "validThrough": "Aug 5, 2019 10:07:26 PM",
    "crawled": "Aug 3, 2019 3:06:26 AM",
    "content": "<div><p> <br>Deploying a hadoop cluster, maintaining a hadoop cluster, adding and removing nodes using cluster monitoring tool Cloudera Manager, configuring and upgrading the cloudera manager,cdh,cdsw and kafka etc</p> <p> <br>Role : L2 engineer role .</p> <p>2. Implementing, managing and administering the overall hadoop infrastructure.<br>3. Takes care of the day-to-day running of Hadoop clusters<br>4. A hadoop administrator will have to work closely with the database team, network team, BI team and application teams to make sure that all the big data applications are highly available and performing as expected.<br>5. If working with open source Apache Distribution then hadoop admins have to manually setup all the configurations- Core-Site, HDFS-Site, YARN-Site and Map Red-Site.<br>6. However, when working with hadoop distribution like Cloudera the configuration files are setup on startup and the hadoop admin need not configure them manually.<br>7. Hadoop admin is responsible for capacity planning and estimating the requirements for lowering or increasing the capacity of the hadoop cluster.<br>8. Hadoop admin is also responsible for deciding the size of the hadoop cluster based on the data to be stored in HDFS.<br>9. Ensure that the hadoop cluster is up and running all the time.<br>10. Monitoring the cluster connectivity and performance.<br>11. Manage and review Hadoop log files.<br>12. Backup and recovery tasks<br>13. Resource and security management<br>14. Troubleshooting application errors and ensuring that they do not occur again.<br>15. Assisting users on connectivity for various tools like tableau,alteryx,talend and powerbi.<br>16. CDSW upgrade,administration and monitoring<br>17. KAFKA upgrade,administration and monitoring - is managed by datascientists as of now<br>18. Shell scripting and automation.<br>19. Knowledge of python</p> <p> </p> <p>Reach:</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "D5yvTLslSLWAvTPtQantLA",
    "url": "https://remoteok.io/jobs/74307",
    "title": "Data Science Course Mentor",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 12:55:16 AM",
    "validThrough": "Aug 10, 2019 12:55:16 AM",
    "crawled": "Aug 3, 2019 1:06:30 AM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Course Mentor</h3> <div>  <div>   Click here to apply\\n\\nWho We Are \\nAt Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;\\n\\nWe put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;\\n\\n\\nThe Position\\nAt Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;\\n\\nWe put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;\\n\\nStudents enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed technologists. As a Course Mentor, you will support students by acting as an advisor, counselor, and support system as they complete the course and land their first industry job. To achieve this, you will engage with students using the below range of approaches, known as Engagement Formats. Course Mentors are expected to provide support across all formats when needed.&nbsp;\\n\\n\\n\\n* Mentor Sessions: Meet with students 1-on-1 in online video sessions to provide technical and professional support as the student progresses through the curriculum.\\n\\n* Group Sessions: Host online video sessions on topics of your expertise (in alignment with curriculum offerings) for groups of student seeking live support between mentor sessions.&nbsp;\\n\\n* Grading: Reviewing student checkpoints submissions and delivering written feedback, including analysis of projects and portfolios.&nbsp;\\n\\n* Technical Coaching: Provide in-demand support to technical questions and guidance requests that come to the Technical Coaching team through text and video in a timely manner. This team also provides the TA support for immersive programs.&nbsp;\\n\\n* Assessments &amp; Mock Interviews: Conduct 1-on-1 mock interviews and assessments via video calls and provide written feedback to students based on assessment rubrics.&nbsp;\\n\\n\\n\\n\\nIn addition to working directly with students, Course Mentors are expected to maintain an environment of feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.\\n\\nRequirements\\n\\n\\n* Minimum of 1 year professional experience as a Data Scientist or demonstrated expertise with data visualizations and machine learning at an industry level\\n\\n* Proficiency in SQL, Python\\n\\n* Professional experience with Hadoop and Spark a plus\\n\\n* Excellent written and verbal communication\\n\\n* High level of empathy and people management skills\\n\\n* Must have a reliable, high-speed Internet connection\\n\\n\\n\\n\\nBenefits\\n\\n\\n* This is a part-time role (10-25 hours a week)\\n\\n* Fully remote position, with the option to work evenings and weekends in person in 22 US cities\\n\\n* Community of 500+ like-minded Educators looking to impact others and keep their skills sharp\\n\\n* Full access to all of Thinkful Courses for your continued learning\\n\\n* Grow as an Educator\\n\\n\\n\\n\\nApply\\nIf you are interested in this position please provide your resume and a cover letter explaining your interest in the role.\\n\\nThinkful can only hire candidates who are eligible to work in the United States.\\n\\nWe stand against any form of workplace harassment based on race, color, religion, sexual orientation, gender identity or expression, national origin, age, disability, or veteran status. Thinkful provides equal employment opportunities to all employees and applicants. If you're talented and driven, please apply.\\n\\nAt this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\nClick here to apply&nbsp;  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F6lztxZfQf--xM3CJQg-oQ",
    "url": "https://stackoverflow.com/jobs/286543/senior-data-scientist-remote-global-wallethub?a=1y63jbW3HY9a",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 9:30:24 PM",
    "validThrough": "Aug 9, 2019 9:30:24 PM",
    "crawled": "Aug 2, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/286543?reset=False&amp;ra=1y63jbW3HY9a&amp;oqs=a%3D1y63jbW3HY9a' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rHldxCSQRQGnHiq2z-U_lg",
    "url": "https://stackoverflow.com/jobs/286534/data-science-course-mentor-thinkful-inc?a=1y5RHQddlqU0",
    "title": "Data Science Course Mentor at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=50, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 7:30:25 PM",
    "validThrough": "Aug 9, 2019 7:30:25 PM",
    "crawled": "Aug 2, 2019 7:30:25 PM",
    "content": "<h3><span>Data Science Course Mentor</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>sql</div><div>python</div><div>Click here to apply</div><div>Click here to apply&nbsp;</div>                <h4>Job description</h4>                <div><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply</a><strong>Who We Are </strong><br>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;<br><br><strong>The Position</strong>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;Students enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed technologists. As a Course Mentor, you will support students by acting as an advisor, counselor, and support system as they complete the course and land their first industry job. To achieve this, you will engage with students using the below range of approaches, known as Engagement Formats. Course Mentors are expected to provide support across all formats when needed.&nbsp;<ul><li><strong>Mentor Sessions: </strong>Meet with students 1-on-1 in online video sessions to provide technical and professional support as the student progresses through the curriculum.</li><li><strong>Group Sessions: </strong>Host online video sessions on topics of your expertise (in alignment with curriculum offerings) for groups of student seeking live support between mentor sessions.&nbsp;</li><li><strong>Grading: </strong>Reviewing student checkpoints submissions and delivering written feedback, including analysis of projects and portfolios.&nbsp;</li><li><strong>Technical Coaching: </strong>Provide in-demand support to technical questions and guidance requests that come to the Technical Coaching team through text and video in a timely manner. This team also provides the TA support for immersive programs.&nbsp;</li><li><strong>Assessments &amp; Mock Interviews:</strong> Conduct 1-on-1 mock interviews and assessments via video calls and provide written feedback to students based on assessment rubrics.&nbsp;</li></ul>In addition to working directly with students, Course Mentors are expected to maintain an environment of feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.<strong>Requirements</strong><ul><li>Minimum of 1 year professional experience as a Data Scientist or demonstrated expertise with data visualizations and machine learning at an industry level</li><li>Proficiency in SQL, Python</li><li>Professional experience with Hadoop and Spark a plus</li><li>Excellent written and verbal communication</li><li>High level of empathy and people management skills</li><li>Must have a reliable, high-speed Internet connection</li></ul><strong>Benefits</strong><ul><li>This is a part-time role (10-25 hours a week)</li><li>Fully remote position, with the option to work evenings and weekends in person in 22 US cities</li><li>Community of 500+ like-minded Educators looking to impact others and keep their skills sharp</li><li>Full access to all of Thinkful Courses for your continued learning</li><li>Grow as an Educator</li></ul><br><strong>Apply</strong><br>If you are interested in this position please provide your resume and a cover letter explaining your interest in the role.Thinkful can only hire candidates who are eligible to work in the United States.We stand against any form of workplace harassment based on race, color, religion, sexual orientation, gender identity or expression, national origin, age, disability, or veteran status. Thinkful provides equal employment opportunities to all employees and applicants. If you're talented and driven, please apply.<br><br>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming<a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply&nbsp;</a>                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Zm9GHPkbQEals62eBbhHTA",
    "url": "https://remote.co/job/machine-learning-expert/",
    "title": "Machine Learning Expert",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scipy/python/5",
      "DBG_TECH1:techWeightMap:{python=17, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=46, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "PulsePoint",
      "sameAs": "https://www.pulsepoint.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 5:43:39 PM",
    "validThrough": "Aug 9, 2019 5:43:39 PM",
    "crawled": "Aug 2, 2019 6:25:02 PM",
    "content": "<h3>Machine Learning  Expert at <span>PulsePoint</span></h3><div><span><i></i> Remote</span>        </div><div>            <p><strong>Location: REMOTE</strong></p><p><strong>Note: This is a REMOTE position, reporting into our NYC home office.</strong></p><p>PulsePoint , a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.</p><p>Our organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization .</p><p><strong>The goals of the PulsePoint Data Science Engineering team:</strong></p><ul><li>Optimize and validate targeting mechanisms for specific health conditions</li><li>Improve and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month</li><li>Collaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.</li></ul><p><strong>What you will be tasked to do:</strong></p><ul><li>Research and develop user profiling models to enhance our recommendation engine to leverage both online and offline data.</li><li>Support and enhance the existing work on health user profiling, prediction, and targeting tools.</li><li>Contribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.</li><li>Support existing codebases for data integration and production support for our core models.</li></ul><p><strong>What you need to be successful in this role:</strong></p><ul><li>3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist</li><li>Advanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala</li><li>Advanced knowledge of Python using the numpy/scipy/pandas/skilearn stack</li><li><strong>MS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience</strong></li></ul><p><strong>** All applicants must submit a code sample or a GitHub link to be considered **</strong></p><p>At PulsePoint , data is at the core of everything we do and Data Science is a&nbsp;<strong>high profile</strong>&nbsp;and&nbsp;<strong>high impact</strong>&nbsp;team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for A players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.</p>        </div><div>        <a href='http://www.pulsepoint.com/job-board?gh_jid=1281522' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5u3-HeKlTBCPsrs2qkA8tg",
    "url": "https://jobmote.com/job/56051/data-scientist-and-development-engineer-remote-ok-attractive-pay/",
    "title": "Data scientist and development engineer (remote OK) ***attractive pay*",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "infoCorvus",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 10:07:34 PM",
    "validThrough": "Aug 4, 2019 10:07:34 PM",
    "crawled": "Aug 2, 2019 3:06:25 AM",
    "content": "<div><p> </p><p><strong>Come work for a leading database company developing the next generation advanced analytical database </strong></p><p> </p><p> </p><p> </p><p><strong>Duties:</strong></p><p> </p><ul><li><ul><li>Participate in leading - not bleeding - and pragmatic applicable research and development</li></ul></li></ul><p> </p><ul><li><ul><li>Apply advanced statistical and machine learning techniques</li><li>Solve a number of challenging database problems outside the traditional arena of</li></ul></li></ul><p> </p><ul><li><ul><li>database internals and know-how</li><li>including algorithm design,</li></ul></li></ul><p> </p><ul><li><ul><li>verification,</li><li>scaling,</li></ul></li></ul><p> </p><ul><li>performance,</li><li>computational complexities, and their design and</li><li>Code implementation into services amendable to the optimal combination of offline and real-time data analysis and insight rendering.</li></ul><p><strong>Skills: </strong></p><p> </p><ul><li><ul><li>Solid theoretical, mathematical and practical working knowledge of various statistical, inferential, and machine learning models, techniques, trade-offs</li></ul></li></ul><p> </p><ul><li><ul><li>Implementation experience in cloud or on-premise , with productive fluency in multiple languages like python, R, JavaScript, visualization techniques</li><li>Basic working database knowledge</li><li>Ability to work in a team environment while also functions as an individual contributor who needs minimal handholding to know how to self-actualize, prioritize and make progress with minimal handholding.</li><li>A fast learner who s not hesitant to take on new things;</li></ul></li></ul><p> </p><ul><li><ul><li>A problem solver with analytical thinking and unwavering persistence to overcome</li><li> </li></ul></li></ul><p> </p><ul><li>Clear and good verbal and written communication skills</li></ul><p> </p><p> </p><p> </p><p><strong>Qualifications:</strong></p><p> </p><ul><li>At least 4 years of relevant hands-on experience with skills in the above areas</li><li>A successful track record in a similar role</li></ul> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2-KraVEeTiaAft0tIAMvOA",
    "url": "https://news.ycombinator.com/item?id=20588928",
    "title": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 12:23:11 AM",
    "validThrough": "Aug 9, 2019 12:23:11 AM",
    "crawled": "Aug 2, 2019 1:09:12 AM",
    "content": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full-time | Local or Remote | <a href='https://www.sourceress.com/jobs' rel='nofollow'>https://www.sourceress.com/jobs</a><p>We already have significant machine learning expertise, so are happy to hire great engineers without prior ML experience who are willing to learn. We strongly value personal growth, and want to help you grow into a great engineer (or engineering leader), so this approach applies to our other engineering roles as well.</p><p>Our mission is to help people find work that matters. We believe that the world is better when people understand the opportunities available to them. Our human-assisted AI platform delivers great results to our customers (customer quote: &quot;I'd have a panic attack if you guys stopped existing&quot;).</p><p>Because of this, we raised $3.5M from OpenAI researchers and Lightspeed at one of the highest ever valuations coming out of YC. Our team has previously sold companies, published machine learning research, has Dropbox's former Chief of Staff, and previously worked at Google, Airbnb, McKinsey, etc.</p><p>Qualifications:</p><p>- Do you understand the value of shipping quickly and of software craftsmanship, and have the judgment to know when to apply each?</p><p>- Do you enjoy collaborating with other developers and helping them grow?</p><p>- Do you share our values? <a href='https://www.sourceress.com/jobs#values' rel='nofollow'>https://www.sourceress.com/jobs#values</a></p><p>Stack: Python 3, Typescript, React, AWS, PostgreSQL</p><p>To Apply: <a href='https://www.sourceress.com/jobs#current-openings' rel='nofollow'>https://www.sourceress.com/jobs#current-openings</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xalH2nMgQy64LYuRZH1FjA",
    "url": "https://news.ycombinator.com/item?id=20588897",
    "title": "OnSpecta | Redwood City, CA & Warsaw, Poland | Software Engineer, Performance Engineer (HPC), ...",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 12:17:21 AM",
    "validThrough": "Aug 9, 2019 12:17:21 AM",
    "crawled": "Aug 2, 2019 1:09:12 AM",
    "content": "OnSpecta | Redwood City, CA &amp; Warsaw, Poland | Software Engineer, Performance Engineer (HPC), Machine Learning Engineer | Visa<p>OnSpecta is an early-stage startup founded by successful serial entrepreneurs and deep learning experts, and was born out of MIT’s neuroscience lab. We offer a Deep Learning Server (DLS) which increases the performance of deep learning computations on Intel and ARM CPUs, GPUs and ASICs etc. We're a small team (~10), so you'll have a huge opportunity to make a difference.</p><p>We are looking for talented software performance engineers to work directly with our technical founders. If you have experience in C++ and are interested in working on cutting-edge AI/ML infrastructure tech, please reach out to us. See more at <a href='http://onspecta.com/careers.html' rel='nofollow'>http://onspecta.com/careers.html</a> We're also looking for Machine Learning Engineers (experience with Python + TensorFlow required).</p><p>Please reach out to hiring@onspecta.com and include &quot;HN: &quot; in the subject. (Note: while we're open to remote work, you must be in California's or Central/Easter Europe's timezones. Local candidates are preferred).</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "n-5sE7NDTruD_Zu3n3PTyw",
    "url": "https://news.ycombinator.com/item?id=20587710",
    "title": "SOLV3D [https://solv3d.com] | Senior Data Scientist / Developer | Calgary, AB, Canada | Full ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=4}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 10:00:00 PM",
    "validThrough": "Aug 8, 2019 10:00:00 PM",
    "crawled": "Aug 1, 2019 10:32:05 PM",
    "content": "SOLV3D [<a href='https://solv3d.com' rel='nofollow'>https://solv3d.com</a>] | Senior Data Scientist / Developer | Calgary, AB, Canada | Full-time | ONSITE preferred, however REMOTE (Canada) also welcome<p>We’re looking for a Senior Data Scientist/Developer to assist with the enhancement and expansion of SOLV3D’s leading Software as a Service (SaaS) applications. Within this role, the individual will be required to apply their experience and expertise in providing input to SOLV3D’s software development team in the design, development, testing and maintenance stages of software development. This position involves design and implementation of a new machine learning based module for our SOLV3D engine application.</p><p>Minimum qualifications:</p><p>* 6+ years of experience collaborating and working on software development projects* Bachelor’s Degree or higher in computer science/applied mathematics/GIS-related or relevant field* Solid track record of managing and delivering enterprise or start-up SaaS applications* Experience working on all levels of the technology stack – database, business logic, frontend, testing* Knowledge and experience with Git, Python, JavaScript, MySQL/MariaDB, HTML and CSS* Experience designing and developing machine learning and deep learning systems* Experience working in an Agile environment, particularly Scrum* Experience with unit testing, integration testing and TDD* Experience working with cloud providers, particularly AWS using S3, EC2, and RDS</p><p>About SOLV3DWe are a young, dynamic start-up based in in Calgary, Alberta looking to set the geomatics software world on fire with our processing, visualization and collaboration applications. We were founded on a need for professional-grade point cloud processing.</p><p>Our first product, SOLV3D engine, was born of that need, and enables users to optimize their point cloud data for effective use within their applications and workflows. Our follow-on product, SOLV3D encompass, addressed the need for a simple, easy-to-use, web-based viewer for geo-referenced data. It gives users the ability to merge together a myriad of geospatial datasets. Within a web-based environment, it enables all stakeholders to easily gain situational awareness and work together on their projects and/or AOIs, regardless of geographical location or level of expertise.</p><p>I am the CTO, so please send me your questions/resume with [HN] in the subject line to kmiller at solv3d.com</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "m7sAS6fDRCeq-OSjm7E0Tg",
    "url": "https://news.ycombinator.com/item?id=20586259",
    "title": "Thrilling | full stack/frontend engineers | full-time | REMOTE or LA, NY, SF | https:/ ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angular/frontend/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:firebase/mobile/8",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=8, go=0, nodejs=1, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/mobile",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "mobile"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:37:26 PM",
    "validThrough": "Aug 8, 2019 7:37:26 PM",
    "crawled": "Aug 1, 2019 9:32:11 PM",
    "content": "Thrilling | full stack/frontend engineers | full-time | REMOTE or LA, NY, SF | <a href='https://shopthrilling.com' rel='nofollow'>https://shopthrilling.com</a><p>At Thrilling we're helping traditional brick-and-mortar vintage apparel stores sell their clothing online for the first time. Vintage and secondhand clothing has a huge role to play in improving the environmental impact of the Fashion industry, and by partnering with local stores we can leverage their unique, curated inventories and help small business owners compete in the global economy. We aim to do good, and do well. Our name comes from the thrill of the hunt, and we're working to bring the same excitement of shopping the best vintage stores, online. Read more about us here:<a href='https://www.entrepreneur.com/amphtml/325805' rel='nofollow'>https://www.entrepreneur.com/amphtml/325805</a></p><p>We're looking for engineers 2 &amp; 3 to join me and the rest of our small and growing team to help us change the landscape of online vintage and secondhand shopping. We need hungry self-starters with some prior software dev experience. Fashion is a diverse industry and we reflect and value that at our company. Having recently closed our seed round of funding we're rapidly expanding. We've built an app for efficient uploading of products and inventory management, as well as our customer-facing ecom marketplace. In addition to building out those systems there are new ones to create that have yet to be specced. Your work will have a massive impact on our growth and success.</p><p>Here's some of the tools we use: TypeScript, Angular, Ionic, GitHub, Jira, GraphQL, Google Cloud, Heroku, Firebase, Imgix, Sketch.</p><p>Here's some of the areas we're expanding into: ML, computer vision, recommendation systems, and always, always killer UX.</p><p>If this sounds interesting, email me at tech@shopthrilling.com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xYNubIjSRxOfNIlR88uYvw",
    "url": "https://news.ycombinator.com/item?id=20586476",
    "title": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| https://www.factual.com ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 3N OR(options, avail, allow) NOT encourag",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:58:01 PM",
    "validThrough": "Aug 8, 2019 7:58:01 PM",
    "crawled": "Aug 1, 2019 9:32:11 PM",
    "content": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| <a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a><p>Factual is currently hiring Software Engineers and Data Scientists, at all levels, in the Los Angeles office. Remote positions available for experienced candidates. Factual is the location data company that the world’s most valuable brands and technology companies trust to understand and intelligently grow their businesses. We help engineering teams, marketers and data analysts build the best digital products, deliver more impactful marketing and transform their businesses with the most accurate and comprehensive data on places and people worldwide.</p><p>There are many challenging problems to work on at all layers of the stack: data cleaning and canonicalization, storage, deduping, serving, APIs, improving data using machine learning, etc. If you love data, Factual is the place to be. Experience with Clojure, machine learning, NLP, algorithm design, or Hadoop/Spark is a plus!</p><p>You can email me personally at alexr@factual.com, or view our job postings here: <a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5xuxQrTtQIGPLExJL4-F2Q",
    "url": "https://news.ycombinator.com/item?id=20586166",
    "title": "play | Saalbach.com, Austria | Video, Machine Vision, AI | Remote Ok | Full-/Part-time/Co ...",
    "tags": [
      "DBG:surround``remot W OR(contractor,assist,ok)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=20, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:28:26 PM",
    "validThrough": "Aug 8, 2019 7:28:26 PM",
    "crawled": "Aug 1, 2019 7:32:07 PM",
    "content": "play | Saalbach.com, Austria | Video, Machine Vision, AI | Remote Ok | Full-/Part-time/Co-Creators<p>You are a Machine Visionary, Software Wizard or Master of Code?</p><p>Join us.</p><p>play is, simply put, about the beaming of emotions via video. The most beautiful medium to capture emotions, to share and beam them around the world.</p><p>What?</p><p>Just follow this super inviting “call to action”. Find out what we are working on and how we can collaborate:</p><p><a href='https://www.playsys.at/join_us/' rel='nofollow'>https://www.playsys.at/join_us/</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gXPqdyt4Ti2jwA7Yq0aSwg",
    "url": "https://news.ycombinator.com/item?id=20585019",
    "title": "Resemble AI | Toronto or Remote | Full-Time | Backend/Infra & Full-Stack Engineers Resemble AI ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=10, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:59:33 PM",
    "validThrough": "Aug 8, 2019 5:59:33 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Resemble AI | Toronto or Remote | Full-Time | Backend/Infra &amp; Full-Stack Engineers<p>Resemble AI creates high-quality synthetic voices that capture human emotion. We're a venture-backed high-growth startup that's looking to shake up an entire industry with state of the art AI.</p><p>Our product changes the way that thousands of brands, media companies, creative agencies, and game studios work with voice content.</p><p>We’re a remote-first team that thrives on flexibility and creativeness. We cover expenses for office space, equipment, and all of the other perks and benefits that make you productive. We also believe that to build an enticing product and solid team is by encouraging innovation is by enabling continuous education. That's why every other Friday is a day that you can use to work on anything you want, Resemble-related or not.</p><p>We're hiring for two roles:</p><p>Backend/Infrastructure Engineer - Looking for those that take pride in creating robust distributed systems. Most of the work is in Python and we use GCP as our cloud provider.</p><p>Full Stack Engineer - Product-driven Engineer that is able to craft end-to-end features. We work with Ruby on Rails, React, with microservices written in Python and deployed on GCP.</p><p>If interested, reach out directly to me: zohaib@resemble.ai</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zUiHGxcUTLuSFeuAi166Yg",
    "url": "https://news.ycombinator.com/item?id=20584616",
    "title": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:23:49 PM",
    "validThrough": "Aug 8, 2019 5:23:49 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR REMOTE | <a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a><p>================</p><p>We're the fastest growing unicorn you've never heard of [0] and was just recently named CNBCs Most Disruptive Business beating out Airbnb, Stripe, Flexport, and more [3].</p><p>Indigo is revolutionizing agtech by offering better crops to farmers through technology. Agtech is one of the most underhyped technology trends [1] and we're serving a multi-trillion dollar marketplace services industry [2].</p><p>Our group is working on the Uber for Agriculture. We're developing a Transportation network to connect farmers with preferred carriers (trucks) to help them ship millions of bushels of grain across the United States. It's like a real world Traveling Salesman Problem with even more requirements.</p><p>We're growing so fast that I have to hire another 10 engineers just for my group in 2019. Back-end, front-end, mobile... you name it, we need the help (see all of them here: <a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a> ).</p><p>Our tech stack includes AWS, Docker, Kubernetes (DevOps), Postgres (DB), Node &amp; GraphQL (back-end), React &amp; Apollo (front-end), and Python (data science / comp bio).</p><p>We also offer incredible perks. Free lunch (a rarity in Boston), massive commuter benefits (both MBTA and bicycling), fitness reimbursement, ample vacation; we really focus on and believe in both health and sustainability.</p><p>I'd be happy to tell you more, so feel free to PM me and I'll personally refer you to the company.</p><p>[0] <a href='https://www.builtinboston.com/2017/09/26/agtech-startup-indigo-boston-tech-unicorn' rel='nofollow'>https://www.builtinboston.com/2017/09/26/agtech-startup-indi...</a></p><p>[1] <a href='http://stateofstartups.firstround.com/2018/#trends-and-takes' rel='nofollow'>http://stateofstartups.firstround.com/2018/#trends-and-takes</a></p><p>[2] <a href='https://andrewchen.co/how-marketplaces-will-reinvent-the-service-economy/' rel='nofollow'>https://andrewchen.co/how-marketplaces-will-reinvent-the-ser...</a></p><p>[3] <a href='https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor-50-companies.html' rel='nofollow'>https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2bUtor1zQJenVcnGvbMolQ",
    "url": "https://news.ycombinator.com/item?id=20584487",
    "title": "Moonlight | Software Engineer | REMOTE | Fulltime | https://www.moonlightwork.com Hey all - ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:13:11 PM",
    "validThrough": "Aug 8, 2019 5:13:11 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Moonlight | Software Engineer | REMOTE | Fulltime | <a href='https://www.moonlightwork.com' rel='nofollow'>https://www.moonlightwork.com</a><p>Hey all - we're hiring a remote backend developer to join the team at Moonlight. We're building LinkedIn for software developers, and companies pay us to match to job candidates. The stack is Go on Kubernetes using gRPC, MySQL, Redis, etc. Lots going on and many fun challenges, ranging from ML to real-time messaging. This role will either be our second engineering hire. I wrote everything until now - so email me if you have any questions!</p><p>More details here -&gt;</p><p><a href='https://hire.withgoogle.com/public/jobs/moonlightworkcom/view/P_AAAAAAIAAFeNB7zCTG98gQ?trackingTag=slack' rel='nofollow'>https://hire.withgoogle.com/public/jobs/moonlightworkcom/vie...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Ti-gzoRUTRGAXnVNuMTdAg",
    "url": "https://news.ycombinator.com/item?id=20584790",
    "title": "Kira Systems | Multiple Senior Software Developers | Toronto, Canada | Remote | Onsite | https: ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=6, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/other",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "other"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:39:28 PM",
    "validThrough": "Aug 8, 2019 5:39:28 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Kira Systems | Multiple Senior Software Developers | Toronto, Canada | Remote | Onsite | <a href='https://www.kirasystems.com' rel='nofollow'>https://www.kirasystems.com</a><p>Kira Systems is a powerful machine learning software that identifies, extracts, and analyzes text in your contracts and other documents. Our software is intuitive and easy-to-use to uncover relevant information for some of the largest law firms, professional services and corporate companies in the world.</p><p>We are always looking for talented people to join our team locally, remotely, and offer support for those looking to relocate to our headquarters in Toronto.</p><p>We're hiring Machine Learning Devs, Security Engineering Lead and Developers to work in all areas of our stack. Possibilities include working on Clojure web server, backend data processing services, and both our platform API and SDK. We use PostgreSQL to store our data and don’t hide SQL behind big frameworks. We also use many other popular technologies such as Go, RabbitMQ, Zookeeper, ElasticSearch, and Docker.</p><p>For more information, visit our careers page <a href='https://www.kirasystems.com/careers' rel='nofollow'>https://www.kirasystems.com/careers</a> or email us at jobs@kirasystems.com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j8HtTOq9QKeubdb6jdY7JQ",
    "url": "https://news.ycombinator.com/item?id=20585004",
    "title": "SEEKING FREELANCER | Technical Writers, Bloggers - Machine Learning, Deep Learning, Artificial ...",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/14",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=42, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:58:32 PM",
    "validThrough": "Aug 8, 2019 5:58:32 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "SEEKING FREELANCER | Technical Writers, Bloggers - Machine Learning, Deep Learning, Artificial Intelligence | Remote (anywhere on the blue planet)<p>FloydHub is a YC start-up building AI infrastructure and tools. We have a popular platform with a highly satisfied and growing user base.</p><p>We are passionate about the power of artificial intelligence and truly believe these technologies will make a lasting positive impact on the world. We are doing our part to accelerate the adoption of AI by creating easy-to-use tools and by educating more people about fundamental concepts, best practices and advanced techniques in AI. Our blog plays a critical role in educating our current audience and others interested in entering the field.</p><p>We are looking for bloggers, writers, and content editors to create engaging and informative pieces for our audience.  If you are a data scientist or software engineer looking to write about your areas of expertise or what you are learning, we are still interested. This is a great opportunity for you to contribute to the biggest technology revolution since the advent of the internet and work alongside influencers in AI.</p><p>Come write for us. Come be part of the revolution.</p><p><a href='https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;utm_medium=post&amp;utm_campaign=call_for_writers_august_2019' rel='nofollow'>https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "l_-k_bryROqSv7bS9tQiyg",
    "url": "https://news.ycombinator.com/item?id=20585078",
    "title": "Frame Health | Senior/Lead Developer | Los Angeles or Boston | Full-time/Contract | ONSITE or ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=10, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 6:03:58 PM",
    "validThrough": "Aug 8, 2019 6:03:58 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Frame Health | Senior/Lead Developer | Los Angeles or Boston | Full-time/Contract | ONSITE or possibl REMOTE | <a href='http://framehealth.com' rel='nofollow'>http://framehealth.com</a>Frame Health brings the power of behavioral and personality science to enhance many aspects of health care, leading to better outcomes, economics, and patient happiness. Our small company has exciting partnerships with leading national healthcare organizations.We're seeking strong generalist technologists with a data science interest or background. Technologies: Ruby/Rails, Python, Javascript, and React.Please email: developerjobs@framehealth.com.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kIxRhfpdQfGNfbYRHItxCA",
    "url": "https://news.ycombinator.com/item?id=20584732",
    "title": "Citymapper | Full-time, VISA (for experienced candidates), London, REMOTE possible We need ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:33:14 PM",
    "validThrough": "Aug 8, 2019 5:33:14 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Citymapper | Full-time, VISA (for experienced candidates), London, REMOTE possible<p>We need great engineers who are up to the challenge of making cities usable.Join us and work on a daily use-case app for you and millions of city-dwellers in 40 cities around the world.Current mobility trends (scooters, electric bikes, cabs, …) are changing cities - and we are helping users to find and book the best transport options for them.  - Our multimodal transport app helps millions of people to get from A to B in our 40 cities  - Citymapper Pass is a transport only payment card covering all private and public transport with a weekly subscription (<a href='https://citymapper.com/pass' rel='nofollow'>https://citymapper.com/pass</a>)Check out our blog at <a href='https://engineering.citymapper.com' rel='nofollow'>https://engineering.citymapper.com</a> to get a better idea of what we are doing.</p><p>We are looking especially for: (Have a look on our careers page for a full list - <a href='https://citymapper.com/jobs' rel='nofollow'>https://citymapper.com/jobs</a>)Experienced backend engineers (Python, Go, AWS, …) <a href='https://citymapper.workable.com/jobs/6531' rel='nofollow'>https://citymapper.workable.com/jobs/6531</a>Data Science Engineers (data scientist working within an engineering team) <a href='https://citymapper.workable.com/jobs/40247' rel='nofollow'>https://citymapper.workable.com/jobs/40247</a>iOS Engineer <a href='https://citymapper.workable.com/jobs/7972' rel='nofollow'>https://citymapper.workable.com/jobs/7972</a></p><p>You can contact me directly at marius@citymapper.com if you have any questions (no recruiters please). Otherwise please apply through our website: <a href='https://citymapper.com/jobs' rel='nofollow'>https://citymapper.com/jobs</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GXQ4RkLkT4CTvJtfpoIDRA",
    "url": "https://jobmote.com/job/54036/senior-web-developer-remote/",
    "title": "Senior Web Developer (Remote)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=4}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blend360",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 10:07:19 PM",
    "validThrough": "Aug 3, 2019 10:07:19 PM",
    "crawled": "Aug 1, 2019 3:06:25 AM",
    "content": "<div>Dynamic, Entrepreneurial Marketing Consulting Company is seeking a Marketing Operations Manager to contribute to Financial Services Client?s customer retention strategy. If you have an entrepreneurial spirit and passion, are driven by results, solid campaign execution skills, we?re looking for you!?<br><br>C2G Partners is a successful marketing and analytics solutions company that has been ranked among Inc. Magazine?s ?Inc. 500 - 5000? list fastest growing companies in America, five out of the last six years. Our name C2G Partners means 'Committed to Growth'?, and this reflects both our desire to deliver exceptional results to our clients in helping them grow their business, as well as a strong growth culture that develops our employees and grows our company.? We aspire to be the preeminent provider of data driven marketing solutions in the industry.<br><br>The Senior Web Developer solves client problems using leading marketing technologies including solutions from Adobe, Google and Salesforce. Projects will include implementation, integration and enhancement of digital marketing tools. ??In this role, you?ll satisfy your desire for hands-on development, while exciting your entrepreneurial spirit with critical solution designs. This is a unique opportunity to help build a new division of the Data Science practice, focused on digital analytics and marketing technologies.<br><br>Key Responsibilities<ul><li>Design, document and implement technical solutions to client business questions in Adobe Experience Cloud, Google Marketing Cloud and Salesforce Marketing Cloud using relevant technical skills. Example projects may include:<ul><li>Re-architecture of existing digital marketing tools</li><li>Optimization of lead-generation efforts using Salesforce Marketing Cloud</li><li>Integration and ingestion of offline and online data in Adobe Audience Manager to deliver targeted remarketing advertisements</li><li>Implementation of tag management solutions (such as Google Tag Manager and Adobe Launch)</li></ul></li><li>Develop deep knowledge of emerging data governance, privacy, and information security regulations that affect marketing ? and understand the impact to solution offerings</li><li>Deliver high-quality projects on time and within budget in a fast-paced environment</li><li>Employ industry best practices in solution design, implementation, and testing</li></ul>The Details:<ul><li>Location: Remote (East Coast preferred)</li><li>Duration: Full-time</li><li>Travel Requirements: Up to 30-40%</li><li>Benefits: Health, Vision, Dental, 401K plan, Life Insurance, Pretax Commuter Benefits, and an incredibly supportive team cheering you on!</li></ul>Required Skills &amp; Qualifications:<ul><li>Degree in Computer Science, Engineering, MIS, or similar field</li><li>Minimum 3-5 years of hands-on experience with the following technologies:<ul><li>JavaScript (Advanced)</li><li>HTML &amp; CSS (Intermediate)</li><li>SQL, REST &amp; SOAP APIs</li></ul></li><li>Proven ability to collaborate and communicate effectively (written and oral) with both IT and marketing professionals</li><li>Ability to manage priorities across multiple projects</li></ul>Desired Skills &amp; Qualifications:<ul><li>Hands on experience with the following technologies:<ul><li>Adobe Experience Cloud solutions, particularly Analytics, Target or Audience Manager</li><li>Google Marketing Cloud, particularly GA360 and BigQuery</li><li>Tag Management technologies, especially data layer architecture and implementation</li><li>Mobile SDKs for marketing technologies</li><li>JSON</li></ul></li><li>Comfortable working in an Agile environment</li></ul>?</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6tkFWez4R4ulv-HzHYYxCw",
    "url": "https://www.workingnomads.co/job/go/24734/",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:velocity/java/8",
      "DBG_TECH1:techWeightMap:{python=7, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=8, apple=0, java=11, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Toptal",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 9, 2019 12:20:02 PM",
    "validThrough": "Jul 16, 2019 12:20:02 PM",
    "crawled": "Jul 31, 2019 6:26:46 PM",
    "content": "<p><strong>About </strong><strong>Toptal</strong></p><p>Toptal is a global network of top talent in business, design, and technology that enables companies to scale their teams, on-demand. With $100+ million in annual revenue and triple-digit growth, Toptal is the&nbsp;<a href='https://www.toptal.com/careers#remote-team' rel='nofollow'>largest fully distributed workforce</a>&nbsp;in the world.</p><p>We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun (see this&nbsp;<a href='http://www.huffingtonpost.com/entry/work-from-anywhere-in-the-world_us_581a1f01e4b083aaeef76a9b?064s98zsrt19n3ik9' rel='nofollow'>video</a>&nbsp;from The Huffington Post). We see no borders, move at a fast pace, and are never afraid to break the mold</p><p><strong>Position Description</strong></p><p>At Toptal, we measure everything and always rely on data to guide all of our initiatives, including both our long-term strategy and our day-to-day operations.</p><p>As a Data Engineer, your main goal is to be one step ahead of data scientists and analysts, and support them by providing infrastructure and tools they can use to deliver end-to-end solutions to business problems that can be developed rapidly and maintained easily. This is more than building and maintaining ETL pipelines. We need innovation, creativity and solutions that will have significant impact on our velocity. We, in turn, will give you autonomy and freedom to turn your ideas into reality.</p><p><strong>Responsibilities:</strong></p><ul><li>Build scalable, highly performant infrastructure for delivering clear business insights from a variety of raw data sources.</li><li>Develop batch &amp; real-time analytical solutions, prototypes, and proofs of concept for selected solutions.</li><li>Implement complex analytical projects with a focus on collecting, managing, analyzing, and visualizing data.</li><li>Build frameworks and tools to empower our data scientists and analysts.</li><li>Be in constant communication with team members and other relevant parties and convey results efficiently and clearly.</li></ul><p><strong>Requirements:</strong></p><ul><li>Working experience with&nbsp;<strong>Python</strong>,&nbsp;<strong>Pandas</strong>. Prior experience with&nbsp;<strong>Luigi</strong>&nbsp;is a plus.</li><li>Working experience with&nbsp;<strong>Scala</strong>&nbsp;and&nbsp;<strong>Airflow</strong>&nbsp;is a big plus.</li><li>Familiarity with&nbsp;<strong>Google Cloud Platform</strong>&nbsp;(e.g.&nbsp;<strong>GCS</strong>&nbsp;and BigQuery) is a plus.</li><li>Working experience with&nbsp;<strong>Dimensional Modeling</strong>&nbsp;and&nbsp;<strong>Rails</strong>&nbsp;is a plus.</li><li>Familiarity with the basic principles of&nbsp;<strong>distributed computing</strong>&nbsp;and&nbsp;<strong>data modeling</strong>.</li><li>Extensive experience with object-oriented design and coding and testing patterns, including experience with engineering software platforms and data infrastructures. Familiarity with functional programming concepts is a plus.</li><li>Outstanding communication and interpersonal skills.</li><li>Be excited about collaborating daily with your team and other groups while working via a distributed model.</li><li>Be eager to help your teammates, share your knowledge with them, and learn from them.</li><li>Be open to receiving constructive feedback.</li><li>You must be a world-class individual contributor to thrive at Toptal.</li></ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "BcQdIIQSQCifX5atpn75wg",
    "url": "https://stackoverflow.com/jobs/141116/freelance-interview-engineer-karat?a=LkcSbeLCa0o",
    "title": "Freelance Interview Engineer at Karat  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/mobile",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "mobile",
      "python"
    ],
    "hiringOrganization": {
      "name": "Karat",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 50000,
      "maxValue": 160000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 50k - 160k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 6:23:01 PM",
    "validThrough": "Aug 7, 2019 6:23:01 PM",
    "crawled": "Jul 31, 2019 6:23:01 PM",
    "content": "<h3><span>Freelance Interview Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer, Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Software Development / Engineering</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Karat | No office location<br></div><h4>Technologies</h4><div></div><div>technical-interviewing</div><div>data-structures</div><div>algorithm</div><div>java</div><div>python</div><div>jcs150 1</div><div>JLK 1</div><div>Kier 1</div><div>Austin Heimark 1</div>                <h4>Job description</h4>                <div><p><strong>Who is Karat?</strong> Karat is the world's leader in conducting first-round technical interviews. Our network of experienced interview engineers have conducted over 20,000 technical interviews on behalf of clients including Indeed, Pinterest, Intuit, and Citrix. We continuously analyze our interview data to get smarter and more predictive with every interview we conduct. As a result, our clients reclaim 60% of engineering hours per hire, accelerate achievement of their hiring goal by 25%, and offer an exceptional experience with 95% of candidates rating their experience as positive.</p><p><strong>Our Mission</strong> Our mission is to be the world’s interviewer. We conduct highly predictive interviews for our clients with rigor, humanity and fairness. Karat helps companies hire the engineers they need to create the future and helps ensure that engineers are in jobs that maximize their strengths.</p><p><strong>Join our community of Freelance Interview Engineers.</strong> Karat Interview Engineers are a network of experienced software engineers who are equipped with the best practices and technology required to be professional interviewers. Every interviewer in the network is an accomplished engineer. &nbsp;Our interviewers include development managers, software engineers and freelancers covering the full technology stack.</p><p><strong>Flexible, high impact work that is compensated at highly competitive rates.</strong> As an Interview Engineer, you will be compensated at highly competitive rates for your interviewing expertise. &nbsp;The time commitment is flexible---many of our interviews happen on nights and weekends. &nbsp;Some experts do 10 interviews/week while others do over 25 interviews/week. &nbsp;You can work from anywhere, anytime. &nbsp;You will sharpen your interviewing skills and transform the interviewing experience for every candidate and company. Interviews are paid at a flat rate of $100 USD per interview (60 minutes interview + up to 30 minutes for written feedback report).</p><p><strong>We are looking for experienced software engineers who believe that interviewing is a first-class job. You should possess:</strong></p><ul><li>Interviewing experience focused on evaluating fundamental computer science skills (i.e. data structures, algorithms etc.), software craftsmanship (i.e. understanding of unit testing, source control, APIs etc.), and/or specific technologies (i.e. iOS, distributed systems etc.).</li><li>Strong oral and written communication skills. Able to empathize with candidates and provide actionable feedback.</li><li>An ability to structure your schedule (i.e. you can pick certain blocks of time during the day, evenings, weekends).</li><li>A genuine desire to continuously improve the Karat service and technical interviewing.</li></ul>                </div>            <div>        <a href='https://grnh.se/1295fb4f2' rel='nofollow'>                        Apply now        </a></div>            <h4>About Karat</h4>            <div><p><strong>Interviewing is broken. &nbsp;Karat professionalizes interviewing.</strong></p><ul><li>Karat is on a mission to assess the world's talent. &nbsp;We are the first dedicated marketplace for technical interviewers. Karat's network of seasoned engineers conduct the first rounds of technical interviews for elite engineering companies. Our robust platform saves teams thousands of valuable hours while allowing them to focus on the top performing candidates. &nbsp;Karat's unique approach recognizes that people are central to the hiring process and that they can be supercharged by leveraging machine learning and our rich database of the world's interviews.</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Flexible Hours - You own your schedule</span>                            </li>                            <li>                                <span></span>                                <span>Work from anywhere</span>                            </li>                            <li>                                <span></span>                                <span>Transparent compensation</span>                            </li>                            <li>                                <span></span>                                <span>Bonus programs</span>                            </li>                            <li>                                <span></span>                                <span>Regular company outings</span>                            </li>                            <li>                                <span></span>                                <span>Access to a world-class community of expert interviewers</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xraRxYzxSoOCfmID4wCdfg",
    "url": "http://workinstartups.com/job-board/job/82892/data-scientist-extraordinaire-at-exciting-startup-at-clikd-dating-app/",
    "title": "Data Scientist Extraordinaire at Exciting Startup",
    "tags": [
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:php/php/5",
      "DBG_TECH1:k/t/w:wordpress/php/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=10, embedded=0, frontend=3}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Clikd Dating App",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 11:41:15 AM",
    "validThrough": "Aug 7, 2019 11:41:15 AM",
    "crawled": "Jul 31, 2019 1:06:31 PM",
    "content": "<p>Here at CLiKD We are currently recruiting for an intern with attitude. We are an early stage startup we are enjoying some great traction; you may have seen us featured on/in BBC News, Evening Standard, MTV, GQ, London Live, The Telegraph, Daily Mail plus many more, and we are looking for someone to join the team at this very exciting time. Our app is called CLiKD, you can find more info at www.clikdapp.com &ndash; we have been nominated for 4 awards and won best innovation in the dating industry 2017 as well as holding the number 4 spot for the UK&rsquo;s best dating blog!<br /><br />What we are looking for:<br />People with a passion for data, algorythims and business. Your number one aim will be able to help us to improve the in app mertrics and refine our recommendations algorthim. You will be part of fun and competitive team which is seeking to make CLiKD the next big dating app. You will be managed by our business development manager but also have scope to push your own businesses ideas. If your looking to get experience, well we are a startup which believes in giving you the opportunity to try things. With over 2.5 million personality based questions already answered by our ~40,000 users we have the data to build the most powerfull recommendation algorithm in the industry and this is your chance to shape that!</p><br /><p><br />You will be a confident communicator, with strong communication skills and go-get attitude. You&rsquo;ll need to be passionate about meeting new people and happy to muck in and get involved in a range of commercial initiatives as well as provide valuable insights and guidance to our app development team.<br /><br />Whilst you&rsquo;ll be working with our Business Development Manager and the CEO, you&rsquo;ll also have independence to work on many of small projects and experience any of the wider functions of an exciting app startup , hopefully allowing you to build your own portfolio of great work.</p><br /><p><br />This role is best aimed at those looking to gain some experience, put their academic studies to practical use or maybe you have an app idea yourself and would like to see how it&rsquo;s done, as long as you are passionate about what ever you do then we want you!<br /><br />You will be required to give us 2-3 days a week though we can be flexible to extent as to the time though this will generally be expected during 9-5:30.<br /><br />The company is growing quickly and we are keen to take people with us on our exciting journey and we are currently fundraising so we hope that post fundraising we will look to hire interns who prove themselves to be asset to the company. Sadly the current position is renumerated in expenses (normally &pound;15 per day) and equity.<br /><br /><br />SKILLS:&nbsp;<br />This opportunity is for someone with the right attitude, but we do need some basics:<br />-A background in Data Science and analysis<br />-Familiarity with Amazon Red Shift, MySQL, Tableau and Segment<br />-Technically proficient in terms of using standard office equipment<br />-Excellent communicator<br />-An enthusiasm for creating business and talking to people.&nbsp;<br />-Confidence, enthusiasm and the ability to challenge conventional thinking<br />-Anything else you can bring the table is a plus! PHP, HTML, CSS, SEO, PPC, Social Media Management/Advertising, Web Design, Wordpress, Photoshop, Final Cut, etc. amazing, but by no means essential.<br /><br /><br /><br />WHAT YOU&rsquo;LL GET:&nbsp;<br />The opportunity to work for an exciting new start up, shaping the future of the CLiKD app (and the dating industry) and growing a startup.<br />The chance to work on some crazy projects: https://www.clikdapp.com/love-at-first-flight<br />The chance to work on some great community projects: https://www.clikdapp.com/loveinlondon<br />The chance to show off your creative side and work with other creatives: https://www.clikdapp.com/blog https://www.youtube.com/channel/UCBE7SuipvhPp4snKJPhhOKQ<br />A repository of portfolio work<br />The opportunity to work with a wide range of interesting entrepreneurs and awesome brands.<br />Weekly seminars from experienced professionals on a range of business topics.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XBiNwWw2QMisDh6LF_-e7Q",
    "url": "https://jobmote.com/job/53965/senior-data-architect-remote/",
    "title": "Senior Data Architect- REMOTE",
    "tags": [
      "DBG:surround``OR(work,countri,locat,contract,base,you W can) 2W anywher",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>NiFi, AWS, glue, Kinesis, ETL<br><br>If you are a Senior Data Architect (remote) with experience in AWS and ETL development/pipelines, please read on!<br><br>Located in Denver, Colorado (but this person can be located anywhere in the U.S.), we specialize in assisting our clients with their digital assets in the crypto portfolio/management space. We have been in business for a couple of years and are growing immensely. We are a tight-knit team over here so someone who enjoys working collaboratively will work great here!<br><br>We are looking for a talented Data Architect who is going to have a strong background in AWS, ETL development and Linux. Any experience with Glue, Kinesis, or Nifi is a PLUS! You will be responsible for building or architecting the infrastructure, as well as data modeling and potentially ingestion and ex-filtration of data to different sources. This is a leadership role so someone who enjoys being the most Senior on the team will like it here! Any experience in the Crypto, Blockchain, or Fiance world would also be a PLUS!<br><br>**Will require 50% travel to Denver at first, then flatten out to 25%**<br><br>What You Will Be Doing<br><br>-Working collaboratively in a team<br>-Utilizing AWS and ETL pipelines<br>-Architecting the infrastructure<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- NiFi<br>- AWS<br>- glue<br>- Kinesis<br>- ETLSo, if you are a Senior Data Architect- REMOTE with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zbp7oc8jQM25-_aGlUog9w",
    "url": "https://jobmote.com/job/53957/senior-data-quality-analyst-relocation-or-work-remote/",
    "title": "Senior Data Quality Analyst - Relocation or Work Remote",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 75000,
      "maxValue": 88000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 75k - 88k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Job DescriptionPremier global, high growth San Antonio Company is adding to the team due to growth. This well- established Company is known for its phenomenal benefits, single digit turnover, team atmosphere, internal promotion track record, and work life balance. It has an incredible reputation for being people centric and a huge contributor to the community.The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensuring that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primaryApply best-in-class testing methodologies to ensuring the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop an expertise in the Co. data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Co. data.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications and technical architecture QualificationsQualifications Bachelor's Degree (Master's preferred) 5+ years' experience; working with end-users stakeholders in testing and analytics Advanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause. Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills Excellent planning, organization and time management skills- Intense curiosity and passion for data. Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferred Experience with Total Quality Management (TQM) preferred. Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $75,000 -$88,000 plus 10% bonus, several weeks of vacation and great benefits</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GR3Q7fLWQuOMZIA8c8tRAQ",
    "url": "https://jobmote.com/job/53954/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Sr. Engineer - Product development?<br><br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.<br><br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.<br><br>Check out our website below to learn more about what we do and how we help our clients.<br><br>Primary Responsibilities:<br><br>???????? Provide thought leadership in architecture, design for analytics products<br><br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements<br><br>???????? Lead cross functional product development efforts<br><br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan<br><br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines<br><br>???????? Provide technical support to assist clients and partners during and post implementation<br><br>???????? Manage development resources onsite and offshore<br><br>???????? Develop and expand our application knowledge base and best practices for delivering data products<br><br>Required Experience and Skills:<br><br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem<br><br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must<br><br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must<br><br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem<br><br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills<br><br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.<br><br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture<br><br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)<br><br>???????? Experience with NoSQL databases<br><br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.<br><br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.<br><br>???????? Experience in professional services or technical consulting with enterprise software solutions<br><br>???????? Proven ability to balance and manage multiple, competing priorities.<br><br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.<br><br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.<br><br>What We Offer:<br><br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement<br><br>???????? Global career mobility, employee recognition programs, professional development<br><br>???????? State of the art technology which allows for seamless global connectivity<br><br>???????? Rich wellness program and health incentives<br><br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately<br><br>#LI-RD1<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eXvc5tc5Re6H4f7aUYmZhA",
    "url": "https://www.remotepython.com/jobs/bab7737f42d34a1b9de7072bf785c1d7/",
    "title": "Remote Data Scientist at Toughbyte",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``work 2W wherev 2W you",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:fabric/python/8",
      "DBG_TECH1:k/t/w:kotlin/mobile/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=5, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Toughbyte",
      "sameAs": "https://www.toughbyte.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 5:08:19 PM",
    "validThrough": "Aug 6, 2019 5:08:19 PM",
    "crawled": "Jul 30, 2019 5:08:19 PM",
    "content": "<h3>Remote Data Scientist</h3>Company: Toughbyte<br>Job Type:&nbsp;Full-time<div>                              <div>                      </div>                    <p></p><p>Our client is developing software to support the global food industry. The platform supports information flows within and across companies in the food value chain, enabling players in the industry to focus on their own specific tools and systems.</p><p><br>They are not building ERP systems, but rather the information fabric that can connect these systems and/or be the platform on which a new generation of ERP features can be built. Examples of such features are end-to-end tracking and tracing of foods to ensure food safety and product differentiation and new ways to trade to manage the ebbs and flow of supply and demand.<br><br>It is a remote-only company and they give their employees the opportunity to solve challenges in the global food industry while living and working wherever you are most comfortable. The company believes in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth.</p><p><strong>Requirements</strong></p><p>You have a proven track record of reading data and making solid conclusions. You know both the art <em>and</em> science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might help us further bolster our conclusions.  You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them!<br><br><strong>Must have skills:<br></strong><br></p><ul><li>Strong ML experience (not just a researcher)</li><li>Python</li><li>Strong development skills</li></ul><p><strong>Good to have skills:<br></strong><br></p><ul><li>Kotlin</li><li>Personality: communicative, independent, responsible </li><li>Teamwork </li></ul><p></p>                      <h4>Desired Skills</h4>            <ul>                              <li><span>Data Science</span></li>                              <li><span>Machine Learning</span></li>                          </ul>                                <h4>How to Apply</h4>            <p></p><p>Please send your CV to nina.shcherbakova@toughbyte.com</p><p></p>                                <h4>Contact Info</h4>            <ul>                                          <li><strong>Company Website:</strong> <a href='https://www.toughbyte.com/' rel='nofollow'>https://www.toughbyte.com/</a></li>            </ul>                  </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eX1n1odFQGCe15miRdECFw",
    "url": "https://remoteok.io/jobs/74209",
    "title": "Paid Research Study For Developers With Machine Learning Python Experience",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=38, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "User Research International",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 3:31:52 AM",
    "validThrough": "Aug 6, 2019 3:31:52 AM",
    "crawled": "Jul 30, 2019 4:06:30 AM",
    "content": "<span></span> <span><h4>User Research International</h4></span> <br> <h3>Paid Research Study For Developers With Machine Learning Python Experience</h3> <div>  <div>   <br>User Research International is a research company based out of Redmond, Washington. Working with some of the biggest companies in the industry, we aim to&nbsp;improve your experience via&nbsp;paid research studies. Whether it be the latest video game or productivity tools, we value your&nbsp;feedback and experience. We are currently conducting a research study called The Data Science\\Machine Learning Study. We are looking for current&nbsp;full-time&nbsp; Developers or Data Scientists&nbsp;who are familiar with&nbsp;Machine Learning,&nbsp;Python, and Jupyter Notebooks.This study is&nbsp;a one time study held remotely. We’re offering $200 for participation in this study. Session lengths are 1 hour. These studies provide a platform for our researchers to receive feedback. This will be a one hour open ended interview with the researcher. We want to understand how you personally create and work with machine learning models. We have included the survey link for the study below. Taking the survey will help determine if you fit the profile requirements. If you complete the survey, and you are actually a fit to the study's requirements, URI will follow up with you. I have summarized the study details below. Thank you!   <br>   <br>Study: The Data Science\\Machine Learning&nbsp;Study   <br>   <br>Gratuity: $200   <br>   <br>Session Length:&nbsp;1 hour&nbsp;   <br>   <br>Location:&nbsp;Remote via an online meeting   <br>   <br>Dates:&nbsp;August. Available&nbsp;times are located within the survey   <br>   <br>Survey: The Data Science\\Machine Learning&nbsp;Study  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "8MTcq0kwQV-ClUKxLDqRUQ",
    "url": "https://jobmote.com/job/53741/data-engineer-remote/",
    "title": "Data Engineer (Remote)",
    "tags": [
      "DBG:surround``5N( opportun,             2N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=56, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 50000,
      "maxValue": 55000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 50k - 55k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:07:27 PM",
    "validThrough": "Aug 1, 2019 10:07:27 PM",
    "crawled": "Jul 30, 2019 3:06:25 AM",
    "content": "<div>Data Engineer (Remote) - <br><br>Urgent requirement for a leading client in the travel and tourism industry looking for a Data Engineer (Remote). Even though they have been in the industry for over 25 years, they still have an innovative, entrepreneurial and start up mentality. <br><br>They are in the process of moving their data storage to scalable environment using Google Cloud Services. They are experimenting with live streaming data and improving the batch processing. <br><br>Data Engineer (Remote) - Key requirements:<br><br>Experienced Data Engineer with expertise in writing advanced SQL<br>Strong experience with Python programming<br>Proven ability to work with a variety of data infrastructure, including relational databases (e.g. DB2, MySQL), and column store (e.g. Google Big Query, Redshift)<br>Expertise in building and maintaining reliable ETL jobs<br>Experience working with Talend, Luigi or Apache Airflow.<br><br>Data Engineer (Remote) - Role and responsibility: <br><br>Responsibility to deliver the data requirements to the business<br>Migrating data pipelines from legacy platforms to the new cloud based data stack<br>Lead in solving Insurance specific challenges and delivering innovative solutions for the business<br>Learning and working with cutting-edge tech and solutions.<br><br>As a Data Engineer (Remote), you would have the opportunity to join at an exciting period of exceptional projected growth. The team move fast and deliver excellence at pace, never accepting second best.<br><br>We are looking to line up interviews as of immediately, so if you are interested in hearing more about this vacancy and organisation, please don't hesitate to apply.<br><br>Location: Remote (Required to be UK based)<br><br>Employment: Permanent<br><br>Salary: £50,000 - £55,000 (depending on experience)<br><br>Sponsorship: Not available</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "oJKxihbnTmCVeaFyWGlCng",
    "url": "https://jobmote.com/job/53728/data-engineer-remote/",
    "title": "Data Engineer (Remote)",
    "tags": [
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:07:26 PM",
    "validThrough": "Aug 1, 2019 10:07:26 PM",
    "crawled": "Jul 30, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>AWS, ETL, Data Conversion, Oracle, SQL<br><br>If you are a Data Engineer (Remote) with experience, please read on!<br><br>What You Will Be Doing<br><br> Recommend and implement data processing tools and technologies<br> Extract, transform and load data pipelines from end-to-end<br> Create, develop and document data mapping rules<br> Data cleansing and transformation<br> Write specifications from which conversion programs will be written<br> Collaborate with subject matter experts to ensure that the specifications meet the business and system requirements<br> Utilize tools and applications to analyze and convert data to a standardized format<br> Recommend and implement data processing tools and technologies to keep us at the forefront of real estate data science<br> Develop continuous process improvements<br> Identify and fix data bugs and improve the overall quality of information<br><br>What You Need for this Position<br><br> Have 3+ years of experience using data and related technologies such as SQL, Oracle, AWS and scripting languages to aggregate, gather, and manipulate data<br> Understand databases, data conversion, and data cleansing methods<br> Have experience parsing and mapping data<br> Have advanced Microsoft Excel experience<br> Are an analytical, results-driven individual with great attention to detail and excellent problem solving and critical thinking skills<br> Real Estate data experience is a plus!<br><br>What's In It for You<br><br>- Competitive Pay<br>- Partial or full remote is an option!<br>- Medical, Dental, Vision<br>- Flexible PTOSo, if you are a Data Engineer (Remote) with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "L7latbTzSvykpqHSCgs42w",
    "url": "https://stackoverflow.com/jobs/285252/paid-research-study-for-developers-with-machine-user-research-international?a=1xFd0np8eBQA",
    "title": "Paid Research Study for Developers with Machine Learning + Python Experience at User Research ...",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:techWeightMap:{python=8, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "User Research International",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:30:25 PM",
    "validThrough": "Aug 5, 2019 10:30:25 PM",
    "crawled": "Jul 29, 2019 10:30:25 PM",
    "content": "<h3><span>Paid Research Study for Developers with Machine Learning + Python Experience</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>AI Research, Market Research, Surveying</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: User Research International | No office location<br></div><h4>Technologies</h4><div></div><div>python</div><div>machine-learning</div><div>jupyter-notebook</div><div>data-science</div><div>jupyter-lab</div>                <h4>Job description</h4>                <div><p>User Research International is a research company based out of Redmond, Washington. Working with some of the biggest companies in the industry, we aim to&nbsp;improve your experience via&nbsp;paid research studies. Whether it be the latest video game or productivity tools, we value your&nbsp;feedback and experience. We are currently conducting a research study called The Data Science\\Machine Learning Study. We are looking for current<strong>&nbsp;full-time&nbsp; Developers or Data Scientists</strong>&nbsp;who are familiar with&nbsp;Machine Learning,&nbsp;Python, and Jupyter Notebooks.This study is&nbsp;a one time study held remotely. We’re offering <strong>$200</strong> for participation in this study. Session lengths are 1 hour. These studies provide a platform for our researchers to receive feedback. This will be a one hour open ended interview with the researcher. We want to understand how you personally create and work with machine learning models. We have included the survey link for the study below. Taking the survey will help determine if you fit the profile requirements. If you complete the survey, and you are actually a fit to the study's requirements, URI will follow up with you. I have summarized the study details below. Thank you!</p><p>Study: The Data Science\\Machine Learning&nbsp;Study</p><p>Gratuity: <strong>$200</strong></p><p>Session Length:&nbsp;1 hour&nbsp;</p><p>Location:&nbsp;Remote via an online meeting</p><p>Dates:&nbsp;August. Available&nbsp;times are located within the survey</p><p>Survey: <a title=&quot;Click here to qualify for participating in the Data Science\\Machine Learning Survey&quot; href='https://uriuxn.ca1.qualtrics.com/jfe/form/SV_2fTdSmgpchX943P?SOURCE=StackOverflow' rel='nofollow'>The Data Science\\Machine Learning&nbsp;Study</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/285252?reset=False&amp;ra=1xFd0np8eBQA&amp;oqs=a%3D1xFd0np8eBQA' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About User Research International</h4>            <div><p>We use your experience to improve upon the products you use. Whether it be the latest video game or productivity tools, we value your experience.&nbsp;</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Paid research studies</span>                            </li>                            <li>                                <span></span>                                <span>Improving tech</span>                            </li>                            <li>                                <span></span>                                <span>Getting  your feedback and experience</span>                            </li>                            <li>                                <span></span>                                <span>Meeting researchers working directly on the products you use</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZZzeZGbSR_-rj02Z6r98yg",
    "url": "http://workinstartups.com/job-board/job/82786/cto-at-tbc/",
    "title": "CTO",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:android/java/1",
      "DBG_TECH1:k/t/w:android/mobile/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=4, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=2, java=1, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TBC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 11:02:07 PM",
    "validThrough": "Aug 4, 2019 11:02:07 PM",
    "crawled": "Jul 29, 2019 12:06:30 PM",
    "content": "Looking for a CTO as a partner within a venture that is going through its first round of investment. Equity rather than salary at this stage. Must be prepared to get hands dirty and be able to code including Amazon Lex/Lambda and front end iOS and Android. <br />Project is secret but has a great team on board. Very cutting edge tech. Great founders and amazing proposition.<br />Looking for a CTO who wants to build something on the side as the heavy lifting has been done. A great opportunity for someone that wants to help women globally.<br />Please reply with CV. Experience of previous startup successes a bonus. Work can be remote at this stage but must be in London for meetings with the founding team. <br />We're at a stage of building MVP having full proposition, brand, UI/UX and full tech proposition established.<br />This is an opportunity for someone who can create a great future for themselves within a team that just wants to do something AMAZING!",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Z_Yxf1InSQKrpOKs362YNA",
    "url": "https://jobmote.com/job/52859/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:25 PM",
    "validThrough": "Jul 31, 2019 10:07:25 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2dYAiTMESuqEbnE533ulNg",
    "url": "https://jobmote.com/job/52843/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>Sr. Engineer - Product development?<br><br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.<br><br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.<br><br>Check out our website below to learn more about what we do and how we help our clients.<br><br>Primary Responsibilities:<br><br>???????? Provide thought leadership in architecture, design for analytics products<br><br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements<br><br>???????? Lead cross functional product development efforts<br><br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan<br><br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines<br><br>???????? Provide technical support to assist clients and partners during and post implementation<br><br>???????? Manage development resources onsite and offshore<br><br>???????? Develop and expand our application knowledge base and best practices for delivering data products<br><br>Required Experience and Skills:<br><br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem<br><br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must<br><br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must<br><br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem<br><br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills<br><br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.<br><br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture<br><br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)<br><br>???????? Experience with NoSQL databases<br><br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.<br><br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.<br><br>???????? Experience in professional services or technical consulting with enterprise software solutions<br><br>???????? Proven ability to balance and manage multiple, competing priorities.<br><br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.<br><br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.<br><br>What We Offer:<br><br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement<br><br>???????? Global career mobility, employee recognition programs, professional development<br><br>???????? State of the art technology which allows for seamless global connectivity<br><br>???????? Rich wellness program and health incentives<br><br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately<br><br>#LI-RD1<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IC7N0AWzSlyUl5pE1Cw6nQ",
    "url": "https://jobmote.com/job/52837/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>Azure Big Data Engineer (Remote Flexibility)<br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.<br> *AZURE EXPERIENCE REQUIRED<br> Skills:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience with data pipeline and workflow management tools</li></ul>Benefits:<ul><li>Medical</li><li>Dental</li><li>Vision</li><li>Family leave</li><li>PTO</li><li>Retirement Plan</li><li>Remote options</li></ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br><br><b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "VrBoioWkTZ-olOsb2AlUjw",
    "url": "https://jobmote.com/job/52831/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9F-zgQMfQZusSb0mQVwt4Q",
    "url": "https://www.remoteage.com/remote-jobs/data-engineer-true-north-11/",
    "title": "Data Engineer, True North",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:iphone/apple/2",
      "DBG_TECH1:k/t/w:iphone/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=6, c=2, mobile=3, go=0, nodejs=2, bigdata-ml=56, ruby=2, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Delaware North",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 27, 2019 1:08:59 PM",
    "validThrough": "Aug 3, 2019 1:08:59 PM",
    "crawled": "Jul 27, 2019 2:07:19 PM",
    "content": "<h3> Data Engineer, True North </h3>\n<div>\n United States, New York\n</div>\n<div>\n Company: Delaware North\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p>Our Exciting Work Environment This position will be based out of Delaware North’s new global headquarters, a state-of-the-art, 12-story, mixed-use building in downtown Buffalo, N.Y. The headquarters facility, reflective of our values, integrates the latest advances in environmental, energy conservation and office design. <br>The Opportunity At Delaware North we have a a long history of operational success and we have ambitious goals for our future growth and operating performance. These aspirations are supported by a transformative enterprise-wide initiative called True North. True North re-imagines the Delaware North operating model by creating processes and tools and providing enhanced support to our local teams that will enable us to best serve our guests, clients, and 55,000+ associates. <br> To achieve these goals, we need people like you. The True North team is hiring a Data Engineer to be part of our Data Solutions Team. <br> Data Solutions is a rapidly growing team that enables Delaware North’s vision of using data as differentiator in the hospitality industry. Our work is the foundation of company initiatives to automate business processes, gather insights, and make informed decisions. Our team uses PaaS solutions and Open Source Software to aggregate, process, catalog and distribute large data sets throughout Delaware North’s global organization, client base and partners. These foundational services empower Delaware North’s mobile, data science, business intelligence, and operational systems. Users of the Delaware North Data Platform range from NASA to several MLB, NBA, NHL, &amp; NFL teams. As a member of our team, the Data Solutions Support Engineer will provide health monitoring and unparalleled customer advocacy for Delaware North’s distributed data platform (Data Lake). <br> The Data Engineer will work closely with the Business to identify and specify opportunities for integration with existing systems in a highly resilient manner using Delaware North’s Data Platform. After the identification of business requirements, the Data Engineer will participate in various exercises to design a technical solution as well as participate in the implementation with internal team mates and off-shore resources. As implementation progresses, the Data Engineer will keep the lines of communication open with internal clients regarding solution status and address technical blockers that may arise. Additionally, the holder of this position will develop integration tests to validate solution acceptance criteria and participate in free-form experimental exercises to keep skills and team goals modernized. <br> Where you fit in:</p>\n <ul>\n  <li> Design and implement project based solutions </li>\n  <li> Implement data platform improvements and new features </li>\n  <li> Assist support team with resolution of Data Platform bug fixes </li>\n  <li> Interface with clients, vendors, and internal users of the data platform on understanding the data </li>\n  <li> Participate in group design and architecture sessions </li>\n  <li> Author documentation for standard operating procedures, knowledge base articles, etc. </li>\n </ul>\n <p> Skills &amp; experience you need:</p>\n <ul>\n  <li> Minimum 2 years of related professional experience </li>\n  <li> Bachelor’s degree in Computer Science, Information Systems or similar STEM field preferred </li>\n  <li> Experience designing and developing solutions with a modern programming language such as Python, Ruby, JavaScript, Java, C#, etc </li>\n  <li> Working knowledge of data structures and formats such as JSON and XML </li>\n  <li> Excellent organizational, oral and written communication skills </li>\n  <li> Ability to effectively collaborate with Business Users and vendors to address development issues </li>\n  <li> Ability to effectively troubleshoot and track issues through to resolution </li>\n  <li> Passion for delivering high quality and meaningful results </li>\n  <li> Technical specification and use case (story) documentation. </li>\n  <li> Such as UML, Domain and Entity Relationship Modeling, Business Process Notation </li>\n  <li> Data Persistence Methods such as NoSQL and RDBMS (MSSQL, Oracle, MySQL, MongoDB) </li>\n  <li> Familiarity with Data Mapping &amp; Transformation Techniques </li>\n </ul>\n <p> Preferred skills:</p>\n <ul>\n  <li> Familiarity with RESTful Web Services, ETL, ESB, and microservices </li>\n  <li> Integration testing and automation using a continuous integration (CI) platform (such as Jenkins, TeamCity or Bamboo) </li>\n  <li> Familiarity with cloud computing, analysis &amp; implementation experience (bonus if it relates to Amazon Web Services specifically) </li>\n  <li> Experience working with Agile methodologies </li>\n  <li> Proficiency with Unix/Linux </li>\n  <li> Experience with Configuration Management tools (such as Ansible, Chef, etc.) </li>\n </ul>\n <p> Here’s some of what you’ll get in return:</p>\n <ul>\n  <li> Join a creative and highly collaborative team that is empowered to select the right technology for the task at hand </li>\n  <li> Regularly scheduled “innovation time” to work on creative applications of new technology (doesn’t have to be work related) </li>\n  <li> Flexible work schedule, “casual Fridays”, and ability to work remotely in certain cases </li>\n  <li> Opportunity for travel to interesting field locations (small percentage of travel required) </li>\n  <li> Company paid iPhone with LTE service </li>\n  <li> Free coffee, espresso, cappuccino, fruits, and bagels </li>\n  <li> Yearly paid training, conference and certifications of your choice </li>\n  <li> Career growth – Delaware North values and invests in its family and promotes from within regularly </li>\n  <li> Benefits including health, dental, paid vacation &amp; holidays, life insurance, short &amp; long term disability, company discounts </li>\n  <li> Bonus eligibility </li>\n  <li> 401k with employer match and financial planning services </li>\n  <li> Choice of MacBook Pro or PC Ultrabook and peripherals </li>\n </ul>\n <p>Who We Are Take your career beyond the ordinary-to the extraordinary.<br> At Delaware North, you’ll love where you work, who you work with, and how your day unfolds. Whether it’s in sporting venues, casinos, airports, national parks, iconic hotels, or premier restaurants, there’s no telling where your career can ultimately take you. We empower you to do great work in a company with 100 years of success, stability and growth. If you have drive and enjoy the thrill of making things happen – share our vision, grow with us.<br> Delaware North is one of the largest privately held hospitality companies in the world. Founded in 1915 and owned by the Jacobs family for more than 100 years, Delaware North has global operations at high-profile places such as sports and entertainment venues, national and state parks, destination resorts and restaurants, airports, and regional casinos. Our 55,000 employee associates are dedicated to creating special experiences one guest at a time in serving more than a half-billion guests annually. Delaware North operates in the sports, travel hospitality, restaurant and catering, parks, resorts, gaming, and specialty retail industries and has annual revenue of about $3 billion. Learn more about Delaware North, a global leader in hospitality, at .<br> All applicants will be subject to a pre-employment background check and may be subject to a pre-employment drug test depending upon the position and/or client requirements.<br> Delaware North Companies, Incorporated and its subsidiaries consider applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status. Delaware North is an equal opportunity employer.<br> #LI-PE1<br></p> \n <div> \n  <a href='https://www.jobg8.com/ATSApply.aspx?re6gYjdkhs%2frkEJdnuzpmwq' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "bGHjqDpvRYiFLE2IeFYV3g",
    "url": "http://workinstartups.com/job-board/job/82776/graphic-designer-at-vendi-an-ai-assisted-p2p-marketplace-to-buy-and-sell-verified-phones-at-vendi/",
    "title": "Graphic Designer at vendi, an AI-assisted P2P marketplace to buy and sell verified phones",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(fulltim,offer) 5W 2N(work,remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "vendi",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 27, 2019 9:49:56 AM",
    "validThrough": "Aug 3, 2019 9:49:56 AM",
    "crawled": "Jul 27, 2019 11:06:30 AM",
    "content": "**Intro:**\n<br>\n<br>Interested in working with an exciting young tech-startup that uses Machine Learning to create a high quality marketplace community…to become the Amazon of peer to peer? vendi is an AI-assisted marketplace for you to buy and sell quality products. We are starting with phones. We use AI to list and verify the phone for you in seconds.\n<br>\n<br>This is an awesome opportunity to work with a young and dynamic team and get a good foothold in a fast expanding startup company. You will have a possibility to grow within the team, playing a crucial role in taking the companies design to the next level. Perfect for anyone who is interested in the tech industry and even more of a plus if you have an interest in AI and Machine Learning.\n<br>\n<br>**About the role:****\n<br>\n<br>We are looking for a Graphic Designer who can support our team in our office in central London. We will also offer the opportunity to work remotely. This internship is a unique opportunity to gain insights into a new venture during the early stages of growth.\n<br>\n<br>The main contents of the role is to improve the existing design of the website, help on social media content, and the app. We need someone who learns fast, is self-motivated, proactive and multi-disciplined.\n<br>\n<br>**Your Skills**\n<br>\n<br>Uses Illustrator/Invision/Photoshop/Sketch or any similar UI Graphic Design tools.\n<br>A plus if you are knowledgeable about marketplace startups.\n<br>You are driven and have a “hands-on” mentality;\n<br>You feel comfortable handling different and multiple tasks on a daily basis;",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j2H86qOVT8a1tH-YRR89GQ",
    "url": "https://jobmote.com/job/52569/remote-working-machine-learning-engineer-uk/",
    "title": "Remote-working Machine Learning Engineer UK",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:express/nodejs/16",
      "DBG_TECH1:k/t/w:java/java/14",
      "DBG_TECH1:k/t/w:java/mobile/7",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/28",
      "DBG_TECH1:k/t/w:neo4j/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/14",
      "DBG_TECH1:techWeightMap:{python=14, other=0, dotnet=0, c=0, mobile=7, go=0, nodejs=16, bigdata-ml=34, ruby=0, apple=0, java=14, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Searchability",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 60000,
      "maxValue": 60000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 60k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:07:21 PM",
    "validThrough": "Jul 29, 2019 10:07:21 PM",
    "crawled": "Jul 27, 2019 3:06:25 AM",
    "content": "<div>\n <p><strong>Remote Machine Learning Engineer - Machine Learning / Software Engineering / AWS / Python or Java</strong></p> \n <p><strong>BRAND NEW FULLY REMOTE OPPORTUNITY WITHIN AN EXCITING AND EXPANDING START-UP DEVELOPING A CUTTING-EDGE CLOUD PRODUCT!!</strong></p> \n <ul>\n  <li>Mid-level to senior candidates will be considered</li>\n  <li><strong>Full-time remote working opportunity </strong></li>\n  <li>Flexible working hours and flexible annual leave</li>\n  <li>Machine Learning / Software Engineering / AWS / Python or Java</li>\n  <li><strong>Salary up to £60,000</strong></li>\n  <li>To apply, either call <strong>/</strong> or email </li>\n </ul>\n <p>Headquartered in Southampton, we are a rapidly expanding start-up who are seeking to appoint a talented Machine Learning Engineer with solid Machine Learning / Software Engineering / AWS / Python or Java knowledge to join our team. Using cutting-edge technology, we are developing a cloud product providing scalable predictive maintenance to globally recognised clients.</p> \n <p>Sourced by <strong></strong> - your 24/7 twitter feed of latest IT vacancies across the South West!</p> \n <p><strong>WHO ARE WE? </strong></p> \n <p>Since our inception in 2014, we have continued to grow and are now a leading cloud-based software house for predictive maintenance. Driven by the Industrial IoT, We are developing cutting-edge cloud products within the manufacturing sector, focused around advanced condition monitoring and providing scalable prognostics. We fully promote a start-up vibe, based around trust and excellence. We offer remote working, flexible working hours and flexible annual leave. Now with globally recognised clients and having branched out into Europe, we are now looking to further expand our team by appointing a talented and dedicated Machine Learning Engineer with solid Machine Learning / Software Engineering / AWS / Python or Java experience.</p> \n <p><strong>WHAT WILL YOU BE DOING? </strong></p> \n <p>Immersing yourself as a key member of the engineering team, you will use your Machine Learning / Software Engineering / AWS / Python or Java skills to bring research into production. You will be building complex Machine Learning applications and regualrly be involved in Microservice architecture. You will understand information from the R&amp;D teams and be able to put this into production software. You will be building complex applications using best practices such as code reviews, continuous deployment and test-driven development. You will be utilising your knowledge of supervised and unsupervised Machine Learning techniques daily. Ideally, you will have knowledge of either MongoDB, Redis or Neo4J. Interviews are being held week beginning <strong>29th July</strong>, so please apply today to express your interest!</p> \n <p><strong>WE NEED YOU TO HAVE….</strong></p> \n <ul>\n  <li>Machine Learning / Software Engineering / AWS / Python or Java</li>\n  <li>Ideally at least 2 years' experience</li>\n  <li>Experience with supervised and unsupervised Machine Learning techniques</li>\n  <li>Experience with Microservices architecture</li>\n  <li>Experience with Linux or Docker </li>\n </ul>\n <p><strong>IT'S NICE TO HAVE….</strong></p> \n <ul>\n  <li>Experience with MongoDB, Redis or Neo4j</li>\n  <li>Familiar with scalable cloud systems</li>\n </ul>\n <p><strong>TO BE CONSIDERED….</strong></p> \n <p>Please either apply by clicking online or emailing me directly to - For further information please call me on <strong>/ </strong>. I can make myself available outside of normal working hours to suit from 7am until 10pm. If unavailable, please leave a message and either myself or one of my colleagues will respond. By applying for this role, you give express consent for us to process &amp; submit (subject to required skills) your application to our client in conjunction with this vacancy <strong>only. </strong>Also feel free to follow me on Twitter<strong> </strong>or connect with me on LinkedIn! I look forward to hearing from you.</p> \n <p><strong>KEY SKILLS: </strong></p> \n <p><strong>Machine Learning / Software Engineering / AWS / Python or Java </strong> </p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TqR3y-SqTUSb-cyvDpHONw",
    "url": "https://jobmote.com/job/52540/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:07:21 PM",
    "validThrough": "Jul 29, 2019 10:07:21 PM",
    "crawled": "Jul 27, 2019 3:06:25 AM",
    "content": "<div>\n This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.\n <br>\n <br>?\n <br>\n <br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:\n <ul>\n  <li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li>\n  <li>Seeking new learning from the collected data</li>\n  <li>Taking advantage of the increasing amount of data collected from the company's new products</li>\n  <li>Leveraging new data collection processes and sources</li>\n  <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li>\n  <li>Anticipating, identifying and investigating data trends</li>\n  <li>Discovering actionable insights</li>\n  <li>Identifying business opportunities</li>\n </ul>?\n <br>\n <br>Candidates will have a minimum background consisting of the following:\n <ul>\n  <li>Must reside within a three hour drive of Madison, Wisconsin</li>\n  <li>Five years of experience as a Data Scientist</li>\n  <li>Strong ability to talk through findings and algorithms?</li>\n  <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li>\n  <li>SQL relational database experience</li>\n  <li>Data visualization experience</li>\n  <li>Data analysis programming language experience</li>\n  <li>Statistical software experience</li>\n  <li>ETL knowledge</li>\n </ul>\n <em><b>Preferred</b></em> but \n <em><b>not required</b></em> backgrounds will include \n <b><em> any </em></b> of the following:?\n <ul>\n  <li>Insurance industry experience</li>\n  <li>Tableau experience</li>\n  <li>Power BI experience</li>\n  <li>SQL Server experience</li>\n  <li>SSRS, Performance Point experience</li>\n  <li>Python experience</li>\n  <li>Algorithm ?experience</li>\n  <li>AWS Cloud service experience EC2 experience</li>\n  <li>RDS experience S3 experience</li>\n </ul>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F-FvbzvIRRKfzjCmzhdXIw",
    "url": "https://www.remoteage.com/remote-jobs/big-data-engineer-54/",
    "title": "Big Data Engineer",
    "tags": [
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=122, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Oscar Technology",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 1:37:56 PM",
    "validThrough": "Aug 2, 2019 1:37:56 PM",
    "crawled": "Jul 26, 2019 2:08:14 PM",
    "content": "<h3> Big Data Engineer </h3>\n<div>\n Netherlands, Not Specified\n</div>\n<div>\n Company: Oscar Technology\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p><strong>Big Data Engineer – The Hague – Hadoop, ETL</strong></p>\n <p><strong>The Role</strong></p>\n <p>Are you a wiz at creating, managing and optimising big data infrastructures as well as developing creative data driven solutions? Do you have experience with Hadoop eco systems and your looking to work as part as one of the Netherlands most revered Data Science teams whilst earning excellent bonuses and getting 30 days holiday a year?</p>\n <p>If you’re a data engineer, your probably highly versatile… you will be expected to manage data infrastructures, develop software solutions and integrate data from various systems whilst working on creative machine learning software solutions for nationally based clients.</p>\n <p><strong>Big Data Engineer Role Requirements</strong></p>\n <ul>\n  <li>Hadoop (Minimum one year)</li>\n  <li>ETL</li>\n  <li>SQL</li>\n </ul>\n <p><strong>The Company</strong></p>\n <p>The type of company that understands that its candidates are at the fore front of its business and therefor treats them accordingly, salaries are far above average with an exceedingly good bonus, mobile phone and laptop, 8% holiday allowance on top of your salary and a great culture to work in!</p>\n <p><strong><em>Apply now;</em></strong></p>\n <p>If you’re a big data engineer with experience with Hadoop, ETL and SQL and you’re looking to work on continuously exciting projects with of the Netherlands most successful Data Science teams whilst earning a great salary and exceptional benefits then don’t waste time.</p>\n <p><strong><em>Interviews for this position will be commencing immediately, don’t miss out and submit your CV by clicking ‘apply now’!</em></strong></p>\n <p><strong>Big Data Engineer – The Hague – Hadoop, ETL</strong></p>\n <p>Oscar Technology is acting as an Employment Agency in relation to this vacancy.</p>\n <p>To understand more about what we do with your data please review our privacy policy at https://our-privacy-policy.</p>\n <p></p> \n <div> \n  <a href='https://www.jobg8.com/Traffic.aspx?YprSDCQqZZRc2eduf8Kq5Qa' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "PJ9Q5ZKvRZu-yMipAQtoGw",
    "url": "https://stackoverflow.com/jobs/284584/senior-data-scientist-remote-global-wallethub?a=1xrjQAPyAAAo",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:06:25 AM",
    "validThrough": "Aug 2, 2019 10:06:25 AM",
    "crawled": "Jul 26, 2019 10:06:25 AM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/284584?reset=False&amp;ra=1xrjQAPyAAAo&amp;oqs=a%3D1xrjQAPyAAAo' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "k7VMPt_qRM-JCVaT2hx6MA",
    "url": "https://jobmote.com/job/52469/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:07:26 PM",
    "validThrough": "Jul 28, 2019 10:07:26 PM",
    "crawled": "Jul 26, 2019 3:06:25 AM",
    "content": "<div>\n Company Information\n <br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n <br>\n <br>Job Summary\n <br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.\n <br>\n <br>Primary Job Duties &amp; Responsibilities\n <br>\n <ul>\n  <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> \n  <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> \n  <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> \n  <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> \n  <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> \n  <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> \n  <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> \n  <li>This position is open for candidates to work remotely.</li> \n </ul>\n <br>Minimum Qualifications\n <br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.\n <br>\n <br>Education, Work Experience &amp; Knowledge\n <br>\n <ul>\n  <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> \n  <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> \n  <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> \n  <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> \n  <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> \n  <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> \n  <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> \n  <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> \n  <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> \n  <li>Experience building microservices and Real Time APIs</li> \n  <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> \n  <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> \n  <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> \n  <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> \n  <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> \n  <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> \n  <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> \n  <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> \n  <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> \n  <li>Advanced IT process improvement, and problem-solving skills</li> \n  <li>Comfortable presenting to senior management</li> \n </ul>\n <br>Job Specific &amp; Technical Skills &amp; Competencies\n <br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.\n <br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.\n <br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.\n <br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.\n <br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.\n <br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th\n <br>\n <br>Environmental/Work Schedules/Other\n <br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.\n <br>\n <br>Physical Requirements\n <br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.\n <br>\n <br>Licensing or Certificates\n <br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe\n <br>\n <br>Equal Employment Opportunity Statement\n <br>Travelers is an equal opportunity employer. \n <br>To apply for this position please \n <b>CLICK HERE</b> \n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xphu0IMHRHqKkY8FqmRxwA",
    "url": "https://jobmote.com/job/52468/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:07:26 PM",
    "validThrough": "Jul 28, 2019 10:07:26 PM",
    "crawled": "Jul 26, 2019 3:06:25 AM",
    "content": "<div>\n Company Information\n <br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n <br>\n <br>Job Summary\n <br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.\n <br>\n <br>Primary Job Duties &amp; Responsibilities\n <br>\n <ul>\n  <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> \n  <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> \n  <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> \n  <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> \n  <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> \n  <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> \n  <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> \n  <li>This position is open for candidates to work remotely.</li> \n </ul>\n <br>Minimum Qualifications\n <br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.\n <br>\n <br>Education, Work Experience &amp; Knowledge\n <br>\n <ul>\n  <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> \n  <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> \n  <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> \n  <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> \n  <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> \n  <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> \n  <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> \n  <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> \n  <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> \n  <li>Experience building microservices and Real Time APIs</li> \n  <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> \n  <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> \n  <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> \n  <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> \n  <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> \n  <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> \n  <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> \n  <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> \n  <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> \n  <li>Advanced IT process improvement, and problem-solving skills</li> \n  <li>Comfortable presenting to senior management</li> \n </ul>\n <br>Job Specific &amp; Technical Skills &amp; Competencies\n <br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.\n <br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.\n <br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.\n <br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.\n <br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.\n <br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th\n <br>\n <br>Environmental/Work Schedules/Other\n <br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.\n <br>\n <br>Physical Requirements\n <br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.\n <br>\n <br>Licensing or Certificates\n <br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe\n <br>\n <br>Equal Employment Opportunity Statement\n <br>Travelers is an equal opportunity employer. \n <br>To apply for this position please \n <b>CLICK HERE</b> \n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qJwiLmdfSPGbjXewSFRLOQ",
    "url": "https://remoteok.io/jobs/74140",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``work 2W wherev 2W you",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=20, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Crisp ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:51:50 PM",
    "validThrough": "Aug 1, 2019 10:51:50 PM",
    "crawled": "Jul 25, 2019 11:30:31 PM",
    "content": "<span></span> \n<span><h4>Crisp</h4>&nbsp;</span> \n<br> \n<h3>Data Scientist</h3> \n<div> \n <div> \n  <br>Crisp is a remote-only company and we give our employees the opportunity to solve problems in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth. \n  <br> \n  <br>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turning previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more. &nbsp; \n  <br> \n  <br>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;and&nbsp;science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might could help us further bolster our conclusions. &nbsp;You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them! \n  <br> \n  <br>We are building a product engineering team with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific educational background, technology, experience or geographical location.&nbsp; We are however looking for specific traits in the people we work with. You might not yet be able to check all of the boxes, but at least you aspire to do so!&nbsp; \n  <br> \n  <br>Signs of a great candidate Toolbox oriented.&nbsp;Whether your background is in mathematics, statistics, machine learning, artificial intelligence, or something else, you have enough experience to intuitively shortlist tools and approaches from most of these disciplines.&nbsp; \n  <br> \n  <br>Understanding business and customer needs. &nbsp;You believe in creating models that will help the company and make short- and long-term impact, focusing on“bang-for-the-buck”.&nbsp; \n  <br> \n  <br>Performance recognized by your peers.&nbsp;Past colleagues would love to work with you again. \n  <br> \n  <br>Starter and finisher.&nbsp;You often identify a problem, design a solution and bring it to a state of completion - alone or with collaborators. You’ve worked with developers in the past, hope to continue doing so, but you would get far even without technical help. \n  <br> \n  <br>Work hard and smart.&nbsp;Your work ethic is unquestioned, and you know how to get things done so you can balance your work and personal life in a sustainable way. \n  <br> \n  <br>Disciplined and reliable.&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early. \n  <br> \n  <br>Collaborative.&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to make the team perform. \n  <br> \n  <br>Appreciation of honest feedback.&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You feedback given to as an opportunity to get better and strive to do the same for others. \n  <br> \n  <br>Analytical and practical mind.&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed.&nbsp; \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "M11C4ngDQ1q14KXYd9xBpQ",
    "url": "https://www.remotepython.com/jobs/6e7a9f42e303484d80abff58ea6952ae/",
    "title": "Sr Software Developer/Data Engineer at Pivot Bio",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Pivot Bio",
      "sameAs": "https://www.pivotbio.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 6:25:42 PM",
    "validThrough": "Aug 1, 2019 6:25:42 PM",
    "crawled": "Jul 25, 2019 6:25:42 PM",
    "content": "<h3>Sr Software Developer/Data Engineer</h3>Berkeley, California, United States\n<br>Company: Pivot Bio\n<br>Job Type:&nbsp;Full-time\n<div> \n <div> \n </div> \n <p></p>\n <p>We are seeking an experienced software engineer to design, build, and maintain tools that streamline our research and development efforts. As an essential part of our data science team this role will help our researchers develop a pipeline of products to support the agricultural community.</p>\n <p>The first responsibility of this role will be to build tools for our field team to ingest and register spatial data coming in from our field and agronomy team but has the potential to grow into a lead position managing multiple key projects.</p>\n <p>Location: Remote OK</p>\n <p>Responsibilities: Independently design and develop data, software, or technology solutions to answer scientific or business questions. Demonstrate proficiency across a range of technologies related to programming languages, data integration, data warehousing, visualization, and analytics. Collaborate with research scientists to identify and understand their analytical and informatics needs and translate these into solutions. Communicate and collaborate effectively with colleagues in varied scientific and technical roles. Maintain a working knowledge of technologies, development tools, practices, methods and libraries relevant to software engineering and data science. Present projects and systems in front of both scientific and technical audiences.</p>\n <p></p> \n <h4>Desired Skills</h4> \n <ul> \n  <li><span>Big Data</span></li> \n  <li><span>Data Science</span></li> \n </ul> \n <h4>Contact Info</h4> \n <ul> \n  <li><strong>Company Website:</strong> <a href='https://www.pivotbio.com/' rel='nofollow'>https://www.pivotbio.com/</a></li> \n </ul> \n</div>\n<a href='https://www.python.org/jobs/3985/' rel='nofollow'>Apply</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "1nejIQgQR7yYRE96LyhrBg",
    "url": "https://stackoverflow.com/jobs/284454/data-scientist-remote-europe-crisp?a=1xoCfYBA0oPC",
    "title": "Data Scientist - [Remote] - [Europe] at Crisp  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:jvm/java/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Crisp",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 5:06:25 PM",
    "validThrough": "Aug 1, 2019 5:06:25 PM",
    "crawled": "Jul 25, 2019 5:06:25 PM",
    "content": "<h3><span>Data Scientist - [Remote] - [Europe]</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Computer Software, Food &amp; Beverage</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>VC Funded</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Crisp | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT+01:00) Central European Time - Belgrade </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n jvm\n</div>\n<div>\n postgresql\n</div> \n<h4>Job description</h4> \n<div>\n <p>Crisp is a remote-only company and we give our employees the opportunity to solve problems in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth.</p>\n <p>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turning previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more. &nbsp;</p>\n <p>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;<em>and</em>&nbsp;science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might could help us further bolster our conclusions. &nbsp;You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them!</p>\n <p>We are building a product engineering team with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific educational background, technology, experience or geographical location.&nbsp; We are however looking for specific traits in the people we work with. You might not yet be able to check all of the boxes, but at least you aspire to do so!&nbsp;</p>\n <p><strong>Signs of a great candidate</strong> <strong>Toolbox oriented.&nbsp;</strong>Whether your background is in mathematics, statistics, machine learning, artificial intelligence, or something else, you have enough experience to intuitively shortlist tools and approaches from most of these disciplines.&nbsp;</p>\n <p><strong>Understanding business and customer needs. &nbsp;</strong>You believe in creating models that will help the company and make short- and long-term impact, focusing on“bang-for-the-buck”.&nbsp;</p>\n <p><strong>Performance recognized by your peers.</strong>&nbsp;Past colleagues would love to work with you again.</p>\n <p><strong>Starter and finisher.</strong>&nbsp;You often identify a problem, design a solution and bring it to a state of completion - alone or with collaborators. You’ve worked with developers in the past, hope to continue doing so, but you would get far even without technical help.</p>\n <p><strong>Work hard and smart.</strong>&nbsp;Your work ethic is unquestioned, and you know how to get things done so you can balance your work and personal life in a sustainable way.</p>\n <p><strong>Disciplined and reliable.</strong>&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early.</p>\n <p><strong>Collaborative.</strong>&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to make the team perform.</p>\n <p><strong>Appreciation of honest feedback.</strong>&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You feedback given to as an opportunity to get better and strive to do the same for others.</p>\n <p><strong>Analytical and practical mind.</strong>&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed.&nbsp;</p> \n</div> \n<div> \n <a href='https://crisp.recruiterbox.com/jobs/fk0jolc?source=StackoverflowJobPosting' rel='nofollow'> Apply now </a>\n</div> \n<h4>About Crisp</h4> \n<div>\n <p>Our main goals with Crisp are easy to explain: We want to build a company that we would like to&nbsp;<em>enjoy&nbsp;</em>spending the rest of our careers in, that has a positive impact on the world and that will outlast us.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Fully remote</span> </li> \n <li> <span></span> <span>Excellent health insurance and benefits</span> </li> \n <li> <span></span> <span>Founders with proven track record</span> </li> \n <li> <span></span> <span>Well funded (by founders)</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Ld45jq9XROGFmRC2R4WFEg",
    "url": "https://www.remoteage.com/remote-jobs/senior-data-engineer-true-north/",
    "title": "Senior Data Engineer, True North",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:iphone/apple/2",
      "DBG_TECH1:k/t/w:iphone/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=6, c=2, mobile=3, go=0, nodejs=2, bigdata-ml=56, ruby=2, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Delaware North",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 1:22:20 PM",
    "validThrough": "Aug 1, 2019 1:22:20 PM",
    "crawled": "Jul 25, 2019 2:08:21 PM",
    "content": "<h3> Senior Data Engineer, True North </h3>\n<div>\n United States, New York\n</div>\n<div>\n Company: Delaware North\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p>Our Exciting Work Environment This position will be based out of Delaware North’s new global headquarters, a state-of-the-art, 12-story, mixed-use building in downtown Buffalo, N.Y. The headquarters facility, reflective of our values, integrates the latest advances in environmental, energy conservation and office design. <br>The Opportunity <br> At Delaware North we have a a long history of operational success and we have ambitious goals for our future growth and operating performance. These aspirations are supported by a transformative enterprise-wide initiative called True North. True North re-imagines the Delaware North operating model by creating processes and tools and providing enhanced support to our local teams that will enable us to best serve our guests, clients, and 55,000+ associates. <br> To achieve these goals, we need people like you. The True North team is hiring a Senior Data Engineer to be part of the Data Solutions Team. <br> Data Solutions is a rapidly growing team that enables Delaware North’s vision of using data as differentiator in the hospitality industry. Our work is the foundation of company initiatives to automate business processes, gather insights, and make informed decisions. Our team uses PaaS solutions and Open Source Software to aggregate, process, catalog and distribute large data sets throughout Delaware North’s global organization, client base and partners. These foundational services empower Delaware North’s mobile, data science, business intelligence, and operational systems. Users of the Delaware North Data Platform range from NASA to several MLB, NBA, NHL, &amp; NFL teams. As a member of our team, the Data Solutions Support Engineer will provide health monitoring and unparalleled customer advocacy for Delaware North’s distributed data platform (Data Lake). <br> The Senior Data Engineer will work closely with the Business to identify and specify opportunities for integration with existing systems in a highly resilient manner using Delaware North’s Data Platform. After the identification of business requirements, the Senior Data Engineer will participate in various exercises to design a technical solution as well as participate in the implementation with internal team mates and off-shore resources. As implementation progresses, the Senior Data Engineer will keep the lines of communication open with internal clients regarding solution status and address technical blockers that may arise. Additionally, the holder of this position will develop integration tests to validate solution acceptance criteria and participate in free-form experimental exercises to keep skills and team goals modernized. <br> Where you fit in: </p>\n <ul>\n  <li> Design and implement project based solutions </li>\n  <li> Implement data platform improvements and new features </li>\n  <li> Ability to effectively collaborate with business leadership, vendor and client stakeholders to establish solution requirements and execute on technical designs and final implementation. </li>\n  <li> Assist support team with resolution of Data Platform bug fixes </li>\n  <li> Interface with clients, vendors, and internal users of the data platform on understanding the data </li>\n  <li> Participate in group design and architecture sessions </li>\n  <li> Author documentation for standard operating procedures, knowledge base articles, etc. </li>\n </ul>\n <p> Skills &amp; experience that you’ll need: </p>\n <ul>\n  <li> Minimum 5 years professional experience with the following\n   <ul>\n    <li> Designing and developing solutions with a modern programming language such as Python, Ruby, JavaScript, Java, C#, etc </li>\n    <li> Development of backend systems and services. </li>\n    <li> Full Stack and/or DevOps </li>\n    <li> Data Persistence Methods such as NoSQL and RDBMS (MSSQL, Oracle, MySQL, MongoDB) </li>\n    <li> Data structures and formats such as JSON and XML </li>\n    <li> Data Mapping &amp; Transformation Techniques </li>\n   </ul></li>\n  <li> Excellent organizational, oral and written communication skills </li>\n  <li> Collaborate with Business Users and vendors to address development issues </li>\n  <li> Troubleshoot and track issues through to resolution </li>\n  <li> Technical specification and use case (story) documentation, such as UML, Domain and Entity Relationship Modeling, Business Process Notation. </li>\n  <li> Passion for delivering high quality and meaningful results. </li>\n </ul>\n <p> Nice to have: </p>\n <ul>\n  <li> Familiarity with RESTful Web Services, ETL, ESB, and microservices </li>\n  <li> Integration testing and automation using a continuous integration (CI) platform (such as Jenkins, TeamCity or Bamboo) </li>\n  <li> Familiarity with cloud computing, analysis &amp; implementation experience (bonus if it relates to Amazon Web Services specifically) </li>\n  <li> Experience working with Agile methodologies </li>\n  <li> Experience with frontend development </li>\n  <li> Proficiency with Unix/Linux </li>\n  <li> Experience with Configuration Management tools (such as Ansible, Chef, etc.) </li>\n </ul>\n <p> Here’s some of what you’ll get in return </p>\n <ul>\n  <li> Join a creative and highly collaborative team that is empowered to select the right technology for the task at hand </li>\n  <li> Regularly scheduled “innovation time” to work on creative applications of new technology (doesn’t have to be work related) </li>\n  <li> Flexible work schedule, “casual Fridays”, and ability to work remotely in certain cases </li>\n  <li> Opportunity for travel to interesting field locations (small percentage of travel required) </li>\n  <li> Company paid iPhone with LTE service </li>\n  <li> Free coffee, espresso, cappuccino, fruits, and bagels </li>\n  <li> Yearly paid training, conference and certifications of your choice </li>\n  <li> Career growth – Delaware North values and invests in its family and promotes from within regularly </li>\n  <li> Benefits including health, dental, paid vacation &amp; holidays, life insurance, short &amp; long term disability insurance, company discounts </li>\n  <li> Bonus eligibility </li>\n  <li> 401k with employer match and financial planning services </li>\n  <li> Choice of MacBook Pro or PC Ultrabook and peripherals </li>\n </ul>\n <p>Who We Are Take your career beyond the ordinary-to the extraordinary.<br> At Delaware North, you’ll love where you work, who you work with, and how your day unfolds. Whether it’s in sporting venues, casinos, airports, national parks, iconic hotels, or premier restaurants, there’s no telling where your career can ultimately take you. We empower you to do great work in a company with 100 years of success, stability and growth. If you have drive and enjoy the thrill of making things happen – share our vision, grow with us.<br> Delaware North is one of the largest privately held hospitality companies in the world. Founded in 1915 and owned by the Jacobs family for more than 100 years, Delaware North has global operations at high-profile places such as sports and entertainment venues, national and state parks, destination resorts and restaurants, airports, and regional casinos. Our 55,000 employee associates are dedicated to creating special experiences one guest at a time in serving more than a half-billion guests annually. Delaware North operates in the sports, travel hospitality, restaurant and catering, parks, resorts, gaming, and specialty retail industries and has annual revenue of about $3 billion. Learn more about Delaware North, a global leader in hospitality, at .<br> All applicants will be subject to a pre-employment background check and may be subject to a pre-employment drug test depending upon the position and/or client requirements.<br> Delaware North Companies, Incorporated and its subsidiaries consider applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status. Delaware North is an equal opportunity employer.<br> #LI-PE1<br></p> \n <div> \n  <a href='https://www.jobg8.com/Traffic.aspx?00WLhg2l6rarDAF9XbGfxQu' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DbZo40OnTL2P40n8jyyPWA",
    "url": "https://remoteok.io/jobs/74115",
    "title": "Data Analyst",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Amida Technology Solutions",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 24, 2019 8:41:57 PM",
    "validThrough": "Jul 31, 2019 8:41:57 PM",
    "crawled": "Jul 24, 2019 9:30:31 PM",
    "content": "<span></span> \n<span><h4>Amida Technology Solutions</h4></span> \n<br> \n<h3>Data Analyst</h3> \n<div> \n <div> \n  <br>Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact. \n  <br>Our team is comprised of creative, forward thinkers who are passionate about using cutting edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high growth environment that values fresh ideas, candid conversations, and authentic teamwork. \n  <br>Amida is currently looking for a Data Analyst to join our team in Washington DC or from a remote location within the continental US. In this role you will work across our client engagements, providing expertise in data collection, data analysis, data mapping, data profiling, data mining and data modeling.&nbsp; You will be responsible for inspecting, cleansing, transforming and modeling data and will address issues related to data completeness and quality, as well as contribute to and produce technical and data process documentation.&nbsp; \n  <br>What you will be doing: \n  <br>* Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions \n  <br>* Apply analytical methodologies and principles to&nbsp;meet client needs. \n  <br>* Prepare forecast&nbsp;and analyze&nbsp;trends, develops and analyzes metrics, and prepares reports and recommendations related to management. \n  <br>* You will also be responsible&nbsp;for focusing on&nbsp;business performance, project analysis, internal control, risk assessment, and support of project objectives. \n  <br> \n  <br> \n  <br>What we are looking for: \n  <br>* B.S. and/or M.S. in a quantitative field such as Computer Science, Statistics, or Mathematics \n  <br>* Minimum 3-5 year of recent professional experience in data science, data mining and/or data analysis \n  <br>* Experience in data migration to include data mapping and data profiling \n  <br>* Prior experience working with Healthcare data, or in the Healthcare field \n  <br>* Ability to conduct data profiling and predictive analysis using a variety of standard tools \n  <br>* Programming proficiency in a subset of Python \n  <br>* Experience with data visualization tools and methodologies \n  <br>* Ability to communicate concisely and effectively with software engineers and clients \n  <br>* Ability to obtain a Public Trust security clearance \n  <br> \n  <br> \n  <br>Preferred Skills \n  <br>* Exposure to Amazon Web Services (AWS) and cloud-based systems \n  <br>* Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA) \n  <br>* Prior experience with metadata management to include meta tagging \n  <br>* Previous experience working in an Agile Team setting and using Agile management tools such as Jira \n  <br>* Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "FCqRYWOcTTyz9hd6-cc57g",
    "url": "https://jobmote.com/job/52107/data-architect-remote/",
    "title": "Data Architect - (Remote)",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=26, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Feuji",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 24, 2019 11:01:33 AM",
    "validThrough": "Jul 27, 2019 11:01:33 AM",
    "crawled": "Jul 24, 2019 3:06:26 PM",
    "content": "<div>\n Title Data Architect Remote Fulltime Responsibilities Ability to understand the business requirements and to decompose for further analysis Proven track record in architecture, performance and highly-scalable Data Platform Ability to understand customer s business outcomes and to guide the customer through a Data workshop The aptitude and attitude needed to be a Trusted Advisor to the customer Understanding of various architectural patterns in Big Data Ability to operate in an agile environment Ability to actively seek out optimization approaches for Data Platform Ability to understand and articulate a problem Proven track record on Pre-sales engagements Qualifications Proven and deep knowledge of Big Data Architectural patterns Proven and deep knowledge in Batch and streaming patterns Proven experience in architecting Big Data Platform including building out data pipelines, ETL jobs, and visualization through dashboards Experience in Enterprise Data Warehouse (EDW) Deep expertise in AWS Data Analytics services Deep expertise in GCP Data Analytics services Big Data cert in AWS is a Plus Hands on experience with Python, Scala, etc. Experience with Machine Learning such as AWS SageMaker is a plus\n <br> Associated topics: data analytic, data center, data engineer, data integrity, data warehouse, data warehousing, database, etl, sql, sybase\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eL5npav9QKe78yhR-T6vPA",
    "url": "https://jobmote.com/job/51784/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:07:20 PM",
    "validThrough": "Jul 26, 2019 10:07:20 PM",
    "crawled": "Jul 24, 2019 3:06:25 AM",
    "content": "<div>\n <p>Job Description<br>The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.</p>\n <p>Responsibilities<br>Define and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architecture</p>\n <p>Qualifications<br>Bachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#<br><br>Additional Information<br>Compensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote<br></p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "utVQcAK8Rwqbmq6_fAOdag",
    "url": "https://jobmote.com/job/51783/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:07:20 PM",
    "validThrough": "Jul 26, 2019 10:07:20 PM",
    "crawled": "Jul 24, 2019 3:06:25 AM",
    "content": "<div>\n <p>Job Description<br>The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.</p>\n <p>Responsibilities<br>Define and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architecture</p>\n <p>Qualifications<br>Bachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#<br><br>Additional Information<br>Compensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote<br></p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "HweRHeWwRo2F6Tarxy4FDQ",
    "url": "https://stackoverflow.com/jobs/283906/senior-software-engineer-rho-ai?a=1xddNx0BcRuU",
    "title": "Senior Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/20",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=60, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:30:25 PM",
    "validThrough": "Jul 30, 2019 10:30:25 PM",
    "crawled": "Jul 23, 2019 10:30:25 PM",
    "content": "<h3><span>Senior Software Engineer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Full Stack Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data Science, Software Development / Engineering</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Rho AI | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-06:00) Central Time +/- 2 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n single-page-application\n</div>\n<div>\n sql\n</div>\n<div>\n nosql\n</div>\n<div>\n docker\n</div> \n<h4>Job description</h4> \n<div>\n <p>Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste). We value pragmatic solutions and have cultivated a modern technology stack that combines software development (python microservices, react frontends), infrastructure automation (docker, kubernetes), and machine learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p>\n <p>As a member of the software engineering team, you are looking to:</p>\n <ul>\n  <li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li>\n  <li>Join a group of talented and congenial team members in an experienced individual contributor role (mix of architecting / building / mentoring), with future people management opportunities (if you like).</li>\n  <li>Lead engineering projects by collaborating with team members and customers, facilitating technology architecture decisions, driving forward work streams, and releasing high quality software.</li>\n  <li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li>\n </ul>\n <p><strong>You have</strong>:</p>\n <ul>\n  <li>(Must) Been the tech lead of a project that uses a Python based stack.</li>\n  <li>(Must) Good communication skills for technical and non-technical audiences.</li>\n  <li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li>\n  <li>(Must) Worked on all layers of the stack - databases, services, and frontends.</li>\n  <li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li>\n  <li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li>\n  <li>(Should) Have experience working within a microservices oriented architecture.</li>\n  <li>(Nice) Built systems that process large amounts of data and/or traffic.</li>\n  <li>(Nice) Strong computer science principles, and/or algorithmic skills.</li>\n  <li>(Nice) Experience with machine learning applications.</li>\n </ul>\n <p><strong>You meet these criteria</strong>:</p>\n <ul>\n  <li>You are seeking a full-time job.</li>\n  <li>You reside in the United States.</li>\n  <li>You are&nbsp;authorized / eligible to work for any company in the United States.</li>\n  <li>You are in a continental US time zone, or willing to align your schedule.</li>\n </ul>\n <strong>To get an interview, you must supply:</strong>\n <ul>\n  <li>A cover letter that explains why you are 1)&nbsp;<em>specifically interested</em>&nbsp;in Rho AI as a company and 2) a&nbsp;<em>good fit</em>&nbsp;for this particular position.</li>\n  <li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/283906?reset=False&amp;ra=1xddNx0BcRuU&amp;oqs=a%3D1xddNx0BcRuU' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Rho AI</h4> \n<div>\n <p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p>\n <p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p>\n <p><strong>Work at Rho AI</strong></p>\n <p>At Rho AI, you will work with a talented group of data scientists, engineers and thought leaders to drive technological change through data science. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p>\n <p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Work from anywhere in the world with flexible work schedules.</span> </li> \n <li> <span></span> <span>Health insurance &amp; FSA accounts</span> </li> \n <li> <span></span> <span>Competitive salaries along with 401k</span> </li> \n <li> <span></span> <span>4 weeks of PTO</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F4vRKXsEQyWDi02GduUNwQ",
    "url": "https://remote.co/job/senior-r-developer/",
    "title": "Senior R Developer",
    "tags": [
      "DBG:surround``OR(work,countri,locat,contract,base,you W can) 2W anywher",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "Crunch.io",
      "sameAs": "https://crunch.io/index.html"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 6:10:02 PM",
    "validThrough": "Jul 30, 2019 6:10:02 PM",
    "crawled": "Jul 23, 2019 6:23:50 PM",
    "content": "<h3>Senior R Developer at <span>Crunch.io</span></h3>\n<div>\n <span><i></i> Remote</span> | \n <span> International </span>\n</div>\n<div> \n <p><strong>Reporting to: </strong>VP of Product<strong><br>Location: Anywhere</strong></p>\n <p>Crunch.io is seeking a talented, motivated, and versatile human to help lead the development of our R data science products. Crunch provides a modern platform for survey data analysis, and a central feature of our product is the ability to manipulate and analyze datasets stored in the cloud using R. As senior R developer, you will have three main responsibilities. First, you will work with the rest of our team to design and implement novel features that deliver real value and change our clients’ workflows for the better. Second, as the primary point of contact between our R user community and the development team, you will serve as their voice in product development. And third, you will often directly help clients manipulate and explore data using Crunch, including helping clients design and implement workflows that incorporate Crunch.</p>\n <p><strong>Key responsibilities for the position include:</strong></p>\n <ul>\n  <li>Teaching users how to work with the library through documentation and direct conversations.</li>\n  <li>Writing scripts that help clients implement Crunch and make it a part of their workflow, including ETL, data analysis, and outputs.</li>\n  <li>Developing and maintaining our core R packages, including new feature design, comprehensive testing, and documentation</li>\n  <li>Supporting our community of R users by responding to feature requests and triaging bug reports</li>\n  <li>Evangelizing our product and educating our R user base by contributing to our technical blog and helping enrich our support documentation</li>\n  <li>Translating API speak to R that feels natural and native</li>\n  <li>Engaging with and contributing to the broader open source R ecosystem</li>\n </ul>\n <p><strong>Depending on your interests and skills, there are opportunities to get involved in:</strong></p>\n <ul>\n  <li>API design: developing good conventions that enable our platform to scale and make it easy for client applications to consume them</li>\n  <li>JavaScript development, helping our frontend developers implement features you’ve utilized in R</li>\n  <li>Product management, building on your interactions with our users to shape our product roadmap and feature design</li>\n  <li>Python development, ranging from implementing APIs you need for the R packages, to statistical modeling, numerical computing, machine learning, and natural language processing</li>\n </ul>\n <p>In any given week, you might implement an R interface for a new API our backend has added, write a blog post introducing that new feature, track down a bug report from a user, write a test that reproduces the issue, and assist customers in implementing Crunch via the Crunch R packages.</p>\n <p><strong>Qualifications:</strong></p>\n <ul>\n  <li>Expert-level skills in R, including experience delivering code that others rely on to do their work. Prior experience creating and maintaining R packages is highly valued.</li>\n  <li>Serious commitment to high development standards, including comprehensive testing, in whatever language you’re working</li>\n  <li>Demonstrated ability to work with a team of peers, understanding and respecting the responsibilities and expertise developers, designers, QA folks, and others bring to the project</li>\n  <li>Eagerness to take ownership of projects and deliver results on schedule</li>\n  <li>Experience in a “data science,” such as social science, market research, or data visualization, is a plus.</li>\n </ul>\n <p>Crunch offers competitive salary; health, dental, and vision insurance; and equity options. We are a small but growing company spread from UTC+1 to +11, mostly in the Western hemisphere. Remote work is flexible and largely independent, yet highly cooperative.</p>\n <p>We are an equal-opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status.</p> \n</div>\n<div> \n <a href='https://crunch.io/jobs/senior-r-developer/' rel='nofollow'>Apply for job</a> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gFXaswIzRu2eKZx5X9lPOg",
    "url": "https://jobmote.com/job/51649/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 80000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 80k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 10:07:19 PM",
    "validThrough": "Jul 25, 2019 10:07:19 PM",
    "crawled": "Jul 23, 2019 3:06:26 AM",
    "content": "<div>\n Job DescriptionThe ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architectureQualificationsQualificationsBachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $80,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote\n <p>by Jobble</p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pls9GIA3QS2v_RBMbZEJVw",
    "url": "http://workinstartups.com/job-board/job/82589/data-analyst-at-hubble/",
    "title": "Data Analyst",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hubble",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 1:35:01 PM",
    "validThrough": "Jul 29, 2019 1:35:01 PM",
    "crawled": "Jul 22, 2019 5:06:34 PM",
    "content": "DESCRIPTION\n<br>\n<br>Hubble is the UK’s leading PropTech scale-up; changing the face of commercial property. Our mission is to find the perfect home for every company and we’ve built an online platform to help businesses rent, manage and share office space in London. We’ve raised over £6m in venture funding from the most respected investors in technology and real estate to make this mission a reality.\n<br>\n<br>As a Data Analyst you will be working closely with Data Science, Engineering and Business Operations to support all teams with day to day reporting, problem-solving and using data to provide key company insights. You will work across a range of areas such as our acquisition strategies, product funnels, supply and demand dynamics, sales performance and more.\n<br>\n<br>\n<br>RESPONSIBILITIES\n<br>\n<br>Own the data request process from prioritisation through to delivery.\n<br>Support all departments through report creation, ad-hoc data analysis and answering business questions by interrogating our database.\n<br>Create and maintain company dashboards.\n<br>Empower all teams with the right tools to understand the data and make decisions quickly\n<br>End-to-end ownership of data quality in our core datasets and data pipelines.\n<br>Experiment with new tools and technologies to meet business requirements regarding performance, scaling, and data quality.\n<br>Improve existing processes and make data pipelines more efficient and reliable.\n<br>\n<br>\n<br>REQUIREMENTS\n<br>\n<br>Strong SQL knowledge and experience.\n<br>Excellent problem-solving skills - ability to see beyond the numbers and think logically.\n<br>Previous experience in a similar role, ideally in a startup environment\n<br>Experience solving real problems using data analysis techniques and statistical rigour.\n<br>Excellent communication skills; the ability to convey complex analysis results clearly.\n<br>Business-minded as well as technically capable\n<br>\n<br>\n<br>BENEFITS\n<br>\n<br>We make sure everyone in the team is comfortable and has the best environment for them. We offer flexible hours, remote working and have a relaxed attitude to taking holiday - focusing only on whether work gets done. Benefits can be tweaked on an individual basis depending on what makes you most productive. Here are some of the things we offer:\n<br>\n<br>Remuneration competitive with industry and level of experience.\n<br>Macbook, peripherals and standing desk.\n<br>Expense budget &amp; travel.\n<br>Noise-cancelling headphones.\n<br>Spotify Premium or Apple Music.\n<br>Kindle Unlimited + free technical books.\n<br>Health &amp; Pension.\n<br>Cycle to Work scheme.\n<br>\n<br>Hubble is an equal opportunities employer. We are a diverse bunch of people who are committed to maintaining a welcoming culture of inclusion and equality. We encourage applications from anyone that meets the requirements for the role.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "arfb2PbwTvqY89O5-VQ1Yw",
    "url": "https://remote.co/job/coding-specialist-9/",
    "title": "Coding Specialist",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=1, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "nThrive",
      "sameAs": "https://www.nthrive.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 6:03:43 PM",
    "validThrough": "Jul 26, 2019 6:03:43 PM",
    "crawled": "Jul 19, 2019 6:26:08 PM",
    "content": "<h3>Coding Specialist at <span>nThrive</span></h3>\n<div>\n <span><i></i> Remote</span> \n</div>\n<div> \n <p><strong>Job ID: </strong>2019-26481</p>\n <p><strong>Employment Type: </strong><strong>Full Time</strong></p>\n <p><strong>Hours Per Week:</strong> 40</p>\n <p><strong>Onsite Work Schedule Details:</strong> M-F 8a-4:30p</p>\n <p><strong>City: </strong><strong>Remote</strong></p>\n <p><strong>Overview</strong></p>\n <p>The Coding Specialist will work closely with HIM and other support departments to reimburse healthcare claims. This individual will utilize specialized medical classification software to assign procedure and diagnosis codes for insurance billing as well as review claims data to ensure that assigned codes meet required legal and insurance rules and that required signatures and authorizations are in place before submission.</p>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Selects and sequences ICD-10, and/or CPT/HCPCS codes for designated patient types which may include but are not limited to: Ancillary (Diagnostic)/ Recurring; Hospital, Clinic; Physician Pro Fee; Technical Fee or Evaluation and Management.</li>\n  <li>Reviews and analyzes clinical records to ensure that APC assignments accurately reflect the diagnoses/procedures documented in the clinical record.</li>\n  <li>Abstracts clinical data from the record after documentation review to ensure that it is adequate and appropriate to support diagnoses, procedures and discharge disposition is selected.</li>\n  <li>May act as a resource with client staff for data integrity, clarification and assistance in understanding and determining appropriate and compliant coding practices including provider queries.</li>\n  <li>Maintains strict patient and provider confidentiality in compliance with all federal, state, and hospital laws and guidelines for release of information.</li>\n  <li>Maintain current working knowledge of ICD-10 and/or CPT/HCPCS and coding guidelines, government regulations, protocols and third-party requirements regarding coding and/or billing.</li>\n  <li>Participate in continuing education activities to enhance knowledge, skills, and maintain current credentials.</li>\n  <li>Supports nThrive’s Compliance Program by adhering to policies and procedures pertaining to HIPAA, FDCPA, FCRA, and other laws applicable to nThrive’s business practices. This includes: becoming familiar with nThrive’s Code of Ethics, attending training as required, notifying management or nThrive’s Helpline when there is a compliance concern or incident, HIPAA-compliant handling of patient information, and demonstrable awareness of confidentiality obligations.</li>\n </ul>\n <p><strong>Qualifications</strong></p>\n <ul>\n  <li><strong>Active RHIA, RHIT, CCS</strong></li>\n  <li>3+ years of recent and relevant hands-on coding experience including active production coding</li>\n  <li>Ability to consistently code at 95% threshold for both accuracy and quality while maintaining client-specific and nThrive production standards</li>\n  <li>Proficient computer knowledge including MS Office (Outlook, Word, Excel, Power Point)</li>\n  <li>Must display excellent interpersonal and problem-solving skills with all levels of internal and external customers</li>\n  <li>Candidates must successfully pass pre-employment coding test</li>\n  <li>Cable or DSL high-speed, wired Internet Connection</li>\n </ul>\n <p><strong>About nThrive</strong></p>\n <p><strong>Be Inspired. Ignite Change. Transform Health Care.</strong><br>From Patient-to-Payment, nThrive provides all the technology, advisory expertise, services, analytics and education programs health care organizations need to thrive in the communities they serve. Our colleagues share a united passion to help health care organizations strengthen their financial position, which translates to accessible, quality care for all. This passion fuels our drive to innovate and participate in community outreach through the nThrive CARES program. Our colleagues are encouraged to think differently and empowered to make a lasting impact that ensures our health care providers, and our world, are healthy and productive.</p> \n</div>\n<div> \n <a href='https://careers-nthrive.icims.com/jobs/26482/coding-specialist/job' rel='nofollow'>Apply for job</a> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tcklNtXcSryZxuiIN7glaA",
    "url": "https://stackoverflow.com/jobs/282773/senior-data-scientist-remote-global-wallethub?a=1wPFbjoIMtgI",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 7:06:24 AM",
    "validThrough": "Jul 26, 2019 7:06:24 AM",
    "crawled": "Jul 19, 2019 7:06:24 AM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282773?reset=False&amp;ra=1wPFbjoIMtgI&amp;oqs=a%3D1wPFbjoIMtgI' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "g49hsIg7TEq_JXGKoGmJjg",
    "url": "https://remoteok.io/jobs/74021",
    "title": "Software Engineers",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:c++/c/16",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=16, mobile=0, go=0, nodejs=0, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "GrammaTech",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 5:42:58 AM",
    "validThrough": "Jul 26, 2019 5:42:58 AM",
    "crawled": "Jul 19, 2019 6:06:30 AM",
    "content": "<span></span> \n<span><h4>GrammaTech</h4></span> \n<br> \n<h3>Software Engineers</h3> \n<div> \n <div> \n  <br>Overivew: \n  <br> \n  <br>Are you ready to be challenged, right from the interview process?&nbsp; Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you. \n  <br> \n  <br>GrammaTech is looking for software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Significant experience contributing to large projects, developing software, with focus on C++ and Python.&nbsp; \n  <br> \n  <br>REMOTE EMPLOYEES WILL BE CONSIDERED IF SKILLS AND EXPERIENCE MATCH. \n  <br> \n  <br>Responsibilities: \n  <br> \n  <br>A research-oriented software engineer is expected to:&nbsp; \n  <br> \n  <br> \n  <br>* Study and implement approaches drawn from academic literature or in-house design \n  <br> \n  <br>* Evaluate the resulting prototype implementation to test its value in addressing the research goals \n  <br> \n  <br>* Report results to the PI and respond by adapting the prototype to better address research goals \n  <br> \n  <br>* Contribute to presentations and written reports to keep research sponsors up to date on project progress \n  <br> \n  <br>* Prepare prototypes for demonstrations and evaluations by research sponsors \n  <br> \n  <br>* Transition prototypes into deployable products&nbsp; \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Qualifications: Required: \n  <br> \n  <br> \n  <br>* BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus. \n  <br> \n  <br>* Experience in development activities on large code bases with software design, build, and test from scratch \n  <br> \n  <br>* Familiarity with common software architectures, design patterns, and software development life cycle practices including effectively using revision control systems (git) and container technology (docker) \n  <br> \n  <br>* Knowledge of security and bug finding, capability of finding problems within software code \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Preferred: \n  <br> \n  <br> \n  <br>* MS or PhD in computer science or equivalent \n  <br> \n  <br>* Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc. \n  <br> \n  <br>* Knowledge of machine code, such as ARM, x86, or x86-64 \n  <br> \n  <br>* Static analysis for binaries and/or source code \n  <br> \n  <br>* Experience with fuzzing and sandboxing \n  <br> \n  <br>* Compiler design, compiler front-end integration, parsers \n  <br> \n  <br>* Dynamic analysis, program instrumentation, and profiling \n  <br> \n  <br>* System-administration experience, especially related to security \n  <br> \n  <br>* Malware-analysis techniques \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>About the Company: \n  <br> \n  <br>We have offices in Ithaca, NY and Madison, WI — but will consider remote employees when there is a strong match of skills and experience. \n  <br> \n  <br>Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing.&nbsp; \n  <br> \n  <br>GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.&nbsp; Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems. &nbsp;Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales. \n  <br> \n  <br>GrammaTech, Inc. is an Equal Opportunity/Affirmative Action employer.&nbsp; \n  <br> \n  <br>Members of underrepresented groups are encouraged to apply, please call 607-273-7340 if assistance is needed. \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "w38xNldaRWy1kDDu4N1Xsg",
    "url": "https://jobmote.com/job/51107/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Eliassen Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:26 PM",
    "validThrough": "Jul 21, 2019 10:07:26 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <br>\n <br>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out the foundation platform around Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions. \n <br>\n <br>\n <strong>Responsibilities/Skills: </strong>\n <br>\n <ul>\n  <li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption </li>\n  <li>Build Back end applications using Java, Spark/Scala, Python </li>\n  <li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda </li>\n  <li>Work on performance optimizations on Hbase and Solr </li>\n  <li>Work on Performance optimization on Spark Jobs and MapReduce jobs </li>\n  <li>Ability to debug complex production scenarios </li>\n  <li>Master-s degree in Computer Science, Management Information Systems #eg1989 </li>\n </ul>\n <br>\n <br>For immediate consideration, email your updated resume to Dan Malta at\n <br>\n <br>Job ID: 321205 \n <br>\n <br>\n <strong>About Eliassen Group: </strong>\n <br>\n <br>Eliassen Group provides strategic talent solutions to drive our clients- innovation and business results. Leveraging over 30 years of success, our expertise in IT staffing, Agile consulting, creative services, managed services, and life sciences enables us to partner with our clients to execute their business strategy and scale effectively. Headquartered in Reading, MA and with offices from coast to coast, Eliassen Group offers local community presence, deep networks, as well as national reach. For more information, visit .\n <br>\n <br>Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\n <br>\n <br>Don-t miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a \n <strong> <em> $1,000 referral check ! </em> </strong>\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ptoSvXqbQ_S36a1C_57V0w",
    "url": "https://jobmote.com/job/51098/hadoop-developer-100-remote/",
    "title": "Hadoop Developer -100% REMOTE",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "HCL Global Systems",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:26 PM",
    "validThrough": "Jul 21, 2019 10:07:26 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <p> <strong>Role: Hadoop Developer</strong></p> \n <p> <strong>Location: Jacksonville, FL (REMOTE)</strong></p> \n <p> <strong>Duration: Long Term</strong></p> \n <p> <strong>Job Description: </strong></p> \n <ul>\n  <li>Write code for moderately complex system designs. Write programs that span platforms. Code and/or create Application Programming Interfaces (APIs).</li> \n  <li>Write code for enhancing existing programs or developing new programs.</li> \n  <li>Review code developed by other IT Developers.</li> \n  <li>Provide input to and drive programming standards.</li> \n  <li>Write detailed technical specifications for subsystems. Identify integration points.</li> \n  <li>Report missing elements found in system and functional requirements and explain impacts on subsystem to team members.</li> \n  <li>Consult with other IT Developers, Business Analysts, Systems Analysts, Project Managers and vendors.</li> \n  <li> Scope time, resources, etc., required to complete programming projects. Seek review from other IT Developers, Business Analysts, Systems Analysts or Project Managers on estimates.</li> \n  <li>Perform unit testing and debugging. Set test conditions based upon code specifications. May need assistance from other IT Developers and team members to debug more complex errors.</li> \n  <li>Supports transition of application throughout the Product Development life cycle. Document what has to be migrated. May require more coordination points for subsystems.</li> \n  <li>Researches vendor products / alternatives. Conducts vendor product gap analysis / comparison.</li> \n  <li>Accountable for including IT Controls and following standard corporate practices to protect the confidentiality, integrity, as well as availability of the application and data processed or output by the application.</li> \n  <li>The essential functions listed represent the major duties of this role, additional duties may be assigned.</li>\n </ul>\n <p> <strong> </strong> <strong>Years of Experience Experience Details</strong></p> \n <ul>\n  <li>5+ years related work experience or equivalent combination of transferable experience and education</li> \n  <li>IT development/programming/coding professional work experience</li> \n  <li>Specific Tools/Languages Required:</li> \n  <li>HADOOP</li> \n  <li>Spark</li> \n  <li>Experience with Agile Methodology</li>\n </ul>\n <p> <strong> </strong> <strong>Comments for Suppliers: </strong></p> \n <p> <strong>- Manager is look for someone with 3-4 year experience with Hadoop/Spark ETL</strong></p> \n <p> <strong>- Experienced in Agile methodologies</strong></p> \n <p> <strong>- Healthcare experience is strongly preferred</strong></p> \n <p> <strong> </strong> <strong>Additional Required Qualifications:</strong></p> \n <ul>\n  <li>Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures</li> \n  <li>Proficiency using versioning tools</li> \n  <li>Thorough knowledge of Information Technology fields and computer systems</li> \n  <li>Demonstrated organizational, analytical and interpersonal skills</li> \n  <li>Flexible team player</li> \n  <li>Ability to manage tasks independently and take ownership of responsibilities</li> \n  <li>Ability to learn from mistakes and apply constructive feedback to improve performance</li> \n  <li>Must demonstrate initiative and effective independent decision-making skills</li> \n  <li>Ability to communicate technical information clearly and articulately</li> \n  <li>Ability to adapt to a rapidly changing environment</li> \n  <li>In-depth understanding of the systems development life cycle</li> \n  <li>Proficiency programming in more than one object oriented programming language</li> \n  <li>Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio</li> \n  <li>Proficiency using debugging tools</li> \n  <li>High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy</li>\n </ul>\n <p> <strong>Thanks &amp; Regards</strong></p> \n <p> <strong> </strong> <strong>Gireesh| Technical Recruiter</strong></p> \n <p>E: O: EXT 147</p> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Agfq-HtjR5aO0ymFr-ZARA",
    "url": "https://jobmote.com/job/51116/aws-big-data-consultant-remote-europe-us-east-coast/",
    "title": "AWS Big Data Consultant - Remote (Europe / US East Coast)",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "50% remote",
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "INTUITIVE TECHNOLOGY PARTNERS, INC.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:27 PM",
    "validThrough": "Jul 21, 2019 10:07:27 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <p>Role: Senior Consultant</p> \n <p>Specialization: Big Data &amp; Analytics</p> \n <p>Location: East Hanover, NJ. Ideally the Consultant is required in Europe, however any location in East Coast, US will work.</p> \n <p>Remote: 100%. Although this position is remote work, the consultant is required to travel for team meetings and client location as required.</p> \n <p>Start date: ASAP</p> \n <p>Duration: Available at least 3 days a week till end of December 2019.</p> \n <p>Requirement description:</p> \n <p>- Big Data specialty (AWS and 3pty), at least 3 years in the role (Consultant, Solution Architect, Big Data Engineer, Big Data SME, or similar) <br>- At least 3 years of experience with AWS services (within AWS, partner or another company) <br>- Based in EMEA or US East Coast <br>- Track record of delivering complex big data project similar in size (at least 1 good reference) <br>- Experience in Pharma industry or similar <br>- Databricks know-how is a big plus</p> \n <p> </p> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rNoOUkRQQRO8sG1YrG74lQ",
    "url": "https://stackoverflow.com/jobs/282724/software-engineers-research-security-grammatech-inc?a=1wOE0QGlt6Io",
    "title": "Software Engineers - Research (Security) at GrammaTech, Inc. (Ithaca, NY) ",
    "tags": [
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 9W 4N( OR(offic,onsit), time)",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:c++/c/24",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:sonarqube/java/8",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=24, mobile=0, go=0, nodejs=0, bigdata-ml=18, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "GrammaTech, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 12:06:25 AM",
    "validThrough": "Jul 26, 2019 12:06:25 AM",
    "crawled": "Jul 19, 2019 12:06:25 AM",
    "content": "<h3><span>Software Engineers - Research (Security)</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Desktop Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Computer Software, Cybersecurity, Security Software</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: GrammaTech, Inc. | Ithaca, NY\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-05:00) Eastern Time </span> \n  </div> \n  <div> \n   <span>Office Location:</span> \n   <span>Ithaca, NY.</span> \n   <span>Employees can also work full time from this office.</span> \n  </div> \n  <div> \n   <span>Visa Sponsorship:</span> \n   <span>Yes</span> \n  </div> \n  <div> \n   <span>Relocation Assistance:</span> \n   <span>Yes</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n c++\n</div>\n<div>\n python\n</div>\n<div>\n git\n</div>\n<div>\n docker\n</div>\n<div>\n static-analysis\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Overivew:</strong></p>\n <p>Are you ready to be challenged, right from the interview process?&nbsp; Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you.</p>\n <p>GrammaTech is looking for software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Significant experience contributing to large projects, developing software, with focus on C++ and Python.&nbsp;</p>\n <p><strong>REMOTE EMPLOYEES WILL BE CONSIDERED IF SKILLS AND EXPERIENCE MATCH.</strong></p>\n <p><strong>Responsibilities:</strong></p>\n <p>A research-oriented software engineer is expected to:&nbsp;</p>\n <ul>\n  <li>Study and implement approaches drawn from academic literature or in-house design</li>\n  <li>Evaluate the resulting prototype implementation to test its value in addressing the research goals</li>\n  <li>Report results to the PI and respond by adapting the prototype to better address research goals</li>\n  <li>Contribute to presentations and written reports to keep research sponsors up to date on project progress</li>\n  <li>Prepare prototypes for demonstrations and evaluations by research sponsors</li>\n  <li>Transition prototypes into deployable products&nbsp;</li>\n </ul>\n <p><strong>Qualifications:</strong> Required:</p>\n <ul>\n  <li>BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus.</li>\n  <li>Experience in development activities on large code bases with software design, build, and test from scratch</li>\n  <li>Familiarity with common software architectures, design patterns, and software development life cycle practices including effectively using revision control systems (git) and container technology (docker)</li>\n  <li>Knowledge of security and bug finding, capability of finding problems within software code</li>\n </ul>\n <p>Preferred:</p>\n <ul>\n  <li>MS or PhD in computer science or equivalent</li>\n  <li>Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc.</li>\n  <li>Knowledge of machine code, such as ARM, x86, or x86-64</li>\n  <li>Static analysis for binaries and/or source code</li>\n  <li>Experience with fuzzing and sandboxing</li>\n  <li>Compiler design, compiler front-end integration, parsers</li>\n  <li>Dynamic analysis, program instrumentation, and profiling</li>\n  <li>System-administration experience, especially related to security</li>\n  <li>Malware-analysis techniques</li>\n </ul>\n <p><strong><em>About the Company:</em></strong></p>\n <p><em>We have offices in Ithaca, NY and Madison, WI — but will consider remote employees when there is a strong match of skills and experience.</em></p>\n <p>Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing.&nbsp;</p>\n <p>GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.&nbsp; Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems. &nbsp;Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales.</p>\n <p><em>GrammaTech, Inc. is an Equal Opportunity/Affirmative Action employer.&nbsp;</em></p>\n <p><em>Members of underrepresented groups are encouraged to apply, please call 607-273-7340 if assistance is needed.</em></p> \n</div> \n<div> \n <span>Apply now</span>\n</div> \n<h4>About GrammaTech, Inc.</h4> \n<div>\n <p>GrammaTech has two distinct business development units, the Product Team and the Research Team. Information on both can be found on the company website but this position is on the Research Team and some of our past projects can be found on our website,&nbsp;<a href='https://www.grammatech.com/sponsored-research' rel='nofollow'>https://www.grammatech.com/sponsored-research</a>.</p>\n <p>The <strong>Product Team</strong> focuses on our Code Sonar product line:</p>\n <p>CodeSonar employs a unified dataflow and symbolic execution analysis that examines the computation of the complete application. By not relying on pattern matching or similar approximations, CodeSonar's static analysis engine is extraordinarily deep, finding 3-5 times more defects on average than other static analysis tools.</p>\n <p>Unlike many software development tools, such as testing tools, compilers, configuration management, etc., SAST tools can be integrated into a team's development process at any time with ease. SAST technologies like CodeSonar simply attach to your existing build environments to add analysis information to your verification process.</p>\n <p>The <strong>Research Team </strong>responds to Request for Proposals from government and other sponsors:</p>\n <p>Our expertise in software analysis and binary transformation comes from decades of experience of high-tech research with the U.S. government and other organizations. Over the past two decades, we have partnered with several groups to help solve some of the most complex software challenges that impact devices' resiliency, safety, and security. Our work has been focused in three areas:</p>\n <ul>\n  <li><strong>Software Assurance:</strong>&nbsp;new techniques and technologies for analyzing and correcting software to ensure runtime integrity and prevent unplanned system breaches and failures.</li>\n  <li><strong>Software Hardening:</strong>&nbsp;technologies solely focused on system resiliency.</li>\n  <li><strong>Autonomic Computing:</strong>&nbsp;providing software systems with the ability to ‘self-protect’</li>\n </ul> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Competitive base salaries - whether in Ithaca, Madison or remote!</span> </li> \n <li> <span></span> <span>Flex Time - flexible hours, ample vacation time, available day one</span> </li> \n <li> <span></span> <span>Floating Holidays - flexible holidays can be taken on any day</span> </li> \n <li> <span></span> <span>Healthcare -health, dental, &amp; vision; covered day one</span> </li> \n <li> <span></span> <span>Annual bonuses and raises - above cost of living increases</span> </li> \n <li> <span></span> <span>Generous pension plan - after 13 months of employment</span> </li> \n <li> <span></span> <span>SNACKS - plenty of free snacks!</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "E_8GV6D3T7G_CCu-xIIASg",
    "url": "https://stackoverflow.com/jobs/282710/data-engineer-scala-spark-remote-semanticbits?a=1wOlXRkOeIyA",
    "title": "Data Engineer (Scala/Spark) - Remote at SemanticBits  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:angular/frontend/8",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:scala/java/15",
      "DBG_TECH1:k/t/w:spring-boot/java/8",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=42, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "SemanticBits",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:30:26 PM",
    "validThrough": "Jul 25, 2019 10:30:26 PM",
    "crawled": "Jul 18, 2019 10:30:26 PM",
    "content": "<h3><span>Data Engineer (Scala/Spark) - Remote</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Digital Health</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n </div> \n</div> \n<div>\n Company: SemanticBits | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-05:00) Eastern Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n scala\n</div>\n<div>\n apache-spark\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p>SemanticBits is looking for a talented Data Engineer who is eager to apply computer science, software engineering, databases, and distributed/parallel processing frameworks to prepare big data for the use of data analysts and data scientists. You will deliver data acquisition, transformations, cleansing, conversion, compression, and loading of data into data and analytics models. You will work in partnership with data scientists and analysts to understand use cases, data needs, and outcome objectives. You are a practitioner of advanced data modeling and optimization of data and analytics solutions at scale. Expert in data management, data access (big data, data marts, etc.), programming, and data modeling; and familiar with analytic algorithms and applications (like machine learning).</p>\n <p>SemanticBits is a leading company specializing in the design and development of digital health services, and the work we do is just as unique as the culture we’ve created. We develop cutting-edge solutions to complex problems for commercial, academic, and government organizations. The systems we develop are used in finding cures for deadly diseases, improving the quality of healthcare delivered to millions of people, and revolutionizing the healthcare industry on a nationwide scale. There is a meaningful connection between our work and the real people who benefit from it; and, as such, we create an environment in which new ideas and innovative strategies are encouraged. We are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional success every day.</p>\n <p>Requirements:</p>\n <ul>\n  <li>Bachelor’s degree in Computer Science (or a related field)</li>\n  <li>Three or more years in data engineering</li>\n  <li>At least two years working with Scala and Spark</li>\n  <li>Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases (SQL and relational design), networking</li>\n  <li>Demonstrable experience engineering scalable data processing pipelines.</li>\n  <li>Demonstrable expertise with Scala, Spark, and wrangling of various data formats - Parquet, CSV, XML, JSON.</li>\n  <li>Experience with the following technologies is highly desirable: Teradata, AWS EMR, AWS EC2, AWS S3, Airflow, SAS, Hadoop, Java, Spring Boot, Angular</li>\n  <li>Experience with Agile methodology, using test-driven development.</li>\n  <li>Excellent command of written and spoken English</li>\n  <li>Self-driven problem solver</li>\n </ul>\n <p>Benefits:</p>\n <ul>\n  <li>Generous base salary</li>\n  <li>Three weeks of PTO</li>\n  <li>Excellent health benefits program (Medical, dental and vision)</li>\n  <li>Education and conference reimbursement</li>\n  <li>401k retirement plan. We contribute 3% of base salary irrespective of employee's contribution</li>\n  <li>100% paid short-term and long-term disability</li>\n  <li>100% paid life insurance</li>\n  <li>Flexible Spending Account (FSA)</li>\n  <li>Casual working environment</li>\n  <li>Flexible working hours</li>\n </ul>\n <p>SemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.</p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282710?reset=False&amp;ra=1wOlXRkOeIyA&amp;oqs=a%3D1wOlXRkOeIyA' rel='nofollow'>Apply now</a>\n</div> \n<h4>About SemanticBits</h4> \n<div>\n <p>SemanticBits is a leading company specializing in the design and development of digital health services, and the work we do is just as unique as the culture we’ve created. We develop cutting-edge solutions to complex problems for commercial, academic, and government organizations. The systems we develop are used in finding cures for deadly diseases, improving the quality of healthcare delivered to millions of people, and revolutionizing the healthcare industry on a nationwide scale. There is a meaningful connection between our work and the real people who benefit from it; and, as such, we create an environment in which new ideas and innovative strategies are encouraged. We are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional success every day.</p>\n <p><strong>Salary &amp; Benefits</strong></p>\n <ul>\n  <li>Generous base salary</li>\n  <li>Three weeks of PTO</li>\n  <li>Excellent health benefits program (Medical, dental and vision)</li>\n  <li>Education and conference reimbursement</li>\n  <li>401k retirement plan. We contribute 3% of base salary irrespective of employee's contribution</li>\n  <li>100% paid short-term and long-term disability</li>\n  <li>100% paid life insurance</li>\n  <li>FSA</li>\n  <li>Casual Working Environment</li>\n  <li>Flexible Office Hours</li>\n </ul>\n <p>SemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Medical, dental, vision, life, disability</span> </li> \n <li> <span></span> <span>Matched 401K plan</span> </li> \n <li> <span></span> <span>Generous vacation allowances, floating holidays, and sick leave</span> </li> \n <li> <span></span> <span>Continued Education Reimbursement</span> </li> \n <li> <span></span> <span>Free coffee and snacks</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "x79qXzSkQ1OR1_Jb992Rkw",
    "url": "https://stackoverflow.com/jobs/282404/senior-data-engineer-data-architect-do-good-literacypro-systems-inc?a=1wHZtWK5Suf6",
    "title": "Senior Data Engineer / Data Architect - Do Good. Do Well. Have Fun Doing It. at LiteracyPro ...",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "LiteracyPro Systems, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 200000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 200k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 9:30:23 PM",
    "validThrough": "Jul 25, 2019 9:30:23 PM",
    "crawled": "Jul 18, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Data Engineer / Data Architect - Do Good. Do Well. Have Fun Doing It.</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Database Administrator</span> \n  </div> \n </div> \n</div> \n<div>\n Company: LiteracyPro Systems, Inc. | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-07:00) Mountain Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div>\n etl\n</div>\n<div>\n sql\n</div>\n<div>\n pentaho\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Type: </strong></p>\n <p>Contract position for approximately 3 months. Will be able to start project within a week.</p>\n <p><strong>Brief Job Description:</strong> &nbsp;</p>\n <p>LiteracyPro creates software for social good. Our data collection and reporting software helps government and community-based organizations help hundreds of thousands of disadvantaged people improve their opportunities to get jobs with sustainable, living wages for themselves and their families. Enjoy being part of a fun group of bright, passionate folks, in a great working environment, with generous salary &amp; benefits while helping those who help others.</p>\n <p>Our newest product, CommunityPro Suite (CPS), is a growing SaaS case management, referral, reporting and analysis enterprise application that enables hundreds of agencies to securely match, consolidate and share data in real time. The purpose of the software is to reduce organizational friction by helping local agencies better collaborate to help people achieve economic self-sufficiency for themselves and their families. The end-goal of CPS is to play an important role in helping to create healthy, vibrant communities in this country and the world.</p>\n <p>Our Company is experiencing explosive growth due to increasing national demand for our software, and we’re looking for that rare, accomplished data analyst who wants to do good, get paid well and have fun doing it. We’re seeking someone with an energizing leadership style, and who has the smarts, passion and people skills to guide our efforts on all aspects of the data management process, including: on-boarding; acquisition; attribution; transformation; and reporting of newly acquired data sets to provide high-quality data supporting analytics and our clients’ needs in a timely fashion.</p>\n <p>Given the highly execution-focused nature of the work, the ideal candidate will roll up their sleeves to ensure that their projects meet deadlines and will always look for ways to optimize processes in future cycles.</p>\n <p><strong>Responsibilities:</strong></p>\n <p>This position has the primary responsibility for the acquisition, transformation, and maintenance of data for our primary SAAS application. This data is interchanged from and returned to an increasingly diverse set of third-party source systems.</p>\n <ul>\n  <li>Conduct in-depth data profiling and data quality assessments of data received from multiple source systems to determine the current level of data accuracy, conformation to standards, reporting requirements, etc.</li>\n  <li>Investigate data flow issues by discovering system states that prevent successful job completion (source systems, infrastructure, etc.).</li>\n  <li>Identify and analyze the errors/inconsistencies in the data; provide timely resolutions for data lineage and data cleansing.</li>\n  <li>Build and validate a data quality framework with alerts for data discrepancies.</li>\n  <li>Work with the product owner/system owner, development, and QA teams to ensure alignment and proper interpretation of complex data requirements.</li>\n  <li>Develop technical documentation, including requirements documents, process overviews, data models, data flow, and ETL jobs.</li>\n </ul>\n <p><strong>Experience and Qualifications:</strong></p>\n <ul>\n  <li>6+ years performing analysis and building data processes.</li>\n  <li>6+ years of experience with ETL tasks such as reviewing business requirements, developing and troubleshooting data cleansing and loading solutions, preparing solution documentation, data dictionaries, metadata repositories, and database security.</li>\n  <li>6+ years of industry experience with the development and implementation of enterprise-level data warehousing and supporting business intelligence initiatives, particularly focused on star schema data modeling.</li>\n  <li>6+ years of experience with database design, including mastery of complex report queries and SQL optimization.</li>\n  <li>Experience with MySQL, Amazon Web Services, Microsoft Azure. Experience with Pentaho CE a plus!</li>\n  <li>Familiarity with the data security and privacy requirements of FERPA, HIPPA, SOC2 and related industry and legal standards</li>\n </ul>\n <ul>\n  <li>Degree in Computer Science, Information Systems, Mathematics, or equivalent quantitative field</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282404?reset=False&amp;ra=1wHZtWK5Suf6&amp;oqs=a%3D1wHZtWK5Suf6' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About LiteracyPro Systems, Inc.</h4> \n<div>\n <p><strong>Our Mission</strong></p>\n <p><em>“To be a powerful force of good in the world by creating revolutionary tools for those serving humanity.”</em></p>\n <p><strong>Our Culture</strong></p>\n <ul>\n  <li>Aptitude to thrive in a pioneering environment and successfully manage multiple priorities and projects with critical deadlines.</li>\n  <li>Insanely curious, naturally approaches challenges with energy and positivity.</li>\n  <li>Your word is your bond. Your sincerity and honesty easily generate a deep sense of admiration and loyalty in your team.</li>\n  <li>You’re an exceptional listener; you ask lots of questions to better understand complex problems and interpersonal matters.</li>\n  <li>You can laugh at yourself; you’re only human and make mistakes like the rest of us.</li>\n </ul>\n <p><strong>Our Core Values:</strong></p>\n <p>The very core of LiteracyPro Systems is our genuine belief in, and adherence to, the company’s six core values:</p>\n <ul>\n  <li>Honesty and ethical behavior above all else</li>\n  <li>Teamwork—we sink or swim together</li>\n  <li>Work hard, have fun</li>\n  <li>Passion for excellence—second best will never suffice</li>\n  <li>We follow through on our commitments—we mean what we say and we say what we mean</li>\n  <li>Service to our community</li>\n </ul>\n <p>These six core values guide us in everything we do—from the commitments we make and the execution of our business plan, to the way we treat each other on a daily basis. Our values foster a deep sense of responsibility to our customers, vendors, and investors as well as to fellow team members. We are driven by the satisfaction of excellence.</p>\n <p><strong>Please send a cover letter and your resume to: David Miller, <a href='mailto:dhmiller@literacypro.com' rel='nofollow'>dhmiller@literacypro.com</a><br></strong></p> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eakN1ON_RPmVpf89_B2-GA",
    "url": "https://stackoverflow.com/jobs/282622/r-developer-yougov?a=1wMwwd9rlHhe",
    "title": "R Developer at YouGov  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=15, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "YouGov",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 3:06:25 PM",
    "validThrough": "Jul 25, 2019 3:06:25 PM",
    "crawled": "Jul 18, 2019 3:06:25 PM",
    "content": "<h3><span>R Developer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Market research, Web Technology</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>501–1k people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: YouGov | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-06:00) Central Time +/- 4 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n r\n</div>\n<div>\n shiny\n</div>\n<div>\n python\n</div>\n<div>\n etl\n</div>\n<div>\n Pawel 88 1 6\n</div>\n<div>\n mnowotka Backend Team Lead 6.7k 11 62 110\n</div>\n<div>\n Xbito 1.3k 1 8 8\n</div>\n<div>\n Andy Wong 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><span>Crunch.io, part of the YouGov PLC, is seeking a talented, motivated, and versatile human to help lead the development of our R data science products. Crunch provides a modern platform for survey data analysis, and a central feature of our product is the ability to manipulate and analyze datasets stored in the cloud using R. As senior R developer, you will have three main responsibilities. First, you will work with the rest of our team to design and implement novel features that deliver real value and change our clients’ workflows for the better. Second, as the primary point of contact between our R user community and the development team, you will serve as their voice in product development. And third, you will often directly help clients manipulate and explore data using Crunch, including helping clients design and implement workflows that incorporate Crunch.&nbsp;&nbsp;</span></p>\n <p><strong>Key responsibilities:</strong></p>\n <ul>\n  <li><span>Teaching users how to work with the library through documentation and direct conversations.</span></li>\n  <li><span>Writing scripts that help clients implement Crunch and make it a part of their workflow, including ETL, data analysis, and outputs.&nbsp;&nbsp;</span></li>\n  <li><span>Developing and maintaining our core R packages, including new feature design, comprehensive testing, and documentation</span></li>\n  <li><span>Supporting our community of R users by responding to feature requests and triaging bug reports</span></li>\n  <li><span>Evangelizing our product and educating our R user base by contributing to our technical blog and helping enrich our support documentation</span></li>\n  <li><span>Translating API speak to R that feels natural and native</span></li>\n  <li><span>Engaging with and contributing to the broader open source R ecosystem</span></li>\n </ul>\n <p><span>Depending on your interests and skills, there are opportunities to get involved in:</span></p>\n <ul>\n  <li><span>API design: developing good conventions that enable our platform to scale and make it easy for client applications to consume them</span></li>\n  <li><span>JavaScript development, helping our frontend developers implement features you've utilized in R</span></li>\n  <li><span>Product management, building on your interactions with our users to shape our product roadmap and feature design</span></li>\n  <li><span>Python development, ranging from implementing APIs you need for the R packages, to&nbsp; statistical modeling, numerical computing, machine learning, and natural language processing</span></li>\n </ul>\n <p><span>In any given week, you might implement an R interface for a new API our backend has added, write a blog post introducing that new feature, track down a bug report from a user, write a test that reproduces the issue, and assist customers in implementing Crunch via the Crunch R packages.&nbsp;</span></p>\n <p><strong>Qualifications:</strong></p>\n <ul>\n  <li><span>Expert-level skills in R, including experience delivering code that others rely on to do their work. Prior experience creating and maintaining R packages is highly valued.</span></li>\n  <li><span>Serious commitment to high development standards, including comprehensive testing, in whatever language you're working</span></li>\n  <li><span>Demonstrated ability to work with a team of peers, understanding and respecting the responsibilities and expertise developers, designers, QA folks, and others bring to the project</span></li>\n  <li><span>Eagerness to take ownership of projects and deliver results on schedule</span></li>\n  <li><span>Experience in a &quot;data science&quot;, such as social science, market research, or data visualization, is a plus.</span></li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282622?reset=False&amp;ra=1wMwwd9rlHhe&amp;oqs=a%3D1wMwwd9rlHhe' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About YouGov</h4> \n<div>\n <p>YouGov works with the world's leading brands and organisations to understand what people think.</p>\n <p><strong>Powered&nbsp;by Digital Development</strong></p>\n <p>Our Global Dev group is a tight group of seven teams comprised of about 40 developers based globally in the UK, Poland, USA and beyond.</p>\n <p>The teams coordinate on efforts to build applications and innovate in data collection, survey authoring, profile data management, integration, data analytics, content management, and other areas.</p>\n <p>These applications drive the&nbsp;opinion data engine of YouGov; empowering the biggest and the best organisations around the world with accurate information about what the world thinks. Enabling these organisations to make effective predictions based on what their audience or stakeholders think.</p>\n <p>We believe the more people are able to participate in the decisions made by the institutions that serve them, the better those decisions will be.</p>\n <p><strong>Diverse as the Audience we work with</strong></p>\n <p>YouGov is part of Stonewall's Global Diversity Champions Framework.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Flexibility</span> </li> \n <li> <span></span> <span>Best Equipment</span> </li> \n <li> <span></span> <span>Salary + Bonus</span> </li> \n <li> <span></span> <span>Well-being at Work</span> </li> \n <li> <span></span> <span>Various lifestyle benefits</span> </li> \n <li> <span></span> <span>Culture of Learning</span> </li> \n <li> <span></span> <span>Pension (401K in the USA)</span> </li> \n <li> <span></span> <span>Employee Assistance</span> </li> \n <li> <span></span> <span>Games and Social Events</span> </li> \n <li> <span></span> <span>Good Holiday allowance</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "S-wavKvQRWCyIVsc9y4wmg",
    "url": "https://remoteok.io/jobs/73979",
    "title": "Software Engineer",
    "tags": [
      "DBG:surround``remot 2W work W experi",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=8, ruby=2, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AlphaSights",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "ETB",
      "minValue": 75000,
      "maxValue": 75000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "ETB 75k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 2:13:18 AM",
    "validThrough": "Jul 25, 2019 2:13:18 AM",
    "crawled": "Jul 18, 2019 3:06:30 AM",
    "content": "<span></span> \n<span><h4>AlphaSights</h4></span> \n<br> \n<h3>Software Engineer</h3> \n<span></span> \n<span>verified</span> \n<br> \n<span>Brazil</span> \n<div> \n <div>\n   *[Disclaimer: we are targeting experienced engineers based in Brazil]* \n  <br> \n  <br>At AlphaSights, we search through more than 500 million professionals working in the world today to find the small handful of experts qualified to answer our clients needs. They use these insights to drive amazing progress within their organizations. Our mission is to provide access to dispersed, hidden, and underutilized knowledge. \n  <br> \n  <br>We’ve made terrific progress working in this new space, but there is still an incredible amount of work to do. We’ve only just scratched the surface on how we can apply technology to this problem. \n  <br> \n  <br>AlphaSights' Engineers build features across our ecosystem of products and services, both internal and client facing. As a Fullstack engineer you will remove pain-points, optimize workflows, and enhance the intelligence and capabilities of our systems. You'll work closely with a variety of people in the business to arrive at the best solution, immediately see the impact of your work, and get feedback directly from users. \n  <br> \n  <br>We're looking for people who are interested in building software systems to an incredibly high standard, comfortable working across multiple languages, and learn quickly when new technologies are introduced. \n  <br> \n  <br>We care more about your engineering skill versus your deep knowledge of a particular language or framework. \n  <br> \n  <br>**You will:** \n  <br> \n  <br>* Build and technically own large areas of our product and service ecosystem \n  <br>* Improve the performance of our applications \n  <br>* Improve developer tooling and processes \n  <br>* Work in small, nimble teams \n  <br>* Contribute with our growing Open Source efforts \n  <br>* Understand our business context deeply and leverage your engineering knowledge to propose creative solutions to problems \n  <br> \n  <br>**You might be a fit if you:** \n  <br> \n  <br>Don't worry if your experience or background doesn't match all of these areas, we believe a broad spectrum of experience provides a great perspective on solving problems in new and innovative ways and we’d love to hear from you. \n  <br> \n  <br>* Have at least 6 years of professional experience, and have served as tech lead for a specific application, product area, or infrastructure \n  <br>* You’re an expert in at least one programming Language. Ruby, Java or Python experience would be a plus. \n  <br>* Enjoy mentoring other team members, including code reviews and tech talks \n  <br>* Can balance deep work with cross-team collaboration \n  <br>* Constantly learn from and mentor other engineers \n  <br>* See yourself as an entrepreneur as well as an engineer \n  <br>* Are interested in working in a team applying data science to solve challenging business problems \n  <br>* Previous remote working experience is a plus \n  <br> \n  <br>**You might work on:** \n  <br> \n  <br>* Automate the detection and mitigation of risk in real-time \n  <br>* Propose and deliver a new product initiative to production \n  <br>* Democratize data within the organization \n  <br>* Optimizing and scaling our overall platform architecture \n  <br>* Build tools to schedule multi-party communication with heavy constraints \n  <br>* Help pick and define our tools \n  <br> \n  <br>**Who you would work with:** \n  <br> \n  <br>* You would join a dynamic, multinational, and diverse team who enjoy solving interesting problems in a collaborative environment \n  <br>* We have self-taught engineers as well as graduates from top Computer Science and Engineering schools \n  <br>* Your co-workers will include motivated recent graduates as well as experienced industry leaders from companies such as Google and Amazon \n  <br> \n  <br>Find out more: http://engineering.alphasights.com \n  <br> \n  <br>#Salary \n  <br>$75,000 \n  <br> \n  <br> \n  <br>#Location \n  <br>- Brazil \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0y8YFCtCTGGW3SW5O_hG2A",
    "url": "https://jobmote.com/job/50290/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 10:07:21 PM",
    "validThrough": "Jul 20, 2019 10:07:21 PM",
    "crawled": "Jul 18, 2019 3:06:25 AM",
    "content": "<div>\n Azure Big Data Engineer (Remote Flexibility)\n <br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.\n <br> *AZURE EXPERIENCE REQUIRED\n <br> Skills:\n <ul>\n  <li>Experience using languages like Python, Scala, and Java</li>\n  <li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li>\n  <li>Experience with ETL tools like SSIS, SSAS, SSRS</li>\n  <li>Some familiarity with Microsoft BI and Power BI is great as well</li>\n  <li>Experience with data pipeline and workflow management tools</li>\n </ul>Benefits:\n <ul>\n  <li>Medical</li>\n  <li>Dental</li>\n  <li>Vision</li>\n  <li>Family leave</li>\n  <li>PTO</li>\n  <li>Retirement Plan</li>\n  <li>Remote options</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n <br>\n <b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b>\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "fzYytK21QeiJoECPRV6bAQ",
    "url": "https://jobmote.com/job/50283/aws-big-data-engineer-hadoop-python-remote/",
    "title": "AWS Big Data Engineer - Hadoop, Python - remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=6, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=76, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 10:07:21 PM",
    "validThrough": "Jul 20, 2019 10:07:21 PM",
    "crawled": "Jul 18, 2019 3:06:25 AM",
    "content": "<div>\n AWS Big Data Engineer - Hadoop, Python\n <br>\n <br>AWS Big Data Engineer\n <br>\n <br>Description:\n <br>\n <br>My client in Rockville, MD is looking to bring on a Big Data Engineer to lead the department for the full life cycle of a data migration project. The client is actively interviewing as the project is set to begin the first of September and they are looking to on board their senior leads in advance.\n <br>\n <br>This candidate will be able to manage their own team, participate in the full lifecycle of the migration, and help build out the organizations engineering department.\n <br>\n <br>Role &amp; Responsibilities:\n <ul>\n  <li>Closely working with cross-functional teams.</li>\n  <li>Building fact tables to facilitate quicker and easier data access.</li>\n  <li>Building indices at elastic Search to support real-time dash boards at Kabana, and building predictive models to support AI/ML.</li>\n </ul>Requirements:\n <ul>\n  <li>3+ years of relevant work experience </li>\n  <li>Working experience of Scala, Spark, building ATL query models.</li>\n  <li>Developing shell scripts and running Oozie/spark jobs on Hadoop platform</li>\n  <li>Hadoop platform work using Big Data tools.</li>\n  <li>Working experience on ElasticSearch and Kibana</li>\n </ul>Hadoop, Python\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "r0GqSZ7DQu2XkW7pVu5x9Q",
    "url": "https://remoteok.io/jobs/73976",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:golang/go/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:maven/java/13",
      "DBG_TECH1:k/t/w:npm/nodejs/5",
      "DBG_TECH1:k/t/w:perl/other/20",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:rubygems/ruby/8",
      "DBG_TECH1:techWeightMap:{python=8, other=20, dotnet=0, c=0, mobile=1, go=16, nodejs=7, bigdata-ml=32, ruby=10, apple=0, java=23, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "ActiveState Software ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 12:57:11 AM",
    "validThrough": "Jul 25, 2019 12:57:11 AM",
    "crawled": "Jul 18, 2019 1:06:30 AM",
    "content": "<span></span> \n<span><h4>ActiveState Software</h4>&nbsp;</span> \n<br> \n<h3>Data Engineer</h3> \n<div> \n <div> \n  <br>If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it! \n  <br> \n  <br>This position is open to full-time telecommuters anywhere in North America. You can also choose to work from our headquarters in beautiful Vancouver, BC. \n  <br> \n  <br>This position is open to both junior (including fresh out of school) and senior applicants. The salary for this position will be commensurate with your experience. \n  <br> \n  <br>What You’ll be Doing \n  <br> \n  <br>As a Data Engineer, you will create and maintain a data processing pipeline to feed our automated build systems with information about various open source languages and package updates. This work includes automating processing of open source package update feeds from language repositories including PyPI (Python), CPAN (Perl), Maven (Java), NPM (JavaScript), RubyGems. You will also be creating web crawlers for eco-systems without well defined APIs. \n  <br> \n  <br>Our day to day work practices are centered around GitHub, pull requests, code review, CI for testing, and agile development with Pivotal Tracker as our project management tool. We’re always looking to improve our practices and we expect you to help us to do so. \n  <br> \n  <br>We’re a polyglot company building our system using Golang, Python, Elm, Javascript, Perl, Docker, Kubernetes, DCOS, CircleCI, and other modern tools. Quality is as important as speed. We’re building for the long run, so you’ll need to enjoy writing tests and documentation too. \n  <br> \n  <br>Our team is scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Highfive for video calls and screen sharing, Pivotal Tracker, and Google Drive. \n  <br> \n  <br>We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code. \n  <br> \n  <br>Working at ActiveState \n  <br> \n  <br>ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all of us. \n  <br> \n  <br>Our company is a team of 40+ and growing, with 2/3rds of the positions in technical roles&nbsp; including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events. \n  <br> \n  <br>Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches. \n  <br> \n  <br>What’s in it for You \n  <br> \n  <br> \n  <br>* Working for a stable and growing company that offers the environment and personal growth potential of a start-up. \n  <br> \n  <br>* The chance to work with a smart, passionate team of people. \n  <br> \n  <br>* The chance to work on a project that will change the work lives of developers around the world. \n  <br> \n  <br>* Competitive salary, bonus, and stock option plan. \n  <br> \n  <br>* Comprehensive benefits package and health/wellness credit program. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Requirements \n  <br> \n  <br> \n  <br>* Experience creating and maintaining complex software systems along with the ability to design non-trivial applications and components from scratch. \n  <br> \n  <br>* The ability to write clean, well-tested code with clear documentation. \n  <br> \n  <br>* Deep experience with at least one programming language, and shallow experience with several. \n  <br> \n  <br>* Excellent written and spoken skills, both technical and non-technical. You’ll need to work closely with your developer teammates, as well as be able to have coherent conversations with people from QA, sales, marketing, and other parts of the company. \n  <br> \n  <br>* A willingness to engage in the process of defining our work through conversations with product management, other engineering teams, and the rest of the company. \n  <br> \n  <br>* The ability to help others on the team become better at their jobs through mentoring, thoughtful code reviews, and generally being a team player. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Assets \n  <br> \n  <br>If you have experience with any of the following please make sure to highlight it in your cover letter: \n  <br> \n  <br> \n  <br>* Data processing technologies, including but not limited to Kafka, Hadoop, Hive, Presto, Luigi, Airflow, Storm, etc. \n  <br> \n  <br>* Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI. \n  <br> \n  <br>* Golang code, especially large code bases. \n  <br> \n  <br>* Microservices and message queues. \n  <br> \n  <br>* Docker and Kubernetes. \n  <br> \n  <br>* Perl, Python, Tcl, or Ruby, especially an understanding of their respective language communities and toolchains. \n  <br> \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vxcYyV4uRiyPKMSTkiRY_g",
    "url": "https://remoteok.io/jobs/73971",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``posit 5W 2N(from,anywher)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blue Orange Digital ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 8:58:15 PM",
    "validThrough": "Jul 24, 2019 8:58:15 PM",
    "crawled": "Jul 17, 2019 9:30:31 PM",
    "content": "<span></span> \n<span><h4>Blue Orange Digital</h4>&nbsp;</span> \n<br> \n<h3>Data Scientist</h3> \n<div> \n <div> \n  <br>Job Description \n  <br> \n  <br> \n  <br> \n  <br>You will be joining a highly talented team of engineers working on a custom hiring and talent mapping application. We are helping a large company leverage their data to find the perfect candidates. This ranges from predictive models to answering other very open-ended questions. We have a range of projects from&nbsp; \n  <br> \n  <br>This is a remote position that can be done from anywhere.&nbsp; \n  <br> \n  <br>Responsibilities: \n  <br> \n  <br> \n  <br>* Use statistical, algorithmic, data mining, and visualization techniques to model complex problems, identify opportunities, discover solutions, and deliver actionable business insights. \n  <br> \n  <br>* Own your projects and use this autonomy to find creative and innovative ways of solving problems and delivering solutions. \n  <br> \n  <br>* Handle both parts of the Research &amp; Development process, including clean, rigorous implementations of devised models inside our Analytics system. \n  <br> \n  <br>* Communicate data-driven insights and recommendations to key stakeholders. \n  <br> \n  <br>* Be in constant communication with team members and other relevant parties and convey results efficiently and clearly. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Requirements: \n  <br> \n  <br> \n  <br>* A strong background in advanced mathematics, in particular in probability theory and statistics, data mining, and machine learning. \n  <br> \n  <br>* Comfortable working with messy structured data sets and turning them into machine learning products \n  <br> \n  <br>* Experience in Natural Language Processing (keyword extraction and sentiment analysis) \n  <br> \n  <br>* You must be able to think critically, to look at the big picture and spot what is missing, taking advantage of it to propose improvements and deliver business insights. \n  <br> \n  <br>* 4+ years of professional experience in data science, doing exploratory data analysis, testing hypothesis, and building predictive models. \n  <br> \n  <br>* Ability to quickly and accurately understand complex new concepts. \n  <br> \n  <br>* Proficiency in Python and previous experience efficiently conducting research and creating ad hoc reports. \n  <br> \n  <br>* Familiarity with Scala/Spark a plus \n  <br> \n  <br>* Be excited about collaborating daily with your team and other groups while working via a distributed model. \n  <br> \n  <br>* Be eager to help your teammates, share your knowledge with them, and learn from them. \n  <br> \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "acjP204cSuGGf7dg9XbNNA",
    "url": "https://stackoverflow.com/jobs/282404/senior-data-analyst-do-good-do-well-have-fun-literacypro-systems-inc?a=1wHZtWK5Suf6",
    "title": "Senior Data Analyst - Do Good. Do Well. Have Fun Doing It. at LiteracyPro Systems, Inc.  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "LiteracyPro Systems, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 200000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 200k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 9:30:26 PM",
    "validThrough": "Jul 24, 2019 9:30:26 PM",
    "crawled": "Jul 17, 2019 9:30:26 PM",
    "content": "<h3><span>Senior Data Analyst - Do Good. Do Well. Have Fun Doing It.</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n</div> \n<div>\n Company: LiteracyPro Systems, Inc. | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-07:00) Mountain Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div>\n etl\n</div>\n<div>\n sql\n</div>\n<div>\n pentaho\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Title: </strong></p>\n <p>Senior ETL/Data Analyst (Contractor or Contract-to-Hire Position - we're open to both)</p>\n <p><strong>Brief Job Description:</strong> &nbsp;</p>\n <p>LiteracyPro creates software for social good. Our data collection and reporting software helps government and community-based organizations help hundreds of thousands of disadvantaged people improve their opportunities to get jobs with sustainable, living wages for themselves and their families. Enjoy being part of a fun group of bright, passionate folks, in a great working environment, with generous salary &amp; benefits while helping those who help others.</p>\n <p>Our newest product, CommunityPro Suite (CPS), is a growing SaaS case management, referral, reporting and analysis enterprise application that enables hundreds of agencies to securely match, consolidate and share data in real time. The purpose of the software is to reduce organizational friction by helping local agencies better collaborate to help people achieve economic self-sufficiency for themselves and their families. The end-goal of CPS is to play an important role in helping to create healthy, vibrant communities in this country and the world.</p>\n <p>Our Company is experiencing explosive growth due to increasing national demand for our software, and we’re looking for that rare, accomplished data analyst who wants to do good, get paid well and have fun doing it. We’re seeking someone with an energizing leadership style, and who has the smarts, passion and people skills to guide our efforts on all aspects of the data management process, including: on-boarding; acquisition; attribution; transformation; and reporting of newly acquired data sets to provide high-quality data supporting analytics and our clients’ needs in a timely fashion.</p>\n <p>Given the highly execution-focused nature of the work, the ideal candidate will roll up their sleeves to ensure that their projects meet deadlines and will always look for ways to optimize processes in future cycles.</p>\n <p><strong>Responsibilities:</strong></p>\n <p>This position has the primary responsibility for the acquisition, transformation, and maintenance of data for our primary SAAS application. This data is interchanged from and returned to an increasingly diverse set of third-party source systems.</p>\n <ul>\n  <li>Conduct in-depth data profiling and data quality assessments of data received from multiple source systems to determine the current level of data accuracy, conformation to standards, reporting requirements, etc.</li>\n  <li>Investigate data flow issues by discovering system states that prevent successful job completion (source systems, infrastructure, etc.).</li>\n  <li>Identify and analyze the errors/inconsistencies in the data; provide timely resolutions for data lineage and data cleansing.</li>\n  <li>Build and validate a data quality framework with alerts for data discrepancies.</li>\n  <li>Work with the product owner/system owner, development, and QA teams to ensure alignment and proper interpretation of complex data requirements.</li>\n  <li>Develop technical documentation, including requirements documents, process overviews, data models, data flow, and ETL jobs.</li>\n </ul>\n <p><strong>Experience and Qualifications:</strong></p>\n <ul>\n  <li>6+ years performing analysis and building data processes.</li>\n  <li>6+ years of experience with ETL tasks such as reviewing business requirements, developing and troubleshooting data cleansing and loading solutions, preparing solution documentation, data dictionaries, metadata repositories, and database security.</li>\n  <li>6+ years of industry experience with the development and implementation of enterprise-level data warehousing and supporting business intelligence initiatives, particularly focused on star schema data modeling.</li>\n  <li>6+ years of experience with database design, including mastery of complex report queries and SQL optimization.</li>\n  <li>Experience with MySQL, Amazon Web Services, Microsoft Azure. Experience with Pentaho CE a plus!</li>\n  <li>Familiarity with the data security and privacy requirements of FERPA, HIPPA, SOC2 and related industry and legal standards</li>\n </ul>\n <ul>\n  <li>Degree in Computer Science, Information Systems, Mathematics, or equivalent quantitative field</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282404?reset=False&amp;ra=1wHZtWK5Suf6&amp;oqs=a%3D1wHZtWK5Suf6' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About LiteracyPro Systems, Inc.</h4> \n<div>\n <p><strong>Our Mission</strong></p>\n <p><em>“To be a powerful force of good in the world by creating revolutionary tools for those serving humanity.”</em></p>\n <p><strong>Our Culture</strong></p>\n <ul>\n  <li>Aptitude to thrive in a pioneering environment and successfully manage multiple priorities and projects with critical deadlines.</li>\n  <li>Insanely curious, naturally approaches challenges with energy and positivity.</li>\n  <li>Your word is your bond. Your sincerity and honesty easily generate a deep sense of admiration and loyalty in your team.</li>\n  <li>You’re an exceptional listener; you ask lots of questions to better understand complex problems and interpersonal matters.</li>\n  <li>You can laugh at yourself; you’re only human and make mistakes like the rest of us.</li>\n </ul>\n <p><strong>Our Core Values:</strong></p>\n <p>The very core of LiteracyPro Systems is our genuine belief in, and adherence to, the company’s six core values:</p>\n <ul>\n  <li>Honesty and ethical behavior above all else</li>\n  <li>Teamwork—we sink or swim together</li>\n  <li>Work hard, have fun</li>\n  <li>Passion for excellence—second best will never suffice</li>\n  <li>We follow through on our commitments—we mean what we say and we say what we mean</li>\n  <li>Service to our community</li>\n </ul>\n <p>These six core values guide us in everything we do—from the commitments we make and the execution of our business plan, to the way we treat each other on a daily basis. Our values foster a deep sense of responsibility to our customers, vendors, and investors as well as to fellow team members. We are driven by the satisfaction of excellence.</p>\n <p><strong>Please send a cover letter and your resume to: David Miller, <a href='mailto:dhmiller@literacypro.com' rel='nofollow'>dhmiller@literacypro.com</a><br></strong></p> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kHmR47GmT3CuALK49GvnUA",
    "url": "https://stackoverflow.com/jobs/282320/data-scientist-blue-orange-digital?a=1wGfc0ESu9ig",
    "title": "Data Scientist at Blue Orange Digital  ",
    "tags": [
      "DBG:surround``posit 5W 2N(from,anywher)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blue Orange Digital",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 3:06:55 PM",
    "validThrough": "Jul 24, 2019 3:06:55 PM",
    "crawled": "Jul 17, 2019 3:06:55 PM",
    "content": "<h3><span>Data Scientist</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data Analysis, Financial Technology, Machine Learning</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Blue Orange Digital | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n python\n</div>\n<div>\n apache-spark\n</div>\n<div>\n nlp\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Description</strong><span><br><br></span></p>\n <p><span>You will be joining a highly talented team of engineers working on a custom hiring and talent mapping application. We are helping a large company leverage their data to find the perfect candidates. This ranges from predictive models to answering other very open-ended questions. We have a range of projects from&nbsp;</span></p>\n <p><span>This is a remote position that can be done from anywhere.&nbsp;</span></p>\n <p><span>Responsibilities:</span></p>\n <ul>\n  <li><span>Use statistical, algorithmic, data mining, and visualization techniques to model complex problems, identify opportunities, discover solutions, and deliver actionable business insights.</span></li>\n  <li><span>Own your projects and use this autonomy to find creative and innovative ways of solving problems and delivering solutions.</span></li>\n  <li><span>Handle both parts of the Research &amp; Development process, including clean, rigorous implementations of devised models inside our Analytics system.</span></li>\n  <li><span>Communicate data-driven insights and recommendations to key stakeholders.</span></li>\n  <li><span>Be in constant communication with team members and other relevant parties and convey results efficiently and clearly.</span></li>\n </ul>\n <p><span>Requirements:</span></p>\n <ul>\n  <li><span>A strong background in advanced mathematics, in particular in probability theory and statistics, data mining, and machine learning.</span></li>\n  <li><span>Comfortable working with messy structured data sets and turning them into machine learning products</span></li>\n  <li><span>Experience in Natural Language Processing (keyword extraction and sentiment analysis)</span></li>\n  <li><span>You must be able to think critically, to look at the big picture and spot what is missing, taking advantage of it to propose improvements and deliver business insights.</span></li>\n  <li><span>4+ years of professional experience in data science, doing exploratory data analysis, testing hypothesis, and building predictive models.</span></li>\n  <li><span>Ability to quickly and accurately understand complex new concepts.</span></li>\n  <li><span>Proficiency in Python and previous experience efficiently conducting research and creating ad hoc reports.</span></li>\n  <li><span>Familiarity with Scala/Spark a plus</span></li>\n  <li><span>Be excited about collaborating daily with your team and other groups while working via a distributed model.</span></li>\n  <li><span>Be eager to help your teammates, share your knowledge with them, and learn from them.</span></li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282320?reset=False&amp;ra=1wGfc0ESu9ig&amp;oqs=a%3D1wGfc0ESu9ig' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Blue Orange Digital</h4> \n<div>\n <p>Founded by engineers, Blue Orange Digital wanted to bring an engineering-first approach to the development agency model. We aim to work on projects that use the latest and greatest technologies. We care about the products we build and only work with clients who understand that good applications come from happy engineers. We’re headquartered in NYC and DC with additional remote engineers across the US.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Competitive Salaries</span> </li> \n <li> <span></span> <span>Health/Vision/Dental</span> </li> \n <li> <span></span> <span>401k</span> </li> \n <li> <span></span> <span>Awesome people</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Z6kXWBzTSr2ui78QIW9Ysw",
    "url": "https://jobmote.com/job/50143/senior-aws-data-engineer-utah-remote-flex-135k-bonus/",
    "title": "Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 16, 2019 10:07:21 PM",
    "validThrough": "Jul 19, 2019 10:07:21 PM",
    "crawled": "Jul 17, 2019 3:06:25 AM",
    "content": "<div>\n Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus \n <br> A SaaS based organization that has a product hosted on AWS and looking to hire for a senior level AWS Engineer. The company has their own product to help companies with supply chain, sales, planning and other operations\n <br> Product is hosted on AWS - have developers internally writing the code, they deploy it, use a lot of different open source technologies, all of which is hosted on EC2 instances, they use Amazon built in offerings for RDS and elasticash to use their Redis instances.\n <br> Main requirement is that candidates must understand the business side of the data and load it into their tool for these companies for their behalf. \n <br> AWS Requirements:\n <ul>\n  <li>Redshift</li>\n  <li>EC2</li>\n  <li>S3</li>\n  <li>Hive</li>\n  <li>Lambda</li>\n  <li>EMR</li>\n  <li>DynamoDB</li>\n  <li>Kinesis</li>\n  <li>Glue</li>\n  <li>Athena</li>\n  <li>SQL</li>\n </ul> If you or someone you know is interested in this position, please send your resume directly to [Click Here to Email Your Resum?] or call .\n <br>\n <br>Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.\n <br>\n <br>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.\n <br>\n <br>Utah/Big Data/ Engineering/ SaaS/ Analytics/ AWS/ Amazon web Services/ Remote/ Data/ Salt Lake Ciity/ Highland/ Provo/ Lehi\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UBpwZkJGQx60dEwHydKoeg",
    "url": "https://newyork.craigslist.org/mnh/sof/d/new-york-city-data-scientist-with/6935550355.html",
    "title": "Data Scientist with a rebellious spirit (SoHo)",
    "tags": [
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:scipy/python/5",
      "DBG_TECH1:techWeightMap:{python=26, other=6, dotnet=0, c=8, mobile=1, go=0, nodejs=1, bigdata-ml=72, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 12:00:06 AM",
    "validThrough": "Jul 24, 2019 12:00:06 AM",
    "crawled": "Jul 17, 2019 1:07:18 AM",
    "content": "<span><span>Data Scientist with a rebellious spirit</span><small> (SoHo)</small> </span>\n<div>\n <div> \n  <div></div> \n  <p> <small> (<a href='https://www.google.com/maps/preview/@40.725500,-73.998300,16z' rel='nofollow'>google map</a>) </small> </p>\n </div> \n <p> <span>compensation: <b>market</b></span> <br> <span>employment type: <b>full-time</b></span> <br> <span>telecommuting okay</span> <br> </p> \n</div> “What we need is more people who specialize in the impossible.”\n<br>Theodor Roethke\n<br>\n<br>Founded in 2015, we are a fully funded data and analytics company in\n<br>New York City. We have people from SoFi, Fortress Capital, Credit Suisse and Bank of America.\n<br>\n<br>A TASTE OF WHAT WE DO\n<br>See if you enjoy these questions:\n<br>• If political views in a neighborhood begin to shift, how would it affect demand for mortgages?\n<br>• If you had data on all student loans in the United States, how could you use it to make money?\n<br>• Imagine you have an incredible 99% accurate model predicting defaults on unsecured loans, but it\n<br>is mostly relying on age, race, and gender of the applicant, which would be illegal. Can you still do\n<br>something useful with the model?\n<br>• A model takes 3 days to train, but you must tune it to get improvement in one week to impress\n<br>investors. What would you do?\n<br>• A partner company gave you a proprietary dataset for which we have paid $100k, yet the target\n<br>column has 50% missing values, rendering the whole project unfeasible. How would you\n<br>communicate this situation to your colleagues? What should be the next step?\n<br>• Is the python expression (lambda x: x) in {lambda x: x} true or false?\n<br>OUR GOAL is to become the modern-day “Village Banker”. The traditional Village Banker conducted\n<br>business through relationships and deep knowledge of the end customer’s true financial situation and\n<br>behavioral characteristics. We are doing the same using modern machine learning and data analytics.\n<br>OUR PROPRIETARY risk engine is in production with a top 10 U.S. bank originating over $100 MILLION\n<br>of loans every MONTH!\n<br>\n<br>OUR VALUES\n<br>• COLLABORATIVE – but we respect your autonomy!\n<br>• CURIOUS – new solutions are better than the status quo.\n<br>• RESULTS – we embrace “what works”. Elegant software design is not a priority.\n<br>• AMBIGUITY – we often make decisions based on imperfect information.\n<br>• COMMITTED – once we make a commitment, we see the project to the completion.\n<br>\n<br>POSITION SUMMARY\n<br>The data scientist will develop advanced machine-learning models. Yet it is not about tuning a model from\n<br>98% to 99%; we target problems with no state-of-the-art solution, and no guarantee that a solution exists.\n<br>The business aspect is just as important as the data science one. Expect messy proprietary datasets with\n<br>little or no documentation, arcane compliance requirements, and calculated risk-taking when you only have\n<br>1-2 chances for your model to perform well, or else it risks being discarded.\n<br>\n<br>PRIMARY RESPONSIBILITIES\n<br>• (Help) develop and optimize new models using multiple data sources of varying quality.\n<br>• (Help) manage and monitor existing models.\n<br>• Assist with infrastructure improvements, if you are interested in this direction.\n<br>• Conduct and interpret experiments, conduct R&amp;D. You can typically choose the direction, and it\n<br>can be as math- and CS-heavy as you want!\n<br>• Participate in business-related discussions and build an understanding of the overall context.\n<br>• Be a proactive and enthusiastic team member, as cheesy as it sounds!\n<br>• You must be open to learning.\n<br>\n<br>REQUIRED SKILLS/EXPERIENCE\n<br>• Solid programming fundamentals. You should be able to get an entry-level software position at\n<br>Google or Facebook.\n<br>• Knowledge of Python. Note that R, Java, C++, Clojure, or Javascript do not count.\n<br>• Solid intuition in any of math / physics / computer science / accounting / engineering / law / ...\n<br>• Knowledge of basic statistics.\n<br>• Academic or industry examples of previously built machine learning models are a must. Kaggle\n<br>competitions and personal projects also qualify.\n<br>• Desire to learn more about business and finance.\n<br>• Financial knowledge not required.\n<br>• BS/BA in a highly quantitative field is expected, but we are happy to consider exceptions.\n<br>\n<br>PREFERRED SKILLS/EXPERIENCE\n<br>• Ability to communicate your opinion.\n<br>• Hand-on experience with unclean, semi-structured or unstructured data sets.\n<br>• Proficient in math / statistics.\n<br>• Experience working in teams of analysts, data engineers, statisticians, and data scientists.\n<br>• Experience using Git, pandas/numpy/scipy/scikit-learn/jupyter, bash.\n<br>• Knowledge of Linux, AWS or another cloud, Spark, Hadoop, H2O, Airflow or Luigi.\n<br>• M.S./Ph.D. in a highly quantitative field is preferred, but we care more about what you can do.\n<br>You will be working alongside a 10-year consumer lending veteran who created strategies for Citibank\n<br>and Bank of America, a 10-year recommendation systems expert who taught graduate-level Python\n<br>courses, a Harvard grad with experience in Ethereum smart contracts and litigation analytics, an ACM\n<br>ICPC World Champion with a successful AI startup exit, and several other experts in compliance,\n<br>mortgage industry, capital markets, who know their respective fields inside out.\n<br>\n<br>WHAT WE OFFER\n<br>• Competitive market-based salary with a potential for a bonus or equity options, in case of\n<br>exceptional performance.\n<br>• Position based in New York, NY. Some work from home allowed if you can deliver results.\n<br>• Periodic travel if this is something you are interested in.\n<br>• Informal, caring, open culture with zero bureaucracy. (Well, a tiny bit!)\n<br>• Opportunity to learn and grow. If you are interested in growing in a particular direction (e.g. data\n<br>engineering, more advanced data science, finance, interviewing future candidates, compliance,\n<br>project management, business negotiation), we will come up with a plan and make sure you stay\n<br>on track.\n<br>• Easy access to and regular mentorship from the CEO and other senior team members.\n<br>• Medical insurance: United HealthCare Standard with no annual deductible (100% employer paid)\n<br>for individual employee and family.\n<br>• Dental: MetLife Enhanced (100% employer paid) — annual deductible of $50 (individual) &amp; $150\n<br>(family).\n<br>• 401 (K): 3% employer match.\n<br>• Group Term Life Insurance (up to 2x annual salary).\n<br>• Short-Term and Long-Term Disability insurance\n<br>\n<br>* Occasional telecommuting is fine if you live near NYC. Part-time can be discussed for the right candidate. \n<ul> \n <li>OK for recruiters to contact this job poster.</li> \n <li>do NOT contact us with unsolicited services or offers</li>\n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-je7_5QmTT2ExSB40q5v9Q",
    "url": "https://stackoverflow.com/jobs/280097/marketing-data-analyst-hotjar?a=1vW1ot0gHHTq",
    "title": "Marketing Data Analyst at Hotjar  ",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/2",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:macos/apple/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=19, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=2, java=0, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hotjar",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "EUR",
      "minValue": 50000,
      "maxValue": 70000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "EUR 50k - 70k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 16, 2019 2:06:24 PM",
    "validThrough": "Jul 23, 2019 2:06:24 PM",
    "crawled": "Jul 16, 2019 2:06:24 PM",
    "content": "<h3><span>Marketing Data Analyst</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data &amp; Analytics, SaaS, Web Technology</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Hotjar | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT+01:00) Amsterdam +/- 2 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n r\n</div>\n<div>\n sql\n</div>\n<div>\n python\n</div>\n<div>\n mfitzp Python Developer at Hotjar 11k 5 34 55\n</div>\n<div>\n Rory O'Keeffe Full stack web engineer with a passion for learning and creating cool things 201 1 5\n</div>\n<div>\n eKIK 896 9 6\n</div>\n<div>\n Jonathan Vella Director of Design at HotJar 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Note:</strong>&nbsp;Although this is a remote position, we are only considering candidates based within European or African timezones.</p>\n <p>We’re looking for someone who loves to turn data into insights and communicate findings fearlessly. You want to help teams make data-informed decisions and take data-informed actions, you have a curious mindset and are motivated to understand our business better.</p>\n <p>You will work within our marketing team to make data-driven recommendations on strategy and keep a finger on the pulse of our business. You will analyze the effectiveness of our paid and content campaigns, analyze lead and customer segments and cohorts, assure our marketing tools are communicating effectively, and much more.</p>\n <p><strong>You will:</strong></p>\n <ul>\n  <li><p>Evaluate the performance of our go-to-market strategy by analyzing funnels and metrics</p></li>\n  <li><p>Analyze data from multiple systems to provide a full funnel view of the performance of marketing channels and the content we promote.</p></li>\n  <li><p>Monitor the state of marketing initiatives and produce data-driven hypotheses and communicate insights</p></li>\n  <li><p>Help the marketing team to better understand their functional areas, improve familiarity with and use of data, set the bar for analytics</p></li>\n  <li><p>Present analysis based recommendations to project leaders and teams to shape decision making</p></li>\n  <li><p>Build data models to accelerate the business by providing deeper insights into visitor and customer behaviours, and feed the team’s hunger for actionable insights</p></li>\n  <li><p>Select and integrate new technologies to promote better segmentation and attribution</p></li>\n  <li><p>Work with lead and customer data to create impactful visualization and insight reports to fuel demand projects.</p></li>\n  <li><p>Understand our marketing tool stack, assure seamless communication and align it with our needs to improve data collection and quality.</p></li>\n </ul>\n <p><strong>Requirements</strong></p>\n <ul>\n  <li><p>3+ years of work experience in analytics/data science or a directly related field – some of which is in a technology environment</p></li>\n  <li><p>Experience initiating and delivering applicable analyses/recommendations to guide impact</p></li>\n  <li><p>Experience with building predictive data models to provide deeper insights</p></li>\n  <li><p>Excellent skills with analytics tools, fluency with BI/visualization tools such as Mode, and knowledge of Excel, R, Python, &nbsp;SQL, or other analysis tools</p></li>\n  <li><p>An understanding of SaaS business models and essential metrics</p></li>\n  <li><p>Experience implementing and integrating a marketing automation platform</p></li>\n  <li><p>Critical reasoning skills, including the understanding of common pitfalls of data analysis</p></li>\n  <li><p>A desire to work in a respectful, transparent, and transparent work environment, following Hotjar’s<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269942884/Hotjar+Core+Values' rel='nofollow'>company values</a>,<a href='https://careers.hotjar.com/' rel='nofollow'>&nbsp;culture</a>&nbsp;and<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269779142/Working+at+Hotjar' rel='nofollow'>&nbsp;ways of working</a></p></li>\n  <li><p>Must submit to a background check confidentially processed by our third-party</p></li>\n </ul>\n <p><strong><br>What we offer</strong></p>\n <ul>\n  <li>A remote and accomplished diverse and international team.</li>\n  <li>An opportunity to positively impact people’s experience online and make the web a better place.</li>\n  <li>Annual learning and development budget.</li>\n  <li>Several<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/158105691/Our+Perks' rel='nofollow'>&nbsp;perks</a>&nbsp;designed for your well-being and a healthy work-life balance. (Holiday Budget, Wellbeing Allowance, Working Together Budget, 16 weeks&nbsp;paid parental leave, and much more).</li>\n </ul>\n <p><strong>Compensation</strong></p>\n <p>The budgeted compensation range for this role is €50,000 - €70,000 annually. Ranges are based on market research and are equitable to other roles within Hotjar. The actual compensation offered to our new team member will be based on relative experience and skills. At this time we are only able to provide official employment status to those located in Malta&nbsp;and Germany (for candidates who don’t require visa sponsorship). All other new team members will join as full-time consultants and will be responsible for paying any taxes or applicable fees where they reside.</p> \n</div> \n<h4>About Hotjar</h4> \n<div>\n <p>Hotjar is a rapidly growing startup that is giving thousands of website owners the tools needed to discover how their visitors are really using their website. We are looking for passionate and ambitious developers who can help us shape the product and company while growing with us.</p>\n <p><strong>Culture at Hotjar:</strong></p>\n <p>Headquartered on the beautiful island of Malta, in the “heart” of the Mediterranean, Hotjar is a young startup that embraces remote working and personal development.</p>\n <p>Hotjar’s culture is driven by transparency, respect, open discussion, collaboration and blunt and direct feedback. In fact, we’re obsessed with communicating with our users as well as within the team. We hate bureaucracy and slow moving organizations –&nbsp;but we’re suckers for well-defined processes. We love lean, iterative improvements and success is measured by the value we create for our users.</p>\n <p><strong>The Perks:</strong></p>\n <ul>\n  <li><strong>Remote &amp; Flexible.</strong> Work from anywhere within a European timezone.&nbsp;</li>\n  <li><strong>Ample Time Off.&nbsp;</strong>All team members get 40 days of paid planned leave/year, plus 10 sick days/year and time off to attend conferences / events.</li>\n  <li><strong>Collaborate with prestigious organizations.</strong> Imagine what it will feels like to be part of a product that is used by companies like Time Inc., Nintendo, Lloyd's Bank, Pingdom, Booking.com, Intuit and the Red Cross.</li>\n  <li><strong>Only the best hardware and software</strong>. Mac, PC or Linux –&nbsp;we will get you equipped with the best hardware and software available, of your own choice.</li>\n  <li><strong>Home Office budget.</strong> Every Hotjar team member receives a €4000 home office setup budget, with a yearly €500 top-up thereafter. Upgrade your desk, chair, screens or buy any peripherals you might need.</li>\n  <li><strong>Personal Development budget.</strong> Everyone receives a free Kindle as well as direct management of their own personal development yearly budget of €1,000. Buy books, short courses or magazine subscriptions.</li>\n  <li><strong>Holiday budget.</strong> A spend of €2,000/year for each team mate to spend relaxing and recharging on holiday.</li>\n  <li><strong>Work Together budget.</strong> Even though we're remote, we don't underestimate the value of getting together in person sometimes. Each team member has €2,000/year to spend on travelling to work with other Hotjarians.</li>\n  <li><strong>Working Space Allowance.</strong> Decide how you want to spend your monthly €200, whether it's on a co-working space, working from a coffee shop, getting your favourite coffee delivered to your home office, etc.</li>\n  <li><strong>Wellbeing Allowance.</strong> €200/month to spend on your wellbeing, be that physical, mental or spiritual.</li>\n  <li><strong>Work with a very talented team.</strong> Our team has an impressive background building and optimizing products and businesses around the globe.</li>\n  <li><strong>Make a difference.</strong> Hotjar is ‘democratizing’ site analytics and feedback by making them affordable and easy to use for everyone around the world. We call it the ‘Hotjar revolution’.</li>\n </ul> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>€4,000 Home Office Budget, topped up €500/year</span> </li> \n <li> <span></span> <span>100% Remote</span> </li> \n <li> <span></span> <span>Free Kindle Paperwhite, Fitbit, Headset and Reading Pack</span> </li> \n <li> <span></span> <span>€1,000 Annual Personal Development Budget</span> </li> \n <li> <span></span> <span>€200 Monthly Well Being Allowance</span> </li> \n <li> <span></span> <span>40 days leave annually</span> </li> \n <li> <span></span> <span>Two company retreats each year</span> </li> \n <li> <span></span> <span>€2,000 Annual Holiday Budget</span> </li> \n <li> <span></span> <span>€200 Monthly Working Space Allowance</span> </li> \n <li> <span></span> <span>€2,000 Annual Work Together Budget</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xaFlRnu9QVqyNZghvR88Ow",
    "url": "https://jobmote.com/job/49612/servicenow-senior-developer-remote/",
    "title": "ServiceNow Senior Developer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nelson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 15, 2019 10:07:15 PM",
    "validThrough": "Jul 18, 2019 10:07:15 PM",
    "crawled": "Jul 16, 2019 3:06:24 AM",
    "content": "<div>\n <b>Your New Company</b>\n <br> Your new company is a premier ServiceNow Bronze Partner, helping clients solve problems and achieve success since 2010. They build dynamic teams for delivering adaptable and cost effective solutions for the most complex technology challenges. Using their consulting experience along with boutique firm agility, they help public and private sector clients stay on mission, embrace change, and realize their potential. \n <br>\n <b>Your New Position</b>\n <br> You will be filling a new role in this company as a Senior ServiceNow Developer. You will lead the efforts of stabilizing clients current implementation of ServiceNow and creating a new separate instance which will be expanded enterprise-wide. You will resolve complex bugs/defects, security issues in the ServiceNow environment, and high-impact findings affecting usability of the existing ServiceNow environment. You will be in charge of leading all ServiceNow code reviews as well as performing all ServiceNow code promotions. Once existing instance is stabilized, you will develop new instance to rebuild clients' current modules utilizing global standards.\n <br>\n <br>\n <b>What You Will Need To Succeed </b>\n <br> To be successful, you will need to have a deep understanding of the ServiceNow platform. Extensive experience supporting the implementation, administration, configuration, and/or development of an ITSM tool is important for this position. It is also preferred that you have ServiceNow development experience including scripting, tool configuration, design work, technical configuration, and deployment. Specifically, a strong candidate will be able to develop on the ServiceNow platform including the creation and/or customization of the core applications.\n <br>\n <b>What You Will Get In Return</b>\n <br> This prestigious company allows you to grow as a ServiceNow professional in a high profile environment. You will be offered a comprehensive benefits package including Health, 401K program with the company matching 100% of up to 4% of salary, Dental, Vision, and 15 days PTO. You will also be eligible for an annual bonus as well as referral bonuses.\n <br>\n <b>What You Need to Do Now</b>\n <br> Apply to this advert or reach out to Megan Rossi at [Click Here to Email Your Resum?] to arrange a time to speak more about this position. Please provide your most updated CV with all of your ServiceNow experience, as well as you availability for calls.\n <br>\n <br>What You Will Need To Succeed \n <br>To be successful, you will need to have a deep understanding of the ServiceNow platform. Extensive experience supporting the implementation, administration, configuration, and/or development of an ITSM tool is important for this position. It is also preferred that you have ServiceNow development experience including scripting, tool configuration, design work, technical configuration, and deployment. Specifically, a strong candidate will be able to develop on the ServiceNow platform including the creation and/or customization of the core applications.\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "1vMeAsufQEKzHbP68PVq5w",
    "url": "https://weworkremotely.com/remote-jobs/rho-ai-senior-software-engineer-2",
    "title": "Rho AI: Senior Software Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/12",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "https://rho.ai"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 16, 2019 12:18:37 AM",
    "validThrough": "Jul 23, 2019 12:18:37 AM",
    "crawled": "Jul 16, 2019 1:06:22 AM",
    "content": "<h3> Senior Software Engineer </h3>\n<div>\n <div>\n  <span></span>\n </div>\n <div>\n  <span>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</span>\n </div>\n <div>\n  <br>\n </div>\n <div>\n  <span>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste). We value pragmatic solutions and have cultivated a modern technology stack that combines software development (python microservices, react frontends), infrastructure automation (docker, kubernetes), and machine learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</span>\n  <br>\n </div>\n <div></div>\n <div></div>\n <div>\n  &nbsp;\n  <br>\n </div>\n <div></div>\n <div></div>\n <div>\n  <span>Why Rho AI?</span>\n </div>\n <div>\n  <br>\n </div>\n <ul>\n  <li><span>The people - dependable, driven, and collaborative team.</span></li>\n  <li><span>The problems - mix of products and services across diverse domains.</span><br></li>\n  <li><span>The tech - modern tools to build pragmatic data-driven applications.</span><br></li>\n  <li><span>The structure - 100% remote-only team &amp; self-funded since 2012.</span></li>\n </ul>\n <div>\n  &nbsp;\n  <br>\n </div>\n <div></div>\n <div></div>\n <div>\n  <span>Sound interesting? Please reach out if:</span>\n </div>\n <div>\n  <br>\n </div>\n <div>\n  <span>You are looking to:</span>\n </div>\n <div>\n  <br>\n </div>\n <ul>\n  <li><span>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</span><br></li>\n  <li><span>Join a group of talented and congenial team members in an experienced individual contributor role (mix of architecting / building / mentoring), with future people management opportunities (if you like).</span><br></li>\n  <li><span>Lead engineering projects by collaborating with team members and customers, facilitating technology architecture decisions, driving forward work streams, and releasing high quality software.</span><br></li>\n  <li><span>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</span></li>\n </ul>\n <div>\n  <span><br></span>\n </div>\n <div>\n  <span>You have:</span>\n </div>\n <ul>\n  <li><span>(Must) Been the tech lead of a project that uses a Python based stack.</span><br></li>\n  <li><span>(Must) Good communication skills for technical and non-technical audiences.</span><br></li>\n  <li><span>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</span><br></li>\n  <li><span>(Must) Worked on all layers of the stack - databases, services, and frontends.</span><br></li>\n  <li><span>(Must) A collaborative attitude oriented around craftsmanship and team success.</span><br></li>\n  <li><span>(Should) An interest in systems thinking &amp; enjoy stitching components together.</span><br></li>\n  <li><span>(Should) Have experience working within a microservices oriented architecture.</span><br></li>\n  <li><span>(Nice) Built systems that process large amounts of data and/or traffic.</span><br></li>\n  <li><span>(Nice) Strong computer science principles, and/or algorithmic skills.</span><br></li>\n  <li><span>(Nice) Experience with machine learning applications.</span><br><br></li>\n </ul>\n <div>\n  &nbsp;You would like these perks:\n </div>\n <ul>\n  <li><span>Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.</span><br></li>\n  <li><span>Work with a highly engaged team, learn together, and make decisions that impact the whole company.</span><br></li>\n  <li><span>Benefits, including health insurance and 401k.</span><br><span>&nbsp;</span><br></li>\n </ul>\n <div>\n  <span>You meet these criteria:</span>\n </div>\n <ul>\n  <li><span>You are seeking a full-time job.</span><br></li>\n  <li><span>You reside in the United States.</span><br></li>\n  <li><span>You are </span><span>authorized / eligible to work for any company in the United States.</span></li>\n  <li><span>You are in a continental US time zone, or willing to align your schedule.</span><br><br></li>\n </ul>\n <div>\n  <span>To get an interview, you must supply:</span>\n </div>\n <ul>\n  <li><span>A cover letter that explains why you are 1) </span><em>specifically interested</em><span> in Rho AI as a company and 2) a </span><em>good fit</em><span> for this particular position.</span><br></li>\n </ul>\n <ul>\n  <li><span>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</span><br></li>\n </ul>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "8_RbZfQySYu7x5EI54Iftg",
    "url": "https://jobmote.com/job/49555/data-engineer-chicago-il-200k-perm-remote/",
    "title": "Data Engineer - Chicago, IL-200k-Perm-Remote",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 14, 2019 10:07:22 PM",
    "validThrough": "Jul 17, 2019 10:07:22 PM",
    "crawled": "Jul 15, 2019 3:06:24 AM",
    "content": "<div>\n <b>Data Engineer -</b> \n <b>Chicago, IL-200k-Perm-Remote</b>\n <br>\n <br>\n <b>Position:</b> Data Engineer\n <br>\n <b>Technology:</b> Big Data\n <br>\n <b>Location:</b> Chicago, IL\n <br>\n <b>Job Type:</b> Permanent\n <br>\n <br>\n <b>About the Role:</b>\n <br> Our client has an exciting role opening up for a data engineer. The role consists of data engineering responsible for building pipelines in AWS/Azure/GCP cloud. This is a very \n <b>hands on</b> coding position specifically in \n <b>Java</b> or \n <b>Scala coding</b>\n <br>\n <br>The ideal candidate is a passionate IT expert who has worked hands on as a date engineer for the past few year are heavily involved in big data coding.\n <br>\n <br>What you Bring to the table:\n <ul>\n  <li>AWS (EMR, Redshift, Athena, Lambda, S3, Glue) ? 1 or 2 of these</li>\n  <li>Azure (HDI, Databricks)</li>\n  <li>GCP (Dataproc, BigQueries)</li>\n  <li>Data engineer experience</li>\n  <li>Java/Scala coding</li>\n </ul>What they can give you :\n <ul>\n  <li>Health Care Plan (Medical, Dental &amp; Vision)</li>\n  <li>Retirement Plan (401k, IRA)</li>\n  <li>Paid Time Off (Vacation, Sick &amp; Public Holidays)</li>\n  <li>Family Leave (Maternity, Paternity)</li>\n  <li>Work From Home</li>\n  <li>Stock Option Plan</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling \n <b> (ext. 7598</b>\n <b>)</b>. I'm eagerly looking forward to helping you advance your career!\n <br>\n <br>\n <b>What's in it for you:</b>\n <br> These roles don't last long on the market. Be in touch quickly and I can place you with your desired job in a timely manner. Don't hesitate to achieve the better job you are looking for and want now. Please send your resume and I'm excited to meet with you. I am unlike other recruiters in that I thrive on building our relationship and making it more personal to ensure working together is a happy experience for you!\n <br> Nigel Frank International is the Global Leader in Microsoft Azure recruitment. We are a part of Frank Recruitment Group, one of the most successful global recruitment businesses in the last 10 years and backed by private equity firm TPG Growth.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "X6XqYWORQMy2P7EJzzX2Wg",
    "url": "https://jobmote.com/job/49516/senior-data-architect-remote/",
    "title": "Senior Data Architect- REMOTE",
    "tags": [
      "DBG:surround``OR(work,countri,locat,contract,base,you W can) 2W anywher",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 13, 2019 10:07:23 PM",
    "validThrough": "Jul 16, 2019 10:07:23 PM",
    "crawled": "Jul 14, 2019 3:06:25 AM",
    "content": "<div>\n Minimum Required Skills:\n <br>NiFi, AWS, glue, Kinesis, ETL\n <br>\n <br>If you are a Senior Data Architect (remote) with experience in AWS and ETL development/pipelines, please read on!\n <br>\n <br>Located in Denver, Colorado (but this person can be located anywhere in the U.S.), we specialize in assisting our clients with their digital assets in the crypto portfolio/management space. We have been in business for a couple of years and are growing immensely. We are a tight-knit team over here so someone who enjoys working collaboratively will work great here!\n <br>\n <br>We are looking for a talented Data Architect who is going to have a strong background in AWS as well as ETL development. Any experience with Glue, Kinesis, or Nifi is a PLUS! You will be responsible for building or architecting the infrastructure, as well as data modeling and potentially ingestion and ex-filtration of data to different sources. This is a leadership role so someone who enjoys being the most Senior on the team will like it here! Any experience in the Crypto, Blockchain, or Fiance world would also be a PLUS!\n <br>\n <br>What You Will Be Doing\n <br>\n <br>-Working collaboratively in a team\n <br>-Utilizing AWS and ETL pipelines\n <br>-Architecting the infrastructure\n <br>\n <br>What You Need for this Position\n <br>\n <br>At Least 3 Years of experience and knowledge of:\n <br>\n <br>- NiFi\n <br>- AWS\n <br>- glue\n <br>- Kinesis\n <br>- ETLSo, if you are a Senior Data Architect- REMOTE with experience, please apply today!\n <br>\n <br>Applicants must be authorized to work in the U.S.\n <br>\n <br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!\n <br>\n <br>Looking forward to receiving your resume and going over the position in more detail with you.\n <br>\n <br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.\n <br>\n <br>Looking forward to receiving your resume!\n <br>\n <br>CyberCoders\n <br>\n <br>CyberCoders, Inc is proud to be an Equal Opportunity Employer\n <br>\n <br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n <br>\n <br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n <br>\n <br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6lSS8I7_Su-t35hQkI9jxQ",
    "url": "https://jobmote.com/job/49497/big-data-engineer-remote/",
    "title": "Big Data Engineer (REMOTE)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 13, 2019 10:07:22 PM",
    "validThrough": "Jul 16, 2019 10:07:22 PM",
    "crawled": "Jul 14, 2019 3:06:25 AM",
    "content": "<div>\n Big Data Engineer\n <br> REMOTE\n <br> ($170k-$200k)\n <br> This client is looking for engineers who are heavily involved in Big Data workloads in the Cloud. They really want someone who is 80% hands on a day to day basis.\n <br> Data pipeline creation in Cloud technologies\n <ul>\n  <li>AWS (EMR, Redshift, Athena, Lambda, S3, Glue)</li>\n  <li>Azure (HDI, Databricks)</li>\n  <li>GCP (Dataproc, BigQueries)</li>\n </ul> *Does not need to be proficient in all of these but the more the better\n <br> Role:\n <ul>\n  <li>Responsible for building data pipelines in AWS/Azure/GCP</li>\n  <li>Needs to be very hands on, will be development as the role is coding focused</li>\n </ul>\n <ul>\n  <li>Experienced using Scala or Java</li>\n  <li>Will be coding 80-90% of the time</li>\n </ul>\n <ul>\n  <li>Experienced in moving data workloads into the cloud for the past 2-3 years</li>\n </ul> Benefits:\n <br> -Competitive Base Salary\n <br> -PTO Flexibility\n <br> -401k\n <br> -Health Benefits: Medical, Dental, Vision\n <br> -High Energy Company Culture\n <br> -Great Professional Development\n <br> -Casual Dress Code\n <br> -Stock Options\n <br> -Remote Flexibility\n <br> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xraeeosUSBmD6_DFz-TONg",
    "url": "https://jobmote.com/job/49379/senior-data-etl-engineer-partial-remote/",
    "title": "Senior Data ETL Engineer- Partial Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 12, 2019 10:07:31 PM",
    "validThrough": "Jul 15, 2019 10:07:31 PM",
    "crawled": "Jul 13, 2019 3:06:26 AM",
    "content": "<div>\n Minimum Required Skills:\n <br>SQL, Oracle, AWS, ETL, Mapreduce, ElasticSearch, Data Conversion\n <br>\n <br>We are one of the most successful technology start-ups in the Philadelphia region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. \n <br>\n <br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.\n <br>\n <br>We need a Data Rockstar to help us transform how consumers interact with real estate data.\n <br>\n <br>What You Will Be Doing\n <br>\n <br>- Recommend and implement data processing tools and technologies\n <br>- Extract, transform and load data pipelines from end to end\n <br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info\n <br>- Create, develop and document data mapping rules from multiple sources\n <br>- Develop continuous process movements\n <br>\n <br>What You Need for this Position\n <br>\n <br>- 3+ years experience using data related technologies( MapReduce, ElasticSearch, DynamoDB, Logstash) \n <br>- Full understanding of databases, data conversion, data manipulation, and data cleansing \n <br>- Experience with parsing and mapping data\n <br>- Microsoft Excel proficient \n <br>- Results driven with strong communication skills\n <br>- Real Estate data experience is a plus!\n <br>\n <br>What's In It for You\n <br>\n <br>- Competitive Pay\n <br>- Fully Remote! \n <br>- Medical, Dental, Vision\n <br>- Flexible PTOSo, if you are a Senior Data ETL Engineer- Partial Remote with experience, please apply today!\n <br>\n <br>Applicants must be authorized to work in the U.S.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!\n <br>\n <br>Looking forward to receiving your resume and going over the position in more detail with you.\n <br>\n <br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.\n <br>\n <br>Looking forward to receiving your resume!\n <br>\n <br>CyberCoders\n <br>\n <br>CyberCoders, Inc is proud to be an Equal Opportunity Employer\n <br>\n <br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n <br>\n <br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n <br>\n <br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Wcn8PEWuS8y00ZtRo4tmCw",
    "url": "https://stackoverflow.com/jobs/281028/senior-data-scientist-remote-global-wallethub?a=1wfnBgBpDCpy",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 12, 2019 11:06:25 AM",
    "validThrough": "Jul 19, 2019 11:06:25 AM",
    "crawled": "Jul 12, 2019 11:06:26 AM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/281028?reset=False&amp;ra=1wfnBgBpDCpy&amp;oqs=a%3D1wfnBgBpDCpy' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_zUgXJY9Rd6p8fli_UpC7w",
    "url": "https://stackoverflow.com/jobs/281028/lead-data-scientist-remote-global-wallethub?a=1wfnBgBpDCpy",
    "title": "Lead Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 12, 2019 8:06:24 AM",
    "validThrough": "Jul 19, 2019 8:06:24 AM",
    "crawled": "Jul 12, 2019 8:06:24 AM",
    "content": "<h3><span>Lead Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/281028?reset=False&amp;ra=1wfnBgBpDCpy&amp;oqs=a%3D1wfnBgBpDCpy' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "OOddWMVeTvGu1AjwuJpWjg",
    "url": "https://jobmote.com/job/48950/servicenow-remote-developer/",
    "title": "ServiceNow Remote Developer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angular/frontend/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/3",
      "DBG_TECH1:k/t/w:javascript/nodejs/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=3, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=11}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "Nelson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 11, 2019 10:07:18 PM",
    "validThrough": "Jul 14, 2019 10:07:18 PM",
    "crawled": "Jul 12, 2019 3:06:25 AM",
    "content": "<div>\n <b>ServiceNow Developer - REMOTE - $85,000 - 130,000 - Registered Partner</b>\n <br>\n <br>Job Description:\n <br>\n <br>ServiceNow Developer - REMOTE -- $85,000 - $130,000 - Registered Partner\n <br>\n <br>A global technology company and registered ServiceNow partner is seeking a remote ServiceNow developer to join a team and start working on projects immediately. The company and upper management is extremely flexible and you will have the ability to work whatever hours you want as long as the work gets completed. You possess at least 1 year of ServiceNow experience designing, developing and implementing a complex enterprise integration. You will be offered a great compensation and benefits package upon starting, along with remote flex. The owner is interested in speaking with technical consultants, developers versed in JavaScript, REST, and SOAP, along with custom applications.\n <br> 21 Days PTO!\n <br>\n <br>Essential Requirements:\n <ul>\n  <li>Bachelor's Degree From Accredited University; Computer Science Program Preferred</li>\n  <li>1+ Year of ServiceNow Experience</li>\n  <li>Integration &amp; Implementation Experience w/ SOAP, REST, Agile/Scrum preferred</li>\n  <li>ServiceNow Certified Preferred</li>\n  <li>JavaScript, Angular JS &amp; Custom Application Experience Preferred</li>\n  <li>S. Citizen or Eligible Green Card Holder</li>\n </ul>This process will move efficiently.\n <br>\n <br>Please send your CV to [Click Here to Email Your Resum?] and/or call . Ask for Zach regarding a confidential career screening.\n <br>\n <br>ServiceNow Remote Developer\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Rsri9AHGR36SxRQ8suGaAQ",
    "url": "https://news.ycombinator.com/item?id=20415097",
    "title": "Simon Data | New York, NY | Full Time | Onsite/Remote We're a customer data platform with a ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 11, 2019 9:49:25 PM",
    "validThrough": "Jul 18, 2019 9:49:25 PM",
    "crawled": "Jul 11, 2019 10:31:11 PM",
    "content": "Simon Data | New York, NY | Full Time | Onsite/Remote\n<p>We're a customer data platform with a fully-integrated marketing cloud. Simon’s platform empowers businesses to leverage enterprise-scale big data and machine learning to power customer communications in any channel.</p>\n<p>Simon’s unique approach allows brands to develop incredible personalization capabilities without needing to build and maintain massive bespoke data infrastructure.</p>\n<p>Our culture is rooted in organizational transparency, empowering individuals, and an attitude of getting things done. If you want to be a valuable contributor on a team that cultivates these core values we would love to hear from you.</p>\n<p>remote roles we're hiring for: solutions architect, security engineer, systems engineer, full stack engineer, devops engineer, data scientist, data engineer</p>\n<p>check out other roles we're hiring for: <a href='https://www.simondata.com/careers' rel='nofollow'>https://www.simondata.com/careers</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "__m3Fxq4SyyYlSkSBjnlgA",
    "url": "http://workinstartups.com/job-board/job/82284/software-engineer-big-data-at-privitar/",
    "title": "Software Engineer - Big Data",
    "tags": [
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``OR(travel,visit) W to 4W OR(offic,headquart,onsit)",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=3, go=3, nodejs=0, bigdata-ml=15, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Privitar",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 11, 2019 3:51:43 PM",
    "validThrough": "Jul 18, 2019 3:51:43 PM",
    "crawled": "Jul 11, 2019 5:06:33 PM",
    "content": "Privitar is a dynamic, Data Privacy start-up based in London, building software to enable the safe and ethical use of valuable data for analytics and machine learning. We work with large organisations worldwide in healthcare, financial services, telecommunications, pharma and government, enabling them to get the most out of data without compromising on privacy and security. We have just completed a $40 million Series B funding round and are growing strongly.\n<br>\n<br>We are looking for multiple talented and passionate engineers who love to build products that have a tangible, positive impact. We are open to all levels of experience, from graduates to experienced senior developers.\n<br>\n<br>Ideal candidates for this role learn and adapt quickly. You’ll combine state-of-the-art technologies with leading-edge algorithms to understand and tackle hard data security and data anonymisation problems. You will also be involved in performance, integrations and UI.\n<br>\n<br>OUR ENG CULTURE\n<br>\n<br>As engineers at Privitar, we are excited and engaged with the problems we are working on. We work together in small teams in a supportive way, developing our skills, learning from each other, and building on each other's ideas. We take a deep pride in the products we build and care about writing clear, well-tested code.\n<br>\n<br>We have a positive, constructive and proactive approach and enjoy working to design and architect solutions, choose technologies, and constantly improve how we work as a team. We are not afraid to question something that might seem obvious or to give it a go and learn how to do things better.\n<br>\n<br>\n<br>ABOUT YOU \n<br>\n<br>LESS EXPERIENCED CANDIDATES\n<br>\n<br>- Bachelor’s or higher degree in Computer Science or a Science or Engineering discipline. We can make exceptions to this for exceptional candidates.\n<br>\n<br>- Experience of coding in Java. Or experience in a related language and evidence of commitment and ability to ramp up in Java.\n<br>\n<br>- Demonstrable interest and knowledge of maths, big data, security or privacy.\n<br>\n<br>- Excellent communication skills\n<br>\n<br>MORE EXPERIENCED CANDIDATES \n<br>\n<br>- The more Java experience the better.\n<br>\n<br>- You are comfortable with being dropped into challenging technical problems and being given the responsibility to solve them.\n<br>\n<br>- Experience building a software product, ideally over the full lifecycle from design to production and ongoing support and enhancement.\n<br>\n<br>- Experience of and commitment to automated testing.\n<br>\n<br>- Ability to deliver results with rapidly evolving propositions, client demands and business needs.\n<br>\n<br>- Knowledge of multiple programming languages\n<br>\n<br>DESIRABLE \n<br>\n<br>- Experience of multithreading or concurrent programming\n<br>\n<br>- Experience building complex distributed systems\n<br>\n<br>- Exposure to Big Data technologies, for example: Hadoop, Spark, Apache Nifi, MapReduce, HDFS, HBase, Hive, Cassandra.\n<br>\n<br>- Understanding of software security and threat models, and experience building secure applications\n<br>\n<br>- Experience with Amazon AWS and other cloud platforms\n<br>\n<br>THE APPLICATION PROCESS \n<br>\n<br>- A phone call with a member of our recruitment team to find out more about Privitar, and to get to know you\n<br>\n<br>- One of the most interesting take home technical exercises you’ll see, designed by Privitar, unique to Privitar, relevant to Privitar \n<br>\n<br>- A ½ day visit to our offices\n<br>\n<br>- Offer",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0b3ls2tPRfaiAs9qrP4EZw",
    "url": "https://jobmote.com/job/48363/azure-data-engineer-130k-150k-remote/",
    "title": "Azure Data Engineer 130k-150k- Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 10:07:18 PM",
    "validThrough": "Jul 13, 2019 10:07:18 PM",
    "crawled": "Jul 11, 2019 3:06:24 AM",
    "content": "<div>\n Azure Big Data Engineer- 130k-150k- Atlanta, Georgia\n <br> My client is seeking a Azure Big Data Engineer where you will help clients leverage data to make informed decisions. You will be knowledgeable of cloud based architectures and Azure technologies. You will be passionate about Big Data and be an expert with Data Warehouse methods and Data Factory. This is a rewarding opportunity to engage in meaningful work. You will be recognized for your accomplishments and analytical capabilities.\n <br> This is a World-Class collaborative opportunity. Don't miss out.\n <br> Responsibilities\n <ul>\n  <li>Interpret the logical side of the data</li>\n  <li>Demonstrate leadership in advanced Advanced Analytics</li>\n  <li>Build Big Data platform from scratch</li>\n  <li>Set up cubes from scratch</li>\n </ul> Requirements\n <ul>\n  <li>Experience with ETL tools</li>\n  <li>Hands-on with Azure Data Lake</li>\n  <li>SQL highly preferred</li>\n  <li>Knowledge of Data Factory, Data Bricks, Spark, Hadoop</li>\n  <li>Experience with Azure analytical services</li>\n </ul> Benefits\n <ul>\n  <li>Comprehensive healthcare benefits</li>\n  <li>Dental, Vision, Disability</li>\n  <li>Matching 401K</li>\n  <li>4 weeks PTO</li>\n </ul> For all inquiries please contact Spencer Villa at ext. 6907 email- [Click Here to Email Your Resum?] \n <br> Nigel Frank International is the Global Leader in Microsoft Recruitment. We place more Microsoft professionals into Microsoft jobs than any other recruitment agency with over 2,000 live jobs on our website at any one time. We are a part of Frank Recruitment Group, one of the most successful global recruitment businesses in the last 10 years and backed by private equity firm TPG Growth We are the recruitment partner of choice for 1000's of Microsoft Partners, Customers &amp; ISV's worldwide with over 1000 dedicated consultants operating in more than 34 countries. Similarly, over half of the candidates that we work with use our recruitment services exclusively. I Specialise in the Microsoft Azure market across the Southeast. I understand the need for discretion &amp; am keen to speak to anyone considering a career change or just wanting to discuss potential opportunities confidentially.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "o5GAHnKmRP2CTokQ2l7Nhw",
    "url": "https://jobmote.com/job/48361/data-engineer-architect-100-remote/",
    "title": "Data Engineer/Architect (100% remote)",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 10:07:18 PM",
    "validThrough": "Jul 13, 2019 10:07:18 PM",
    "crawled": "Jul 11, 2019 3:06:24 AM",
    "content": "<div>\n My client works in the Application Performance Management space, helping organizations accelerate the performance of their Big Data applications and clusters. They analyze these applications, identify root causes of issues, and provide solutions to fix them in fast and easy ways. They originated in 2013, have 100 employees, and are expanding RAPIDLY to keep up with their high demand and growth.\n <br> This candidate will lead and participate in architecture, design and development of various components of their APM solution, by building automated troubleshooting and tuning solutions for Big Data platforms. You will own the data ingestion in regards to applications, then and analyze the data and provide recommendations through algorithms\n <br> Required Skills:\n <br> - Big Data experience - at least 3 year's in a professional environment\n <br> - Hands on in-production experience in a Hadoop ecosystem, working with Spark &amp; Kafka\n <br> - Performance tuning in Cloud (AWS Athena, EMR, Redshift, etc)\n <br> - Hands on Java or Scala development\n <br> - Experience and willingness to be a hands-on individual contributor\n <br> This organization not only offers a very competitive salary, lucrative bonuses, and remote flexibility, but also have very inexpensive health benefits, unlimited PTO, and stock options for all employees! They are a smart team filling a big hole for companies in need, and are looking to hire the best and brightest in the area.\n <br> Job Type: Full Time\n <br>\n <br>To be considered for this role, please call me at or email me your most up-to-date resume at [Click Here to Email Your Resum?] .\n <br>\n <br>Jefferson Frank is the global leader for Amazon Web Services recruitment, advertising more AWS roles than any other agency. We deal with both AWS Partners &amp; End Users throughout North America. By specializing solely in placing candidates in the AWS market we have built relationships with most of the key employers in North America and have a complete understanding of where the best opportunities and AWS jobs are.\n <br>\n <br>Jefferson Frank is acting as an Employment Agency in relation to this vacancy.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2vExRu8xRfSCl8OoZ4nVwA",
    "url": "https://jobmote.com/job/48355/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 10:07:18 PM",
    "validThrough": "Jul 13, 2019 10:07:18 PM",
    "crawled": "Jul 11, 2019 3:06:24 AM",
    "content": "<div>\n Job DescriptionThe ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architectureQualificationsQualificationsBachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote\n <p>by Jobble</p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SmURUjGvSsC-uHBhsAGMRA",
    "url": "https://jobmote.com/job/48346/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 10:07:17 PM",
    "validThrough": "Jul 13, 2019 10:07:17 PM",
    "crawled": "Jul 11, 2019 3:06:24 AM",
    "content": "<div>\n Job DescriptionThe ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architectureQualificationsQualificationsBachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vdbyxgcBSwqKyw0Mhehj_g",
    "url": "https://remote.co/job/data-warehouse-developer-2/",
    "title": "Data Warehouse Developer",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:sql-server/dotnet/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=2, c=0, mobile=0, go=3, nodejs=1, bigdata-ml=5, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=6}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "Cardinal Financial",
      "sameAs": "https://cardinalfinancial.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 6:24:35 PM",
    "validThrough": "Jul 17, 2019 6:24:35 PM",
    "crawled": "Jul 10, 2019 11:01:53 PM",
    "content": "<h3>Data Warehouse Developer at <span>Cardinal Financial</span></h3>\n<div>\n <span><i></i> Remote</span> \n</div>\n<div> \n <p><strong>Department:</strong>&nbsp;Business Intelligence<br><strong>Location:</strong>&nbsp;Remote</p>\n <p><strong>Who We Are:</strong></p>\n <p>Cardinal Financial is a nationwide direct mortgage lender whose mission is to prove that homeownership is possible for everyone. By bringing an open-minded approach to an often closed-minded industry, we’re able to embrace every unique financial situation differently in order to craft the best possible loans for our borrowers. We pride ourselves on providing excellent service backed by our groundbreaking technology, and these two components of our process come together to complete a simple, personalized mortgage experience. But it all starts with our people.</p>\n <p>We believe that no matter where you fit in our organization—Sales, Human Resources, Information Technology, or even re-stocking the break rooms with endless coffee supplies—everyone can influence the experience that we provide to our customers and our partners. We tell our customers and our partners that anything can be reimagined. So why not your career? Looking to join a company that values its people, innovates and expands on its proprietary technology, and is growing at a ridiculous rate?!</p>\n <p><strong>Who We Need:</strong></p>\n <p>Cardinal Financial is in search of a Data Warehouse Developer. Within this position, you’ll be focused on expanding, maturing, and maintaining the Firm’s data analytics platform. The Data Warehouse Developer is responsible for the development of the extraction, transformation, and loading of the data warehouse structures, as well as the business intelligence reporting implementation. This position will collaborate with an advanced line of business users in order to maintain accurate metadata and support early-stage analytics for new datasets and report requirement examples.</p>\n <p><strong>What You Will Do:</strong></p>\n <ul>\n  <li>Develop and support an ETL process for data warehouse structures that support the reporting and data analytic systems.</li>\n  <li>Collaborate with a diverse team of business analysts and report developers to develop and build EDW artifacts, such as SQL code, logical and physical data models, and business intelligence reports.</li>\n  <li>Contribute to software design and architecture while following development specifications and standards.</li>\n  <li>Perform both analyst and developer responsibilities as needed within the full stack supporting the data warehouse.</li>\n  <li>Perform complex analysis and design across multiple database platforms and technologies.</li>\n  <li>May need to instruct and guide those with less experience.</li>\n  <li>To conduct research into new data warehouse applications and determine viability for adoption.</li>\n  <li>Identify and describe BI problems and requirements from across the organization.</li>\n  <li>Collaborate with data providers to ensure the right data is in the warehouse and is updated as changes occur in the data providers’ source system applications.</li>\n  <li>Profile and understand large volumes of source data, including structured and unstructured data. Sources will include MySQL, Microsoft SQL Server, flat files, web application API’s and the Cloud.</li>\n  <li>Regularly conduct ETL and database performance tuning. Look for ways to improve overall performance.</li>\n  <li>Identify opportunities to leverage existing metrics and develop new metrics to help move the organization forward by identifying waste in our processes.</li>\n  <li>Provide insight into creating and maintain a system that helps ad-hoc metrics providers move to a more robust and shareable reporting interface.</li>\n  <li>Assist in the development of metrics and processes to ensure quality standards are met on new and existing data.</li>\n </ul>\n <p><strong>What You Need:</strong></p>\n <ul>\n  <li><strong>Bachelor’s degree in Information Systems or a related field.</strong></li>\n  <li>At least 5 years of recent experience required in full stack data warehouse development.</li>\n  <li>At least 5 years of recent business intelligence semantic layer design and report development using one or more tools like Tableau, OBIEE, Microstrategy, Business Objects, etc.</li>\n  <li>Expert level experience SQL coding/querying skills with a major database platform (e.g., Microsoft SQL Server, Oracle, MySQL Redshift, etc.).</li>\n  <li>Understand data warehouse design and ETL performance techniques.</li>\n  <li>Experience with one or more ETL tools such as Talend, Data Services, Data Integrator, Informatica, SSIS, etc.</li>\n  <li>Experience with large relational data sets, including load performance, query performance, archiving, etc.</li>\n  <li>Experience working with unstructured or semi-structured data; time series data.</li>\n  <li>Ability to provide total analytic support which includes data extraction from multiple sources, synthesizing and aggregating data and developing reports.</li>\n  <li>Ability to clearly explain technical and analytical information (verbally, written, and in presentation format).</li>\n  <li>Strong organization skills.</li>\n  <li>Experience with Amazon Web Services (AWS) data warehousing techniques is a plus, especially Data Management Services, Data Pipeline and AWS Analytics platforms.</li>\n  <li>Experience in ETL job scheduling tools and implementation a plus.</li>\n </ul>\n <p><strong>What We Offer:</strong></p>\n <ul>\n  <li>Strength, Stability, and Vision.</li>\n  <li>An empowered culture where your ideas are important and your voice matters.</li>\n  <li>Opportunity for career growth.</li>\n  <li>Competitive compensation package.</li>\n  <li>Benefits that become effective the first day of the month following your start date including – Medical, Dental, Vision, Life and much more.</li>\n  <li>401K w/ 50% match up to a maximum employee contribution of 5%- Effective the 1st of the month following 30-days of employment.</li>\n </ul>\n <p><strong>WE ARE CARDINAL FINANCIAL</strong></p>\n <p>We started Cardinal Financial with a passion for developing a better mortgage experience. Our proprietary loan origination software, Octane, is a sure advantage, but we soon found out that revolutionary technology only goes so far without revolutionary people. We place a premium on hiring talented, forward-thinking, entrepreneurial spirits who are committed, not only to reimagining the possibilities of mortgage lending, but to delivering a personal experience to every borrower every time. We take a tremendous amount of pride in our people because they’re what sets us apart from the rest. Our culture is strengthened by self-starters who look forward to coming to work every day and are willing to go the extra mile for their colleagues and their clients. Cardinal Financial is where your career meets your calling. Join us and be a part of something more than mortgage lending.</p> \n</div>\n<div> \n <a href='https://cardinalfinancial.com/about/careers/search/job/962-data-warehouse-developer-remote/' rel='nofollow'>Apply for job</a> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "jSw1h6uRQPeWjjwfsAWNxA",
    "url": "https://news.ycombinator.com/item?id=20405691",
    "title": "Moonlight | Software Engineer | REMOTE | Fulltime | https://www.moonlightwork.com Hey all - ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 9:41:14 PM",
    "validThrough": "Jul 17, 2019 9:41:14 PM",
    "crawled": "Jul 10, 2019 11:01:47 PM",
    "content": "Moonlight | Software Engineer | REMOTE | Fulltime | \n<a href='https://www.moonlightwork.com' rel='nofollow'>https://www.moonlightwork.com</a>\n<p>Hey all - we're hiring a remote backend developer to join the team at Moonlight. We're building a professional community for software developers, and companies pay us to match to job candidates. The stack is Go on Kubernetes using gRPC, MySQL, Redis, etc. Lots going on and many fun challenges, ranging from ML to real-time messaging. This role will either be our first or second engineering hire. I wrote everything until now - so email me if you have any questions!</p>\n<p>More details here -&gt; <a href='https://hire.withgoogle.com/public/jobs/moonlightworkcom/view/P_AAAAAAIAAFeNB7zCTG98gQ?trackingTag=slack' rel='nofollow'>https://hire.withgoogle.com/public/jobs/moonlightworkcom/vie...</a> (edited)</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "RInVlifSTj6zsFecQGJnag",
    "url": "https://jobmote.com/job/48306/azure-big-data-engineer-remote-flexibility/",
    "title": "Azure Big Data Engineer (Remote Flexibility)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 9, 2019 10:07:16 PM",
    "validThrough": "Jul 12, 2019 10:07:16 PM",
    "crawled": "Jul 10, 2019 11:01:02 PM",
    "content": "<div>\n Azure Big Data Engineer (Remote Flexibility)\n <br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.\n <br> *AZURE EXPERIENCE REQUIRED\n <br> Skills:\n <ul>\n  <li>Experience using languages like Python, Scala, and Java</li>\n  <li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li>\n  <li>Experience with ETL tools like SSIS, SSAS, SSRS</li>\n  <li>Some familiarity with Microsoft BI and Power BI is great as well</li>\n  <li>Experience with data pipeline and workflow management tools</li>\n </ul>Benefits:\n <ul>\n  <li>Medical</li>\n  <li>Dental</li>\n  <li>Vision</li>\n  <li>Family leave</li>\n  <li>PTO</li>\n  <li>Retirement Plan</li>\n  <li>Remote options</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n <br>\n <b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b>\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "et80ll5CS7qvcp_sOi8KBA",
    "url": "https://jobmote.com/job/48299/lead-aws-data-engineer-philadelphia-pa-remote-flex-150k/",
    "title": "Lead AWS Data Engineer - Philadelphia, PA - REMOTE FLEX - 150K",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=33, ruby=0, apple=0, java=7, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 9, 2019 10:07:15 PM",
    "validThrough": "Jul 12, 2019 10:07:15 PM",
    "crawled": "Jul 10, 2019 11:01:02 PM",
    "content": "<div>\n <b>Lead AWS Data Engineer - Philadelphia, PA - 150K+ - REMOTE FLEX</b>\n <br> I am actively seeking a Lead Data Engineer that has production experience with AWS Data Services to join an exciting company in the Marketing Analytics sector. In this role, you will lead a team that focuses on this client's data-related products.\n <br> Specifically, you will design, develop, and maintain structures, pipelines, and transformations for the company's Data Lake and other key components comprising their Data Platform; furthermore, you will collaborate with Data Scientists to implement algorithms and models supporting their event classification processes.\n <br>\n <b>Qualified Candidates should demonstrate</b>\n <ul>\n  <li> <b>Production experience with AWS Data Services</b> \n   <ul>\n    <li> <b>Redshift, Athena, EMR, Kinesis, Glue, Lambda</b> </li>\n   </ul></li>\n  <li> <b>Production experience building Data Processing Systems using Spark</b> </li>\n  <li> <b>Proficiency developing Data Processing Programs using Python, Scala, and/or Java</b> </li>\n </ul>\n <b>Benefits</b>\n <ul>\n  <li> <b>Competitive Base Salary</b> </li>\n  <li> <b>Performance Based Bonus</b> </li>\n  <li> <b>Remote Flexibility</b> </li>\n  <li> <b>PTO Flexibility</b> </li>\n  <li> <b>Stock Options</b> </li>\n  <li> <b>Health Benefits: Medical, Dental, and Vision</b> </li>\n  <li> <b>401K</b> </li>\n  <li> <b>Casual Dress Code</b> </li>\n  <li> <b>Exciting Company Culture</b> \n   <ul>\n    <li> <b>Happy Hours, Parties, Group Outings</b> </li>\n   </ul></li>\n  <li> <b>Excellent Professional Development</b> \n   <ul>\n    <li> <b>Lunch n' Learn, AWS/Spark/Java Workshops</b> </li>\n   </ul></li>\n </ul> Interviews are now underway and flying by! If your or someone you know could be interested in this opportunity APPLY NOW! Guaranteed immediate consideration!\n <br> To apply, contact me via email: [Click Here to Email Your Resum?] ; phone: (212)- ; or LinkedIn message. Upon conversation, please be able to provide an updated CV.\n <br> Jefferson Frank is the global leader in Amazon Web Services recruiting. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.\n <br> At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "glfcpGg6SrSgYrpNzv-7dg",
    "url": "https://jobmote.com/job/48295/big-data-engineer-remote/",
    "title": "Big Data Engineer (REMOTE)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 9, 2019 10:07:15 PM",
    "validThrough": "Jul 12, 2019 10:07:15 PM",
    "crawled": "Jul 10, 2019 11:01:02 PM",
    "content": "<div>\n Big Data Engineer\n <br> REMOTE\n <br> ($170k-$200k)\n <br> This client is looking for engineers who are heavily involved in Big Data workloads in the Cloud. They really want someone who is 80% hands on a day to day basis.\n <br> Data pipeline creation in Cloud technologies\n <ul>\n  <li>AWS (EMR, Redshift, Athena, Lambda, S3, Glue)</li>\n  <li>Azure (HDI, Databricks)</li>\n  <li>GCP (Dataproc, BigQueries)</li>\n </ul> *Does not need to be proficient in all of these but the more the better\n <br> Role:\n <ul>\n  <li>Responsible for building data pipelines in AWS/Azure/GCP</li>\n  <li>Needs to be very hands on, will be development as the role is coding focused</li>\n </ul>\n <ul>\n  <li>Experienced using Scala or Java</li>\n  <li>Will be coding 80-90% of the time</li>\n </ul>\n <ul>\n  <li>Experienced in moving data workloads into the cloud for the past 2-3 years</li>\n </ul> Benefits:\n <br> -Competitive Base Salary\n <br> -PTO Flexibility\n <br> -401k\n <br> -Health Benefits: Medical, Dental, Vision\n <br> -High Energy Company Culture\n <br> -Great Professional Development\n <br> -Casual Dress Code\n <br> -Stock Options\n <br> -Remote Flexibility\n <br> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kmXH0S4RSIu0q-P0EQaUlQ",
    "url": "https://stackoverflow.com/jobs/280659/software-engineer-search-platform-wikimedia-foundation-inc?a=1w7HTTWMJDnW",
    "title": "Software Engineer, Search Platform at Wikimedia Foundation, Inc.  ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:android/java/1",
      "DBG_TECH1:k/t/w:android/mobile/2",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/8",
      "DBG_TECH1:k/t/w:java/mobile/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:php/php/15",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=10, mobile=6, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=12, gamedev=0, php=15, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TECH1/php",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java",
      "php"
    ],
    "hiringOrganization": {
      "name": "Wikimedia Foundation, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 10, 2019 11:01:01 PM",
    "validThrough": "Jul 17, 2019 11:01:01 PM",
    "crawled": "Jul 10, 2019 11:01:01 PM",
    "content": "<h3><span>Software Engineer, Search Platform</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Backend Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Education Technology, eLearning, Non-Profit</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>201–500 people</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wikimedia Foundation, Inc. | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n java\n</div>\n<div>\n php\n</div>\n<div>\n Matthew Flaschen 227k 38 449 506\n</div>\n<div>\n Dmitry Brant Senior Software Engineer, Product Owner (Android) at Wikimedia Foundation 6.4k 2 25 44\n</div>\n<div>\n Arthur Richards\n</div>\n<div>\n Monte Hurd 2.2k 4 25 34\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Summary</strong></p>\n <p>Our small team is passionate about making knowledge discoverable. We are responsible for Wikidata Query Service (a graph database that allows users to run arbitrary SPARQL queries on Wikidata) and for the search engine used on Wikipedia and its sister projects.</p>\n <p>We are looking for a software engineer to help us bring the Search Platform team to the next level.</p>\n <p>We use open-source tools as much as possible, and always open source our own work. Java, Python, PHP, and Scala make up most of our code, but we value using the right tool for the job. Our world is vast and can be complicated, so we value communication, enthusiasm, and an eagerness to learn.</p>\n <p><strong>You are responsible for:</strong></p>\n <ul>\n  <li>Work and communicate clearly and effectively within a small team that spans multiple time zones</li>\n  <li>Help maintain, scale, and extend query services at the Wikimedia Foundation — this includes the Wikidata Query Service (WDQS) and our Elasticsearch-based search engine</li>\n  <li>Improve the integration of Search, Wikidata Query Service, and the MediaWiki platform</li>\n </ul>\n <p><strong>Skills and Experience:</strong></p>\n <ul>\n  <li>Good working knowledge of software design principles</li>\n  <li>Good understanding of how to scale applications, in terms of load, complexity, and performance</li>\n  <li>Ability to work in a Linux server environment</li>\n  <li>Write code in Java and PHP that stands the test of time</li>\n  <li>Demonstrated experience in large-scale Java applications</li>\n  <li>Be willing to travel occasionally - sometimes internationally - for team and organizational meetings</li>\n  <li>Proficient English speaker</li>\n </ul>\n <p><strong>Additionally, we’d love it if you have:</strong></p>\n <ul>\n  <li>Degree in computer science, statistics, math, physics or other quantitative discipline; equivalent experience learned hands-on on the job also works</li>\n  <li>Experience with graph databases</li>\n  <li>Experience working on open source, collaborative development projects</li>\n  <li>Understanding of free culture / free software / open source principles</li>\n  <li>Exposure to applied machine learning (ML), deep learning, or natural language processing (NLP)</li>\n  <li>Familiarity with statistics</li>\n  <li>Experience with an internet software environment operating at scale; for example, messaging platforms that process hundreds of thousands of events per second</li>\n  <li>Big thumbs ups if you are a contributor to Wikipedia</li>\n </ul>\n <p><em>Show us your stuff! If you have any existing open-source software that you've developed (this could be your own software or patches to other packages), please share the URLs for the source. Links to GitHub, etc. are especially useful.</em>&nbsp;&nbsp;</p>\n <p><strong>The Wikimedia Foundation is...&nbsp;</strong></p>\n <p>...the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p>\n <p><strong><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></strong></p>\n <p><strong>U.S. Benefits &amp; Perks*</strong></p>\n <ul>\n  <li>Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)</li>\n  <li>The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more</li>\n  <li>The 401(k) retirement plan offers matched contributions at 4% of annual salary</li>\n  <li>Flexible and generous time off - vacation, sick and volunteer days, plus 19 paid holidays - including the last week of the year.</li>\n  <li>Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.</li>\n  <li>For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program</li>\n  <li>Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses</li>\n  <li>Telecommuting and flexible work schedules available</li>\n  <li>Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax</li>\n  <li>Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people</li>\n </ul>\n <p><strong><em>*Eligible international workers' benefits are specific to their location and dependent on their employer of record</em></strong></p>\n <p><strong>More information</strong></p>\n <p><a href='https://wikimediafoundation.org/' rel='nofollow'><strong>WMF<br></strong></a><a href='https://wikimediafoundation.org/news/' rel='nofollow'><strong>Blog<br></strong></a><a href='https://meta.wikimedia.org/wiki/Strategy/Wikimedia_movement/2017' rel='nofollow'><strong>Wikimedia 2030<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimedia_Foundation_Medium-term_plan_2019' rel='nofollow'><strong>Wikimedia Medium Term Plan<br></strong></a><a href='https://wikimediafoundation.org/2018/08/30/diversity-inclusion-numbers/' rel='nofollow'><strong>Diversity and inclusion information for Wikimedia workers, by the numbers<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimania_2019' rel='nofollow'><strong>Wikimania 2019<br></strong></a><a href='https://annual.wikimedia.org/2017/' rel='nofollow'><strong>Annual Report - 2017</strong></a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/280659?reset=False&amp;ra=1w7HTTWMJDnW&amp;oqs=a%3D1w7HTTWMJDnW' rel='nofollow'>Apply now</a>\n</div> \n<h4>About Wikimedia Foundation, Inc.</h4> \n<div>\n <p><strong>The Wikimedia Foundation is...</strong></p>\n <p>...the nonprofit organization that supports Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared&nbsp;knowledge,&nbsp;and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive&nbsp;<a href='https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&amp;uselang=en&amp;utm_medium=wmfWikiLink&amp;utm_source=B_FAQ&amp;utm_campaign=C_FAQ' rel='nofollow'>financial support</a>&nbsp;from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p>\n <p><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Fully paid premiums for medical, dental &amp; vision insurance premiums</span> </li> \n <li> <span></span> <span>401(k) with 4% matching contribution</span> </li> \n <li> <span></span> <span>7-12 weeks parental leave with 100% pay + lactation room</span> </li> \n <li> <span></span> <span>Wellness Program ($1800 annual) to promote wellness &amp; personal growth</span> </li> \n <li> <span></span> <span>Pre-tax savings plans for Transportation &amp; Parking</span> </li> \n <li> <span></span> <span>Flexible work schedules and remote working options</span> </li> \n <li> <span></span> <span>Pet Friendly office</span> </li> \n <li> <span></span> <span>Commitment to diversity &amp; inclusion throughout the employee lifecycle</span> </li> \n <li> <span></span> <span>12 days vacation, 19 days holiday, 2 days volunteer work and more!</span> </li> \n <li> <span></span> <span>Lean more at https://wikimediafoundation.org/wiki/Work_with_us</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YtxcoysTT0yhsqaaGbaDTQ",
    "url": "http://workinstartups.com/job-board/job/82163/data-scientist-at-switchee-ltd/",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=49, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Switchee Ltd",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 8, 2019 6:21:27 PM",
    "validThrough": "Jul 15, 2019 6:21:27 PM",
    "crawled": "Jul 8, 2019 7:30:32 PM",
    "content": "One in five households in the UK live in social housing, a sector with the right values at its core but that has historically struggled to deploy innovations in the home. Many residents still can’t afford to heat their homes and live in cold, mouldy properties they can’t be proud of. At Switchee, we believe that everyone deserves to live in a decent home and that the environments we inhabit have a massive influence on our ability to enjoy life and prosper.\n<br>\n<br>We may be only four years old, but it’s already been quite a ride! Our first product, the internet connected Switchee thermostat is already in 40 of the biggest housing providers in the UK. We’re growing 300% year on year and are backed by some of the best-known investors in technology and social impact.\n<br>\n<br>To strengthen our small team of 21 passionate and ambitious people and to take care of them and our office, we are looking for an outstanding individual to join us. Your commitment to our values and mission are paramount.\n<br>\n<br>As Data Scientist you’ll be at the forefront of the next stage of the Switchee platform as we enter an exciting period of growth.\n<br>\n<br>Help us discover the information hidden in vast amounts of our data to make smarter decisions for our business and to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality predictive systems integrated with our products at scale.\n<br>\n<br>As a start-up this role will involve working in all areas of the platform, this role offers there are huge opportunities to apply Data Science right across our business. As this is the first hire for a data scientist it provides a unique opportunity to help us build our data platform from the ground up.\n<br>\n<br>Your responsibilities:\n<br>\n<br>- Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\n<br>- Develop custom data models and algorithms to apply to data sets.\n<br>- Doing ad-hoc analysis and presenting results in a clear manner\n<br>- Coordinate with different functional teams to implement models and monitor outcomes.\n<br>- Support the product team with user testing and development feedback\n<br>- Collaborate with our Firmware team to ensure our hardware and software work seamlessly\n<br>\n<br>Your Experience and skills\n<br>\n<br>- Bachelor's/Master's/PhD or equivalent in Artificial Intelligence, Machine Learning, Computer Science, Statistics, Mathematics, Physics or similar quantitative discipline\n<br>- Proficiency in Python (or R) and experience in developing and deploying models to a production system or commercial use\n<br>- Experience using both SQL/NoSQL and Big Data platforms\n<br>- Experienced with cloud infrastructure (GCP, AWS, Azure)\n<br>- Independent with good communication and team working skills\n<br>- Strong problem-solving skills with an emphasis on product development.\n<br>\n<br>Nice to have:\n<br>\n<br>- Experience working with IOT device:\n<br>- Knowledge of Time series forecasting models\n<br>- AWS Sagemaker\n<br>\n<br>What we look for in you:\n<br>\n<br>We are a diverse bunch of people at Switchee. That said, there are some characteristics we always look for:\n<br>\n<br>- You deeply care about Switchee’s mission; you have a desire to build something revolutionary, that will disrupt an industry, and positively impact ordinary people’s lives.\n<br>- You care about the environment, are interested in energy efficiency and have thought about the challenges and opportunities posed by an evolving domestic energy market.\n<br>- You like technology and neat solutions to complex problems.\n<br>- You thrive on challenge and change; you naturally gravitate to the hardest questions first and love thinking differently to solve them.\n<br>- You are biased towards action and you’re happiest when you’re ‘getting stuff done’.\n<br>- You’re open, positive &amp; straightforward. You’re not afraid to stand up for your convictions, even when it’s hard to do so.\n<br>- You delight in your colleagues’ successes and thrive on your failures; you grasp any opportunity for learning and constantly seek to improve.\n<br>\n<br>More about our mission\n<br>\n<br>We believe that radical innovation in internet connected technology can ensure that every resident, every day, is living in a home that allows them to succeed. That’s why our products are built not just on great technology, but on an understanding of what people want from the space they live in.\n<br>\n<br>This approach led us to reimagine the most mundane household object, a thermostat, into a product that automagically reduces energy bills, looks great and offers control to those who want it.\n<br>\n<br>We are also revolutionising the way social landlords manage their housing stock with an obsessively tailored SAAS property dashboard and handy alerts on things like when the boiler is going to break.\n<br>\n<br>Our next project is to build the ultimate connected hub for the social home. It’s going to revolutionise the way residents interact with their properties and landlords manage their homes.\n<br>\n<br>Life at Switchee\n<br>\n<br>We like to keep things simple and flexible at Switchee and consider you to be joining our family. Currently, we have an informal policy where we each decide how much holiday we want to take with no formal limit. We occasionally work remotely but are sensitive to the needs of our colleagues.\n<br>\n<br>We socialise together with regular outings in London and an annual “working remotely” trip where you have the option (but not obligation) to join us in working from a fun location.\n<br>\n<br>If we end up working together, we can offer a competitive salary and a generous stake in the company.\n<br>\n<br>If you believe in the same things, don’t hesitate any longer, apply now! Please be in touch soon as we’ll proceed once the right person is found. If you’d like to apply please submit a CV and cover letter. \n<br>\n<br>Please note: Successful candidates should be able to attend a face-to-face interview at our office in London.\n<br>\n<br>Switchee is an equal opportunity employer. All applicants will be considered for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. If you’re smart and good at what you do, come as you are.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "KNM8vjFaTay5nFwx5Gj1aw",
    "url": "https://jobmote.com/job/47906/remote-data-associate-french-canadian/",
    "title": "REMOTE Data Associate (French Canadian)",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "50% remote",
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Aerotek",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 8, 2019 10:56:48 AM",
    "validThrough": "Jul 11, 2019 10:56:48 AM",
    "crawled": "Jul 8, 2019 3:06:26 PM",
    "content": "<div>\n <p><strong>JOB DESCRIPTION</strong></p>\n <p> This position will be working with Amazon's <strong>Alexa Data Services Team (ADS). </strong>ADS organization provides data creation, curation, and analytics services to help develop, test, and train the Alexa AI. They work closely with internal customers like Machine Learning Science modeling teams, providing the critical data they need to improve Alexa's Automatic Speech Recognition and Natural Language Understanding models and domain features.</p>\n <p> <strong>Location:</strong> Able to work remotely</p>\n <p><strong>Hours:</strong> Mon-Fri 9:00am-5:00pm <strong>(EASTERN STANDARD TIME)</strong></p>\n <p><strong>Duration:</strong> 3 Month Contract-<em>From there it will depend how the project is going as well as how your performance has been to see if there is room for an extension or not. </em></p>\n <p><strong>JOB MISSION</strong></p>\n <ul>\n  <li>Amazon is hiring Data Associates to work with their remote team on transcriptions of audio files for Automatic Speech Recognition, semantic annotation for Natural Language Understanding, and dialogue evaluation for improving overall customer interaction with Alexa.</li>\n  <li>You will focus on speech and language data, primarily in the areas of transcription, text annotation, and general data analysis to meet the internal customer's request.</li>\n  <li>Driven by your passion for data, you show proactive behavior in solving issues with efficiency and accuracy. Your ability to concentrate and your high attention to details help you deliver high-quality work.</li>\n  <li>In this role, you're comfortable with, and understand, the changes to the conventions deployed in response to internal customers' requests. You demonstrate ability to adjust your workflows accordingly. You prioritize strict compliance with regulatory requirements, and contribute to improvements in the software tools by identifying bugs and suggesting enhancements.</li>\n </ul>\n <p><strong>RESPONSIBILITIES</strong></p>\n <ul>\n  <li>Maintaining strict confidentiality and follow all applicable Amazon policies for securing confidential information</li>\n  <li>Transcribing and annotating high priority deliverables</li>\n  <li>Translating established guidelines into daily work practices and processing data in order of priority</li>\n  <li>Delivering high quality on deadlines</li>\n  <li>Getting the job done and work autonomously with minimum direction</li>\n  <li>Contributing to process improvements to reduce handling time and improve output</li>\n </ul>\n <p> <strong>BASIC QUALIFICATIONS</strong></p>\n <ul>\n  <li><strong>Native-level proficiency in FRENCH CANADIAN AND ENGLISH, both verbal and written skills</strong></li>\n  <li>Comfortable working with speech from various dialects and accents of FRENCH CANADIAN</li>\n  <li>Willing to work with audio content (wearing headsets) for a portion of the day</li>\n  <li>Experience with business software</li>\n  <li>Capable of working in strict compliance with internal guidelines</li>\n  <li>Excellent communication and organizational skills, detailed-oriented, highly collaborative</li>\n  <li>Comfortable working in an ever-changing, highly collaborative and dynamic work environment</li>\n  <li>Willingness to support several projects at one time and to accept re-prioritization as necessary</li>\n  <li>Continuous efforts to deliver the high quality data such as self-analysis</li>\n </ul>\n <p><br></p>\n <p><br></p>\n <p><br></p>\n <p><strong>About Aerotek:</strong></p>\n <p><strong>We know that a company's success starts with its employees. We also know that an individual's success starts with the right career opportunity. As a Best of Staffing<sup> </sup> Client and Talent leader, Aerotek's people-focused approach yields competitive advantage for our clients and rewarding careers for our contract employees. Since 1983, Aerotek has grown to become a leader in recruiting and staffing services. With more than 250 non-franchised offices, Aerotek's 8,000 internal employees serve more than 300,000 contract employees and 18,000 clients every year. Aerotek is an Allegis Group company, the global leader in talent solutions. Learn more at Aerotek.com.</strong></p>\n <br>\n <br>\n <b>The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.</b>\n <br>\n <br>\n <b>If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-###-#### or email accommodation@aerotek .com for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.</b>\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "azxI4ojdT3SXu7slehAftg",
    "url": "https://jobmote.com/job/47549/software-developer-part-remote-c-machine-learning/",
    "title": "Software Developer - Part Remote, C#, Machine Learning",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/6",
      "DBG_TECH1:k/t/w:c#/dotnet/15",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:dotnet/dotnet/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=23, c=6, mobile=0, go=0, nodejs=0, bigdata-ml=42, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Systematic Recruitment",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 6, 2019 10:07:12 PM",
    "validThrough": "Jul 9, 2019 10:07:12 PM",
    "crawled": "Jul 7, 2019 3:06:27 AM",
    "content": "<div>\n <p>Software Developer - Part Remote, C#, Machine Learning</p> \n <p>Machine Learning, Data Engineering and Data Science - probably 3 of the fastest growing areas within technology.</p> \n <p>However, sometimes making the move from your 'typical' Software Development background into one of these areas can prove a little tricky, think chicken vs egg, needing experience but not having the opportunity to get it.</p> \n <p>Well, we're working with a client in Birmingham, just next to the airport, who are looking for a Software Engineer to join their team who's looking to make that change.</p> \n <p>You'll initially be focusing on C#/.NET applications, helping to optimise their existing algorithms for a range of products, however growing with the role and having more of a Machine Learning/Data Engineer focus.</p> \n <p>Ideally, you'll already have an interest in Machine Learning/Data Engineering, with some exposure to Python/R (not essential) and want to make that move.</p> \n <p>They're happy for you to work remotely for part of the week, spending 2/3 days a week in the office.</p> \n <p>The role pays up to £40,000-£50,000 DOE with a 10% bonus and real opportunities for progression.</p> \n <p>Get in touch with Jack IT for a chat today.</p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TP_ai5WoQEy7dJw_qvoC9w",
    "url": "https://jobmote.com/job/47489/senior-data-etl-engineer-partial-remote/",
    "title": "Senior Data ETL Engineer- Partial Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 5, 2019 10:07:13 PM",
    "validThrough": "Jul 12, 2019 10:07:13 PM",
    "crawled": "Jul 6, 2019 3:06:27 AM",
    "content": "<div>\n Minimum Required Skills:\n <br>Mapreduce, ElasticSearch, Data Conversion\n <br>\n <br>We are one of the most successful technology start-ups in the Philadelphia region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. \n <br>\n <br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.\n <br>\n <br>We need a Data Rockstar to help us transform how consumers interact with real estate data.\n <br>\n <br>What You Will Be Doing\n <br>\n <br>- Recommend and implement data processing tools and technologies\n <br>- Extract, transform and load data pipelines from end to end\n <br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info\n <br>- Create, develop and document data mapping rules from multiple sources\n <br>- Develop continuous process movements\n <br>\n <br>What You Need for this Position\n <br>\n <br>- 3+ years experience using data related technologies( MapReduce, ElasticSearch, DynamoDB, Logstash) \n <br>- Full understanding of databases, data conversion, data manipulation, and data cleansing \n <br>- Experience with parsing and mapping data\n <br>- Microsoft Excel proficient \n <br>- Results driven with strong communication skills\n <br>- Real Estate data experience is a plus!\n <br>\n <br>What's In It for You\n <br>\n <br>- Competitive Pay\n <br>- Fully Remote! \n <br>- Medical, Dental, Vision\n <br>- Flexible PTOSo, if you are a Senior Data ETL Engineer- Partial Remote with experience, please apply today!\n <br>\n <br>Applicants must be authorized to work in the U.S.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!\n <br>\n <br>Looking forward to receiving your resume and going over the position in more detail with you.\n <br>\n <br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.\n <br>\n <br>Looking forward to receiving your resume!\n <br>\n <br>CyberCoders\n <br>\n <br>CyberCoders, Inc is proud to be an Equal Opportunity Employer\n <br>\n <br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n <br>\n <br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n <br>\n <br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "51l-qiKbThqgcUOeAlVALw",
    "url": "https://stackoverflow.com/jobs/279533/lead-data-scientist-remote-global-wallethub?a=1vKijb0FVreE",
    "title": "Lead Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 5, 2019 7:30:25 PM",
    "validThrough": "Jul 12, 2019 7:30:25 PM",
    "crawled": "Jul 5, 2019 7:30:25 PM",
    "content": "<h3><span>Lead Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51-200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours.</li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/279533?reset=False&amp;ra=1vKijb0FVreE&amp;oqs=a%3D1vKijb0FVreE' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9W8GszMSSEOqVi32m3vG_g",
    "url": "https://stackoverflow.com/jobs/279343/data-analyst-hotjar?a=1vGlmTioV0w8",
    "title": "Data Analyst at Hotjar  ",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/2",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:macos/apple/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=17, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=2, java=0, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hotjar",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "EUR",
      "minValue": 50000,
      "maxValue": 70000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "EUR 50k - 70k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 5, 2019 11:06:25 AM",
    "validThrough": "Jul 12, 2019 11:06:25 AM",
    "crawled": "Jul 5, 2019 11:06:25 AM",
    "content": "<h3><span>Data Analyst</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data &amp; Analytics, SaaS, Web Technology</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51-200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Hotjar | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT+01:00) Amsterdam +/- 2 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n r\n</div>\n<div>\n sql\n</div>\n<div>\n qa\n</div>\n<div>\n excel\n</div>\n<div>\n mfitzp Python Developer at Hotjar 11k 5 34 55\n</div>\n<div>\n Rory O'Keeffe Full stack web engineer with a passion for learning and creating cool things 201 1 5\n</div>\n<div>\n eKIK 896 9 6\n</div>\n<div>\n Jonathan Vella Director of Design at HotJar 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Note:</strong>&nbsp;Although this is a remote position, we are only looking for candidates in timezones between UTC-1 and UTC+3.</p>\n <p>At Hotjar we’re on a mission to build the leading user feedback and analytics platform, with our product being used by over 915,000 users in 190 countries. As part of our Business Intelligence team, you will make data-driven recommendations on strategy and keep a finger on the pulse of our business.</p>\n <p>We work in an agile and highly collaborative environment, 100% remotely, and challenge the norms of<a href='https://www.hotjar.com/blog/effective-leadership' rel='nofollow'>&nbsp;traditional business leadership</a>. Our focus is on true transparency and respect.</p>\n <p>We’re looking for someone who loves to turn data into insights and communicate findings fearlessly. You want to help teams make data-informed decisions and take data-informed actions, you have a curious mindset, and you are motivated to understand our business better.</p>\n <p><strong>You will:&nbsp;</strong></p>\n <ul>\n  <li><p>Identify and analyze trends or patterns in complex data sets</p></li>\n  <li><p>Develop and implement databases, data collection systems, data analytics and other strategies that improve statistical efficiency and quality</p></li>\n  <li><p>Filter and “clean” data by reviewing multiple data sources and performance indicators to locate and correct inconsistencies.</p></li>\n  <li><p>Support scoping complex data-centric projects across multiple teams and systems, and work on deliverables to promote bias to action</p></li>\n  <li><p>Build data models to accelerate the business by providing deeper insights into visitor and customer behaviors, and feed the team’s hunger for actionable insights</p></li>\n  <li><p>Assist our teams in defining, tracking and optimizing processes, tools, and dashboards for better planning and management of the business</p></li>\n  <li><p>Help analyze the effectiveness of new solutions to inform whether to double down, pivot, or eliminate a new feature or process</p></li>\n  <li><p>Select and integrate new technologies to promote better segmentation and attribution</p></li>\n </ul>\n <p><strong>Requirements</strong></p>\n <ul>\n  <li>Experience in analytics/data science or a directly related field – some of which is in a technology environment</li>\n  <li><p>Experience initiating and delivering applicable analyses/recommendations to guide impact</p></li>\n  <li><p>Excellent skills with analytics tools, fluency with BI/visualization tools such as Mode, Tableau, etc and knowledge of Excel, R, Python, SQL, or other analysis tools</p></li>\n  <li><p>An understanding of SaaS business models and essential metrics</p></li>\n  <li><p>Experience implementing and integrating an event tracking platform</p></li>\n  <li><p>Critical-reasoning skills, including the understanding of common pitfalls of data analysis</p></li>\n  <li><p>A desire to work in a respectful, transparent, and transparent work environment, following Hotjar’s&nbsp;<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269942884/Hotjar+Core+Values' rel='nofollow'>company values</a>,&nbsp;<a href='https://careers.hotjar.com/' rel='nofollow'>culture&nbsp;</a>and&nbsp;<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269779142/Working+at+Hotjar' rel='nofollow'>ways of working</a></p></li>\n  <li><p>Must submit to a background check confidentially processed by our third-party&nbsp;</p></li>\n </ul>\n <p><strong>Plus points:</strong></p>\n <ul>\n  <li><p>Experience with building predictive data models to provide deeper insights</p></li>\n  <li><p>Knowledge of statistics and experience using statistical packages for analyzing datasets</p></li>\n </ul>\n <p><strong>What we offer</strong></p>\n <ul>\n  <li><p>A remote and accomplished diverse and international team</p></li>\n  <li><p>An opportunity to positively enhance people’s experience online and make the web a better place</p></li>\n  <li><p>Annual learning and development budget</p></li>\n  <li><p>Several perks designed for your well-being and a healthy work-life balance. (Holiday Budget, Wellbeing Allowance, Working Together Budget, 16 weeks paid parental leave, and much more)</p></li>\n </ul>\n <p><strong>Compensation Range</strong></p>\n <p>The budgeted compensation range for this role is €50,000 to €70,000 annually. Ranges are based on market research and are equitable to other roles within Hotjar. The actual compensation offered will be based on relative experience. At this time we are only able to provide official employment status to those located in Malta, and Germany (for candidates who don’t require visa sponsorship). All other team members will join as full-time consultants and will be responsible for paying any taxes or applicable fees where they reside.</p> \n</div> \n<div> \n <a href='https://careers.hotjar.com/o/data-analyst-emea/?source=Stackoverflow' rel='nofollow'> Apply now </a>\n</div> \n<h4>About Hotjar</h4> \n<div>\n <p>Hotjar is a rapidly growing startup that is giving thousands of website owners the tools needed to discover how their visitors are really using their website. We are looking for passionate and ambitious developers who can help us shape the product and company while growing with us.</p>\n <p><strong>Culture at Hotjar:</strong></p>\n <p>Headquartered on the beautiful island of Malta, in the “heart” of the Mediterranean, Hotjar is a young startup that embraces remote working and personal development.</p>\n <p>Hotjar’s culture is driven by transparency, respect, open discussion, collaboration and blunt and direct feedback. In fact, we’re obsessed with communicating with our users as well as within the team. We hate bureaucracy and slow moving organizations –&nbsp;but we’re suckers for well-defined processes. We love lean, iterative improvements and success is measured by the value we create for our users.</p>\n <p><strong>The Perks:</strong></p>\n <ul>\n  <li><strong>Remote &amp; Flexible.</strong> Work from anywhere within a European timezone.&nbsp;</li>\n  <li><strong>Ample Time Off.&nbsp;</strong>All team members get 40 days of paid planned leave/year, plus 10 sick days/year and time off to attend conferences / events.</li>\n  <li><strong>Collaborate with prestigious organizations.</strong> Imagine what it will feels like to be part of a product that is used by companies like Time Inc., Nintendo, Lloyd's Bank, Pingdom, Booking.com, Intuit and the Red Cross.</li>\n  <li><strong>Only the best hardware and software</strong>. Mac, PC or Linux –&nbsp;we will get you equipped with the best hardware and software available, of your own choice.</li>\n  <li><strong>Home Office budget.</strong> Every Hotjar team member receives a €4000 home office setup budget, with a yearly €500 top-up thereafter. Upgrade your desk, chair, screens or buy any peripherals you might need.</li>\n  <li><strong>Personal Development budget.</strong> Everyone receives a free Kindle as well as direct management of their own personal development yearly budget of €1,000. Buy books, short courses or magazine subscriptions.</li>\n  <li><strong>Holiday budget.</strong> A spend of €2,000/year for each team mate to spend relaxing and recharging on holiday.</li>\n  <li><strong>Work Together budget.</strong> Even though we're remote, we don't underestimate the value of getting together in person sometimes. Each team member has €2,000/year to spend on travelling to work with other Hotjarians.</li>\n  <li><strong>Working Space Allowance.</strong> Decide how you want to spend your monthly €200, whether it's on a co-working space, working from a coffee shop, getting your favourite coffee delivered to your home office, etc.</li>\n  <li><strong>Wellbeing Allowance.</strong> €200/month to spend on your wellbeing, be that physical, mental or spiritual.</li>\n  <li><strong>Work with a very talented team.</strong> Our team has an impressive background building and optimizing products and businesses around the globe.</li>\n  <li><strong>Make a difference.</strong> Hotjar is ‘democratizing’ site analytics and feedback by making them affordable and easy to use for everyone around the world. We call it the ‘Hotjar revolution’.</li>\n </ul> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>€4,000 Home Office Budget, topped up €500/year</span> </li> \n <li> <span></span> <span>100% Remote</span> </li> \n <li> <span></span> <span>Free Kindle Paperwhite, Fitbit, Headset and Reading Pack</span> </li> \n <li> <span></span> <span>€1,000 Annual Personal Development Budget</span> </li> \n <li> <span></span> <span>€200 Monthly Well Being Allowance</span> </li> \n <li> <span></span> <span>40 days leave annually</span> </li> \n <li> <span></span> <span>Two company retreats each year</span> </li> \n <li> <span></span> <span>€2,000 Annual Holiday Budget</span> </li> \n <li> <span></span> <span>€200 Monthly Working Space Allowance</span> </li> \n <li> <span></span> <span>€2,000 Annual Work Together Budget</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "nfAmin3NRhekPjUzk1oRog",
    "url": "https://jobmote.com/job/47443/solidity-engineer-remote-60-000-120-000/",
    "title": "Solidity Engineer – Remote - £60,000-£120,000",
    "tags": [
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:rust/other/5",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 4, 2019 10:07:18 PM",
    "validThrough": "Jul 11, 2019 10:07:18 PM",
    "crawled": "Jul 5, 2019 3:06:26 AM",
    "content": "<div>\n Solidity Engineer - Remote - £60,000-£120,000\n <br>\n <br>Solidity Engineer - Remote - £60,000-£120,000 - I am currently recruiting for a solidity engineer to join a very well-respected start up within the Ethereum ecosystem. They are at the forefront of bringing enterprise zero-knowledge systems to the public Ethereum space.\n <br>\n <br>They are looking to recruit a solidity engineer to build out the core components of their smart contract architecture. This role would involve both architecture and implementation of their smart contracts as well as mentoring of junior team members. In this role you would also help with the hiring and subsequent scaling of the business.\n <br>\n <br>The ideal candidate will have significant experience of the EVM as well as hands on experience with solidity. You will have come from at least 5 years software development as well as commercial experience with Javascript.\n <br>\n <br>Any experience of Rust and cryptography would be a bonus but is not essential. The client is open to this role being perform completely remotely but their preference would be candidate around EU timezones.\n <br>\n <br>If you are interested in this role please send your cv / github asap\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zsAUS8TyQCaRKayrNNmP2Q",
    "url": "https://jobmote.com/job/47409/spark-pyspark-developer-c2c-remote/",
    "title": "Spark(PySpark) Developer - C2C (REMOTE)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:shell/other/1",
      "DBG_TECH1:techWeightMap:{python=6, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "OrbITpeople",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 4, 2019 10:07:16 PM",
    "validThrough": "Jul 11, 2019 10:07:16 PM",
    "crawled": "Jul 5, 2019 3:06:26 AM",
    "content": "<div>\n <br>Spark(PySpark) Developer - C2C (REMOTE)\n <br>\n <br>Chicago, IL - Contracted\n <br>\n <br> As a Big Data Spark Developer/Engineer, you will interface with key stakeholders and apply your technical proficiency across different stages of the Spark code development life cycle including gathering requirements, implementing complex componential models, massively parallel processing and advanced data modeling as well as performance tuning and scalability. You will play an important role all throughout the development process, from creating the high level design artifacts to actual implementation.\n <br>\n <br>\n <b>Primary skill set: </b> \n <br>\n <br> * PySpark\n <br> * AWS\n <br> * Python\n <br> * Strong ETL processes\n <br> * Linux (scripting Shell/Bash)\n <br>\n <br> Qualifications/experience\n <br> * Hands-on experience with AWS cloud\n <br> * Experience in PySpark development including data frames, data transformations, performance tuning, memory sizing and tuning Spark Master and Executors.\n <br> * Experience in Python and Spark/Python writing streaming and/or batch processing code (for example - coding ETL pipelines). REQUIRED\n <br> * Some hands-on experience with AWS services and solutions (Glue) - REQUIRED\n <br> * hands-on experience working with the Hadoop ecosystem components for data analysis\n <br> * hands-on data modeling including table partitioning models.\n <br>\n <br> Thanks\n <br> Alex Prem | T:\n <br> | \n <br>\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Qi0em6j9Qh-_4JkP8n4C4g",
    "url": "https://www.workingnomads.co/job/go/26877/",
    "title": "Machine Learning Engineer - Remote",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jvm/java/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/12",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=20, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Numbrs Personal Finance AG",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 4, 2019 11:29:31 AM",
    "validThrough": "Jul 11, 2019 11:29:31 AM",
    "crawled": "Jul 4, 2019 12:07:21 PM",
    "content": "<p>At Numbrs, our engineers don’t just develop things – we have an impact. We change the way how people are managing their finances by building the best products and services for our users.&nbsp;<br><br>Numbrs engineers are innovators, problem-solvers, and hard-workers who are building solutions in big data, mobile technology and much more. We look for professional, highly skilled engineers who evolve, adapt to change and thrive in a fast-paced, value-driven environment.<br><br>Join our dedicated technology team that builds massively scalable systems, designs low latency architecture solutions and leverages machine learning technology to turn financial data into action. Want to push the limit of personal finance management? Join Numbrs.</p>\n<p><strong>Job Description</strong></p>\n<p>You will be a part of the Data Science team responsible for designing, developing and supporting big data driven predictive models using the latest technologies in machine learning, user pattern recognition, and data modelling.<br>The team is responsible to gain new insights which result in the development of product’s features to improve user engagement and experience.</p>\n<p><strong>Key Qualifications</strong></p>\n<ul>\n <li>a Bachelor’s or higher degree in technical field of study or equivalent practical experience</li>\n <li>a minimum 5 years of professional experience in Machine Learning</li>\n <li>Experience in pattern recognition, predictive modelling, and statistical analysis</li>\n <li>Strong knowledge in Machine Learning areas such as Neural Networks, Reinforcement Learning, and NLP</li>\n <li>Experience in designing Machine Learning systems at scale</li>\n <li>Experience with Big Data technologies such as Kafka, Spark, and Cassandra</li>\n <li>Fluent with a JVM programming language, ideally Scala.</li>\n <li>Comfort working in a dynamic, research-oriented team with several ongoing concurrent projects</li>\n <li>Excellent troubleshooting and creative problem-solving abilities</li>\n <li>Excellent written and oral communication in English and interpersonal skills</li>\n</ul>\n<p><strong>Location: Remote</strong></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "v9tEEq-fQ1-7fiZryT065w",
    "url": "http://workinstartups.com/job-board/job/82043/cbirmachine-learning-at-tba/",
    "title": "CBIR/Machine Learning",
    "tags": [
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``OR(oper,collabor) 2W remot",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TBA",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 4, 2019 9:48:49 AM",
    "validThrough": "Jul 11, 2019 9:48:49 AM",
    "crawled": "Jul 4, 2019 11:06:32 AM",
    "content": "*********************************************************************************************************\n<br>No agencies or job seekers.\n<br>\n<br>Innovative brand marketing platform requires a specialist engineer with solid working knowledge of reverse image search/CBIR/machine learning.\n<br>\n<br>Working with our CTO (full-stack engineer with 20 years experience) to shape and implement key functionality to showcase to investors.\n<br>\n<br>Collaborative, flexible, remote working. Ideally based near London but not essential.\n<br>\n<br>Contact us for an exploratory chat.\n<br>\n<br>\n<br>*********************************************************************************************************\n<br>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "4s0_XGe7RcWr0kqDtwBffg",
    "url": "https://jobmote.com/job/47333/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 3, 2019 10:07:19 PM",
    "validThrough": "Jul 10, 2019 10:07:19 PM",
    "crawled": "Jul 4, 2019 3:06:25 AM",
    "content": "<div>\n Sr. Engineer - Product development?\n <br>\n <br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.\n <br>\n <br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.\n <br>\n <br>Check out our website below to learn more about what we do and how we help our clients.\n <br>\n <br>Primary Responsibilities:\n <br>\n <br>???????? Provide thought leadership in architecture, design for analytics products\n <br>\n <br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements\n <br>\n <br>???????? Lead cross functional product development efforts\n <br>\n <br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan\n <br>\n <br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines\n <br>\n <br>???????? Provide technical support to assist clients and partners during and post implementation\n <br>\n <br>???????? Manage development resources onsite and offshore\n <br>\n <br>???????? Develop and expand our application knowledge base and best practices for delivering data products\n <br>\n <br>Required Experience and Skills:\n <br>\n <br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem\n <br>\n <br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must\n <br>\n <br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must\n <br>\n <br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem\n <br>\n <br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills\n <br>\n <br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.\n <br>\n <br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture\n <br>\n <br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)\n <br>\n <br>???????? Experience with NoSQL databases\n <br>\n <br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.\n <br>\n <br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.\n <br>\n <br>???????? Experience in professional services or technical consulting with enterprise software solutions\n <br>\n <br>???????? Proven ability to balance and manage multiple, competing priorities.\n <br>\n <br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.\n <br>\n <br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.\n <br>\n <br>What We Offer:\n <br>\n <br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement\n <br>\n <br>???????? Global career mobility, employee recognition programs, professional development\n <br>\n <br>???????? State of the art technology which allows for seamless global connectivity\n <br>\n <br>???????? Rich wellness program and health incentives\n <br>\n <br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately\n <br>\n <br>#LI-RD1\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "wQveCxLHRuqNQqD1XCj0xw",
    "url": "https://jobmote.com/job/47325/aws-senior-big-data-engineer-remote/",
    "title": "AWS Senior Big Data Engineer - REMOTE",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 3, 2019 10:07:19 PM",
    "validThrough": "Jul 10, 2019 10:07:19 PM",
    "crawled": "Jul 4, 2019 3:06:25 AM",
    "content": "<div>\n AWS Senior Big Data Engineer - REMOTE\n <br> I'm currently working with one of Amazon Web Services' leading Consulting Partners. You will have the opportunity to work for a company founded by former Amazon employees who wanted to remain hands-on and implement AWS big data solutions for F500 companies worldwide.\n <br> Because of the high demand for their services, they are looking to double their team over the next 3 months so the hiring process is moving very quickly!!\n <br>\n <br>Role &amp; Responsibilities\n <ul>\n  <li>Experience working and implementing AWS Data Pipelines</li>\n  <li>Experience working with the AWS ecosystem (Redshift, RDS, EMR, Kinesis, S3, EC2, Lambda etc.)</li>\n  <li>Experience Implementing Redshift and ETL in a Professional Environment</li>\n  <li>Extensive hands on experience working with Complex Data Warehouses</li>\n  <li>Exposure to NoSQL-based, SQL-like technologies such as (Hive, Pig, HDFS, Impala)</li>\n  <li>Experience working with Business Intelligence tools such as (MicroStrategy, Business Objects, Cognos) a huge plus</li>\n  <li>Experience working with Enterprise Clients presenting complex solutions</li>\n  <li>Experience working with C-Level Executives</li>\n  <li>40%+ travel</li>\n </ul> Benefits\n <ul>\n  <li>Relocation package</li>\n  <li>Competitive salary </li>\n  <li>Premium healthcare, dental, vision</li>\n  <li>6 weeks PTO</li>\n  <li>Fully remote!</li>\n  <li>Fast interview process</li>\n </ul> If you are interested in this position, please call me (Emily Jaco) at or send your resume to my email address - [Click Here to Email Your Resum?] . Additionally, if you have any questions about benefits and salary, please contact me. Act fast, as this opportunity will most likely be off the market in the near future.\n <br> Jefferson Frank is the global leader in Amazon Web Services recruiting. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.\n <br>\n <br>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "yIWBRuJ7SEqzSvziiMWOZA",
    "url": "https://jobmote.com/job/47316/azure-big-data-engineer-remote-flexibility/",
    "title": "Azure Big Data Engineer (Remote Flexibility)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 3, 2019 10:07:19 PM",
    "validThrough": "Jul 10, 2019 10:07:19 PM",
    "crawled": "Jul 4, 2019 3:06:25 AM",
    "content": "<div>\n Azure Big Data Engineer (Remote Flexibility)\n <br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.\n <br> *AZURE EXPERIENCE REQUIRED\n <br> Skills:\n <ul>\n  <li>Experience using languages like Python, Scala, and Java</li>\n  <li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li>\n  <li>Experience with ETL tools like SSIS, SSAS, SSRS</li>\n  <li>Some familiarity with Microsoft BI and Power BI is great as well</li>\n  <li>Experience with data pipeline and workflow management tools</li>\n </ul>Benefits:\n <ul>\n  <li>Medical</li>\n  <li>Dental</li>\n  <li>Vision</li>\n  <li>Family leave</li>\n  <li>PTO</li>\n  <li>Retirement Plan</li>\n  <li>Remote options</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n <br>\n <b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b>\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "A0wq5YfNQJCTqfXyGPBW_w",
    "url": "https://jobmote.com/job/47310/data-engineer-chicago-il-remote-200k-hands-on-exp-required/",
    "title": "Data Engineer- Chicago, IL-Remote-200k-Hands-on Exp. Required",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 3, 2019 10:07:19 PM",
    "validThrough": "Jul 10, 2019 10:07:19 PM",
    "crawled": "Jul 4, 2019 3:06:25 AM",
    "content": "<div>\n Job Description\n <br>\n <b>Data Engineer-</b> \n <b>Chicago, IL-Remote-200k-Hands-on Exp. Required</b>\n <br>\n <br>\n <b>Position:</b> Data Engineer\n <br>\n <b>Technology:</b> Big Data\n <br>\n <b>Location:</b> Chicago, IL\n <br>\n <b>Job Type:</b> Permanent\n <br>\n <br>*\n <b>Must be on hands-on*</b>\n <br>\n <b>About the Role:</b>\n <br> Ready to work with cutting edge technology filled with a great work environment where you will feel relaxed and excited to challenge yourself? Well it's a good thing you specialize in Azure Big Data! My client likes to hire those with a passion of excellence and a smart mind.\n <br> This role will include leading and participating in architecture, design and development of various components of the data's APM solutions.as well as build automated optimization solutions for Big Data workloads on cloud platforms like AWS, Azure, and Google Cloud.\n <br> The ideal candidate has experience in AWS (EMR, Redshift, Athena, Lambda, S3, Glue), Azure (HDI, Databricks), and/or GCP (Dataproc, BigQueries)!\n <br>\n <br>\n <b>Responsibilities, Skills, and Qualifications:</b>\n <ul>\n  <li>BS/CS, MS/CS or equivalent</li>\n  <li>5+ years of development experience in Big Data and related fields</li>\n  <li>Hands-on experience in the internals of one or more distributed systems like Athena, Redshift, Spark, Kafka, Bigquery, and AWS Lambda running on the cloud</li>\n  <li>Expert in programming with Java or Scala or Python</li>\n  <li>Experience with Apache Airflow a plus</li>\n  <li>Strong analytical and design skills</li>\n  <li>Ability to set and manage priorities judiciously</li>\n  <li>Excellent written, oral communication and interpersonal skills</li>\n  <li>Ability to articulate ideas to both technical and non-technical audiences</li>\n  <li>Exceptionally self-motivated and directed</li>\n  <li>Keen attention to detail</li>\n  <li>Superior analytical, evaluative, and problem-solving abilities</li>\n  <li>Ability to inspire others</li>\n </ul>\n <b>Benefits:</b>\n <ul>\n  <li>-Great pay</li>\n  <li>-Amazing work culture</li>\n  <li>-401k</li>\n  <li>-Health insurance</li>\n  <li>-Dental insurance</li>\n  <li>-Vision insurance</li>\n  <li>-Paid parental leave</li>\n  <li>-Generous paid time-off vacation time</li>\n  <li>-Maternity/Paternity leave</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling \n <b> (ext. 7598</b>\n <b>)</b>. I'm eagerly looking forward to helping you advance your career!\n <br>\n <br>\n <b>What's in it for you:</b>\n <br> These roles don't last long on the market. Be in touch quickly and I can place you with your desired job in a timely manner. Don't hesitate to achieve the better job you are looking for and want now. Please send your resume and I'm excited to meet with you. I am unlike other recruiters in that I thrive on building our relationship and making it more personal to ensure working together is a happy experience for you!\n <br> Nigel Frank International is the Global Leader in Microsoft Azure recruitment. We are a part of Frank Recruitment Group, one of the most successful global recruitment businesses in the last 10 years and backed by private equity firm TPG Growth.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5hM9pD-hTyK9gfK7hKeLDQ",
    "url": "https://jobmote.com/job/47311/remote-data-analyst-data-scientist-must-reside-in-wi-mn-ia-il-in-o/",
    "title": "Remote Data Analyst / Data Scientist - Must reside in WI MN IA IL IN o",
    "tags": [
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/64",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=68, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 3, 2019 10:07:19 PM",
    "validThrough": "Jul 10, 2019 10:07:19 PM",
    "crawled": "Jul 4, 2019 3:06:25 AM",
    "content": "<div>\n This full-time, permanent Data Analyst / Data Scientist ?career opportunity is flexible and can be remote (employees can work from home as the company is very family-orientated).? If the successful candidate prefers to be onsite, that is also welcomed.? Depending on the employee's location, this employee could come in as little as once per quarter.? The company is located west of Madison, Wisconsin and provides risk management and prevention monitoring systems.? The company software is cloud-based, IoT (Internet of Things) and AI (Artificial Intelligence).? This smaller company has been in business for four years and plans on tripling the number of employees this year as their products are in high demand.? Employees are team-oriented and great at collaborating.??\n <br>\n <br>As the company grows, there will be a opportunities for career growth possibly including management.? In fact, a Data Analyst was recently promoted to a Data Scientist.? The technology is very leading edge.? There is freedom in how Data Analysts / Data Scientists go about their day and work.? This successful Data Analyst / Data Scientist will be responsible for the following:\n <ul>\n  <li>Leveraging new data collection processes and sources</li>\n  <li>Developing and deploying innovative methods, models, and algorithms</li>\n  <li>Utilizing statistics, algorithms, data mining, and visualization</li>\n  <li>Interacting with all levels</li>\n  <li>Working with the Data Science and the Product Development employees</li>\n  <li>Anticipating, identifying, and investigating data trends</li>\n  <li>Discovering actionable insights</li>\n  <li>Identifying business opportunities</li>\n  <li>Designing presentations for decision makers</li>\n  <li>Identifying data sources</li>\n </ul>Candidates will have a minimum background consisting of the following:\n <ul>\n  <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent</li>\n  <li>Analytics experience</li>\n  <li>SQL and relational database experience</li>\n  <li>Data visualization tool experience</li>\n  <li>Data analysis programming language experience</li>\n  <li>Statistical software experience</li>\n  <li>ETL knowledge</li>\n  <li>Strong visual presentation skills</li>\n  <li>Strong written and verbal communication skills</li>\n  <li>Ability to prioritize and manage multiple projects</li>\n  <li>A detail orientation</li>\n  <li>An innovative mindset</li>\n  <li>Ability to be on site at least once per quarter</li>\n </ul>Preferred but \n <em><b>not required</b></em>?backgrounds will include?\n <b><em>any</em></b>?of the following:\n <ul>\n  <li>Insurance experience</li>\n  <li>Python experience</li>\n  <li>Algorithm experience</li>\n  <li>AWS Cloud service experience</li>\n  <li>EC2 experience</li>\n  <li>RDS experience</li>\n  <li>S3 experience</li>\n </ul>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ChSklk-7TbOt8qYm_dtSww",
    "url": "https://news.ycombinator.com/item?id=20337128",
    "title": "ZipCam https://www.zip.cam | Full-time | Part-time | Onsite | Remote | Palo Alto, CA ZipCam is ...",
    "tags": [
      "DBG:surround``remot W OR(contractor,assist,ok)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/3",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:embedded/c/1",
      "DBG_TECH1:k/t/w:embedded/embedded/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=1, mobile=0, go=0, nodejs=0, bigdata-ml=31, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 7:08:46 PM",
    "validThrough": "Jul 9, 2019 7:08:46 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "ZipCam \n<a href='https://www.zip.cam' rel='nofollow'>https://www.zip.cam</a> | Full-time | Part-time | Onsite | Remote | Palo Alto, CA\n<p>ZipCam is making intelligent, connected dashcams for driving safety. In the U.S., more than 37,000 lives per year are lost in automobile accidents. Worldwide, an unbelievable 1.25 million people die from car crashes annually. We don't need full self-driving technology to save these lives: we can add computer vision and machine learning technology to existing cars to help people drive more safely, today, in the car they already own.</p>\n<p>ZipCam is looking for machine learning engineers with experience in classification and object recognition in (driving) video clips. Multiple positions available.</p>\n<p>* Summer internship. Onsite (Palo Alto) or Remote OK. Neural network analysis of driving video clips: lane-keeping, accident &quot;near miss&quot; detection, sign reading, stop light classification, stop line detection, other driving tasks. Also with a driver-facing camera: classification of various kinds of distraction (cell phone use, etc). Grad student or college junior/senior with with excellent course background in machine learning and computer science. Possibility to co-author an academic paper. Possible long term employment. $5k/month for a very experienced candidate.</p>\n<p>* Midlevel or Senior Machine Learning Engineer. Full-time. Onsite (Palo Alto) or Remote OK. Major equity &amp; good salary for the right candidate; let's talk. We are seed stage and well funded by angels. You should be have experience running accelerated ML models on video data in the cloud; otherwise we are still stack-agnostic at this point. Experience with internet-of-things (connected cameras) is a plus. Low-power (embedded) computer vision experience is a plus. Management experience is a plus; we will be hiring. Drop us a line to learn more about the product roadmap, it's exciting. This is a big moment in history for this kind of real-world machine learning.</p>\n<p>Please send your resume + linkedin &amp; github URLs to jobs@zip.cam. In your email please include any relevant publications. Describe some large datasets you have worked with. Looking forward to speaking with you.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YvXDwZwLRS-y1v8gdvNdYQ",
    "url": "https://news.ycombinator.com/item?id=20327807",
    "title": "Resemble AI | Toronto or Remote | Full-Time, Interns | Deep Learning & Full-Stack Engineers ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/10",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/24",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=10, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 7:43:24 PM",
    "validThrough": "Jul 8, 2019 7:43:24 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Resemble AI | Toronto or Remote | Full-Time, Interns | Deep Learning &amp; Full-Stack Engineers\n<p>Resemble AI creates high-quality synthetic voices that capture human emotion. We're a venture-backed high-growth startup that's looking to shake up an entire industry with state of the art AI.</p>\n<p>Our product changes the way that thousands of brands, media companies, creative agencies, and game studios work with voice content.</p>\n<p>We’re a remote-first team that thrives on flexibility and creativeness. We cover expenses for office space, equipment, and all of the other perks and benefits that make you productive. We also believe that to build an enticing product and solid team is by encouraging innovation is by enabling continuous education. That's why every other Friday is a day that you can use to work on anything you want, Resemble-related or not.</p>\n<p>We're hiring for two roles:</p>\n<p>Deep Learning Engineer - Knowledge of Tensorflow or Pytorch, and have the ability to quickly iterate and test new hypotheses.</p>\n<p>Full Stack Engineer - Product-driven Engineer that is able to craft end-to-end features. We work with Ruby on Rails, React, with microservices written in Python and deployed on GCP.</p>\n<p>If interested, reach out directly to me: zohaib@resemble.ai</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Y8dq8dn4TjOrcNS50DR9RQ",
    "url": "https://news.ycombinator.com/item?id=20333575",
    "title": "CITIO | Paris | Remote | Full Time | Visa sponsorship | https://cit.io/ CITIO is a newly ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 11:43:34 AM",
    "validThrough": "Jul 9, 2019 11:43:34 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "CITIO | Paris | Remote | Full Time | Visa sponsorship | \n<a href='https://cit.io/' rel='nofollow'>https://cit.io/</a>\n<p>CITIO is a newly founded start-up sponsored by a leader in transportation networks. We leverage Big Data and powerful Machine Learning Tools to provide a better understanding of transportation networks.</p>\n<p>We're looking for a Data scientist (software oriented) with experience running algorithms in production.As a Data Scientist, you will be :</p>\n<p>* expanding your current data model to account for the wealth of data in transport networks</p>\n<p>* working on hard problems like simulation and passenger reconstitution</p>\n<p>* dealing with complex, ambiguous data</p>\n<p>A good knowledge of French is required, as part of the role is client facing.</p>\n<p>Apply here : <a href='https://angel.co/company/citio/jobs/356314-data-scientist-software-oriented' rel='nofollow'>https://angel.co/company/citio/jobs/356314-data-scientist-so...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eMYS0uxwQamhJZ4fPB96RQ",
    "url": "https://news.ycombinator.com/item?id=20329141",
    "title": "Org | NYC, Zug, World | Blockchain, AI, Financial Engineering, P2P | ONSITE, REMOTE | https:/ ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 9:57:31 PM",
    "validThrough": "Jul 8, 2019 9:57:31 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Org | NYC, Zug, World | Blockchain, AI, Financial Engineering, P2P | ONSITE, REMOTE | \n<a href='https://org.network' rel='nofollow'>https://org.network</a>\n<p>Org is reinventing the nature of the firm, through a new platform allowing easier creation of proper unstoppable DAOs.</p>\n<p><a href='https://org.network/jobs/' rel='nofollow'>https://org.network/jobs/</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "oT5QgLnsTXy1p9pZlHlCuQ",
    "url": "https://news.ycombinator.com/item?id=20331140",
    "title": "Epigno Systems | Full-Stack Engineer, DevOps, Data Engineer | Tokyo, Japan | Part-time or Full ...",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR( australia, japan, newzealand)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:flask/python/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:vue.js/frontend/8",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Asia"
    ],
    "tagsNames1": [
      "Asia time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 2:47:44 AM",
    "validThrough": "Jul 9, 2019 2:47:44 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Epigno Systems | Full-Stack Engineer, DevOps, Data Engineer | Tokyo, Japan | Part-time or Full-time | REMOTE\n<p>Do you know that an average Japanese doctor works <i>124</i> hours of overtime per month?Do you want to improve health-care and hospital management in Japan's aging economy?</p>\n<p>Epigno Systems is an early-stage start-up that provides prediction, optimization and visualization solutions to streamline hospital management. We provide consulting services and software solutions to solve hospital business needs.</p>\n<p>Our team is entirely remote. Team members living in the Tokyo area tend to gather at most once a week.We are hiring fast learners that finish their job on time and do <i>not</i> work overtime. As a company that strives to reduce overtime for medical staff, we should show the example, shouldn't we?</p>\n<p>Tech stack: Python / Flask / Docker / VueJS / VanillaJS</p>\n<p>As we are still small, professional Japanese proficiency is currently required for full-time staff to reduce communication overhead. For part-time positions Japanese proficiency is a good-to-have.We hire people located in Japan for the time being.</p>\n<p>Feel free to contact me for applying: malik(at)epigno(dot)jp</p>\n<p>If you can explain what you can do, we will most probably find work that fits your skills :).</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vmyTVXdxToKZnYA_nLDMdw",
    "url": "https://news.ycombinator.com/item?id=20329551",
    "title": "Orchestra | Front-end & Back-end engineers + Product Managers | London, Remote for developers ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 3W onli",
      "DBG_TECH1:k/t/w:angularjs/frontend/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/6",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 10:44:28 PM",
    "validThrough": "Jul 8, 2019 10:44:28 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Orchestra | Front-end &amp; Back-end engineers + Product Managers | London, Remote for developers only | On-site | Full-timeOrchestra helps data scientists deploy machine learning models to production faster whether it's building a Docker image, serving as an API, creating batch processes or integrating directly to enterprise systems. Effectively, we are DevOps for ML and we automate deployment and release management of machine learning models.We're still an early stage startup looking to close our seed round in the next few months. As an early member, you'll have the opportunity to define the space and set the standard for what it means to do DevOps properly within ML. The platform is currently developed using AngularJS, Python, Docker/Kubernetes.Drop me a line at teren@orchestrahq.com if you love ML and want to help get machine learning models deployed faster, at scale and in a variety of shape and form.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "19CNkXvARvSEk6WrTO3QQw",
    "url": "https://news.ycombinator.com/item?id=20330353",
    "title": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 12:28:43 AM",
    "validThrough": "Jul 9, 2019 12:28:43 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full-time | Local or Remote | \n<a href='https://www.sourceress.com/jobs' rel='nofollow'>https://www.sourceress.com/jobs</a>\n<p>We already have significant machine learning expertise, so are happy to hire great engineers without prior ML experience who are willing to learn. We strongly value personal growth, and want to help you grow into a great engineer (or engineering leader), so this approach applies to our other engineering roles as well.</p>\n<p>Our mission is to help people find work that matters. We believe that the world is better when people understand the opportunities available to them. Our human-assisted AI platform delivers great results to our customers (customer quote: &quot;I'd have a panic attack if you guys stopped existing&quot;).</p>\n<p>Because of this, we raised $3.5M from OpenAI researchers and Lightspeed at one of the highest ever valuations coming out of YC. Our team has previously sold companies, published machine learning research, has Dropbox's former Chief of Staff, and previously worked at Google, Airbnb, McKinsey, etc.</p>\n<p>Qualifications:</p>\n<p>- Do you understand the value of shipping quickly and of software craftsmanship, and have the judgment to know when to apply each?</p>\n<p>- Do you enjoy collaborating with other developers and helping them grow?</p>\n<p>- Do you share our values? <a href='https://www.sourceress.com/jobs#values' rel='nofollow'>https://www.sourceress.com/jobs#values</a></p>\n<p>Stack: Python 3, Typescript, React, AWS, PostgreSQL</p>\n<p>To Apply: <a href='https://www.sourceress.com/jobs#current-openings' rel='nofollow'>https://www.sourceress.com/jobs#current-openings</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eiE00lS6Tba7oQVte-aNyA",
    "url": "https://news.ycombinator.com/item?id=20331536",
    "title": "Major League Baseball (MLB.com) | Principal Data Engineer | New York | ONSITE (with flexible ...",
    "tags": [
      "DBG:surround``OR(abl,will,challeng,flexibl,experi,get,prefer) 2W 2N(work,remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 2,
      "maxValue": 2,
      "info": "",
      "unit": "WEEK",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": "USD 2 /Week"
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 4:09:38 AM",
    "validThrough": "Jul 9, 2019 4:09:38 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Major League Baseball (MLB.com) | Principal Data Engineer | New York | ONSITE (with flexible remote work up to 2 days a week)\n<p>Major League Baseball is hiring a Principal Data Engineer to report directly to me, the VP of Data Engineering, at our New York City office. We work with a diverse set of baseball fan transaction and interaction data, helping to connect fans with the game of baseball! I oversee a team of Data Engineers and BI Engineers and we're looking for someone with significant experience with building and maintaining data pipelines to join our team. More info here - <a href='https://grnh.se/c075d4691' rel='nofollow'>https://grnh.se/c075d4691</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "jH-PLejcQLm4ba7nwLqWJg",
    "url": "https://news.ycombinator.com/item?id=20335668",
    "title": "Kira Systems |Machine Learning Developer, Software Developer(s). QE Specialists, Research ...",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/other",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "other"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 4:47:20 PM",
    "validThrough": "Jul 9, 2019 4:47:20 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Kira Systems |Machine Learning Developer, Software Developer(s). QE Specialists, Research Scientist| Toronto, Canada | Remote | Onsite | \n<a href='https://www.kirasystems.com' rel='nofollow'>https://www.kirasystems.com</a>\n<p>Kira Systems makes contract analysis software. We are always looking for talented people to join our team locally, remotely, and for those looking for change to relocate to our headquarters in Toronto.</p>\n<p>We're hiring multiple technical roles to work in all areas of our stack. Possibilities include working on Clojure web server, backend data processing services, and both our platform API and SDK. We use PostgreSQL to store our data and don’t hide SQL behind big frameworks. We also use many other popular technologies such as RabbitMQ, Zookeeper, ElasticSearch, and Docker.</p>\n<p>For more information, visit our careers page <a href='https://www.kirasystems.com/careers' rel='nofollow'>https://www.kirasystems.com/careers</a> or email us at jobs@kirasystems.com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "p_tebZaQS5itC6zxbuOZ9w",
    "url": "https://news.ycombinator.com/item?id=20327382",
    "title": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 7:02:55 PM",
    "validThrough": "Jul 8, 2019 7:02:55 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR REMOTE | \n<a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a>\n<p>================</p>\n<p>We're the fastest growing unicorn you've never heard of [0] and was just recently named CNBCs Most Disruptive Business beating out Airbnb, Stripe, Flexport, and more [3].</p>\n<p>Indigo is revolutionizing agtech by offering better crops to farmers through technology. Agtech is one of the most underhyped technology trends [1] and we're serving a multi-trillion dollar marketplace services industry [2].</p>\n<p>Our group is working on the Uber for Agriculture. We're developing a Transportation network to connect farmers with preferred carriers (trucks) to help them ship millions of bushels of grain across the United States. It's like a real world Traveling Salesman Problem with even more requirements.</p>\n<p>We're growing so fast that I have to hire another 10 engineers just for my group in 2019. Back-end, front-end, mobile... you name it, we need the help (see all of them here: <a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a> ).</p>\n<p>Our tech stack includes AWS, Docker, Kubernetes (DevOps), Postgres (DB), Node &amp; GraphQL (back-end), React &amp; Apollo (front-end), and Python (data science / comp bio).</p>\n<p>We also offer incredible perks. Free lunch (a rarity in Boston), massive commuter benefits (both MBTA and bicycling), fitness reimbursement, ample vacation; we really focus on and believe in both health and sustainability.</p>\n<p>I'd be happy to tell you more, so feel free to PM me and I'll personally refer you to the company.</p>\n<p>[0] <a href='https://www.builtinboston.com/2017/09/26/agtech-startup-indigo-boston-tech-unicorn' rel='nofollow'>https://www.builtinboston.com/2017/09/26/agtech-startup-indi...</a></p>\n<p>[1] <a href='http://stateofstartups.firstround.com/2018/#trends-and-takes' rel='nofollow'>http://stateofstartups.firstround.com/2018/#trends-and-takes</a></p>\n<p>[2] <a href='https://andrewchen.co/how-marketplaces-will-reinvent-the-service-economy/' rel='nofollow'>https://andrewchen.co/how-marketplaces-will-reinvent-the-ser...</a></p>\n<p>[3] <a href='https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor-50-companies.html' rel='nofollow'>https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kCnwO6VFRQS0xaI_UQikRg",
    "url": "https://news.ycombinator.com/item?id=20332198",
    "title": "M-KOPA Solar | Senior Data Engineer | REMOTE (ideally GMT+0 - GMT+4) or ONSITE in Nairobi ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 6:46:04 AM",
    "validThrough": "Jul 9, 2019 6:46:04 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "M-KOPA Solar | Senior Data Engineer | REMOTE (ideally GMT+0 - GMT+4) or ONSITE in Nairobi/London\n<p>M-KOPA Solar is a large-scale solar energy company focusing on pay-as-you-go systems for emerging markets, primarily in East Africa. We sell small home solar systems that provide lighting and energy to customers who are not currently well-served by the traditional electricity grid. We currently have over 700,000 direct customers (equating to roughly 3.5 million people benefiting from our services) and are expanding quickly. M-KOPA may not be a household name in some job markets, but we have a lot of traction, and a solid runway of interesting engineering work.</p>\n<p>By joining us, you will get to work on a compelling social mission, while also enjoying the engineering challenge of working to maintain and evolve a ~1 million device IoT installation.</p>\n<p>We are actively hiring for a senior data engineer. The ideal candidate would be comfortable working to build data warehousing/persistence flows based on streaming data systems (e.g. Kafka, Event Hub). We are a small team, and so an ideal candidate would be excited to interface with BI developers and application developers to select and implement creative data solutions across a wide-ranging problem space, with involvement in everything from infrastructure to schema design.</p>\n<p>Please contact owen.scott@m-kopa.com for more information.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XT3kcbgqQY2Eq03dGG3raQ",
    "url": "https://news.ycombinator.com/item?id=20328654",
    "title": "OnSpecta | Redwood City, CA & Warsaw, Poland | Software Engineer, Research Engineer, Machine ...",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 9:06:08 PM",
    "validThrough": "Jul 8, 2019 9:06:08 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "OnSpecta | Redwood City, CA &amp; Warsaw, Poland | Software Engineer, Research Engineer, Machine Learning Engineer | Visa\n<p>OnSpecta is an early-stage startup founded by successful serial entrepreneurs and deep learning experts, and was born out of MIT’s neuroscience lab. We offer a Deep Learning Server (DLS) which increases the performance of deep learning computations on Intel and ARM CPUs, GPUs and ASICs etc. We're a small team (~10), so you'll have a huge opportunity to make a difference.</p>\n<p>We are looking for talented software performance engineers to work directly with our technical founders. If you have experience in C++ and are interested in working on cutting-edge AI/ML infrastructure tech, please reach out to us. See more at <a href='http://onspecta.com/careers.html' rel='nofollow'>http://onspecta.com/careers.html</a> We're also looking for Machine Learning Engineers (experience with Python + TensorFlow required).</p>\n<p>Please reach out to hiring@onspecta.com and include &quot;HN: &quot; in the subject. (Note: while we're open to remote work, you must be in California's or Central/Easter Europe's timezones. Local candidates are preferred).</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "VfuSU1wzTseACOfYJbbGKw",
    "url": "https://news.ycombinator.com/item?id=20326296",
    "title": "Slytrunk | Data Engineer | Fulltime | Remote (US only) | slytrunk.com Slytrunk is a small team ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 3W onli",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 5:27:52 PM",
    "validThrough": "Jul 8, 2019 5:27:52 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Slytrunk | Data Engineer | Fulltime | Remote (US only) | slytrunk.com\n<p>Slytrunk is a small team of technical experts focused on developing beautiful software applications with a range of incredible clients.</p>\n<p>We're currently looking to onboard a Data Engineer [0].</p>\n<p>The Data Engineer is responsible for building out and managing our Apache &amp; DataStax Cassandra and Solr clusters as a replacement for our existing MySQL databases. The engineer will be responsible for working with Dev and infrastructure teams to; upgrade, manage, optimize, monitor, etc.. our Cassandra and Solr clusters.</p>\n<p>This opportunity will require expertise of Cassandra key concepts such as SSTables, compaction, and garbage collection, as well as Solr concepts such as; core, schema, indexes, and field types. This is a ground floor opportunity to be responsible for DevOps and production support of the new Cassandra and Solr clusters you help design and build.</p>\n<p>We're a very small team with some really awesome clients/projects. All of us are remote, but are highly collaborative. Slytrunk was founded 10 years ago by two engineers and to this day continues to be engineer-focused. Check out the links for more information. Applications go directly to the CEO and founders. Even if you'd like more info before applying, feel free to drop us a line and we can provide you more details.</p>\n<p>[0] <a href='http://bit.ly/sly-data-engineer' rel='nofollow'>http://bit.ly/sly-data-engineer</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NpkDS1dgT1Ste8Wg-ri5XA",
    "url": "https://news.ycombinator.com/item?id=20328369",
    "title": "Petal | New York, NY | Full Stack, Infrastructure, Backend Engineers | ONSITE or REMOTE (US) ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 8:40:26 PM",
    "validThrough": "Jul 8, 2019 8:40:26 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Petal | New York, NY | Full Stack, Infrastructure, Backend Engineers | ONSITE or REMOTE (US)\n<p>Petal is a credit card for people without credit histories, by using machine learning to analyze cash flow to augment traditional credit score-based lending decisions. We've raised our Series B and are growing rapidly.</p>\n<p>Some press we've received: <a href='https://techcrunch.com/2018/10/02/petals-no-fee-credit-card-for-the-credit-score-less-is-now-open-to-the-public/' rel='nofollow'>https://techcrunch.com/2018/10/02/petals-no-fee-credit-card-...</a></p>\n<p>Tech stack: <a href='https://stackshare.io/petal' rel='nofollow'>https://stackshare.io/petal</a></p>\n<p>Please apply here: <a href='https://jobs.lever.co/petalcard?lever-origin=applied&amp;lever-source%5B%5D=HACKER_NEWS' rel='nofollow'>https://jobs.lever.co/petalcard?lever-origin=applied&amp;lever-s...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "if9fsStGSl6waHpZnzhFcQ",
    "url": "https://news.ycombinator.com/item?id=20326179",
    "title": "Noom | Data Engineer, Staff Engineer, Sr. Android Engineer | NYC or REMOTE | FULLTIME | https:/ ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:android/java/3",
      "DBG_TECH1:k/t/w:android/mobile/6",
      "DBG_TECH1:k/t/w:com/dotnet/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=7, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 5:19:11 PM",
    "validThrough": "Jul 8, 2019 5:19:11 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Noom | Data Engineer, Staff Engineer, Sr. Android Engineer | NYC or REMOTE | FULLTIME | \n<a href='https://noom.com' rel='nofollow'>https://noom.com</a>\n<p>At Noom, we use scientifically-proven methods to help users get a handle on chronic medical conditions like obesity, diabetes, and heart disease. We use a variety of technologies, and get to work on hard problems that range from data warehousing to running experiments on mobile devices.</p>\n<p>Our engineering team is expanding, and we have openings for a number of positions that include backend and mobile engineering. Our offices are in NYC, but we are a remote-first organization (some 90% of our team is remote) and are happy to consider candidates anywhere.</p>\n<p>Here are some links where you can apply:</p>\n<p>- Data Engineer - <a href='https://grnh.se/fa9f2f811' rel='nofollow'>https://grnh.se/fa9f2f811</a></p>\n<p>- Staff Engineer - <a href='https://grnh.se/1c6640381' rel='nofollow'>https://grnh.se/1c6640381</a></p>\n<p>- Sr. Android Engineer - <a href='https://grnh.se/98b810ee1' rel='nofollow'>https://grnh.se/98b810ee1</a></p>\n<p>Our stack includes Python, React, Java, and Go, all hosted on AWS.</p>\n<p>I'm Noom's VP of Engineering -- feel free to drop me a note if you have question; I'm mt at noom dot com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "KmmEwg58TLOMuB8kWS5WWQ",
    "url": "https://news.ycombinator.com/item?id=20327989",
    "title": "SEEKING FREELANCER | Technical Writers, Bloggers and Content Editors - Machine Learning, Deep ...",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/18",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=46, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 8:00:15 PM",
    "validThrough": "Jul 8, 2019 8:00:15 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "SEEKING FREELANCER | Technical Writers, Bloggers and Content Editors - Machine Learning, Deep Learning, Artificial Intelligence | Remote (anywhere on the blue planet)\n<p>FloydHub is a YC start-up building AI infrastructure and tools. We have a popular platform with a highly satisfied and growing user base.</p>\n<p>We are passionate about the power of artificial intelligence and truly believe these technologies will make a lasting positive impact on the world. We are doing our part to accelerate the adoption of AI by creating easy-to-use tools and by educating more people about fundamental concepts, best practices and advanced techniques in AI. Our blog plays a critical role in educating our current audience and others interested in entering the field.</p>\n<p>We are looking for bloggers &amp; writers to create engaging and informative pieces for our audience. If you are a data scientist or software engineer looking to write about your areas of expertise or what you are learning, we are still interested. Apply here (FloyHub AI writer): <a href='https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;utm_medium=post&amp;utm_campaign=call_for_writers_jul_2019' rel='nofollow'>https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;...</a></p>\n<p>We are looking for a strong content editor with a flair to create engaging content. You will partner with our writers to improve the quality of our articles and help us make our blog highly informative for the AI community. If you are an editor with experience in delivering technical content, we want to talk to you. You'll have plenty of room let the creative juices flow and tell compelling stories. Apply here (FloydHub Editor): [Apply here](<a href='https://docs.google.com/forms/d/e/1FAIpQLSdhy1I1JlK1XUhzD9VWjjz83RgTgO-W-8-PyjatoYsT3ENgDg/viewform' rel='nofollow'>https://docs.google.com/forms/d/e/1FAIpQLSdhy1I1JlK1XUhzD9VW...</a>)</p>\n<p>This is a great opportunity for you to contribute to the biggest technological revolution since the advent of the internet and work alongside influencers in AI. Come write for us. Come be part of the revolution</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MCdYkv5qSTmpc2dAZ73gng",
    "url": "https://news.ycombinator.com/item?id=20326791",
    "title": "Kalepa | Machine Learning Engineers, Backend / Data Engineers, Full-Stack Engineers | New York ...",
    "tags": [
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=14, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 6:11:21 PM",
    "validThrough": "Jul 8, 2019 6:11:21 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Kalepa | Machine Learning Engineers, Backend / Data Engineers, Full-Stack Engineers | New York City, NY | ONSITE / PARTIAL REMOTE, VISA\n<p>Kalepa is a New York based, VC backed, startup building software to transform and disrupt the $1T commercial insurance market.Engineers at Kalepa will be solving interesting and challenging problems at the intersection of big data pipelines, cutting-edge machine learning models, intuitive frontend apps, and robust infrastructure. You will be working in a small team building technology from the ground up with the latest stack.</p>\n<p>One trillion dollars are spent globally each year on commercial insurance. However, the process for estimating the risk associated with a given business across various perils is still reliant on inefficient and inaccurate forms and research. This information asymmetry leads to a broken set of incentives and a poor experience for both businesses and insurers alike. By combining cutting edge data science, enterprise software, and insurance expertise, Kalepa is delivering precision underwriting at scale. Kalepa is turning real-world data into a complete understanding of risk.</p>\n<p>Kalepa is led by a strong team with experiences from Facebook, APT (acquired by Mastercard for $600M in 2015), the Israel Defense Forces, MIT, Berkeley, and UPenn. We are backed by IA Ventures.</p>\n<p>More details here: <a href='https://www.linkedin.com/jobs/cap/view/1114358414/' rel='nofollow'>https://www.linkedin.com/jobs/cap/view/1114358414/</a></p>\n<p>Contact: paul.monasterio@kalepa.co</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NemY_LplSe65RnAvcQ1cIw",
    "url": "https://news.ycombinator.com/item?id=20326170",
    "title": "Extreme Networks | multiple roles | Shannon, or remote within Ireland [1] | Full Time | https:/ ...",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:rust/other/5",
      "DBG_TECH1:techWeightMap:{python=2, other=5, dotnet=0, c=13, mobile=1, go=3, nodejs=1, bigdata-ml=20, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 5:17:54 PM",
    "validThrough": "Jul 8, 2019 5:17:54 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Extreme Networks | multiple roles | Shannon, or remote within Ireland [1] | Full Time | \n<a href='https://www.extremenetworks.com/company/careers/' rel='nofollow'>https://www.extremenetworks.com/company/careers/</a>\n<p>We're a young startup that has been around since ...1996! We build network/wireless gear and software solutions for analytics, management and security. We're bootstrapping a new engineering base in Shannon, Ireland, to help us transform into a software company. We are a flat organization, and this operation starts with a blank slate (languages, architecture, ideas), so join the team and help us get to the mission of being a 2B$ company in 2020.</p>\n<p>* Software Engineers (Cloud) - multiple positions - <a href='https://www.extremenetworks.com/company/careers/?p=job%2Fos4D9fw2' rel='nofollow'>https://www.extremenetworks.com/company/careers/?p=job%2Fos4...</a></p>\n<p>You'll be working on a brand new project with the aim of building a cloud-based successor of our famous network management platform. We build on serverless stack on AWS and GCP. If you have programmed in any of Go, Java, Rust, Python, JavaScript, C, C++, we would love to hear from you.</p>\n<p>* Machine Learning / Data Science Engineers - multiple positions - <a href='https://www.extremenetworks.com/company/careers/?p=job%2Fo9BG9fwj' rel='nofollow'>https://www.extremenetworks.com/company/careers/?p=job%2Fo9B...</a></p>\n<p>You'll be joining a brand new team of ML and Data Science engineers, that will be extending our analytics and security products. We run analytics for massive customers, both in the cloud and at the edge. Tech we use: GCP BigQuery+PubSub+Dataproc, AWS GreenGrass, both Tensorflow and PyTorch. Lots of ideas to experiments with.</p>\n<p>Feel free to get in touch with me directly (mail in profile) for any question.</p>\n<p>[1] regarding remote: our Irish engineering base is in Shannon, we're always open to remote candidates but for these positions we're restricted in hiring within Ireland sorry.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_iRmYHj9TGCLqVr-a3lNEw",
    "url": "https://news.ycombinator.com/item?id=20330381",
    "title": "Warby Parker | New York, NY | Engineering Manager, Data Engineering | Full-time | Onsite ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 12:31:48 AM",
    "validThrough": "Jul 9, 2019 12:31:48 AM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Warby Parker | New York, NY | Engineering Manager, Data Engineering | Full-time | Onsite preferred but remote possible\n<p>As one of the original &quot;clicks to bricks&quot; retailers, Warby Parker has more interesting retail data than almost anybody else. We run our own supply chain, including an in-house optical lab; we built our own ERP; and, with a strong e-commerce site and close to 100 stores, our omnichannel game is on point.</p>\n<p>One of our biggest challenges is getting all of that data into a coherent form and making it as easy as possible for analysts to use it. We're transitioning right now from an in-house PostgreSQL database to BigQuery, and in the process developing more mature data governance, data modeling, and general processes around data quality. And at the same time, we're working to take our ETL infrastructure to the next level.</p>\n<p>We have a team of seven plus a Product Manager tackling this challenge, with more to come in the future.</p>\n<p>What we need next is an Engineering Manager [0] to nurture this team into its next phase of development. Coach them to the next level, identify where we need to grow and succeed, and make it happen. Let's talk!</p>\n<p>[0] <a href='https://boards.greenhouse.getrake.io/warbyparker/jobs/1755200?gh_jid=1755200' rel='nofollow'>https://boards.greenhouse.getrake.io/warbyparker/jobs/175520...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0z3atf-nRjePoFQWqQ_W6g",
    "url": "https://news.ycombinator.com/item?id=20328908",
    "title": "Invitae | SF, Boston, NYC, and Seattle | US-ONLY REMOTE or ONSITE | FULL-TIME | http://invitae ...",
    "tags": [
      "DBG:surround``remot 9W 4N( OR(offic,onsit), time)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 9:34:24 PM",
    "validThrough": "Jul 8, 2019 9:34:24 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Invitae | SF, Boston, NYC, and Seattle | US-ONLY REMOTE or ONSITE | FULL-TIME | \n<a href='http://invitae.com' rel='nofollow'>http://invitae.com</a>\n<p>Invitae makes genetic testing an integral part of the patient journey. At Invitae, you'll get to change patient’s lives on a daily basis, the scale to impact millions and to live on the cutting edge of medicine. Sound interesting?</p>\n<p>Our open positions:</p>\n<p>* Senior Software Engineers -- front &amp;| backend, we're building distributed systems to handle the scale and complexity of genomic data.</p>\n<p>* Product Data Scientist -- turn data into insights and develop a deep understanding of customer and patient behavior.</p>\n<p>Reach out to NickLS, SethP, or VincentF on LinkedIn if you have questions.</p>\n<p>To learn more about who we are and our company culture -- <a href='https://www.invitae.com/en/careers/' rel='nofollow'>https://www.invitae.com/en/careers/</a></p>\n<p>More details:</p>\n<p>* Career Page -- <a href='https://www.invitae.com/en/careers/' rel='nofollow'>https://www.invitae.com/en/careers/</a></p>\n<p>* Senior Software Eng -- <a href='https://boards.greenhouse.io/invitae/jobs/1720573?gh_jid=1720573' rel='nofollow'>https://boards.greenhouse.io/invitae/jobs/1720573?gh_jid=172...</a></p>\n<p>* Data Scientist -- <a href='https://boards.greenhouse.io/invitae/jobs/1518615?gh_jid=1518615' rel='nofollow'>https://boards.greenhouse.io/invitae/jobs/1518615?gh_jid=151...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "nu2OuFQHSR-RWdhQKKLbXg",
    "url": "https://news.ycombinator.com/item?id=20327389",
    "title": "Citymapper | Full-time, ONSITE, REMOTE possible, VISA (for experienced candidates), London We ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 7:03:40 PM",
    "validThrough": "Jul 8, 2019 7:03:40 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Citymapper | Full-time, ONSITE, REMOTE possible, VISA (for experienced candidates), London\n<p>We need great engineers who are up to the challenge of making cities usable.Current mobility trends (scooters, electric bikes, cabs, …) are changing cities - and we are helping users to find and book the best transport options for them. - Our multimodal transport app helps millions of people to get from A to B in our 40 cities - Citymapper Pass is a Mobility-as-a-Service (MaaS) solution live in London - a transport only payment card covering all private and public transport with a weekly subscription (<a href='https://citymapper.com/pass' rel='nofollow'>https://citymapper.com/pass</a>)Check out our blog at <a href='https://engineering.citymapper.com' rel='nofollow'>https://engineering.citymapper.com</a> to get a better idea of what we are doing.</p>\n<p>We are looking especially for: (Have a look on our careers page for a full list)Experienced backend engineers (Python, Go, AWS, …) <a href='https://citymapper.workable.com/jobs/6531' rel='nofollow'>https://citymapper.workable.com/jobs/6531</a>Data Science Engineers (data scientist working within an engineering team) <a href='https://citymapper.workable.com/jobs/40247' rel='nofollow'>https://citymapper.workable.com/jobs/40247</a>iOS Engineer <a href='https://citymapper.workable.com/jobs/7972' rel='nofollow'>https://citymapper.workable.com/jobs/7972</a></p>\n<p>You can contact me directly at marius@citymapper.com if you have any questions (no recruiters please). Otherwise please apply through our website: <a href='https://citymapper.com/jobs' rel='nofollow'>https://citymapper.com/jobs</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "JszH93ERRuSJ3tMLnE4tIw",
    "url": "https://news.ycombinator.com/item?id=20327071",
    "title": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| https://www.factual.com ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 3N OR(options, avail, allow) NOT encourag",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 6:36:50 PM",
    "validThrough": "Jul 8, 2019 6:36:50 PM",
    "crawled": "Jul 2, 2019 11:45:44 PM",
    "content": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| \n<a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a>\n<p>Factual is currently hiring Software Engineers and Data Scientists, at all levels, in the Los Angeles office. Remote positions available for experienced candidates. Factual is the location data company that the world’s most valuable brands and technology companies trust to understand and intelligently grow their businesses. We help engineering teams, marketers and data analysts build the best digital products, deliver more impactful marketing and transform their businesses with the most accurate and comprehensive data on places and people worldwide.</p>\n<p>There are many challenging problems to work on at all layers of the stack: data cleaning and canonicalization, storage, deduping, serving, APIs, improving data using machine learning, etc. If you love data, Factual is the place to be. Experience with Clojure, machine learning, NLP, algorithm design, or Hadoop/Spark is a plus!</p>\n<p>You can email me personally at alexr@factual.com, or view our job postings here: <a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "CaLRhN5xQVmcfGYtz0FceQ",
    "url": "http://workinstartups.com/job-board/job/81986/junior-data-scientist-intern-at-nimbla/",
    "title": "Junior Data Scientist (Intern)",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=27, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nimbla",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 2, 2019 11:27:40 AM",
    "validThrough": "Jul 9, 2019 11:27:40 AM",
    "crawled": "Jul 2, 2019 1:06:34 PM",
    "content": "*Nimbla* provides a first of a kind invoice protection solution so that Britain’s SMEs continue to trade with confidence. We are building the future of small business protection, and are on high growth trajectory having just closed our first super seed round. A Barclays Techstars Alumni we have the backing from Munich RE, the world’s leading insurers’.\n<br>\n<br>Our future is bright, and we're looking for a talented Junior Data Scientist who wants the freedom to build something different and help us keep the thriving small business enterprise alive. This is the opportunity to help shape the direction of one of the most promising FinTech startups in the UK. We will count on you to make a significant contribution to our success and will support yours in the process.\n<br>\n<br>*About You*\n<br>You are an inquisitive, smart and numerate data scientist, who is looking to start their career at a fast-paced and exciting company. You have the opportunity to learn from and grow by working closely with some experienced data scientists working with large datasets to identify trends through clustering, classification and developing both your exploratory data analysis aswell as beginning to establish your knowledge through creating models and machine learning techniques.\n<br>\n<br>*You will:*\n<br>* Be Creative in your approach to solving problems\n<br>* Have strong problem-solving skills\n<br>* Seek continual learning and self-improvement\n<br>* Be an enthusiastic team player who enjoys collaborating across teams\n<br>* Be able to multitask in a dynamic, early-stage environment\n<br>* Have excellent communication skills\n<br>\n<br>*Your Experience:*\n<br>* Experience of developing in Python \n<br>* Interest in learning algorithms and data structures \n<br>* Knowledge of relational databases and SQL, particularly PostgreSQL \n<br>* Problem-solving skills, and the tenacity to resolve technical problems that you might not have seen before \n<br>* Research and decision-making skills, as you’ll need to decide where to focus your learning, and what to focus on \n<br>\n<br>*Bonus Points For:*\n<br>* Experience with visualisation software, Tableau, Seaborn etc\n<br>* Knowledge of Fin-Tech or Insur-Tech\n<br>\n<br>*At Nimbla We Believe In:*\n<br>* *Fairness:* \n<br>* For our customers: We aim to make Business a fairer place by protecting SMEs from bad debt.\n<br>* For our team: together, we create an environment in which everyone is comfortable developing within their roles and within the business.\n<br>\n<br>* *Learning:*\n<br>Aim to learn something new every day, big or small to grow personally and bring about positive change\n<br>\n<br>* *Creativity:*\n<br>We each strive to be creative, support innovation and wonderful experiences to our users\n<br>\n<br>* *Measuring performance more than time:*\n<br>This position is being offered on a flexible work-week basis with no compromise on salary\n<br>\n<br>* *Flexible working:*\n<br>We are based in the comfortable and trendy Rise London workspace, a stone’s throw from Silicon Roundabout. We will love to see you there, you will also have the opportunity to work remotely and balance your life and your work as works for you.\n<br>\n<br>*What You’d Expect*\n<br>* Full auto-enrollment workplace pension for all employees with 2% employer contribution.\n<br>* Comfortable and trendy Rise London workspace, a stone’s throw from Silicon Roundabout\n<br>* Unlimited coffee, tea and fruit every day\n<br>\n<br>*Work-life balance*\n<br>* Autonomy and empowerment: What matters is that the job gets done and that we help each other in accomplishing our vision and goals. Once the goals are set, how you achieve results is up to you.\n<br>* Radical Candour: We all want to grow, and we help each other do so by maintaining candid, open conversations, especially when it's hard. Be kind, and be opened and honest\n<br>* Dynamic working hours: We trust you to establish an effective working pattern that allows you to excel in your role. This includes working from home, of course.\n<br>* Dogs in the office.\n<br>* Daily talks and meet-ups presented in the building by the Barclays Innovation team.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kb0_IyW7SSmuvyNy2OV4gw",
    "url": "https://jobmote.com/job/46101/data-engineer-chicago-il-remote-200k-hands-on-exp-required/",
    "title": "Data Engineer- Chicago, IL-Remote-200k-Hands-on Exp. Required",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 10:07:13 PM",
    "validThrough": "Jul 8, 2019 10:07:13 PM",
    "crawled": "Jul 2, 2019 3:06:25 AM",
    "content": "<div>\n Job Description\n <br>\n <b>Data Engineer-</b> \n <b>Chicago, IL-Remote-200k-Hands-on Exp. Required</b>\n <br>\n <br>\n <b>Position:</b> Data Engineer\n <br>\n <b>Technology:</b> Big Data\n <br>\n <b>Location:</b> Chicago, IL\n <br>\n <b>Job Type:</b> Permanent\n <br>\n <br>*\n <b>Must be on hands-on*</b>\n <br>\n <b>About the Role:</b>\n <br> Ready to work with cutting edge technology filled with a great work environment where you will feel relaxed and excited to challenge yourself? Well it's a good thing you specialize in Azure Big Data! My client likes to hire those with a passion of excellence and a smart mind.\n <br> This role will include leading and participating in architecture, design and development of various components of the data's APM solutions.as well as build automated optimization solutions for Big Data workloads on cloud platforms like AWS, Azure, and Google Cloud.\n <br> The ideal candidate has experience in AWS (EMR, Redshift, Athena, Lambda, S3, Glue), Azure (HDI, Databricks), and/or GCP (Dataproc, BigQueries)!\n <br>\n <br>\n <b>Responsibilities, Skills, and Qualifications:</b>\n <ul>\n  <li>BS/CS, MS/CS or equivalent</li>\n  <li>5+ years of development experience in Big Data and related fields</li>\n  <li>Hands-on experience in the internals of one or more distributed systems like Athena, Redshift, Spark, Kafka, Bigquery, and AWS Lambda running on the cloud</li>\n  <li>Expert in programming with Java or Scala or Python</li>\n  <li>Experience with Apache Airflow a plus</li>\n  <li>Strong analytical and design skills</li>\n  <li>Ability to set and manage priorities judiciously</li>\n  <li>Excellent written, oral communication and interpersonal skills</li>\n  <li>Ability to articulate ideas to both technical and non-technical audiences</li>\n  <li>Exceptionally self-motivated and directed</li>\n  <li>Keen attention to detail</li>\n  <li>Superior analytical, evaluative, and problem-solving abilities</li>\n  <li>Ability to inspire others</li>\n </ul>\n <b>Benefits:</b>\n <ul>\n  <li>-Great pay</li>\n  <li>-Amazing work culture</li>\n  <li>-401k</li>\n  <li>-Health insurance</li>\n  <li>-Dental insurance</li>\n  <li>-Vision insurance</li>\n  <li>-Paid parental leave</li>\n  <li>-Generous paid time-off vacation time</li>\n  <li>-Maternity/Paternity leave</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling \n <b> (ext. 7598</b>\n <b>)</b>. I'm eagerly looking forward to helping you advance your career!\n <br>\n <br>\n <b>What's in it for you:</b>\n <br> These roles don't last long on the market. Be in touch quickly and I can place you with your desired job in a timely manner. Don't hesitate to achieve the better job you are looking for and want now. Please send your resume and I'm excited to meet with you. I am unlike other recruiters in that I thrive on building our relationship and making it more personal to ensure working together is a happy experience for you!\n <br> Nigel Frank International is the Global Leader in Microsoft Azure recruitment. We are a part of Frank Recruitment Group, one of the most successful global recruitment businesses in the last 10 years and backed by private equity firm TPG Growth.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "U7xvdyUaSregrCfERbeU3A",
    "url": "https://stackoverflow.com/jobs/271964/dev-advocate-developers-care-team-full-remote-heetch?a=1tcUFvIoeuA0",
    "title": "Dev Advocate - Developers Care Team - Full Remote in Europe at Heetch  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:generics/java/8",
      "DBG_TECH1:k/t/w:unity3d/gamedev/8",
      "DBG_TECH1:k/t/w:unity3d/mobile/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=5, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=8, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/gamedev",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "gamedev",
      "java"
    ],
    "hiringOrganization": {
      "name": "Heetch",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 1, 2019 5:06:24 PM",
    "validThrough": "Jul 8, 2019 5:06:24 PM",
    "crawled": "Jul 1, 2019 5:06:24 PM",
    "content": "<h3><span>Dev Advocate - Developers Care Team - Full Remote in Europe</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Carsharing, Marketplace, Transportation</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>51-200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>1</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Heetch | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n open-source\n</div>\n<div>\n github\n</div>\n<div>\n documentation\n</div>\n<div>\n microservices\n</div>\n<div>\n Charrette 325 5 22\n</div>\n<div>\n Asdine Staff engineer at Heetch 1.8k 11 9\n</div>\n<div>\n Abdelkader kouhli 1\n</div>\n<div>\n Guisch In Apprenticeship @ Heetch 3 2\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>⚠️<u>Read before applying:</u></strong></p>\n <p>We're a young company iterating over our remote culture so for now, we're only working with people in locations where the time zone is:&nbsp;<strong>-3 hours &gt; Paris time zone&nbsp;&lt;&nbsp;+3 hours</strong></p>\n <p><strong>Dev Care Experience @Heetch</strong></p>\n <p>The top priority of our developer-driven team is to improve the productivity of other developers in the company by spotting generic needs across teams and addressing them in the most impactful way. Whether this is done by introducing a new technology or designing a creative solution to a problem shared by various teams, it's done through carefully collected feedbacks, analysis and is delivered iteratively, following closely open-source methodologies.</p>\n <p>You can read more about our team on our <a href='https://eng.heetch.com/developer-care-3e22a4d7ff54' rel='nofollow'>blog</a>.</p>\n <p>From the inside, we're a caring team of engineers who share the same set of values:</p>\n <ul>\n  <li><strong>Transparency:</strong> We discuss everything openly.</li>\n  <li><strong>Team Unity:</strong> No one is left behind.</li>\n  <li><strong>Move Fast:</strong> No need to demonstrate for days, do it.</li>\n  <li><strong>Promulgate Knowledge:</strong> Whether it's organizational, cultural or technical, we're eager to learn!</li>\n  <li><strong>It's OK to fail:</strong> Succeed together, learn together.</li>\n </ul>\n <p><strong>What will be your role?</strong></p>\n <p>By joining the team, you'll be in charge of shaping the foundations of our technical writing team, by building with us a communication strategy that is both efficient and sustainable. Ultimately, you will enable software engineers to write publicly about their own work, write top-notch documentation and make communications both inside and outside the company better.</p>\n <p><strong>Does it sound like you?</strong></p>\n <ul>\n  <li>You have a strong and demonstrable ability to communicate well about software engineering: articles, presentation decks, technical docs, slack messages.</li>\n  <li>You've worked before as a software engineer: You might not be able to write professional software but you're able to write some scripts and automate things a bit.</li>\n  <li>You're familiar with open source, Github and software engineering in general.</li>\n  <li>You're able to collaborate and communicate on a global scale with multiple engineering teams to help figure out gaps in our tooling and infrastructure and help drive solutions.</li>\n  <li>You can work entirely remotely and are not afraid of going out over Slack to get answers from people.</li>\n  <li>You have some publicly available articles to showcase your ability to write.</li>\n </ul>\n <p><strong>What will you do?</strong></p>\n <ul>\n  <li>Build a communication strategy to enable all engineers to broadcast about their work</li>\n  <li>Write, review, study, analyse and steer technical documentation at team level than at the company level</li>\n  <li>Be responsible for all aspects related to writing documentation within the team</li>\n  <li>Absorb a huge quantity of knowledge while working with talented engineers that knows how hard good doc can be to write</li>\n  <li>Deliver a concrete plan on how to scale public communications related to tech</li>\n </ul>\n <p><strong>What will be our challenges together?</strong></p>\n <ul>\n  <li>Help engineers to write excellent engineering articles. Establish a writing pipeline, practices and guides to help everyone to get most of their thoughts into great and accessible content.</li>\n  <li>Build top-notch documentation for the other engineers to trust. Work with us to find a sustainable approach in maintaining those, through guidance, advising and advocating the need for good documentation.</li>\n  <li>Help engineers and other managers to collectively deliver public technical contributions, through talks, blog posts and tweets, in order to raise awareness about Heetch and develop its technical reputation.</li>\n  <li>Pave the way to a dedicated team of technical writers and developer advocate that will leverage her/his experience into building a team focused on helping other teams to take their communication to the next level.</li>\n  <li>Continuously learn through an extensive scope of technologies, from Docker to Event-Sourcing and Functional Programming to Data-Science algorithms.</li>\n </ul>\n <p><strong>What's next?</strong></p>\n <p>If your application is selected, the process will be composed of 4 steps:</p>\n <ol>\n  <li>Non-technical interview with the Engineering Manager of your potential team (1h30)</li>\n  <li>Take home assignment (~5 days deadline)</li>\n  <li>Interview with your future teammates (1h)</li>\n  <li>Day on site (Paris) to meet your future stakeholders</li>\n </ol>\n <p>Check out our<a href='https://eng.heetch.com/' rel='nofollow'>&nbsp;Engineering Blog</a>&nbsp;and follow our&nbsp;<a href='https://twitter.com/heetcheng' rel='nofollow'>twitter</a>&nbsp;:)</p>\n <p>You can also have a look at our open-source projects and contributions&nbsp;<a href='https://oss.heetch.com/' rel='nofollow'>here</a>.</p> \n</div> \n<div> \n <a href='https://jobs.lever.co/heetch/7f830d5c-bbe9-46c3-b00a-328f0cffc8a1?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'> Apply now </a>\n</div> \n<h4>About Heetch</h4> \n<div>\n <p>Heetch is a mobility app with a simple mission: We want people to enjoy going out.<br>Every night and every day, our drivers are doing their best to make their rides unforgettable and friendly! We are focused on young people's expectations and are competing within a fast-paced market.</p>\n <p>The service launched in Paris in September 2013 has been growing ever since, with thousands of daily rides in France, Belgium, and Morocco. With more than 1 million users in Europe, we are proud to be one of the fastest growing French startups!</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Full remote and flexible ways of working</span> </li> \n <li> <span></span> <span>Paid conferences attendance/travel</span> </li> \n <li> <span></span> <span>Code Retreat</span> </li> \n <li> <span></span> <span>2 company seminars</span> </li> \n <li> <span></span> <span>Travel budget to visit your co-workers</span> </li> \n <li> <span></span> <span>Heetch Credits</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9vMUVT6vSMOcK73upRzHcA",
    "url": "https://jobmote.com/job/45599/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:07:13 PM",
    "validThrough": "Jul 7, 2019 10:07:13 PM",
    "crawled": "Jul 1, 2019 3:06:24 AM",
    "content": "<div>\n Sr. Engineer - Product development?\n <br>\n <br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.\n <br>\n <br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.\n <br>\n <br>Check out our website below to learn more about what we do and how we help our clients.\n <br>\n <br>Primary Responsibilities:\n <br>\n <br>???????? Provide thought leadership in architecture, design for analytics products\n <br>\n <br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements\n <br>\n <br>???????? Lead cross functional product development efforts\n <br>\n <br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan\n <br>\n <br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines\n <br>\n <br>???????? Provide technical support to assist clients and partners during and post implementation\n <br>\n <br>???????? Manage development resources onsite and offshore\n <br>\n <br>???????? Develop and expand our application knowledge base and best practices for delivering data products\n <br>\n <br>Required Experience and Skills:\n <br>\n <br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem\n <br>\n <br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must\n <br>\n <br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must\n <br>\n <br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem\n <br>\n <br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills\n <br>\n <br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.\n <br>\n <br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture\n <br>\n <br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)\n <br>\n <br>???????? Experience with NoSQL databases\n <br>\n <br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.\n <br>\n <br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.\n <br>\n <br>???????? Experience in professional services or technical consulting with enterprise software solutions\n <br>\n <br>???????? Proven ability to balance and manage multiple, competing priorities.\n <br>\n <br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.\n <br>\n <br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.\n <br>\n <br>What We Offer:\n <br>\n <br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement\n <br>\n <br>???????? Global career mobility, employee recognition programs, professional development\n <br>\n <br>???????? State of the art technology which allows for seamless global connectivity\n <br>\n <br>???????? Rich wellness program and health incentives\n <br>\n <br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately\n <br>\n <br>#LI-RD1\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IxD9MgqvRZmmK3MmYxQ2eQ",
    "url": "https://jobmote.com/job/45591/aws-big-data-engineer-hadoop-python-remote/",
    "title": "AWS Big Data Engineer - Hadoop, Python - remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=6, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=76, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:07:13 PM",
    "validThrough": "Jul 7, 2019 10:07:13 PM",
    "crawled": "Jul 1, 2019 3:06:24 AM",
    "content": "<div>\n AWS Big Data Engineer - Hadoop, Python\n <br>\n <br>AWS Big Data Engineer\n <br>\n <br>Description:\n <br>\n <br>My client in Rockville, MD is looking to bring on a Big Data Engineer to lead the department for the full life cycle of a data migration project. The client is actively interviewing as the project is set to begin the first of September and they are looking to on board their senior leads in advance.\n <br>\n <br>This candidate will be able to manage their own team, participate in the full lifecycle of the migration, and help build out the organizations engineering department.\n <br>\n <br>Role &amp; Responsibilities:\n <ul>\n  <li>Closely working with cross-functional teams.</li>\n  <li>Building fact tables to facilitate quicker and easier data access.</li>\n  <li>Building indices at elastic Search to support real-time dash boards at Kabana, and building predictive models to support AI/ML.</li>\n </ul>Requirements:\n <ul>\n  <li>3+ years of relevant work experience </li>\n  <li>Working experience of Scala, Spark, building ATL query models.</li>\n  <li>Developing shell scripts and running Oozie/spark jobs on Hadoop platform</li>\n  <li>Hadoop platform work using Big Data tools.</li>\n  <li>Working experience on ElasticSearch and Kibana</li>\n </ul>Hadoop, Python\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "4Bzgj-9fQFW56aJXb0o3OA",
    "url": "https://jobmote.com/job/45578/data-engineer-architect-100-remote/",
    "title": "Data Engineer/Architect (100% remote)",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:07:12 PM",
    "validThrough": "Jul 7, 2019 10:07:12 PM",
    "crawled": "Jul 1, 2019 3:06:24 AM",
    "content": "<div>\n My client works in the Application Performance Management space, helping organizations accelerate the performance of their Big Data applications and clusters. They analyze these applications, identify root causes of issues, and provide solutions to fix them in fast and easy ways. They originated in 2013, have 100 employees, and are expanding RAPIDLY to keep up with their high demand and growth.\n <br> This candidate will lead and participate in architecture, design and development of various components of their APM solution, by building automated troubleshooting and tuning solutions for Big Data platforms. You will own the data ingestion in regards to applications, then and analyze the data and provide recommendations through algorithms\n <br> Required Skills:\n <br> - Big Data experience - at least 3 year's in a professional environment\n <br> - Hands on in-production experience in a Hadoop ecosystem, working with Spark &amp; Kafka\n <br> - Performance tuning in Cloud (AWS Athena, EMR, Redshift, etc)\n <br> - Hands on Java or Scala development\n <br> - Experience and willingness to be a hands-on individual contributor\n <br> This organization not only offers a very competitive salary, lucrative bonuses, and remote flexibility, but also have very inexpensive health benefits, unlimited PTO, and stock options for all employees! They are a smart team filling a big hole for companies in need, and are looking to hire the best and brightest in the area.\n <br> Job Type: Full Time\n <br>\n <br>To be considered for this role, please call me at or email me your most up-to-date resume at [Click Here to Email Your Resum?] .\n <br>\n <br>Jefferson Frank is the global leader for Amazon Web Services recruitment, advertising more AWS roles than any other agency. We deal with both AWS Partners &amp; End Users throughout North America. By specializing solely in placing candidates in the AWS market we have built relationships with most of the key employers in North America and have a complete understanding of where the best opportunities and AWS jobs are.\n <br>\n <br>Jefferson Frank is acting as an Employment Agency in relation to this vacancy.\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xL6f-z22QyiWU2xjD2Cf9A",
    "url": "https://jobmote.com/job/45576/senior-aws-data-engineer-utah-remote-flex-135k-bonus/",
    "title": "Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:07:12 PM",
    "validThrough": "Jul 7, 2019 10:07:12 PM",
    "crawled": "Jul 1, 2019 3:06:24 AM",
    "content": "<div>\n Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus \n <br> A SaaS based organization that has a product hosted on AWS and looking to hire for a senior level AWS Engineer. The company has their own product to help companies with supply chain, sales, planning and other operations\n <br> Product is hosted on AWS - have developers internally writing the code, they deploy it, use a lot of different open source technologies, all of which is hosted on EC2 instances, they use Amazon built in offerings for RDS and elasticash to use their Redis instances.\n <br> Main requirement is that candidates must understand the business side of the data and load it into their tool for these companies for their behalf. \n <br> AWS Requirements:\n <ul>\n  <li>Redshift</li>\n  <li>EC2</li>\n  <li>S3</li>\n  <li>Hive</li>\n  <li>Lambda</li>\n  <li>EMR</li>\n  <li>DynamoDB</li>\n  <li>Kinesis</li>\n  <li>Glue</li>\n  <li>Athena</li>\n  <li>SQL</li>\n </ul> If you or someone you know is interested in this position, please send your resume directly to [Click Here to Email Your Resum?] or call .\n <br>\n <br>Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.\n <br>\n <br>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.\n <br>\n <br>Utah/Big Data/ Engineering/ SaaS/ Analytics/ AWS/ Amazon web Services/ Remote/ Data/ Salt Lake Ciity/ Highland/ Provo/ Lehi\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0qLPsPRYQA6FrnUNl9bI3w",
    "url": "https://jobmote.com/job/45566/remote-voip-telecom-engineer/",
    "title": "Remote VoIP/Telecom Engineer",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=1, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Ledgent Technology",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:07:12 PM",
    "validThrough": "Jul 7, 2019 10:07:12 PM",
    "crawled": "Jul 1, 2019 3:06:24 AM",
    "content": "<div>\n Our client is looking for a Sr. VoIP/Telecom Engineer to join their growing team! They are a growing local startup searching for top talent to grow with them.\n <br>\n <br>This is a direct hire opportunity.\n <br>\n <br>\n <b>What they are looking for:</b>\n <ul>\n  <li>Asterisk experience is a must!</li>\n  <li>Ability to build components in Asterisk and/or FreeSwitch and develop custom telecom applications</li>\n  <li>Previous programming experience highly desired</li>\n  <li>Strong understanding of VoIP Calls and troubleshooting</li>\n  <li>Any experience with?OpenSips, Kamailio is a plus</li>\n </ul>\n <b>?What they offer:</b>\n <ul>\n  <li>Excellent benefits! Including above average PTO, 401(k) Match, 100% medical coverage</li>\n  <li>Startup atmosphere - team oriented and encouragement to grow your skill set</li>\n  <li>Competitive?Pay</li>\n  <li>Paid Parking</li>\n </ul>We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.\n <br>Experience with Asterisk and/or FreeSwitch\n <br>Extensive knowledge of VoIP and SIP\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "p8DBCKszT9u_R0MsIMw6nw",
    "url": "https://www.remotepython.com/jobs/91a110e35ffc4e39b7012f68d4242d80/",
    "title": "Data Scientist / Machine Learning Engineer at Joust",
    "tags": [
      "DBG:surround``OR(we’r, we) 4W OR(distribut,scatter,remot,virtual) 4W OR(compani,team,OR(organ,organis))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Joust",
      "sameAs": "https://www.joust.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 10:32:10 PM",
    "validThrough": "Jul 7, 2019 10:32:10 PM",
    "crawled": "Jun 30, 2019 10:32:10 PM",
    "content": "<h3>Data Scientist / Machine Learning Engineer</h3>Denver, Colorado, United States\n<br>Company: Joust\n<br>Job Type:&nbsp;Full-time\n<div> \n <div> \n </div> \n <p></p>\n <p>Joust is a venture backed startup with a mission to make finances easier for freelancers and entrepreneurs. Given the state of banking in the US, it's a serious challenge. But with an amazing team and a revolutionary product we are making a serous dent. As a risk expert at Joust you will be at the core of the solution and your actions will have direct impact on our customers' lives and livelihoods.</p>\n <p>The role requires you to:</p>\n <p>- Be a team player. <br>- Embrace the startup lifestyle (both the upside and downside). <br>- Thrive in uncertain fast-paced environments. <br>- Be courageous in diving into greenfield problem sets. <br>- Take action with minimal directions. <br>- Own your domain and be assertive. <br>- Be thoughtful, analytical, and open minded. <br>- Maintain subjectivity.</p>\n <p>You will report directly to the CEO and COO.</p>\n <p>What you will do:</p>\n <p>- Drive innovation for the risk industry through analytics, data science and test-and-learn. <br>- Assist engineers in creating tools and processes to monitor the effectiveness and impact of our risk systems. <br>- Design, develop and deploy large scale, big data-driven machine learning models that are integrated with key product features. Some examples of potential projects include: <br>- Look-alike modeling algorithms that determine a user’s propensity to take an action in the future. <br>- Multivariate testing framework that empirically evaluates the efficacy of product enhancements as quickly as possible. <br>- Collaborate with Engineering, Product, and Analytics leads to establish analytic standards and platforms that scale and can be leveraged in various initiatives throughout the organization <br>- Ensure that testing and validation is a pervasive component of data science and machine learning solutions</p>\n <p>What you should have:</p>\n <p>- Knowledge of advance quantitative techniques and a rigorous, data-driven approach to problem-solving. <br>- Experience in risk modeling or economic analysis. <br>- A degree in computer science, statistics, econometrics, operations research, mathematics, data science, engineering, or a related quantitative field of study. <br>- Comfort with complex technologies and a conceptual grasp of systems engineering.</p>\n <p>Although we prefer our team to reside in Austin TX, we will gladly accommodate remote work. The Joust team is proud of our varying backgrounds, education levels, and world views. We value diversity and prefer nonconformists.</p>\n <p></p> \n <h4>Desired Skills</h4> \n <ul> \n  <li><span>Data Science</span></li> \n  <li><span>Machine Learning</span></li> \n </ul> \n <h4>Contact Info</h4> \n <ul> \n  <li><strong>Company Website:</strong> <a href='https://www.joust.com/' rel='nofollow'>https://www.joust.com/</a></li> \n </ul> \n</div>\n<a href='https://angel.co/company/joust-banking/jobs/576229-data-scientist-machine-learning-engineer' rel='nofollow'>Apply</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NSVmxrGkRQ2ZuRrCbppiOg",
    "url": "https://stackoverflow.com/jobs/270191/senior-back-end-engineer-loadsmart?a=1sC2Zue0CRpe",
    "title": "Senior Back End Engineer at Loadsmart (Florianópolis, Brazil) ",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:less/frontend/10",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=26, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=10}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Loadsmart",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 3:06:25 AM",
    "validThrough": "Jul 7, 2019 3:06:25 AM",
    "crawled": "Jun 30, 2019 3:06:25 AM",
    "content": "<h3><span>Senior Back End Engineer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Backend Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Logistics &amp; Distribution</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11-50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>3</span> \n   <span>0</span> \n   <span>0</span> \n   <span>2</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Loadsmart | Florianópolis, Brazil\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Office Location:</span> \n   <span>Florianópolis, Brazil.</span> \n   <span>Employees can also work full time from this office.</span> \n  </div> \n  <div> \n   <span>Relocation Assistance:</span> \n   <span>Yes</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n algorithm\n</div>\n<div>\n machine-learning\n</div>\n<div>\n amazon-web-services\n</div>\n<div>\n backend\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Who we are:</strong></p>\n <p>Loadsmart aims to move more with less. We combine great people and innovative technology to more efficiently move freight throughout North America.</p>\n <p>Our focus is on designing and building the best tools for our team and our customers, using machine learning models to connect freight with trucks. We automate with algorithms and scale with integrations to better match supply and demand. In doing this we reduce wasted fuel and lost time, cutting out empty miles for motor carriers and providing cost savings and instant booking for shippers.</p>\n <p><strong>Who you are:</strong></p>\n <p>You believe in game-changing innovations and are excited about reimaging a 700 billion dollar industry.&nbsp; You take your impact seriously.&nbsp; You are passionate about building solutions that create sustainable, resilient, long-lasting value. You are a first-rate software engineer, with experience and a proven ability to think strategically, creatively, commercially, programmatically.</p>\n <p><strong>The role:</strong> We are looking for a Senior Python Back End Engineer to work at our office in Florianopolis. &nbsp;You'll join us in obsessing about transformational technology as part of our backend team. You should have experience and a ability to use experimental ideas to develop new solutions, build new products, and create new concepts. You will be part of our Pricing Data Science team having a strong interface with machine learning.</p>\n <p>***Because we are an international company, we only accept resumes in English.</p>\n <p><strong>Key Responsibilities:</strong></p>\n <ul>\n  <ul>\n   <li>Roll up your sleeves and develop code from day one</li>\n   <li>Develop and improve product features within the engineering and data science teams</li>\n   <li>Actively contribute to and support the design, deployment, and maintenance of critical systems</li>\n   <li>Partner with and support all members of our creative, tight-knit team</li>\n   <li>Exercise your intuitive ability for creative problem solving and contagious positive passion to solve challenging and exciting problems and inspire those around you</li>\n   <li>Move seamlessly from high-altitude thinking to the tangible and practical as a productive member of a lean software development team</li>\n  </ul>\n </ul>\n <p><strong>Qualifications:</strong></p>\n <ul>\n  <ul>\n   <li>You’re fluent in English (both written and spoken) and native Portuguese</li>\n   <li>Programming experience with Python, knowledge of Go is a plus</li>\n   <li>Experienced with Linux and Git</li>\n   <li>Experience with Machine Learning algorithms and data analysis is a plus</li>\n   <li>Experience with testing your own development code</li>\n   <li>Experience with relational databases (MySQL and PostgreSQL), columnar databases (Vertica, Redshift, Greenplum) a plus</li>\n   <li>BS or MS in Computer Science or related field is a plus, but not mandatory</li>\n   <li>Minimum of 5 years working with software programming</li>\n  </ul>\n </ul>\n <p>At Loadsmart, we believe our biggest asset is our people. We are proud to be an equal opportunity employer, hiring and developing individuals from diverse backgrounds and experiences to add to our collaborative culture. Loadsmart treats all candidates and employees with respect and does not discriminate in our recruiting, hiring, and promoting processes, including on the basis of race, color, religion, sex, age, sexual orientation, gender identity and/or expression, national origin, veteran status, or disability</p> \n</div> \n<div> \n <a href='https://jobs.lever.co/loadsmart/595290d2-ee38-4716-a488-807525c04144/apply' rel='nofollow'> Apply now </a>\n</div> \n<h4>About Loadsmart</h4> \n<div>\n <p>Loadsmart aims to move more with less. We combine great people and innovative technology to more efficiently move freight throughout North America. Our focus is on designing and building the best tools for our team and our customers, using machine learning algorithms to connect cargo with trucks. By better matching supply and demand, we reduce wasted fuel and lost time, cutting out empty miles for motor carriers and providing instant booking for shippers. &nbsp;</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Generous Stock Option Plan</span> </li> \n <li> <span></span> <span>Competitive Salary</span> </li> \n <li> <span></span> <span>Building a rapidly-growing tech company</span> </li> \n <li> <span></span> <span>International environment/career</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YnXXDMhoThyKOMajAU2mfw",
    "url": "https://stackoverflow.com/jobs/270057/senior-data-engineer-powerinbox?a=1szgf9TSxZjW",
    "title": "Senior Data Engineer at PowerInbox (New York, NY) ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 9W 4N( OR(offic,onsit), time)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:boost/c/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "PowerInbox",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 120000,
      "info": "Equity",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 90k - 120k /Year | Equity"
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 3:06:25 AM",
    "validThrough": "Jul 7, 2019 3:06:25 AM",
    "crawled": "Jun 30, 2019 3:06:25 AM",
    "content": "<h3><span>Senior Data Engineer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>System Administrator</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Ad Tech, Adserver, Email Marketing</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11-50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>VC Funded</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>2</span> \n   <span>1</span> \n   <span>1</span> \n   <span>0</span> \n   <span>0</span> \n   <span>2</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: PowerInbox | New York, NY\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-05:00) Eastern Time </span> \n  </div> \n  <div> \n   <span>Office Location:</span> \n   <span>New York, NY.</span> \n   <span>Employees can also work full time from this office.</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n sql\n</div>\n<div>\n r\n</div>\n<div>\n bigdata\n</div>\n<div>\n database\n</div>\n<div>\n Julien VP Engineering at PowerInbox, and Engine developer at ScummVM 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>PowerInbox is looking for a Senior Data Engineer</strong></p>\n <p>*This job is fully remote (only in the USA, though) with the option to work from out NYC office*</p>\n <p><strong>If you join us, what will you do?</strong></p>\n <p><span>Build and maintain a real-time big data pipeline and reporting system for power</span><strong>inbox</strong><span>. The data pipeline will feed our AI and analytics platform. The reporting system will automatically distribute reports to recipients on a configurable schedule. As needed, you will provide special reports as requested by sales and operations teams. This role offers opportunities to work with big data, data science, cloud computing, and the latest software technology.</span></p>\n <p><em><span>Specific Goals</span></em></p>\n <ul>\n  <li><span>Build and maintain a data pipeline for power</span><strong>inbox</strong><span> machine learning.</span></li>\n  <li><span>Assist with the development of a data warehouse on which reports are derived.</span></li>\n  <li><span>Process 8 billion event transactions each month.</span></li>\n  <li><span>Assure data is captured and stored without loss.</span></li>\n  <li><span>Write code to provide reports for powerinbox.</span></li>\n  <li><span>Write a system that will run reports on a configurable schedule.</span></li>\n  <li><span>Increase revenue per 1,000 items by $0.10 each quarter.</span></li>\n  <li><span>Respond to ad-hoc requests for information.</span></li>\n </ul>\n <p><strong>In order to be great at your job,</strong></p>\n <p><em><span>You Are</span></em></p>\n <p><span>A fast learner; have great analytical skills; relentless and persistence in accomplishing goals; enthusiastic with an infectious personality.</span></p>\n <p><em><span>You Work</span></em></p>\n <p><span>Efficiently; with flexibility; proactively; with attention to detail; to high standards.</span></p>\n <p><em><span>Together We</span></em></p>\n <p><span>Emphasize honesty and integrity; require teamwork; have open communication; follow-through on commitments; stay calm under pressure.</span></p>\n <p><em><span>You Have</span></em></p>\n <p><span>Four to six years experience with Python or R; three or more years experience developing and deploying software on Linux; three or more years working with SQL; at least two years experience providing data analysis; professional experience with data science knowledge; and working knowledge of BI tools and software.</span></p>\n <p><strong>This is extra, but if you have it, it will make us happy</strong></p>\n <ul>\n  <li><span>Experience working remotely</span></li>\n  <li><span>Knowledge of/interest in the digital and AdTech landscape</span></li>\n  <li><span>Experience working with big data </span></li>\n </ul>\n <p><strong>About PowerInbox</strong></p>\n <p><em><span>Who We Are</span></em></p>\n <p><span>We are a digital monetization startup ecosystem that is always open to new talent</span></p>\n <p>&nbsp;<em><span>Why We Are</span></em></p>\n <p><span>Personalization is key and we at PowerInbox believe that email is not meant to be stationary and static, but relevant and filled with dynamic content and advertisements.</span></p>\n <p><em><span>What We Are</span></em></p>\n <p><span>We at PowerInbox boost your revenue and brand engagement through real-time advertising, and native ad displays. </span></p>\n <p>&nbsp;<span>If interested please send your resume to <a href='mailto:hr@powerinbox.com' rel='nofollow'>hr@powerinbox.com</a></span></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/270057?reset=False&amp;ra=1szgf9TSxZjW&amp;oqs=a%3D1szgf9TSxZjW' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About PowerInbox</h4> \n<div>\n <p>We are an award-winning, profitable startup with a unique culture and a great benefits package. Our engineering team works remotely from all around the US, with the option to come in and work from our NYC office. On top of fully remote, other benefits include unlimited vacation days, 100% health benefits, 401K match and company stock options. Check us out here-&nbsp;<a href='https://powerinbox.com/thepeople' rel='nofollow'>https://powerinbox.com/thepeople</a></p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Remote Working</span> </li> \n <li> <span></span> <span>Flat Organization structure</span> </li> \n <li> <span></span> <span>401K Match</span> </li> \n <li> <span></span> <span>No politics</span> </li> \n <li> <span></span> <span>Unlimited PTO</span> </li> \n <li> <span></span> <span>Bias for action</span> </li> \n <li> <span></span> <span>Health Benefits 100% cover</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MhC7fTZ7TpOlNIpbnsFvow",
    "url": "https://stackoverflow.com/jobs/273813/data-scientist-a-mediocre-corporation?a=1tPmk35Gf62A",
    "title": "Data Scientist at a mediocre corporation  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:pandas/python/10",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=14, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=64, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "a mediocre corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 3:06:25 AM",
    "validThrough": "Jul 7, 2019 3:06:25 AM",
    "crawled": "Jun 30, 2019 3:06:25 AM",
    "content": "<h3><span>Data Scientist</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>2</span> \n   <span>0</span> \n   <span>0</span> \n   <span>1</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: a mediocre corporation | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div>\n python\n</div>\n<div>\n pandas\n</div>\n<div>\n data-science\n</div>\n<div>\n sql\n</div>\n<div>\n data-modeling\n</div> \n<h4>Job description</h4> \n<div>\n <p>A Mediocre Corporation is looking for extraordinary <strong>Data Scientists</strong> to work alongside our teams in order to provide analytical support to a variety of projects (for example: email targeting, business optimization, customer recommendations). You’ll be responsible for conducting advanced statistical analysis and working with cross functional teams of technical and non-technical members to help drive innovative business solutions. If this doesn’t sound like the most mediocre job in data science then we’d like to talk to you. But only if you’re an amazing rock star, or a ninja, or a zombie hunter, or whatever term all the cool recruiters are throwing around these days.</p>\n <p>You can expect to conduct statistical analysis of big data sets to identify trends and provide actionable insights. You’ll be asked to measure the performance and results of various data experiments. You’ll also be working with our engineering team to help define and manage our big data infrastructure and to develop new products (including assisting with data architecture and modeling).</p>\n <p>You’ll be expected to research new trends in the industry and utilize up-to-date technology and analytical skills to attack each project. Ideal candidates are those that have experience moving data projects forward by acquiring and converting data into useful formats when necessary.</p>\n <p>We’re looking for someone who has:</p>\n <ul>\n  <li>Years of experience as a Data Scientist working closely with business stakeholders to give actionable insights.</li>\n  <li>Strong coding ability in Python, including experience with various data science libraries such as pandas.</li>\n  <li>Experience with a variety of data stores and technologies such as PostgreSQL, MongoDB, and InfluxDB.</li>\n  <li>Experience working with large data sets and distributed computing tools.</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/273813?reset=False&amp;ra=1tPmk35Gf62A&amp;oqs=a%3D1tPmk35Gf62A' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About a mediocre corporation</h4> \n<div>\n <p>Do you remember Woot? We built that and sold it to Amazon. Now we're on to more mediocre sites, like <a href='https://meh.com' rel='nofollow'>meh.com</a>, <a href='https://casemates.com' rel='nofollow'>casemates.com</a>, <a href='https://mediocritee.com' rel='nofollow'>mediocritee.com</a>,&nbsp;<a href='https://morningsave.com' rel='nofollow'>morningsave.com</a>, and <a href='https://sidedeal.com' rel='nofollow'>sidedeal.com</a>.</p> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "s4qcpQrYQouEFStnrwI1Ww",
    "url": "https://stackoverflow.com/jobs/163486/remote-data-scientist-masters-or-phd-required-surge?a=SPllvgdKtAQ",
    "title": "REMOTE Data Scientist, Masters or PhD Required at Surge  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=6, other=1, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=47, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Surge",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 3:06:25 AM",
    "validThrough": "Jul 7, 2019 3:06:25 AM",
    "crawled": "Jun 30, 2019 3:06:25 AM",
    "content": "<h3><span>REMOTE Data Scientist, Masters or PhD Required</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Software Development</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>201-500 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>1</span> \n   <span>1</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Surge | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n amazon-web-services\n</div>\n<div>\n python\n</div>\n<div>\n tableau\n</div>\n<div>\n hadoop\n</div>\n<div>\n reporting-services\n</div> \n<h4>Job description</h4> \n<div>\n <p>Surge Forward is looking for smart, self-motivated, experienced, senior-level consultants who enjoy the freedom of telecommuting and flexible schedules, to work as long-term, consistent (40 hrs/week) independent contractors on a variety of software development projects.</p>\n <p>Requirements:</p>\n <p>- Advanced degree (M.S. or Ph.D.) in Engineering, Math, Finance, Computer Science, Physics<br>- OR related industry experience for 2-5 years in production/client-facing environments, with a focus on analytic products and projects with a Bachelors in Engineering, Math, Finance, Computer Science, Physics<br>- Able to write SQL scripts and dialects for analysis and reporting<br>- Experience using one or more programming languages including Python<br>- Experience with Cloud Platforms including AWS<br>- Strong experience in Excel<br>- Experience with big data: processing, filtering, and presenting large quantities (100K to Millions of rows) of data<br>- Manipulate spreadsheets with Python or another scripting language<br>- Experience with Tableau or other visualization tools<br>- Experience with statistical tools (e.g. R) and analysis, regression modeling and forecasting, time series analysis<br>- Experience deploying and integrating into production systems and data-driven products<br>- Strong communication skills and ability to multi-task</p>\n <p>- PST preferred<br>- Will require a 30-45 min test and tech interview (likely different for this position)</p>\n <p><br>Preferred Qualifications:<br>- Experience in advanced machine-learning methodologies including supervised and unsupervised learning<br>- Experience with clustered data processing including Hadoop, Spark, Map-reduce, Hive<br>- Experience using programing languages Scala and Bash<br>- End-to-end experience designing and deploying</p>\n <p><strong>Only candidates located in the immediate area&nbsp;can be considered at this time. Sorry, No Visas.</strong></p>\n <p><strong>Resume must include the tech stack under each job&nbsp;directly on the resume in order to be considered.</strong></p>\n <p>For immediate consideration, email resume and include your cell phone number and start date: <a href='mailto:jobs@surgeforward.com' rel='nofollow'>jobs@surgeforward.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/163486?reset=False&amp;ra=SPllvgdKtAQ&amp;oqs=a%3DSPllvgdKtAQ' rel='nofollow'>Apply now</a>\n</div> \n<h4>About Surge</h4> \n<div>\n <p>Surge is an onshore provider of custom web, cloud, mobile, digital, and desktop software development and consulting services to clients in every industry, from hot startups to Fortune 500 companies.<br><br>Founded in 2007, and listed on the Inc. 5000 list of America’s fastest growing companies for five straight years, Surge has successfully delivered hundreds of software products, apps, and solutions to its clients using a proven agile/scrum development process combined with an elite group of North American software professionals.<br><br>Simply put, Surge offers America’s best software engineers, on demand, at rates 30-50% less than the competition.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Great Pay</span> </li> \n <li> <span></span> <span>Choose Your Hours</span> </li> \n <li> <span></span> <span>Work From Home</span> </li> \n <li> <span></span> <span>Work With Happy People</span> </li> \n <li> <span></span> <span>Zero Commute</span> </li> \n <li> <span></span> <span>See Your Family More</span> </li> \n <li> <span></span> <span>Travel While You Work</span> </li> \n <li> <span></span> <span>Software Provided</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "nmr-m4V3S1WerYDKlAS0xA",
    "url": "https://stackoverflow.com/jobs/269679/senior-software-engineer-spark-nagarro?a=1sroWrwpht3a",
    "title": "Senior Software Engineer - Spark at Nagarro  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=21, ruby=0, apple=0, java=7, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/West"
    ],
    "tagsNames1": [
      "US Pacific time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nagarro",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jun 30, 2019 3:06:25 AM",
    "validThrough": "Jul 7, 2019 3:06:25 AM",
    "crawled": "Jun 30, 2019 3:06:25 AM",
    "content": "<h3><span>Senior Software Engineer - Spark</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Backend Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Agile Software Development, Computer Software, Information Technology</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>5k-10k people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div> \n <h4>Reactions to this job</h4> \n <div> \n  <div> \n   <span>1</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n   <span>0</span> \n  </div> \n </div> \n <div> \n  <div> \n   <div> \n    <div></div> \n   </div> \n   <div> \n    <strong>New!</strong> How do you feel about this job listing? \n   </div> \n   <div> \n   </div> \n  </div> \n </div> \n <div></div>\n</div>\n<div>\n Company: Nagarro | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-08:00) Pacific Time +/- 8 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n apache-spark\n</div>\n<div>\n java\n</div>\n<div>\n hadoop\n</div>\n<div>\n Aman Shankhdhar 11 2\n</div>\n<div>\n Akash Bajaj 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Required experience and skills:</strong>&nbsp;</p>\n <ul>\n  <li>Expertise in Java or Scala</li>\n  <li>Familiarity with cluster computing technologies such as Apache Spark or Hadoop MapReduce</li>\n  <li>Familiarity with relational and big data such as Postgres, HDFS, Apache Kudu and similar technologies</li>\n  <li>Strong skills in analytic computing and algorithms</li>\n  <li>Strong mathematical background, including statistics and numerical analysis</li>\n  <li>Knowledge of advanced programming concepts such as memory management, files &amp; handles, multi-threading and operating systems.</li>\n  <li>Passion for finding and solving problems</li>\n  <li>Excellent communication skills, proven ability to convey complex ideas to others in a concise and clear manner&nbsp;</li>\n </ul>\n <p><strong>Desirable experience and skills:</strong>&nbsp;</p>\n <ul>\n  <li>Familiarity with scripting languages such as Python or R</li>\n  <li>Experience in performance measurement, bottleneck analysis, and resource usage monitoring</li>\n  <li>Familiarity with probabilistic and stochastic computational techniques</li>\n  <li>Experience with data access and computing in highly distributed cloud systems</li>\n  <li>Prior history with agile development</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/269679?reset=False&amp;ra=1sroWrwpht3a&amp;oqs=a%3D1sroWrwpht3a' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Nagarro</h4> \n<div>\n <p><strong>Unlike most IT vendors who use commodity engineers to address each project in the same way, Nagarro’s intelligent and passionate experts help leading technology ﬁrms address complex, multi-disciplinary challenges in innovative, cost-effective and game-changing ways. Our customers rely on us to keep pace with new expectations, new possibilities and new competitors because the world is changing faster every day.&nbsp;<br></strong></p>\n <p><strong>SERVICE OFFERINGS &amp; EXPERTISE</strong></p>\n <p><strong>Application Development</strong></p>\n <p>Agile application development is at the core of Nagarro’s DNA, our team help our clients build next-gen software solutions and business critical systems.</p>\n <p><strong>Independent Testing &amp; Validation</strong></p>\n <p>Driven by our PROVEN testing methodology, our IV&amp;V experts use automation tools as an integral part of the test strategy to ensure high quality software.</p>\n <p><strong>Cloud Services and Security</strong></p>\n <p>Nagarro’s Cloud &amp; Security CoE can help you deﬁne and execute a sound cloud strategy, helping you navigate complex compliance and security challenges with ease.</p>\n <p><strong>User Experience</strong></p>\n <p>Our team of UX specialists‚ designers and thinkers help drive user delight by crafting user-centric experiences.&nbsp;</p>\n <p><strong>Product Engineering</strong></p>\n <p>Our experts partner with some of the world’s leading software product companies to create cutting-edge consumer and enterprise software.&nbsp;</p>\n <p><strong>SUCCESS STORIES</strong></p>\n <p><strong>Innovation partner to a leading European bank</strong></p>\n <p>Nagarro has delivered 50+ turnkey projects through a secured development center set up dedicatedly for the client. The solutions encompass a wide spectrum including mobile banking, net banking, telebanking, social media analytics and legacy transformation and modernization.&nbsp;</p>\n <p><strong>Calendar application for mobile and wearables&nbsp;</strong></p>\n <p>Nagarro offers product co-development services to a leading provider of cloud-based conferencing solutions. A calendar application has been developed for both mobile and wearables which helps users to schedule, view and edit events by synchronizing with multiple calendar services. This application won the best wearable app of 2015 in the “Business Tools” category.</p>\n <p><strong>Process analytics to help optimize jet engine manufacturing</strong></p>\n <p>Nagarro helps stabilize the complicated manufacturing of composite fan blades for commercial jet engines with a unique process analytics solution that uses advanced statistical models and approaches. Installed at ﬁve global sites, this system helps cement the client’s industry leadership.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Regular workshops &amp; webinars</span> </li> \n <li> <span></span> <span>Meetups, events, hackathons</span> </li> \n <li> <span></span> <span>Work-life balance</span> </li> \n <li> <span></span> <span>Technology groups to share best practices</span> </li> \n <li> <span></span> <span>Client on-site exposure</span> </li> \n <li> <span></span> <span>Global set-up</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  }
]
}
