{
 "items": [
  {
    "id": "wEBfob96QG2mf1xCFNhZtA",
    "url": "https://www.remoteage.com/remote-jobs/big-data-engineer-telecommute/",
    "title": "Big Data Engineer – Telecommute",
    "tags": [
      "DBG:surround``3N(telecommut, posit) NOT fulltim",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UnitedHealth Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 15, 2019 4:03:07 PM",
    "validThrough": "Sep 22, 2019 4:03:07 PM",
    "crawled": "Sep 15, 2019 4:07:20 PM",
    "content": "<h3>            Big Data Engineer – Telecommute        </h3><div>United States, Illinois</div><div>Company: UnitedHealth Group<p></p></div><div>                    <h4>Overview</h4>                    <p>Challenge brings out the best in us. It also attracts the best. That’s why you’ll find some of the most amazingly talented people in health care here. Bring your skills and talents to a role where you’ll have the opportunity to make an impact on a huge scale. This is the place to do your life’s best work.(sm)You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities:Design, code, test, document, and maintain high-quality and scalable analytic solutionsIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze customer requirements with respect to current solutionMake accurate development effort estimates to assist management in project and resource planningParticipate in code reviews and assistance for junior analysts Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production supportKeep skills up to date through ongoing self-directed trainingThe ideal candidate will be a self-starter who can learn things quickly who is enthusiastic, active, and eager to learn.</p><p><b>Required Qualifications:</b>Bachelor’s degree in a technical field, or equivalent experience5+ years of hands-on Software Development experience3+ years of development experience with (Java or Scala), and Web Services2+ years of experience in big data technologies like Spark, Cassandra, Hadoop, etc2+ years of experience in messaging (Kafka preferred), NoSQL databases (Cassandra/Hbase preferred), Docker, Kubernetes 2+ years of previous relational database experience Understanding of service oriented architecture (SOA) conceptsExperience with Agile/SCRUM methodology/best practices Experience and successful track-record of learning new tools and technologies and leveraging these on integration and implementation projects Preferred Qualifications:Experience in infrastructure services on at least one major cloud platform (Azure preferred)Advanced degree in a technical field Healthcare industry experience Formal training and/or certification in any of the above-mentioned tools and technologies Careers with Optum. Here’s the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world’s large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life’s best work.(sm)*All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.Job Keywords: Big Data Analyst, telecommute, telecommuter, telecommuting, work from home, travel, remote</p><p><b>Job Title: </b> Big Data Engineer – Telecommute <br><b>Shift: </b> Day Job <br><b>Travel: </b> No <br><b>Business: </b> OI Business Operations <br><b>Family: </b> Analytics <br><b>Telecommuter Position: </b> Yes <br><b>Job Level: </b> Individual Contributor <br><b>Overtime Status: </b> Exempt <br><b>Posted Date: </b> 9/13/2019 <br><b>City: </b> Schaumburg <br><b>State: </b> IL <br><b>Country: </b> United States <br><b>Department: </b> Optum Enterprise Analytics<br> – provided by Dice</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?UzBlbx50%2fHeRIrhxRYDdrwk' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Es5BMtzoQfKjJiqVseF03Q",
    "url": "https://jobmote.com/job/73744/remote-data-engineer/",
    "title": "Remote Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "VirtualVocations",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 14, 2019 1:15:35 PM",
    "validThrough": "Sep 17, 2019 1:15:35 PM",
    "crawled": "Sep 14, 2019 6:23:02 PM",
    "content": "<div>A web design company is filling a position for a Remote Data Engineer.<br><br>Must be able to: <br> Design and implement sophisticated data pipelines<br> Build a computing platform to support data driven analytics<br> Design and implement real-time analytics streams<br>Qualifications Include:<br><br> 2-5 years' experience as a data engineer designing and supporting data pipelines<br> Experience with big data infrastructure to support data science on Linux based systems<br> Knowledge of the ETL process and patterns of real time data pipelines<br> Experience with Apache Spark and Kafka<br> Working knowledge of Python, Java, or Scala<br> Ability to allocate work with cloud based AWS resources<br> Associated topics: data architect, data engineer, data integration, data management, database, database administrator, etl, erp, mongo database administrator, teradata</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "EYLXIQdHRhyxWwyToF77cA",
    "url": "https://jobmote.com/job/72714/sr-data-engineer-remote-position/",
    "title": "Sr. Data Engineer (Remote Position)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:com/dotnet/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Primesoft, Inc",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 13, 2019 10:07:38 PM",
    "validThrough": "Sep 16, 2019 10:07:38 PM",
    "crawled": "Sep 14, 2019 3:06:24 AM",
    "content": "<div><p> <strong>Role</strong>: Sr. Data Engineer</p> <p> <strong>Location</strong>: Stamford, CT</p> <p> <strong>Exp:</strong> 9+ Yrs</p> <p> <strong>MOI</strong>: Skype</p> <p> <strong>Position:</strong> Remote</p> <p> <strong>Technologies:</strong> Spark, Kafka, AWS, Python</p> <p> <strong>Description:</strong></p> <ul><li> <strong>9+ years</strong> of hands-on <strong>Data Engineering</strong> with a focus on low latency Streaming and analysis.</li> <li> <strong>4+ years</strong> of experience building low-latency production systems applying big data and cloud technologies (e.g. HDFS, Storm, Spark, Kafka, Amazon AWS, REST, etc.).</li> <li> <strong>2+ years of Spark and Kafka</strong> expertise are required.</li> <li>Excellent ability to understand complex requirements and to translate those requirements into working designs and high-quality software. Ability to blend a fast-moving startup perspective with the requirements of a highly regulated organization.</li> <li> <strong>3+ years</strong> in teams applying modern<strong> agile</strong> software development practices with a focus on test-driven development and test automation</li> <li>Proven track record of building complex, novel systems in startups or other organizations and industries such as IoT</li> <li>Experience in NoSQL stores (e.g. DynamoDB, MongoDB, HBase, Cassandra, etc) and RDBMS.</li></ul><p> </p> <p>Regards,</p> <p>Prakash</p> <p>732-79-5440</p> <p>prakash.v(at)primesoftinc(dot)com</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "khQxT4zKTy2Zwxx3kvZxHA",
    "url": "https://jobmote.com/job/72705/data-engineer-fully-remote/",
    "title": "Data Engineer - Fully Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 13, 2019 10:07:38 PM",
    "validThrough": "Sep 16, 2019 10:07:38 PM",
    "crawled": "Sep 14, 2019 3:06:24 AM",
    "content": "<div><br><br><p>This is a fully remote position with a premier Washington D.C. client. They are looking for a Data Engineer to work with various teams and integrate data via ETL Pipelines from various different languages. Working closely company executives you will also build out policies, compliance and governance requirements, contributing to the enterprise. This is is a perfect opportunity for someone with mid-level experience and needs that vertical move within their career. </p><br><p>Role &amp; Responsibilities</p><br><ul><li><br></li><li> ETL <br></li><li> SQL Quieres <br></li><li> Working with company executives. <br></li></ul><br><p><br>Skills &amp; Qualifications</p><br><ul><li><br></li><li> Python <br></li><li> AWS<br></li><li> ElasticSearch <br></li></ul><br><p>Benefits</p><br><ul><li><br></li><li> FULLY REMOTE <br></li><li> 100% Paid Healthcare <br></li><li> PTO Days <br></li></ul> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "H1tDYkR0S86eBEdUPsRZpg",
    "url": "https://jobmote.com/job/72597/senior-data-engineeratstamford-ct-full-100-remote/",
    "title": "Senior Data EngineeratStamford, CT (Full 100 % Remote)",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:apache-storm/java/16",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Intone Networks Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 12, 2019 10:07:36 PM",
    "validThrough": "Sep 15, 2019 10:07:36 PM",
    "crawled": "Sep 13, 2019 3:06:25 AM",
    "content": "<div><p> <strong>Title: Senior Data Engineer</strong>  </p> <p> <strong>Location: Stamford, CT (Full Remote)</strong>  </p> <p> <strong>Duration: 12+ Months</strong>  </p> <p> <strong>Interview Process: Phone and Skype Interviews</strong>  </p> <p> <strong>Experience Level: 8+ years</strong>  </p> <p>  </p> <p> <strong> Technologies:</strong> Spark, Kafka, AWS, Python </p> <p>  </p> <p> <strong> Top Skills Details:</strong> </p> <ol><li>8+ years of hands-on Data Engineering with a focus on low latency Streaming and analysis.</li> <li>4+ years of experience building low-latency production systems applying big data and cloud technologies (e.g. HDFS, Storm, Spark, Kafka, Amazon AWS, REST, etc.).</li> <li>2+ years of Spark and Kafka expertise are required.</li> <li>Excellent ability to understand complex requirements and to translate those requirements into working designs and high-quality software. Ability to blend a fast-moving startup perspective with the requirements of a highly regulated organization.</li></ol><p>  </p> <p> <strong> Description:</strong> </p> <ul><li>Responsible for implementing software components for highly available, low latency streaming.</li> <li>Work closely with architects and technical product managers to translate overall system architecture and product requirements.</li> <li>Building Data Pipelines in order to leverage consumer data more effectively.</li> <li>Analyze available data sets to create opportunity for business stakeholders.</li> <li>Participate in software design reviews, code reviews, and provide input and feedback to other members of the development team.</li> <li>Write unit, functional, regression tests for your code, and you contribute to the test automation, continuous integration and deployment processes together with everyone else in the development team</li></ul><p>  </p> <p> <strong> Technical Description:</strong> </p> <ul><li>7+ years of hands-on Data Engineering work; with 10+ years of professional experience focused on leveraging Data Effectively.</li> <li>4+ years experience building low-latency production systems applying big data and cloud technologies (e.g. HDFS, Storm, Spark, Kafka, Amazon AWS, REST, etc.).</li> <li>2+ years of Spark and Kafka expertise are required.</li> <li>3+ years in teams applying modern agile software development practices with a focus on test-driven development and test automation</li> <li>B.S. in Computer Science or related Engineering is required, a Master s degree is desirable</li> <li>Proven track record of building complex, novel systems in startups or other organizations and industries such as IoT</li> <li>Experience in NoSQL stores (e.g. DynamoDB, MongoDB, HBase, Cassandra, etc) and RDBMS.</li></ul><p>  </p> <p> <strong>THIS IS NOT A DIRECT MACHINE LEARNING ROLE, but this role will be working with the data science team to utilize ML to reduce Credit Card fraud using real time, low latency processing for their organization, as well as being leveraged for the entire Credit segment of Company's business.</strong>  </p> <p>  </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "HiUM85iXTZOeTPe-pE-r_Q",
    "url": "https://jobmote.com/job/72596/remote-data-architect/",
    "title": "Remote -Data Architect",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AdvanceSoft Inc",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 12, 2019 10:07:36 PM",
    "validThrough": "Sep 15, 2019 10:07:36 PM",
    "crawled": "Sep 13, 2019 3:06:25 AM",
    "content": "<div><p>Data Architect Position-</p> <p>Clearance:- <strong>MBI clearance required</strong></p> <p>Client:- IRS/BAH</p> <p>Location:- Herndon-VA - Remote</p> <p>Duration:- Long term</p> <p>Interview mode:- Phone/Skype</p> <p>Rate:- DOE</p> <p>Immediate interview &amp; hiring</p> <p> </p> <p>Following is the Data Architect position description.</p> <p> </p> <p>Data modeling at the conceptual and logical level</p> <ul><li>Data model implementation at the physical level</li> <li>5+ years experience with cloud-based big data storage, processing, ETL/ELT, and ingest tools such as S3, AWS Glue, and Apache Spark</li> <li>3+ years experience with manipulating both SQL and NoSQL-based file types and data structures</li> <li>3+ years experience with software development as part of an agile-based Dev team</li> <li>Ability to work in diverse environments and communicate complex ideas to teammates, clients, and non-technical experts</li></ul><p> </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vUS0aZ71Rq-9IVu2MumWYQ",
    "url": "https://stackoverflow.com/jobs/296070/senior-graphics-developer-luna?a=1Bi97wOj97Ms&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Graphics Developer at Luna (Kraków, Poland) ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:animation/gamedev/8",
      "DBG_TECH1:k/t/w:assembly/c/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:game-developer/gamedev/13",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:k/t/w:rust/other/30",
      "DBG_TECH1:techWeightMap:{python=0, other=30, dotnet=0, c=6, mobile=0, go=3, nodejs=1, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=21, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/other",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "other"
    ],
    "hiringOrganization": {
      "name": "Luna",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 40000,
      "maxValue": 120000,
      "info": "Equity",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 40k - 120k /Year | Equity"
    },
    "employmentType": "UNSET",
    "published": "Sep 12, 2019 7:30:24 PM",
    "validThrough": "Sep 19, 2019 7:30:24 PM",
    "crawled": "Sep 12, 2019 7:30:24 PM",
    "content": "<h3><span>Senior Graphics Developer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Graphics/Game Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Cloud Computing, Data Science, Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Luna | Kraków, Poland<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Kraków, Poland.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div></div><div>rust</div><div>webassembly</div><div>graphics</div><div>rendering</div><div>webgl</div>                <h4>Job description</h4>                <div><p><strong>Senior Graphics Developer</strong></p><p><a href='https://luna-lang.org' rel='nofollow'>Luna</a> is looking for a senior graphics developer to take charge of the design, development, and evolution of a new WebGL-based GUI for Luna, a project said by Singularity University to have the potential to change the lives of one-billion people. If you bring strong technical skills and a passion for performance, this could be the role for you.</p><p>As a senior graphics developer you'll be a key part of bringing the vision for Luna 2.0 into reality, with your work being integral to the realisation of the next iteration of Luna. You'll be able to collaborate with world-class team of skilled engineers, community managers, and business developers (from Bloomberg, PayPal, and GitHub to name a few), and make your indelible mark on the future of Luna.</p><p><strong>What You'll Do</strong></p><p>As a senior graphics developer, you'll be responsible for designing and building a high-performance renderer based on web technologies for use in the Luna IDE: Luna Studio. This will involve:</p><ul><li>Working closely with stakeholders and customers to design the new GUI for Luna Studio.</li><li>Developing a design for the new renderer that will be used to implement this GUI.</li><li>Implementing the new renderer in a high-performance manner on top of WebGL and Rust (via Web Assembly).</li><li>Building a next-generation UI framework using this renderer for use in Luna Studio.</li><li>Using this UI framework to build the new GUI for Luna Studio itself.</li><li>Debug performance issues to ensure that the renderer is capable of achieving high performance even on low-powered hardware.</li><li>Creating visualisations for data science libraries using the renderer and D3.js.</li></ul><p><strong>The Skills We're Looking For</strong></p><p>We have a few particular skills that we're looking for in this role:</p><ul><li>A strong focus on both user experience and aesthetics.</li><li>3+ years experience with WebGL (or OpenGL).</li><li>A deep understanding of graphics abstractions including: VAOs, FBOs, PBOs, buffer types, and asynchronous computation modes.</li><li>A deep understanding of GPU techniques including: efficient buffer management, efficient GLSL construction, high-performance vector and font rendering, post-processing, 3D scene description (with nested objects), lights, cameras, and animation.</li><li>2+ years experience with Rust, including experience writing <code>unsafe</code> code for FFI and performance, and using the macro system for metaprogramming. You should be able to write <em>idiomatic</em> rust code.</li><li>Practical experience building high-performance graphical interfaces for end-user-facing applications.</li></ul><p>As part of the hiring process for this job posting we're <em>very</em> interested in your previous work in these areas. Please link us to your Rust projects, blog posts and shadertoy shaders if you have them! It's important for us to understand your experience at the start of the hiring process.</p><p>It would be a big bonus if you had:</p><ul><li>Experience with Rust's WASM toolchain, with wasm-bindgen, and experience with WASM itself.</li><li>Experience with visual programming systems such as Houdini, Max/MSP, Lab VIEW, or Touch Designer.</li><li>Knowledge of the runtime and memory models used by various JavaScript virtual machines.</li><li>Knowledge of D3.js, and experience using it to visualise data.</li></ul><p>Avoid <a href='https://www.forbes.com/sites/womensmedia/2014/04/28/act-now-to-shrink-the-confidence-gap/' rel='nofollow'>the confidence gap</a>. You don't have to match <em>all</em> of the skills above to apply!</p><p><strong>Who You'll Work With</strong></p><p>You'll be joining a distributed, multi-disciplinary team that includes people with skills spanning from compiler development to data-science. Though you'll have your area to work on, our internal culture is one of collaboration and communication, and input is always welcomed.</p><p>We firmly believe that only by working <em>together</em>, rather than putting our team members in their own boxes, can we create the best version of Luna that can be.</p><p><strong>The Details</strong></p><p>As part of the Luna team you'd be able to work from anywhere, whether that be at home, or on the go! We have team members distributed across the world, from San Francisco, to London, to Kraków. We welcome remote work and flexible schedules, or you can work from the Kraków office (or our planned SF office) if you'd like. We can provide competitive compensation and holiday, as well as the possibility of equity as time goes on.</p><p><strong>How To Apply?</strong></p><p>Send us an email at <code><a href='mailto:jobs@luna-lang.org' rel='nofollow'>jobs@luna-lang.org</a></code>, and tell us a little bit about yourself and why you think you'd be a good fit for the role! You can also tell us about:</p><ul><li>Some of your past work or projects.</li><li>Why you'd like to work on Luna, and where you imagine Luna being in 5 years.</li><li>The most important features of a team that you'd like to work in.</li><li>Whether you take pride in your ability to communicate clearly and efficiently with your team.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/296070?reset=False&amp;ra=1Bi97wOj97Ms&amp;oqs=a%3D1Bi97wOj97Ms%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Luna</h4>            <div><p><strong>About Luna</strong><br>Luna is an award-winning general-purpose programming language and data-science platform, selected by NASA and Singularity University as a technology with the potential to impact the lives of one-billion people worldwide. It spans the entire stack, from high-level visualisation and communication, to the<br>nitty-gritty of running backend services in a single language. With inbuilt capabilities for visualisation and a dual-syntax architecture, the possibilities are limitless.<br><br>At Luna, we have a world-class team, with developers, community managers, and business developers from all walks of life and backgrounds, and work in close collaboration with industry advisers such as Robert Gentleman, the creator of the R programming language and computational biologist at 23andMe, and Edward Kmett, a skilled language designer and machine intelligence researcher at MIRI.<br><br>We welcome anybody to our team, as long as you have the desire and drive to see Luna succeed.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Team built around the Humility, Respect, and Trust ideology.</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours, possible part / full time remote work.</span>                            </li>                            <li>                                <span></span>                                <span>Work in a small team of world-class engineers and make impact on Luna.</span>                            </li>                            <li>                                <span></span>                                <span>Competitive compensation + possibility of equity as time goes on.</span>                            </li>                            <li>                                <span></span>                                <span>Equality, diversity &amp; inclusion.</span>                            </li>                            <li>                                <span></span>                                <span>We've got standing desks in our office (no one uses them though :P).</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ROpBFgpkTBO7eT3VvJ2lrw",
    "url": "https://remoteok.io/jobs/75050",
    "title": "Senior Data Engineer",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/10",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=1, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=49, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "NAVIS",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 12, 2019 6:05:01 AM",
    "validThrough": "Sep 19, 2019 6:05:01 AM",
    "crawled": "Sep 12, 2019 6:06:30 AM",
    "content": "<span></span> <span><h4>NAVIS</h4></span> <br> <h3>Senior Data Engineer</h3> <div>  <div>   \\n&nbsp;NAVIS is excited to be hiring a&nbsp;Sr. Data Engineer!&nbsp;&nbsp;This is a NEW position due to growth in this area.&nbsp;\\n\\nBe a critical element of what sets NAVIS apart from everyone else!&nbsp; Join the power behind the best-in-class Hospitality CRM software and services that unifies hotel reservations and marketing teams around their guest data to drive more bookings and revenue.\\n\\nOur&nbsp;Guest Experience Platform&nbsp;team is seeking an experienced Senior Data Engineer to play a lead role in the building and running of our modern big data and machine learning platform that powers our products and services. In this role, you will responsible for building the analytical data pipeline, data lake, and real-time data streaming services.&nbsp; You should be passionate about technology and complex big data business challenges.\\n\\nYou can have a huge impact on everything from the functionality we deliver for our clients, to the architecture of our systems, to the technologies that we are adopting.&nbsp;\\n\\nYou should be highly curious with a passion for building things!\\n\\nClick here for a peek inside our Engineering Team\\n\\n\\nDUTIES &amp; RESPONSIBILITIES:\\n\\n\\n* Design and develop business-critical data pipelines and related back-end services\\n\\n* Identification of and participation in simplifying and addressing scalability issues for enterprise level data pipeline\\n\\n* Design and build big data infrastructure to support our data lake\\n\\n\\n\\n\\n\\nQUALIFICATIONS:\\n\\n\\n* Python - expert-level / programming mastery of Python or PySpark (at least five (5) years of continuous Python experience within the context of data pipelines / big data)\\n\\n* The ability to teach advanced Python or PySpark development techniques to developers with mid-level Python skill sets\\n\\n* At least two (2) years of extensive experience with Hadoop Ecosystem (Spark / PySpark)\\n\\n* Experience with building, breaking, and fixing production data pipelines\\n\\n* Hands-on SQL skills and background in other data stores like SQL Server, Postgres, or MongoDB\\n\\n* Experience with continuous delivery and automated deployments (Terraform)\\n\\n* ETL experience\\n\\n* Able to identify and participate in addressing scalability issues for enterprise level / big data\\n\\n\\n\\n\\n\\nDESIRED, BUT NOT REQUIRED SKILLS:\\n\\n\\n* Any experience with AWS services like Glue, S3, SQS, Lambda, Fargate, EC2, Athena, Kinesis, Step Functions, DynamoDB, CloudFormation and CloudWatch will be a huge plus\\n\\n* Any experience with&nbsp;MapReduce, Yarn, HDFS, Hive, Presto, HBase, Parquet is preferred, but not required\\n\\n* Experience with machine learning or interest in picking it up\\n\\n\\n\\n\\n\\nPOSITION LOCATION:\\n\\nThere are 3 options for the location of this position:\\n\\n\\n* Can work&nbsp;remotely&nbsp;in the continental US with occasional travel to Bend, Oregon\\n\\n* Based at a shared office space in the heart of downtown Portland, Oregon\\n\\n* Based at our offices in Bend, Oregon (relocation assistance package available)\\n\\n\\n\\n\\nCheck out this video to learn more about the Tech scene in Bend, Oregon\\n\\n\\nNAVIS OFFERS:\\n\\n\\n* An inclusive, fun, values-driven company culture – we’ve won awards for it\\n\\n* A growing tech company in Bend, Oregon\\n\\n* Work / Life balance - what a concept!\\n\\n* Excellent benefits package with a Medical Expense Reimbursement Program that helps keep our medical deductibles LOW for our Team Members\\n\\n* 401(k) with generous matching component\\n\\n* Generous time off plus a VTO day to use working at your favorite charity\\n\\n* Competitive pay + annual bonus program\\n\\n* FREE TURKEYS (or pies) for every Team Member for Thanksgiving (hey, it's a tradition around here)\\n\\n* Your work makes a difference here, and we make a huge impact to our clients’ profits\\n\\n* Transparency – regular All-Team meetings, so you can stay in-the-know with what’s going on in all areas our business\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Y3JPAcXiQRm0iKq8TZqIEQ",
    "url": "https://jobmote.com/job/72476/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 11, 2019 10:07:55 PM",
    "validThrough": "Sep 14, 2019 10:07:55 PM",
    "crawled": "Sep 12, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "inp7q7v0SUOJ4t6NiII1Ug",
    "url": "https://stackoverflow.com/jobs/295698/senior-data-engineer-big-data-data-pipelines-navis?a=1BapynA47D0s&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Data Engineer - Big Data / Data Pipelines - REMOTE at NAVIS (Bend, OR) ",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=12, other=0, dotnet=1, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=57, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "NAVIS",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 12, 2019 12:06:24 AM",
    "validThrough": "Sep 19, 2019 12:06:24 AM",
    "crawled": "Sep 12, 2019 12:06:24 AM",
    "content": "<h3><span>Senior Data Engineer - Big Data / Data Pipelines - REMOTE</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>CRM, Enterprise Software, Hospitality</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: NAVIS | Bend, OR<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Bend, OR.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>apache-spark</div><div>pyspark</div><div>hadoop</div><div>etl</div>                <h4>Job description</h4>                <div><p>&nbsp;NAVIS is excited to be hiring a&nbsp;<strong>Sr. Data Engineer</strong>!&nbsp;&nbsp;<em>This is a NEW position due to growth in this area.&nbsp;</em></p><p>Be a critical element of what sets NAVIS apart from everyone else!&nbsp; Join the power behind the best-in-class Hospitality CRM software and services that unifies hotel reservations and marketing teams around their guest data to drive more bookings and revenue.</p><p>Our&nbsp;<em>Guest Experience Platform</em>&nbsp;team is seeking an experienced Senior Data Engineer to play a lead role in the building and running of our modern big data and machine learning platform that powers our products and services. In this role, you will responsible for building the analytical data pipeline, data lake, and real-time data streaming services.&nbsp; You should be passionate about technology and complex big data business challenges.</p><p>You can have a huge impact on everything from the functionality we deliver for our clients, to the architecture of our systems, to the technologies that we are adopting.&nbsp;</p><p><em>You should be highly curious with a passion for building things!</em></p><p><strong><a href='https://thenavisway.wistia.com/medias/ce96ssiv8o' rel='nofollow'>Click here for a peek inside our Engineering Team</a></strong></p><p><strong>DUTIES &amp; RESPONSIBILITIES:</strong></p><ul><li>Design and develop business-critical data pipelines and related back-end services</li><li>Identification of and participation in simplifying and addressing scalability issues for enterprise level data pipeline</li><li>Design and build big data infrastructure to support our data lake</li></ul><p><strong>QUALIFICATIONS:</strong></p><ul><li>Python - expert-level / programming mastery of Python or PySpark (at least five (5) years of continuous Python experience within the context of data pipelines / big data)</li><li>The ability to teach advanced Python or PySpark development techniques to developers with mid-level Python skill sets</li><li>At least two (2) years of extensive experience with Hadoop Ecosystem (Spark / PySpark)</li><li>Experience with building, breaking, and fixing production data pipelines</li><li>Hands-on SQL skills and background in other data stores like SQL Server, Postgres, or MongoDB</li><li>Experience with continuous delivery and automated deployments (Terraform)</li><li>ETL experience</li><li>Able to identify and participate in addressing scalability issues for enterprise level / big data</li></ul><p><strong>DESIRED, BUT NOT REQUIRED SKILLS:</strong></p><ul><li>Any experience with AWS services like Glue, S3, SQS, Lambda, Fargate, EC2, Athena, Kinesis, Step Functions, DynamoDB, CloudFormation and CloudWatch will be a huge plus</li><li>Any experience with&nbsp;MapReduce, Yarn, HDFS, Hive, Presto, HBase, Parquet is preferred, but not required</li><li>Experience with machine learning or interest in picking it up</li></ul><p><strong>POSITION LOCATION:</strong></p><p>There are 3 options for the location of this position:</p><ul><li>Can work&nbsp;<strong><em>remotely</em></strong>&nbsp;in the continental US with occasional travel to Bend, Oregon</li><li>Based at a shared office space in the heart of downtown Portland, Oregon</li><li>Based at our offices in Bend, Oregon (relocation assistance package available)</li></ul><p><a href='https://www.youtube.com/watch?v=mbKByBpXqaw&amp;' rel='nofollow'><strong>Check out this video to learn more about the Tech scene in Bend, Oregon</strong></a></p><p><strong>NAVIS OFFERS:</strong></p><ul><li>An inclusive, fun, values-driven company culture – we’ve won awards for it</li><li>A growing tech company in Bend, Oregon</li><li>Work / Life balance - what a concept!</li><li>Excellent benefits package with a Medical Expense Reimbursement Program that helps keep our medical deductibles LOW for our Team Members</li><li>401(k) with generous matching component</li><li>Generous time off plus a VTO day to use working at your favorite charity</li><li>Competitive pay + annual bonus program</li><li>FREE TURKEYS (or pies) for every Team Member for Thanksgiving (hey, it's a tradition around here)</li><li>Your work makes a difference here, and we make a huge impact to our clients’ profits</li><li>Transparency – regular All-Team meetings, so you can stay in-the-know with what’s going on in all areas our business</li></ul>                </div>            <div>        <a href='https://www.naviscrm.com/about/jobs-board/?gh_jid=4204053002' rel='nofollow'>                        Apply now        </a></div>            <h4>About NAVIS</h4>            <div><p><strong>ABOUT NAVIS:</strong><br>NAVIS is the only Unified CRM solution for hotels and vacation rental management companies that brings their data and their reservations sales, marketing, and revenue teams together to drive more direct bookings and revenue.&nbsp; Because we believe technology should make you money, not cost you money, we developed our game-changing Revenue Performance Platform™ to transform teams into revenue makers, enabling them to drive, capture and convert more direct bookings. We deliver actionable guest insights so departments can seamlessly sell and market together. The result is always a dramatic increase in direct sales and profit. We guarantee it.<br><br>Founded in 1987, NAVIS is a privately held company with headquarters in Bend, Oregon, and growing locations in Orlando, Florida and Reno, Nevada.<br><br><strong>We have been named on &quot;Top Workplaces&quot; lists for EIGHT years running!&nbsp;</strong></p><p>NAVIS has been recognized as a &quot;Top Workplace&quot; by The Oregonian for several years, a &quot;Top 10 Workplace&quot; by the Orlando Sentinel in 2018, and a &quot;Best Place to Work&quot; by the Northern Nevada Human Resources Association in 2018.</p><p><br><strong>At NAVIS, our Core Values are:</strong></p><ul><li><em>Golden Rule:</em>&nbsp;I treat others as I want to be treated</li><li><em>Integrity:</em>&nbsp;I am a person of my word and highly trusted</li><li><em>Innovation:&nbsp;</em>I create solutions for difficult business problems</li><li><em>Performance:</em>&nbsp;I am part of an ambitious team and my results matter</li><li><em>Attitude:</em>&nbsp;I am a positive influence, I love my team and the work we do</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Summer &quot;Bucket List&quot; Challenge</span>                            </li>                            <li>                                <span></span>                                <span>Software Engineers get their choice of Macs or PCs</span>                            </li>                            <li>                                <span></span>                                <span>VTO Time - time off for volunteering at the cause of your choice</span>                            </li>                            <li>                                <span></span>                                <span>&quot;MERP&quot; benefit helps defray the costs of meeting medical deductibles</span>                            </li>                            <li>                                <span></span>                                <span>Competitive Salaries + Bonus Program</span>                            </li>                            <li>                                <span></span>                                <span>Free Turkeys (or pies) at Thanksgiving (hey - it's a NAVIS tradition)</span>                            </li>                            <li>                                <span></span>                                <span>We take Halloween VERY seriously around here</span>                            </li>                            <li>                                <span></span>                                <span>401(k) with Matching Component</span>                            </li>                            <li>                                <span></span>                                <span>Get perks around town just by flashing your NAVIS badge</span>                            </li>                            <li>                                <span></span>                                <span>Open-concept, collaborative work environment w/ stand-up desks</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "OMXeDppxTYyyiuQGIAynxg",
    "url": "https://stackoverflow.com/jobs/295665/senior-data-engineer-spark-expertise-nyc-or-securityscorecard?a=1B9J0LgiMZMc&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Data Engineer - Spark expertise - NYC or Remote North America at SecurityScorecard (New ...",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/24",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SecurityScorecard",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 11, 2019 7:30:24 PM",
    "validThrough": "Sep 18, 2019 7:30:24 PM",
    "crawled": "Sep 11, 2019 7:30:24 PM",
    "content": "<h3><span>Senior Data Engineer - Spark expertise - NYC or Remote North America</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Cybersecurity, SaaS</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: SecurityScorecard | New York, NY<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time +/- 4 hours</span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>New York, NY.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                    </div>                    </div>                <h4>Technologies</h4><div></div><div>apache-spark</div><div>hadoop</div><div>sql</div><div>scala</div>                <h4>Job description</h4>                <div><p><strong>About Us</strong></p><p>The SecurityScorecard ratings platform helps enterprises across the globe manage the cyber security posture of their vendors. Our SaaS products have created a new category of enterprise software and our culture has helped us be recognized as one of the 10 hottest SaaS startups in NY for two years in a row. Our investors include both Sequoia and Google Ventures. We are scaling quickly but are ever mindful of our people and products as we grow.</p><p>This role will be based in our HQ in NYC, or remote (home office) i North America.</p><p><strong>Position Summary</strong></p><p>The Senior Data Analytics Engineer will build meaningful analytics that inform companies of security risk. &nbsp;You will be working closely with our Data Science team, implementing algorithms and managing the analytic pipeline. We have over 1 PB of data, so the ideal candidate will have experience processing and querying large amounts of data.&nbsp;&nbsp;</p><p><strong>Responsibilities</strong></p><ul><li>Manage the analytic pipeline using Spark, Hadoop, etc&nbsp;</li><li>Leverage cutting-edge technologies to support new and existing and services and processes.</li><li>Quickly and efficiently design and implement in an agile environment</li><li>Work with other team members to implement consistent architecture</li><li>Drive projects through all stages of development</li><li>Actively share knowledge and responsibility with other team members and teams</li><li>Improve the effective output of the engineering team by managing quality, and identifying inconsistencies. &nbsp;</li></ul><p><strong>Skills and Experience:</strong></p><ul><li>Bachelor's degree (CS, EE or Math preferred) or equivalent work experience as well as interest in a fast paced, complex environment.</li><li>5+ years of experience&nbsp;Scala or another functional language experience in a commercial environment (highly preferred)</li><li>3+ Experience with Spark, and the Hadoop ecosystem and similar frameworks</li><li>Familiarity with various tools such as AWS and Docker and an instinct for automation</li><li>Expert in SQL</li><li>Strong understanding of Software Architecture principles and patterns.</li><li>Experience working with 3rd party software and libraries, including open source</li><li>Experience with Postgres</li></ul><p><strong>Traits:</strong></p><ul><li>Quick-thinker who takes ownership and pride in their work</li><li>A commitment and drive for excellence and continual improvement&nbsp;</li><li>A strong sense of adventure, excitement and enthusiasm.</li><li>Excellent systems analytical, problem solving and interpersonal skills</li></ul>                </div>            <div>        <a href='https://grnh.se/2a3e6a751' rel='nofollow'>                        Apply now        </a></div>            <h4>About SecurityScorecard</h4>            <div><p><strong>About SSC</strong></p><p>At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.</p><p>Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Unlimited PTO</span>                            </li>                            <li>                                <span></span>                                <span>Health Benefits Starting Day One</span>                            </li>                            <li>                                <span></span>                                <span>401k</span>                            </li>                            <li>                                <span></span>                                <span>Education Stipend</span>                            </li>                            <li>                                <span></span>                                <span>Learning and Development</span>                            </li>                            <li>                                <span></span>                                <span>Stocked Kitchen</span>                            </li>                            <li>                                <span></span>                                <span>Remote Work Options</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "wc9TCiTKRhSvR7t9um8wxw",
    "url": "http://workinstartups.com/job-board/job/84288/data-engineer-at-landinsight/",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``remot W OR(contractor,assist,ok)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:node.js/nodejs/13",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=14, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "LandInsight",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 11, 2019 12:01:58 PM",
    "validThrough": "Sep 18, 2019 12:01:58 PM",
    "crawled": "Sep 11, 2019 1:06:32 PM",
    "content": "<p><strong data-redactor-tag=&quot;strong&quot;>About the company</strong></p><br /><p>LandInsight is a new platform that is fundamentally changing how the property industry buys land for development. It&rsquo;s a big data platform that speeds up the process of finding, assessing and buying land. It comes at an important time, one of the biggest challenges for the UK housing crisis is tackling the shortage of development land. Our tech has changed the game and as a result we&rsquo;ve become the UK&rsquo;s fastest growing PropTech company (and we&rsquo;ve got the awards to prove it!).</p><br /><p>&nbsp;</p><br /><p><strong data-redactor-tag=&quot;strong&quot;>Our culture</strong></p><br /><p>We live and breath our values of &lsquo;open&rsquo;, &lsquo;empower&rsquo; and &lsquo;home&rsquo;, they are in the footprints of all we do and who we are.</p><br /><p>We truly believe that businesses flourish when people are empowered to work collaboratively and harmoniously. That&rsquo;s why we prioritise team building, high engagement and knowledge sharing in every thread of company. Sitting in our open plan offices means not only knowing the founders, but also learning about the conception and scale of a startup.</p><br /><p>We don&rsquo;t just make empty gestures about our culture - we were voted as the 3rd best UK SaaS Company to work at, and have also received awards for &lsquo;Best at Employee Development&rsquo;.</p><br /><p>&nbsp;</p><br /><p>Check out our tech blog <a href='https://workable.com/nr?l=https%3A%2F%2Ftech-blog.landinsight.io%2F' rel='nofollow noreferrer noopener'>here</a></p><br /><p>&nbsp;</p><br /><p><strong data-redactor-tag=&quot;strong&quot;>Your mission </strong></p><br /><p>At the heart of our product is open data, which we pull in from a wide range of sources. Our customers expect the data to be up to date, accurate, and intelligently integrated into our platform.</p><br /><p>The datasets typically contain 1-30 million items. In some cases this is nice and clean at the point we receive it, but in other cases we have to use a combination of machine-learning and hand-crafted algorithms to extract metadata from plain text or pdfs. Also, since most of our data is geospatial, we focus a lot on geocoding data accurately and joining across geospatial datasets.</p><br /><p>In this role, you will first need to assess the infrastructure we currently have, as built by our full-stack engineers. You will then plan how to migrate towards a more robust system, this includes building tools and processes that will empower our remote contractors to keep a check on, and maintain, parts of the system (e.g. scrapers). Importantly, the new system will need to be flexible as we add new datasets and squeeze more meaning from existing datasets.</p><br /><p>A second aspect of the role will be working with geospatial data generated by our users. This part of the business is more in its infancy, but we have grand ambitions for it and would want you to aid in the decision making, even if not working on the implementation yourself.</p><br /><p>&nbsp;</p><br /><p><strong data-redactor-tag=&quot;strong&quot;>Key Responsibilities</strong></p><br /><ul><br /><li>Developing (improving existing and/or creating new) interfaces and/or pipelines to facilitate data collection.</li><br /><li>Identifying, debugging and fixing issues. This includes liaising with other technical/non-technical staff.</li><br /><li>Working closely with remote colleagues (technical and non-technical) who also work on data projects</li><br /><li>Improving our algorithms that derive data from the incoming datasets.</li><br /><li>Educating our full-stack engineers to be better data engineers.</li><br /></ul><br /><p><strong>Requirements</strong></p><br /><ul><br /><li>You are highly competent in one or more programming languages (5+ years experience)</li><br /><li>You are able to reason about the behaviour of systems before starting to build them</li><br /><li>You have built a variety of data processing/management systems</li><br /><li>You have experience with various data visualisation and business intelligence systems</li><br /><li>You are a clear communicator in both written and verbal forms</li><br /><li>AWS is desirable</li><br /><li>NodeJS (or simply JavaScript) is desirable</li><br /><li>MongoDB is desirable</li><br /><li>Postgres is desirable</li><br /><li>Elasticsearch is desirable</li><br /><li>Geographical Information Systems is desirable</li><br /><li>ScrapingHub is desirable</li><br /></ul><br /><p><strong>Benefits</strong></p><br /><ul><br /><li>Flexible working hours</li><br /><li>Professional and personal training budget</li><br /><li>Competitive salary and equity options</li><br /><li>25 days paid holiday (additional to bank holidays)</li><br /><li>Unlimited unpaid holidays</li><br /><li>Dog friendly office</li><br /><li>Loads of social events, including a quarterly away day, an annual ski trip and monthly socials</li><br /><li>Gym and wellness contributions, and a cycle to work scheme</li><br /><li>Dedication to hiring for cultural fit, so you know you&rsquo;re going to be sitting next to someone who you want to grab a beer/glass of prosecco with (usually at the free WeWork bar we have available after 2pm every day!</li><br /></ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZBE_d6ttSWay3-FTrxsweg",
    "url": "https://jobmote.com/job/72255/data-engineer-100-remote-working/",
    "title": "Data Engineer - 100% Remote Working",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 10:08:09 PM",
    "validThrough": "Sep 13, 2019 10:08:09 PM",
    "crawled": "Sep 11, 2019 3:06:24 AM",
    "content": "<div>A chance to join one of the most exciting teams to come out of Silicon Valley in recent years as they look to expand their tech team into the UK. Working on industry leading product with some of the brightest managers in the game coming from Google and LinkedIn. A real sense of autonomy and avoidance of micromanagement.<br><br>You: <br><br>You will ideally be a Senior Data Engineer at the moment or someone looking to make the step up the career ladder, ideally coming from a from a product focused environment. From a technical perspective as well as being an experienced Data Engineer you will have experience or be a proficient Backend Developer, ideally you will have commercial experience of most of the following: <br><br>** Spark/AWS/Snowflake<br><br>** Java/Scala/Go<br><br>** Working on large data sets<br><br>** Stakeholder Management<br><br>The Role:<br><br>Being based remotely you will be happy to work autonomously and be accountable in terms of product and process ownership. One of the biggest areas for our client is the desire to continue your professional development, keeping abreast of the ever-changing world of data. Ultimately the company revolves around the ability to solve problems so someone that is naturally inquisitive and keen to learn and further develop their skills will fit in well.<br><br>** Building Distributed, high volume data pipelines.<br><br>** Model multiple data streams into formats like parquet to enable calculations.<br><br>** Improve data pipeline performance and enhance scalability limits.<br><br>The Company:<br><br>Having almost a storybook style start-up story they have really exploded out of the Silicon Valley and are tackling some of the biggest household names across tech and retail in the world. With a stellar leadership team, who are constantly pushing the boundaries and striving to achieve more, you will be working for an organisation that is trying to be one of the very best on the planet. They provide various platforms to customers across the planet, from automated testing services to customer and functional analytics. Very much a team first environment you will be keen to work with and collaborate with others, this being facilitated by a network of other employees around the UK and US.<br><br>Application &amp; Interview Process:<br><br>To apply for this role, click on the link below and feel free to get in touch with Greg at Cathcart Associates for a more detailed chat</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "lBYrliD_QdC1_SaGHpJZiQ",
    "url": "https://remote.co/job/data-analyst-mobile-apps-and-product/",
    "title": "Data Analyst, Mobile Apps and Product",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG_TECH1:k/t/w:android/java/2",
      "DBG_TECH1:k/t/w:android/mobile/4",
      "DBG_TECH1:k/t/w:app-store/mobile/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=5, mobile=14, go=0, nodejs=0, bigdata-ml=56, ruby=0, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wikimedia",
      "sameAs": "https://wikimediafoundation.org/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 7:05:00 PM",
    "validThrough": "Sep 17, 2019 7:05:00 PM",
    "crawled": "Sep 10, 2019 7:31:26 PM",
    "content": "<h3>Data Analyst, Mobile Apps and Product at <span>Wikimedia</span></h3><div><span><i></i> Remote</span>        </div><div>            <p><strong>Location: San Francisco, CA or Remote</strong></p><p><strong>Data Analyst (Mobile Apps &amp; Product)</strong></p><p><strong>Summary</strong></p><p>The Wikimedia Foundation is looking for a Data Analyst to join our team, reporting to the Head of Product Analytics. The Product Analytics team is a collaborative team with organization-wide impact. We provide quantitatively based user insights to improve decision-making within the Foundation and the Wikimedia Movement. Our focus is on supporting product decisions that enable our communities to achieve Wikimedia’s vision: a world in which every single human being can freely share in the sum of all knowledge.</p><p>We’re looking for a Data Analyst who will advance our team’s mission of informing decisions by providing impactful, accessible, and ethical data and insights. In this role, you will help our iOS and Android mobile apps teams improve Wikipedia editor and reader experiences by analyzing user behavior and identifying impacts from product tests. You’ll work with product teams to ensure that tagging and metrics are appropriately defined and implemented, and promote best practices for measuring user behavior across our websites and mobile apps.</p><p>The insights you generate will impact one of the most relied-upon digital platforms in the world, and your work will support our strategic direction toward service and equity. Our commitment to user privacy sets Wikimedia sites apart from almost all major websites, and inspires creative approaches to our data work.</p><p><strong>In this role, you will:</strong></p><ul><li>Identify key metrics for measuring progress against product and organizational goals.</li><li>Collaborate with product, business, and technology teams to ensure that tagging and metrics are appropriately implemented.</li><li>Work with data and metrics in App Store Connect, Play Store Console, and App Annie that supplement our internal analytics solutions.</li><li>Build data visualizations, reports, and dashboards, and guide stakeholders in how to interpret the data.</li><li>Design, execute, and evaluate experiments and quantitative research to inform product decisions.</li><li>Analyze Wikipedia usage volume, user behavior, and performance data to identify opportunities and areas for improvement.</li><li>Work with large-scale data, using tools such as Hadoop, Hive/Presto, Druid, Superset, Turnilo, Spark, and Jupyter.</li><li>Communicate data insights clearly and responsively to a range of departmental, organisational, volunteer, and public stakeholders.</li></ul><p><strong>Skills and Experience:</strong></p><ul><li>Experience with tracking and analytics on consumer, mass media, or social network mobile apps and websites. (Our tracking system is homegrown, but prior experience with tools like Google Analytics, Mixpanel, Adobe Analytics, etc. is helpful.)</li><li>Comfortable using analytics tools and scripting languages to create reports that blend data from multiple sources (our team frequently uses Python or R, Hadoop, Hive/Presto, Spark, and Druid).</li><li>Ability to communicate findings and recommendations clearly to colleagues with diverse backgrounds and areas of expertise.</li><li>Strong working knowledge of SQL.</li><li><strong>Bachelor’s degree in a related field or the equivalent in relevant work experience.</strong></li></ul><p><strong>Qualities that are important to us:</strong></p><ul><li>Flexible and open to change and new information.</li><li>Comfortable working in a highly collaborative, consensus-oriented environment.</li></ul><p><strong>Additionally, we’d love it if you have any of the following:</strong></p><ul><li>Fluency in a language other than English (our apps teams are interested in expanding our reach in Asia, Africa, and Latin America).</li><li>Experience with open source technologies and communities.</li><li>Experience contributing to Wikimedia projects.</li></ul><p><strong>The Wikimedia Foundation is… </strong></p><p>…the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p><p><strong><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></strong></p><p><strong>U.S. Benefits &amp; Perks*</strong></p><ul><li>Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)</li><li>The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more</li><li>The 401(k) retirement plan offers matched contributions at 4% of annual salary</li><li>Flexible and generous time off – vacation, sick and volunteer days, plus 19 paid holidays – including the last week of the year.</li><li>Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.</li><li>For those emergency moments – long and short term disability, life insurance (2x salary) and an employee assistance program</li><li>Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses</li><li><strong>Telecommuting and flexible work schedules available</strong></li><li>Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax</li><li>Great colleagues – diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people</li></ul><p><strong><em>*ligible international workers’ benefits are specific to their location and dependent on their employer of record</em></strong></p><p><strong>More information</strong></p><p><strong>WMF</strong><br><strong>Blog</strong><br><strong>Wikimedia 2030</strong><br><strong>Wikimedia Medium Term Plan</strong><br><strong>Diversity and inclusion information for Wikimedia workers, by the numbers</strong><br><strong>Wikimania 2019</strong><br><strong>Annual Report – 2017</strong></p>        </div><div>        <a href='https://boards.greenhouse.io/wikimedia/jobs/1860246?gh_src=fcvclhyn1' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "1POh-NUQRPipChQZcsFMwQ",
    "url": "https://stackoverflow.com/jobs/288152/software-engineer-create-devops-for-ai-dotscience?a=1yDvz3ma1BKM&so_medium=Talent&so_source=TalentApi",
    "title": "Software Engineer | create 'DevOps for AI' platform & tools | 100% remote at Dotscience  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/32",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:go/go/15",
      "DBG_TECH1:k/t/w:golang/go/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:node.js/nodejs/65",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:shell/other/1",
      "DBG_TECH1:techWeightMap:{python=25, other=7, dotnet=0, c=0, mobile=0, go=52, nodejs=65, bigdata-ml=84, ruby=2, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "Dotscience via techfolk",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 60000,
      "maxValue": 80000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "GBP 60k - 80k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 5:06:23 PM",
    "validThrough": "Sep 17, 2019 5:06:23 PM",
    "crawled": "Sep 10, 2019 5:06:23 PM",
    "content": "<h3><span>Software Engineer | create 'DevOps for AI' platform &amp; tools | 100% remote</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>DevOps</span>                                    </div>                            </div>                    </div>                <div>Company: Dotscience via techfolk | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+00:00) London +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>go</div><div>node.js</div><div>python</div><div>docker</div>                <h4>Job description</h4>                <div><p>Dotscience is hiring remote back end software engineers to help tackle some of the considerable challenges ahead in developing AI for production use. We're mainly working in Go, plus Python and Node.js and we'll support your learning if you need to cross train.</p><p>Our end-to-end machine learning toolset helps our customers stabilise and scale their AI initiatives; from development to production, we help them track full evolution of models and metrics throughout the lifecycle. Think 'DevOps for ML'.</p><p>We're hiring someone to help architect and implement data science automation solutions and tooling. We’re building from the ground up, inheriting zero legacy code. Collaborating with our product and design teams, you'll develop a product which is robust and scalable for cloud and on-premise use. You'll also help us to integrate with, and to automate, most of the major AI/ML ecosystems as we build out our tech</p><p>We'll listen to your opinions and actively encourage you to make recommendations as to how we can improve our products.</p><p>Now is an exciting time to join us; we're hiring a range of skills across the stack and can potentially shape your role in ways that build upon your strengths.&nbsp;</p><p><strong><br>Example first projects</strong></p><ul><li>Building features on the Dotscience platform that enables data scientists to create, collaborate on and to manage their workflows</li><li>Building API’s and SDK’s to support data pipelines and model deployment</li><li>Scaling the platform to support large and complex data science workloads</li><li>Maintain an operational stack and infrastructure for back end services</li></ul><p><strong>We're looking for</strong></p><ul><li>Strong back end coding skills, using a statically typed programming language - we use mainly Go (Golang), plus Python and Node.js, and can support your transition and learning</li><li>A technical understanding of building AI/ML pipelines in research or production environments</li><li>Familiarity with Containers from an architectural perspective</li><li>Familiarity with a scripting language, such as Bash, Perl, Python, Ruby, Shell etc.</li><li>Solid understanding of Computing or AI - gained from practical application, or through education&nbsp;</li><li>Familiarity with the principles of Agile, automated testing and continuous delivery</li><li>Clear desire to learn, to improve and to share knowledge with colleagues</li><li>Considering senior to principal level remote back end jobs such as: Go Developer | Golang Developer | Python Developer | Node.js Developer | Back End Engineer | Lead Engineer | AI Tools Engineer | Machine Learning Developer | Artificial Intelligence Engineer | Data Scientist | etc.</li></ul><p><strong>Current stack - we'll welcome your influence</strong></p><p>Go (Golang) | Python | Node.js | PostgreSQL | Docker | Kubernetes | AWS | GCE | GitHub | GitLab | Tensorflow</p><p><strong>Salary and benefits</strong></p><ul><li>£60,000 to £80,000+ negotiable - we're keeping an open mind</li><li>Flexible and family friendly working environment - no core hours, work at the times that suit you</li><li>Remote workers package, including fully expensed work travel costs</li><li>25 days holiday + UK national/public holidays/local benefits | private medical cover | life cover/income protection insurance | group personal pension/contributory pension | conference involvement encouraged | open source projects include <a title=&quot;Tensorflow for Dotscience&quot; href='https://github.com/dotmesh-io/jupyterlab-tensorflow' rel='nofollow'>Tensorflow for Dotscience</a> and <a title=&quot;Jupyterlab plugins&quot; href='https://github.com/dotmesh-io/jupyterlab-plugin' rel='nofollow'>Jupyterlab plugins for Dotscience</a></li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/288152?reset=False&amp;ra=1yDvz3ma1BKM&amp;oqs=a%3D1yDvz3ma1BKM%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Dotscience</h4>            <div><p>Launched July 2019, Dotscience is funded by DDN, the world’s largest privately-held storage company. We're an innovation project being run like a start-up and we're looking for someone who cares greatly about how and why things work, about engineering quality and about user value. Our aim is to help data science and ML teams to collaborate, to build and to deploy AI models effectively. We believe that building and deploying ML models should be easy, fast and safe. Our mission is to build an end-to-end data science toolset that holds AI accountable for its decision making. An entirely distributed team, we collaborate through daily stand-ups and use tools such as GitHub, Slack, Hangouts and Google Docs. We also meet up every six-eight weeks, for example at a nice holiday cottage, to get to know each other better, to hold work sprints, to enjoy downtime together, and to discuss our mission plans. We offer a supportive, flexible, high-trust work environment, where you are encouraged to grow your role at a pace to suit you.</p><p><strong>Location:</strong> remote/work from home - within the UK, France, Germany and/or the US - please note that you need to be living in, and have the right to work in, one of these countries.</p><p><strong>Even if your CV isn't ready, please talk with Vittoria at techfolk to find out more:</strong></p><p>0117 318 2447 | <a href='mailto:hello@techfolk.co.uk' rel='nofollow'>hello@techfolk.co.uk</a> | @we_are_techfolk</p><p>RECRUITERS: Dotscience has selected techfolk as its exclusive recruitment partner for this position and cold calling and speculative applications are not welcomed.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2RCl3FeSQdOGfOeX8Wb2iA",
    "url": "https://stackoverflow.com/jobs/295253/senior-software-engineer-musement?a=1B19Sv2wOFH2&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Software Engineer at Musement (Milan, Italy) ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:android/java/1",
      "DBG_TECH1:k/t/w:android/mobile/2",
      "DBG_TECH1:k/t/w:django/python/16",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/15",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=22, other=0, dotnet=0, c=0, mobile=4, go=3, nodejs=0, bigdata-ml=17, ruby=0, apple=2, java=1, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "Musement",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 5:06:23 PM",
    "validThrough": "Sep 17, 2019 5:06:23 PM",
    "crawled": "Sep 10, 2019 5:06:23 PM",
    "content": "<h3><span>Senior Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                            </div>                    </div>                <div>Company: Musement | Milan, Italy<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Milan, Italy.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div>python</div><div>algorithms</div><div>heuristics</div><div>mapreduce</div><div>pipeline</div><div>http://www.greatplacetowork.it/</div>                <h4>Job description</h4>                <div><p><strong>Your Mission @Musement/Triposo</strong></p><p>In the Triposo team, we take terabytes of input data from various internet sources and extract as much travel-related content as we can. We match the content from different sources to cross-check the information and obtain a more complete picture of each place we've found.</p><p>We organise it all into a coherent hierarchy and rank everything from a traveller's perspective, including taking into account different personas. Along the way we apply smart algorithms and data mining techniques to analyse the data and extract even more information about places.</p><p>Finally, it goes into a database that powers our API and apps.</p><p>Sound like your cup of tea? Come join us! You'll get to shape the future direction of the pipeline and the travel API, working on adding new features and more smart analysis.</p><p>Our pipeline is implemented in python, using a mapreduce framework. The API is implemented using Django, deployed to AWS using Docker containers and serving data out of a postgres database.</p><p><strong>The role</strong></p><p>This is not an ordinary development job. Candidates must be comfortable designing, implementing and maintaining complex algorithms.&nbsp;We're looking for smart, talented developers who are willing to learn whatever it takes to get the job done. These things are more important to us than experience with any particular technologies, so if that's you, then don't worry if you don't tick all the other boxes.</p><p>Because we are a distributed international team, there is the possibility to work either remotely or&nbsp;in our office in Milan. When working remotely, an EMEA timezone is strongly preferred and you will be expected to travel occasionally to meet up face-to-face.</p><p><strong>What you will do</strong></p><ul><li>You won’t just be writing code all day, you’ll play an active part in shaping our product</li><li>You'll spend time on innovation on a regular basis</li><li>You'll be part of an excellent independent team&nbsp;working in a dynamic environment</li></ul><p><strong>Desired experience</strong></p><ul><li>experience with Linux or similar environment recommended</li><li>experience with Python recommended</li><li>experience with mapreduce and similar techniques for data processing an advantage</li><li>experience with machine learning an advantage</li><li>experience with natural language processing an advantage</li><li>experience with Django, AWS and/or Docker a bonus</li></ul><p><strong>About you</strong></p><ul><li>good communication skills</li><li>written and spoken English (level B2 or higher)</li><li>affinity with travel a plus</li></ul><p><strong>Benefits</strong></p><ul><li>Every Friday is a Tech Friday, where you can study and/or test new technologies</li><li>Tickets for tech conferences</li><li>Freedom to choose your dev tools (hardware and software)</li></ul><p>If working&nbsp;in the Milan office:</p><ul><li>Free fruit</li><li>Free Espresso and breakfast</li><li>Free beer (only on Friday)</li><li>Meal tickets</li></ul>Musement is a certified Great Place To Work® and among the Top 20 Best Workplaces in Italy&nbsp;<a href='http://www.greatplacetowork.it/' rel='nofollow'>http://www.greatplacetowork.it/</a>                </div>            <div>        <a href='https://musement.recruiterbox.com/jobs/fk03xs2?pjb_hash=mnCvd505&amp;apply_now=true' rel='nofollow'>                        Apply now        </a></div>            <h4>About Musement</h4>            <div><p><strong>MUSEMENT&nbsp;</strong>helps travelers enjoy in-destination experiences to the fullest, sourcing local knowledge and recommendations to make the best use of time. Whether it’s activities, tours, tickets or just ideas for a great night out, we make all bookings easy and secure with&nbsp;<strong><a href='http://musement.com/' rel='nofollow'>Musement.com</a></strong>&nbsp;and our app (iOS and Android). This is the new travel: bookings on the go, the best selections, immediate skip-the-line access to venues and events, bespoke experiences and local knowledge – the right tools delivering useful information in the simplest way. We launched in Milan in 2013 and have since taken root in 70 different countries. Right now, our offer extends to 450 cities, thousands of potential things to do and see, and availability in eight languages – making us a leading guide for international travel activities. Our traveler-friendly technology has been featured in such international publications as Wired, TechCrunch, Daily Telegraph, Bloomberg, Corriere della Sera and Times of India. We’ve been selected by Apple as ‘Best of 2014’ in European App Stores and again in 2016 as one of its ‘Best Apps to Start 2016.’ In October 2017 we acquired the travel content platform Triposo, bringing together more than 12 million travelers across both platforms and offering them hyper-personalized travel content and booking options. In December 2017 we were awarded with the Great Place To Work Italia Certification. We were successfully ranked in the Top 20 Best Workplaces in Italy (Medium size companies category).</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "p6LaUnB9QuK1T99-gWlqgA",
    "url": "http://workinstartups.com/job-board/job/84231/senior-software-engineer-at-cv-partner/",
    "title": "Senior Software Engineer",
    "tags": [
      "DBG:surround``OR(abl,will,challeng,flexibl,experi,get,prefer) 2W 2N(work,remot)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:coffeescript/frontend/3",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/3",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/24",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/16",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:rust/other/10",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:k/t/w:vue.js/frontend/8",
      "DBG_TECH1:techWeightMap:{python=0, other=15, dotnet=0, c=0, mobile=0, go=0, nodejs=5, bigdata-ml=26, ruby=18, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=26}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "CV Partner",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 11:31:55 AM",
    "validThrough": "Sep 17, 2019 11:31:55 AM",
    "crawled": "Sep 10, 2019 1:06:33 PM",
    "content": "<div><br /><h2>The role</h2><br /><div class=&quot;article_rich_text w-richtext&quot;><br /><p>We are looking for a talented senior engineer to join our small-but-growing company at an exciting time for the tech team.</p><br /><p>Started in 2012, CV Partner was initially built by the founder using all the coolest technology for that time: Rails, CoffeeScript and Mongo. A couple of years later a React frontend was added and this stack enabled us to remain agile while we discovered our clients' needs and quickly build the functionality they were seeking. We ended up creating a tool that they enjoy using and has a measurable improvement in their productivity and ability to win bids.</p><br /><p>Now, 7 years on, with a bigger team, many features added, larger clients signed and much more data being processed we're finding the limitations of the current architecture. Some tech debt has accumulated and it&rsquo;s becoming increasingly difficult to keep the ever-expanding Rails app up to date with the latest versions and add new features in a timely manner. Also, we're slightly embarrassed to still be using CoffeeScript in 2019.</p><br /><p>So, we've started to put in place some infrastructure that will help us transition to building microservices. We've begun work on an event-source based architecture with plans to utilise the CQRS pattern. We&rsquo;ve already built some of the main building blocks in Rust and are starting to flesh out how some of the trickier aspects will work (e.g. auth, shared frontend components etc).</p><br /><p>The team is currently comprised of all senior-level people, including two software engineers, a DevOps and a UX designer. The founder also still codes occasionally as we haven't built up the courage to revoke his git access yet.</p><br /><p>You'll help put in place the foundations of the technology and engineering practices that can provide a platform for the company to meet the needs of our clients over the coming years. That means deciding on programming languages, tools and services to help build robust, fast and secure software. We're looking at things such as TypeScript, Vue and GraphQL/AppSync but nothing is set in stone and we value using the best tool for the job.</p><br /><p>The next phase of growth will be to start bringing mid-level or junior engineers into the team, so you should be happy mentoring those with less experience and when the time comes, we'd value your input into the hiring process.</p><br /><p>We're pretty laid-back when it comes to flexible working so you&rsquo;ll have the opportunity to spend some time working from home or a co-working space close to home if you have a long commute. As a company, we are distributed across three countries already so most comms are through slack or video call. However, we do value face-to-face communication as not even the best video-conferencing tools can replace a good huddle around a whiteboard. But as said, we're pretty chilled about it, so if you're the right person for us, we'll figure something out.</p><br /></div><br /><h2>Responsibilities</h2><br /><div class=&quot;article_rich_text w-richtext&quot;><br /><ul><br /><li>Develop features for the existing CV Partner application</li><br /><li>Develop the event-sourcing system and platform tools</li><br /><li>Help design and build services on the new platform</li><br /><li>Work closely with DevOps to maintain and enhance the security of CV Partner&rsquo;s systems</li><br /><li>Build internal tools to support business processes</li><br /><li>In the future: Mentor junior or mid-level developers and potentially lead a small team</li><br /></ul><br /></div><br /></div><br /><div><br /><h2>Future challenges</h2><br /><div class=&quot;article_rich_text w-richtext&quot;><br /><ul><br /><li>Break up the current application into smaller services</li><br /><li>Refactor the front-end code, improving the engineering principles around code organisation and testing</li><br /><li>Multi-region production deployments</li><br /><li>Design an effective interview process for junior and mid-level hires</li><br /><li>Automate parsing of CVs and Case Studies - potential for machine learning</li><br /></ul><br /></div><br /></div><br /><div><br /><h2>What we are looking for</h2><br /><div class=&quot;article_rich_text w-richtext&quot;><br /><ul><br /><li>Knowledge in some of the following (Ruby, JavaScript, Clojure, Rust, ElasticSearch, Redis)</li><br /><li>Knowledge of CoffeeScript is not required (we know you won&rsquo;t admit to it anyway)</li><br /><li>Experience in designing microservice architectures</li><br /><li>Enthusiasm to learn new tools and technologies</li><br /><li>Someone with good generalist knowledge: front-end; web development; databases (SQL or otherwise), DevOps; system architecture</li><br /><li>Linux, git, Github knowledge</li><br /><li>Bonus: Event-sourcing/CQRS experience</li><br /><li>Bonus: Front-end expertise</li><br /></ul><br /></div><br /></div><br /><div><br /><h2>Benefits /&nbsp;package</h2><br /><div class=&quot;article_rich_text w-richtext&quot;><br /><p>Location: London, Oslo or Stockholm</p><br /><p>Flexible working / part-remote (with close-to-home co-working)</p><br /><p>Pension contribution</p><br /><p>25 days holiday</p><br /><p>Competitive salary</p><br /><p>Weekly team lunch</p><br /></div><br /></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "A1k202TQTqWhSRlz7YhIlw",
    "url": "https://remoteok.io/jobs/74997",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angular/frontend/16",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:knockout.js/frontend/8",
      "DBG_TECH1:k/t/w:php/php/5",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:k/t/w:twitter-bootstrap/frontend/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=6, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=48, ruby=0, apple=0, java=3, gamedev=0, php=5, embedded=0, frontend=36}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "Hays",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 4:23:14 AM",
    "validThrough": "Sep 17, 2019 4:23:14 AM",
    "crawled": "Sep 10, 2019 5:06:30 AM",
    "content": "<span></span> <span><h4>Hays</h4></span> <br> <h3>Data Engineer</h3> <div>  <div>   \\n\\nHays Specialist Recruitment is working in partnership with Security Scorecard to manage the recruitment of this position\\n\\nThe end client is unable to sponsor or transfer visas for this position; all parties authorized to work in the US without sponsorship are encouraged to apply.\\n\\nThis position is NOT eligible for subcontractors or those that require sponsorship.\\n\\nHays is conducting an exclusive search for a Senior Data Engineer, for a Cybersecurity company based in NYC. Security Scorecard builds a very unique product that rates cybersecurity postures of corporate entities through the scored analysis of cyber threat intelligence signals for the purposes of third party management and IT risk management. They have a very modern Technology stack and work in a dynamic &amp; agile environment.\\n\\nThe position is a 100% remote and you'll be responsible for the management of the Analytic pipeline using Spark, Hardoop etc. Leverage cutting-edge technologies to support new and existing services and processes, drive projects through all stages of development and improving the effective output of the engineering team by managing quality and identifying inconsistencies. Your experience should involve 5+ years with Scala or another functional language (commercial environment preferred), 3+ years with Spark and the Hadoop ecosystem (or similar frameworks), Familiarity with tools like AWS and Docker, experience working with 3rd party software and Expert skills with SQL\\n\\n\\n\\nRemote Data Engineer - Perm - New York, NY\\n \\n \\n Remote Data Engineer Skills &amp; Requirements \\n \\n Responsibilities:\\n * Develop information systems by studying operations\\n * Design, develop, and install software solutions\\n * Support and develop member within the software team\\n * Support a core Angular project among other applications \\n \\n \\n Requirements:\\n * Sr Development Experience\\n * C# (Experience with Object-Oriented Programming languages)\\n * Angular (4+) - [knowledge of CSS, HTML, etc]\\n * JavaScript\\n * SQL Server Design &amp; Architecture\\n * REST based Web Services\\n * MVC Entity Framework\\n \\n \\n Plus Skills\\n * Scripting Experience (i.e. - PowerShell, PHP)\\n * Knockout\\n * Bootstrap\\n * Knowledge of Data Warehousing\\n \\n \\n Why Hays?\\n \\n \\n You will be working with a professional recruiter who has intimate knowledge of the Information Technology industry and market trends . Your Hays recruiter will lead you through a thorough screening process in order to understand your skills, experience, needs, and drivers. You will also get support on resume writing, interview tips, and career planning, so when there's a position you really want, you're fully prepared to get it. Additionally, if the position is a consulting role, Hays offers you the opportunity to enroll in full medical, dental or vision benefits.\\n \\n \\n * Medical \\n * Dental \\n * Vision \\n * 401K \\n * Life Insurance ($20,000 benefit)\\n \\n \\n Nervous about an upcoming interview? Unsure how to write a new resume?\\n \\n \\n Visit the Hays Career Advice section to learn top tips to help you stand out from the crowd when job hunting. \\n \\n \\n Hays is an Equal Opportunity Employer.\\n \\n \\n Drug testing may be required; please contact a recruiter for more information.\\n \\n \\n \\n \\n \\n \\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "H_BBmSncSJWxCdDvnjqVLA",
    "url": "https://remoteok.io/jobs/74998",
    "title": "Senior Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/24",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=64, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hays",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 10, 2019 4:20:19 AM",
    "validThrough": "Sep 17, 2019 4:20:19 AM",
    "crawled": "Sep 10, 2019 5:06:30 AM",
    "content": "<span></span> <span><h4>Hays</h4></span> <br> <h3>Senior Data Engineer</h3> <div>  <div>   \\n\\nHays Specialist Recruitment is working in partnership with Security Scorecard to manage the recruitment of this position\\n\\nThe end client is unable to sponsor or transfer visas for this position; all parties authorized to work in the US without sponsorship are encouraged to apply.\\n\\nThis position is NOT eligible for subcontractors or those that require sponsorship.\\n\\nHays is conducting an exclusive search for a Senior Data Engineer, for a Cybersecurity company based in NYC. Security Scorecard builds a very unique product that rates cybersecurity postures of corporate entities through the scored analysis of cyber threat intelligence signals for the purposes of third party management and IT risk management. They have a very modern Technology stack and work in a dynamic &amp; agile environment.\\n\\nThe position is a 100% remote and you'll be responsible for the management of the Analytic pipeline using Spark, Hardoop etc. Leverage cutting-edge technologies to support new and existing services and processes, drive projects through all stages of development and improving the effective output of the engineering team by managing quality and identifying inconsistencies. Your experience should involve 5+ years with Scala or another functional language (commercial environment preferred), 3+ years with Spark and the Hadoop ecosystem (or similar frameworks), Familiarity with tools like AWS and Docker, experience working with 3rd party software and Expert skills with SQL\\n\\n\\nRemote Senior Data Engineer - Perm - New York, NY\\n \\n \\n Remote Senior Data Engineer Skills &amp; Requirements \\n \\n Responsibilities\\n * Manage the analytic pipeline using Spark, Hadoop, etc \\n * Leverage cutting-edge technologies to support new and existing and services and processes.\\n * Quickly and efficiently design and implement in an agile environment\\n * Work with other team members to implement consistent architecture\\n * Drive projects through all stages of development\\n * Actively share knowledge and responsibility with other team members and teams\\n * Improve the effective output of the engineering team by managing quality, and identifying inconsistencies. \\n \\n \\n Requirements:\\n 3+ years of experience with: \\n * Scala or Python, both preferred\\n * Distributed systems (e.g. Spark, Hadoop)\\n * Database systems (e.g. Postgres, MySQL)\\n Experience with the following is preferred: \\n * IP (v4/v6) allocation and addressing conventions\\n * DNS conventions and best practices\\n * Anti-abuse investigations\\n * Bachelor's degree (CS, CE/EE, Math, or Statistics preferred)\\n \\n \\n Why Hays?\\n \\n \\n You will be working with a professional recruiter who has intimate knowledge of the Information Technology industry and market trends . Your Hays recruiter will lead you through a thorough screening process in order to understand your skills, experience, needs, and drivers. You will also get support on resume writing, interview tips, and career planning, so when there's a position you really want, you're fully prepared to get it. Additionally, if the position is a consulting role, Hays offers you the opportunity to enroll in full medical, dental or vision benefits.\\n \\n \\n * Medical \\n * Dental \\n * Vision \\n * 401K \\n * Life Insurance ($20,000 benefit)\\n \\n \\n Nervous about an upcoming interview? Unsure how to write a new resume?\\n \\n \\n Visit the Hays Career Advice section to learn top tips to help you stand out from the crowd when job hunting. \\n \\n \\n Hays is an Equal Opportunity Employer.\\n \\n \\n Drug testing may be required; please contact a recruiter for more information.\\n \\n \\n \\n \\n \\n \\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NipS0Q-ISImPhIq-qcl44g",
    "url": "https://stackoverflow.com/jobs/294783/data-scientist-remote-united-states-crisp?a=1ARnYqnxarOo&so_medium=Talent&so_source=TalentApi",
    "title": "Data Scientist - [Remote] - [United States] at Crisp  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:jvm/java/26",
      "DBG_TECH1:k/t/w:kotlin/mobile/5",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:k/t/w:velocity/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=5, go=0, nodejs=1, bigdata-ml=37, ruby=0, apple=0, java=34, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Crisp",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Scientist - [Remote] - [United States]</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Computer Software, Food &amp; Beverage</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Crisp | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>data-science</div><div>time-series</div><div>forecasting</div>                <h4>Job description</h4>                <div><p>Here at Crisp, we value the strength in teamwork, and strongly believe that it’s the key to Crisp’s success. By bringing together bright, motivated creators, wherever they live and work, we are leveraging humanity’s diversity of experience and background in order to understand the challenges facing our food supply, and solve them together. Come join us, and help build the type of business you’d like to be a part of.</p><p>We are a remote-first company which means we give you the opportunity to solve challenges in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of empowerment, personal impact and career growth.</p><p>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turn previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more.</p><p>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;<em>and</em>&nbsp;science of analytics - not only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data can help us further bolster our conclusions.&nbsp;You love engaging with customers, learning about their challenges and then diving into the data to see how to solve them!</p><p><strong>Signs of a great candidate</strong></p><ul><li><strong>Collaborative.</strong>&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to help us grow together.</li><li><strong>Customer focused.</strong>&nbsp;User experience trumps everything. You understand that a product will have little value if customers don't enjoy using it.</li><li><strong>Disciplined and reliable.</strong>&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early.</li><li><strong>Appreciative of honest feedback.</strong>&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You view feedback given to you as an opportunity to get better and strive to do the same for others.</li><li><strong>Work smarter and harder.</strong>&nbsp;You often identify a problem, design a solution and bring it to a state of completion - with others, or even on your own. You are fluent with your toolchain and can deliver well-designed, well-tested production-ready features quickly. You find ways of eliminating or automating stuff that is uninteresting or wasteful, rather than complaining about them.</li><li><strong>Analytical and practical mind.</strong>&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed. You strive for correct solutions, but know what actually matters and when to make compromises. You know when to ship and when to optimize.</li></ul><p><strong>Crisp’s tech stack</strong></p><ul><li><strong>Statically typed, modern languages.</strong>&nbsp;We use TypeScript and Kotlin, but knowledge of them is not a requirement and we’re happy to help you come up to speed.</li><li><strong>Continuous deployment.</strong>&nbsp;Code is never far from being deployed to production, because if it’s not in production, it’s not solving problems in the real world. Our branch time spans are short, and features under development are hidden behind feature flags.</li><li><strong>JVM based back-end.</strong>&nbsp;The JVM has a robust, rich ecosystem of libraries and tools that we’re leveraging to help us focus on building solutions, not tool-chains.</li><li><strong>Cloud first.</strong>&nbsp;As a services offering in the 21st century, the cloud isn’t the future, it’s the present. We’re fully invested in using the features offered by our cloud provider in order to minimize technical debt and maximize productivity.</li><li><strong>Micro-services.</strong>&nbsp;Not for the sake of the buzz, but when they make sense. By adopting a modern, thoughtful services architecture we’re able to scale organizationally, reduce technical debt, and maintain a high, sustained velocity.</li></ul><p>We are building a team of developers with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific background, experience or geographical location. Instead we’re looking for individuals that are capable, reliable, and hoping to grow along with us. Do you have strengths you can share? If so, we’d love to hear from you!</p>                </div>            <div>        <a href='https://crisp.recruiterbox.com/jobs/fk03hx7?source=StackoverflowJobPosting' rel='nofollow'>                        Apply now        </a></div>            <h4>About Crisp</h4>            <div><p>Our main goals with Crisp are easy to explain: We want to build a company that we would like to&nbsp;<em>enjoy&nbsp;</em>spending the rest of our careers in, that has a positive impact on the world and that will outlast us.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Fully remote</span>                            </li>                            <li>                                <span></span>                                <span>Excellent health insurance and benefits</span>                            </li>                            <li>                                <span></span>                                <span>Founders with proven track record</span>                            </li>                            <li>                                <span></span>                                <span>Well funded (by founders)</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "l6kHLMPlR0ib8kPRawZHjA",
    "url": "https://stackoverflow.com/jobs/294599/data-analyst-osmosis?a=1ANyLHOup2AE&so_medium=Talent&so_source=TalentApi",
    "title": "Data Analyst at Osmosis  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Osmosis",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 55000,
      "maxValue": 70000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 55k - 70k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Analyst</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                    </div>                <div>Company: Osmosis | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>sql</div><div>python</div><div>r</div><div>google-bigquery</div><div>saas</div>                <h4>Job description</h4>                <div><p><strong>Overview</strong></p><p>Our rapidly scaling medical education technology company is seeking a passionate Data Analyst to join our team. In this role, you will be working with the product, marketing, content, and operations teams to help us build the most joyful, effective learning platform in the medical education space.</p><p>This is a hands-on position in a unique remote, start-up environment, so we are looking for a candidate who is not afraid to roll up their sleeves to do the work and to collaborate with team members across the organization.</p><p><strong>About Osmosis</strong></p><p>Our mission is to “<em>Empower the world’s clinicians &amp; caregivers with the best learning experience possible.”&nbsp;</em>To this end, we have an audience of more than a million current &amp; future clinicians as well as patients and family members. Our members of the Osmosis learning platform and video library &nbsp;use the product to learn efficiently &amp; excel in classes, board exams, and in the clinic.&nbsp;</p><p>We are a team of creative, approachable, and driven entrepreneurs, researchers, and clinicians who are passionate about improving healthcare and education. At Osmosis, we collaborate remotely and value highly-motivated problem solvers who manage their time efficiently, communicate earnestly, work effectively, and understand the importance of life-work balance. &nbsp;We do everything we can to make sure our teammates are successful personally and professionally.</p><p><strong>About the Role</strong></p><p>As a Data Analyst, you will turn data into information, information into insight and insight into business decisions. You’ll develop analysis and reporting capabilities as well as monitor performance and quality control plans to identify improvements. Your primary responsibility will be to work with stakeholders across business functions including product, growth, marketing, and operations to build analytics products that enable data-driven decision making. You will guide analytics projects from discovery to solution and help us raise the bar for how we should apply our data to business decisions. In this role, you will be expected to:&nbsp;</p><ul><li>Complete analysis projects with business stakeholders to monitor the health of the business and help the business make data-driven strategic, product, and operational decisions</li><li>Develop and own business intelligence dashboards, visualizations, and reports to provide ongoing tracking and insights to the team</li><li>Build and improve advanced analytical models for product and business use cases</li><li>Collaborate with data engineer to improve data architecture and maintain a robust and accurate data warehouse</li><li>Acquire data from primary or secondary data sources and maintain databases/data systems</li><li>Identify, analyze, and interpret trends or patterns in complex data sets</li><li>Discover ways to use analytics to support team members across the business to yield action through data-driven decision making</li></ul><p><strong>Qualifications</strong></p><ul><li>2-4 years experience managing data analysis projects. eCommerce or SaaS experience is a plus.</li><li>Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.</li><li>Excel at composing concise efficient SQL queries, writing reports and presenting findings with data visualization tools.</li><li>Experience using a cloud data warehouse environment (such as BigQuery)</li><li>Experience with Python and pandas is a plus.</li><li>Working knowledge of business statistics and probability.</li><li>Ability to build trust and communicate insights effectively with a variety of business stakeholders across analytical levels.</li><li>Desire to be a partner to business stakeholders with a shared goal of using analytics and insights to drive the business forward.</li><li>Communicator. Excellent communication skills and a willingness to give and receive feedback.</li><li>Driven. Proactive and self-driven problem-solving with sharp attention to detail.</li><li>Iterative. You deliver results quickly with iteration, instead of waiting for perfection.&nbsp;</li><li>Adaptable. You are flexible and versatile with projects, goals, and strategies. You move quickly with change and stay open-minded</li><li>Entrepreneurial. You are a proven executor and work with urgency to produce excellent results with limited time and resources</li><li>Lifelong learner. You are actively consuming content (podcasts, blogs, books, etc) and applying these learnings in your work to make sure you are as effective as possible.&nbsp;</li><li>Passion for Osmosis’s mission to provide your future clinicians the best education so they can provide you and your loved ones the best care.</li></ul><p>Osmosis is an equal opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status or other status protected by law.</p><p><strong>To apply, please submit the following to&nbsp;<a href='mailto:careers@osmosis.org' rel='nofollow'>careers@osmosis.org</a>:&nbsp;</strong></p><ul><li>Resume</li><li>Portfolio of any relevant work</li><li>Answers to the following questions (50 words or less for each question):</li></ul><ol><li>What was an interesting data problem you worked on within the last year? How did you identify and address it?</li><li>Describe a situation where you did not have access to all of the data needed to triage a problem or analyze a situation, and how you adapted to it.</li><li>Based solely on what you see on osmosis.org, how would you measure customer lifetime value for Osmosis?</li></ol><p><em>Incomplete applications will not be considered.</em></p>                </div>            <div>        <a href='https://help.osmosis.org/en/articles/3291253-data-analyst' rel='nofollow'>                        Apply now        </a></div>            <h4>About Osmosis</h4>            <div><p><strong>About Osmosis</strong></p><p>Our mission is to “<em>Empower the world’s clinicians &amp; caregivers with the best learning experience possible.”&nbsp;</em>To this end, we have an audience of more than a million current &amp; future clinicians as well as patients and family members. Our members of the Osmosis learning platform and video library &nbsp;use the product to learn efficiently &amp; excel in classes, board exams, and in the clinic.&nbsp;</p><p>We are a team of creative, approachable, and driven entrepreneurs, researchers, and clinicians who are passionate about improving healthcare and education. At Osmosis, we collaborate remotely and value highly-motivated problem solvers who manage their time efficiently, communicate earnestly, work effectively, and understand the importance of life-work balance. &nbsp;We do everything we can to make sure our teammates are successful personally and professionally.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "u9UvJ_RBQ8m41HdLMSl3qw",
    "url": "https://stackoverflow.com/jobs/294515/senior-data-engineer-creative-commons?a=1ALOtLJh0HDO&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Data Engineer at Creative Commons  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=5, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 100000,
      "maxValue": 120000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 100k - 120k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Creative Commons | No office location<br></div><h4>Technologies</h4><div>python</div><div>apache-spark</div><div>postgresql</div><div>amazon-web-services</div>                <h4>Job description</h4>                <div><p>Creative Commons is working on a project to index every piece of content that's openly licensed online and making it searchable and discoverable through <a href='https://search.creativecommons.org/' rel='nofollow'>CC Search</a> and the <a href='https://api.creativecommons.engineering/' rel='nofollow'>CC Catalog API</a>. The Senior Data Engineer reports to the Director of Engineering and is responsible for building and maintaining the data that powers those products (the <a href='https://github.com/creativecommons/cccatalog' rel='nofollow'>CC Catalog</a>). This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners. All the code we write is open source and we’re a 100% remote team.</p><p><strong>Primary responsibilities</strong></p><ul><li>Architect, build, and maintain the existing CC Catalog, including:</li><ul><li>Ingesting content from new and existing sources of CC-licensed and public domain works.</li><li>Scaling the catalog to support billions of records and various media types.</li><li>Implementing resilient, distributed data solutions that operate robustly at web scale.</li><li>Automating data pipelines and workflows.</li><li>Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.</li></ul><li>Augment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.</li><li>Build an open source community around the CC Catalog, including:</li><ul><li>Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.</li><li>Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor.</li><li>Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.</li></ul><li>Collaborate with other outside communities, companies, and institutions to further Creative Commons’ mission.</li></ul><p><strong>Qualifications and requirements</strong></p><ul><li>Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization</li><li>Proficiency with Python</li><li>Proficiency with Apache Spark or similar tools</li><li>Experience with cloud computing platforms (AWS or similar)</li><li>Experience with Apache Airflow or other workflow management software</li><li>Experience with machine learning or interest in picking it up</li><li>Fluent in English</li><li>Excellent written and verbal communication skills</li><li>Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure</li><li>Curiosity and a desire to keep learning</li><li>Commitment to consumer privacy and security</li><li>Nice to have (but not required):</li><ul><li>Experience with contributing to or maintaining open source software</li><li>Experience with web crawling</li><li>Experience with Docker</li></ul></ul><p><strong>Diversity &amp; inclusion</strong></p><p>We believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.</p><p><strong>Work environment and location</strong></p><p>Creative Commons is a fully-distributed organization — we have no central office. This position is in a remote working environment and you can be anywhere in the world as long as you’re available for meetings between 2 PM to 8 PM UTC. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.</p><p><strong>Salary and benefits</strong></p><p>Creative Commons is a leading non-profit employer, offering competitive salaries and benefits, including health and wellness plans, annual retirement contributions, and a positive, supportive work environment. We offer competitive salary in the range for this position from $100,000 - $120,000 USD, commensurate with relevant skills, experience, and location.</p><p><strong>How to apply</strong></p><p>Please email your cover letter and resume as a single PDF to “<a href='mailto:jobs@creativecommons.org' rel='nofollow'>jobs@creativecommons.org</a>” with the subject heading of “Data Engineer / [Last Name].” Phone calls and messages will not be returned.</p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/294515?reset=False&amp;ra=1ALOtLJh0HDO&amp;oqs=a%3D1ALOtLJh0HDO%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Creative Commons</h4>            <div><p>Creative Commons (CC) is a United States-based nonprofit 501(c)3 organization that provides open content copyright licenses, public domain tools, and resources on copyright and information literacy in the digital age. Our free, easy-to-use copyright licenses provide a simple, standardized way for all creators, authors, and producers of knowledge assets and cultural works to give the public permission to share and use their works on conditions of their choice. CC licenses work in tandem with copyright, allowing creators to easily and legally change copyright terms from the default of “all rights reserved” to “some rights reserved” to best suit their needs.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "B8MZ1rChS0yuilPax1991g",
    "url": "https://stackoverflow.com/jobs/293627/senior-type-system-engineer-luna?a=1AtlHRHh98be&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Type-System Engineer at Luna (Kraków, Poland) ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:haskell/other/5",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:scala/java/9",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=2, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Luna",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 40000,
      "maxValue": 120000,
      "info": "Equity",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 40k - 120k /Year | Equity"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Type-System Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>System Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Cloud Computing, Data Science, Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Luna | Kraków, Poland<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Kraków, Poland.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div></div><div>java</div><div>scala</div><div>truffle</div><div>graalvm</div><div>types</div>                <h4>Job description</h4>                <div><p><strong>Senior Type-System Engineer</strong><br><a href='https://luna-lang.org' rel='nofollow'>Luna</a> is looking for a senior type-system engineer to help build the next generation interpreter and runtime for Luna, a project said by Singularity University to have the potential to change the lives of one-billion people. If you have strong technical skills and a passion for all things compiler, then this role could be the one for you.<br><br>As a type-system engineer you'll work as part of the compiler team to design and implement Luna's new type system, including its underlying theory, type-checker, and inference engine. This wok is _intrinsic_ to Luna's evolution, and will provide you with the opportunity to collaborate with a world-class team of engineers, community managers, and business developers (with experience at Bloomberg, GitHub, PayPal, to name a few), making your mark on Luna's future.<br><br><strong>What You'll Do<br></strong>As a senior type-system engineer, you'll be working on the design and development of Luna's new type-system, in conjunction with the rest of the compiler team, to help support the language's evolution. This will involve:</p><ul><li>Determining and formalising the theoretical underpinnings of the new type system in a way as to ensure its soundness.</li><li>Both theoretical and practical treatments of the theory behind Luna's type system.</li><li>Working with the broader compiler team to implement the type-checking and type-inference engines as part of the greater interpreter.</li><li>Using the type-system's information to improve the interpreter's functionality and performance, as well as how it interacts with the users.</li></ul><p><strong>The Skills We're Looking For</strong><br>We have a few particular skills that we're looking for in this role:</p><ul><li>Practical and rich experience writing code in a functional programming language such as Haskell or Scala, including experience with type-level programming techniques (3+ years).</li><li>Experience working with the theory behind powerful type systems, including row types, type-checking and type-inference algorithms, and dependently-typed systems.</li><li>Practical experience building real-world type-systems, including facilities for both type-checking and inference.</li><li>An awareness of the UX impacts of type-systems, and a willingness to minimise their often-intrusive nature.</li><li>Practical experience in building large and complex software systems.</li></ul><p>It would be a big bonus if you had:</p><ul><li>Experience writing Java and Scala code, as these will be used to implement the type-system.</li><li>Experience in writing comprehensive regression tests for both type-inference and type-checking systems.</li></ul><p>Avoid <a href='https://www.forbes.com/sites/womensmedia/2014/04/28/act-now-to-shrink-the-confidence-gap/' rel='nofollow'>the confidence gap</a>. You don't have to match <em>all</em> of the skills above to apply!<br><br><strong>Who You'll Work With</strong><br>You'll be joining a distributed, multi-disciplinary team that includes people with skills spanning from compiler development to data-science. Though you'll have your area to work on, our internal culture is one of collaboration and communication, and input is always welcomed.<br><br>We firmly believe that only by working <em>together</em>, rather than putting our team members in their own boxes, can we create the best version of Luna that can be.<br><br><strong>The Details</strong><br>As part of the Luna team you'd be able to work from anywhere, whether that be at home, or on the go! We have team members distributed across the world, from San Francisco, to London, to Kraków. We welcome remote work and flexible schedules, or you can work from the Kraków office (or our planned SF office) if you'd like. We can provide competitive compensation and holiday, as well as the possibility<br>of equity as time goes on.<br><br><strong>How To Apply?</strong><br>Send us an email at <a href='mailto:jobs@luna-lang.org' rel='nofollow'>jobs@luna-lang.org</a>, and tell us a little bit about yourself and why you think you'd be a good fit for the role! You can also tell us about:</p><ul><li>Some of your past work or projects.</li><li>Why you'd like to work on Luna, and where you imagine Luna being in 5 years.</li><li>The most important features of a team that you'd like to work in.</li><li>Whether you take pride in your ability to communicate clearly and efficiently with your team.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/293627?reset=False&amp;ra=1AtlHRHh98be&amp;oqs=a%3D1AtlHRHh98be%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Luna</h4>            <div><p><strong>About Luna</strong><br>Luna is an award-winning general-purpose programming language and data-science platform, selected by NASA and Singularity University as a technology with the potential to impact the lives of one-billion people worldwide. It spans the entire stack, from high-level visualisation and communication, to the<br>nitty-gritty of running backend services in a single language. With inbuilt capabilities for visualisation and a dual-syntax architecture, the possibilities are limitless.<br><br>At Luna, we have a world-class team, with developers, community managers, and business developers from all walks of life and backgrounds, and work in close collaboration with industry advisers such as Robert Gentleman, the creator of the R programming language and computational biologist at 23andMe, and Edward Kmett, a skilled language designer and machine intelligence researcher at MIRI.<br><br>We welcome anybody to our team, as long as you have the desire and drive to see Luna succeed.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Team built around the Humility, Respect, and Trust ideology.</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours, possible part / full time remote work.</span>                            </li>                            <li>                                <span></span>                                <span>Work in a small team of world-class engineers and make impact on Luna.</span>                            </li>                            <li>                                <span></span>                                <span>Competitive compensation + possibility of equity as time goes on.</span>                            </li>                            <li>                                <span></span>                                <span>Equality, diversity &amp; inclusion.</span>                            </li>                            <li>                                <span></span>                                <span>We've got standing desks in our office (no one uses them though :P).</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qUEf4u1AQGGpAIoyjSveFA",
    "url": "https://stackoverflow.com/jobs/285252/paid-research-study-for-developers-with-machine-user-research-international?a=1xFd0np8eBQA&so_medium=Talent&so_source=TalentApi",
    "title": "Paid Research Study for Developers with Machine Learning + Python Experience at User Research ...",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:techWeightMap:{python=8, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "User Research International",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Paid Research Study for Developers with Machine Learning + Python Experience</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>AI Research, Market Research, Surveying</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: User Research International | No office location<br></div><h4>Technologies</h4><div></div><div>python</div><div>machine-learning</div><div>jupyter-notebook</div><div>data-science</div><div>jupyter-lab</div>                <h4>Job description</h4>                <div><p>User Research International is a research company based out of Redmond, Washington. Working with some of the biggest companies in the industry, we aim to&nbsp;improve your experience via&nbsp;paid research studies. Whether it be the latest video game or productivity tools, we value your&nbsp;feedback and experience. We are currently conducting a research study called The Data Science\\Machine Learning Study. We are looking for current<strong>&nbsp;full-time&nbsp; Developers or Data Scientists</strong>&nbsp;who are familiar with&nbsp;Machine Learning,&nbsp;Python, and Jupyter Notebooks.This study is&nbsp;a one time study held remotely. We’re offering <strong>$200</strong> for participation in this study. Session lengths are 1 hour. These studies provide a platform for our researchers to receive feedback. This will be a one hour open ended interview with the researcher. We want to understand how you personally create and work with machine learning models. We have included the survey link for the study below. Taking the survey will help determine if you fit the profile requirements. If you complete the survey, and you are actually a <strong>fit to the study's requirements, URI will follow up with you</strong>. I have summarized the study details below. Thank you!</p><p>Study: The Data Science\\Machine Learning&nbsp;Study</p><p>Gratuity: <strong>$200</strong></p><p>Session Length:&nbsp;1 hour&nbsp;</p><p>Location:&nbsp;Remote via an online meeting</p><p>Dates: September. Available&nbsp;times are located within the survey</p><p>Survey: <a title=&quot;Click here to qualify for participating in the Data Science\\Machine Learning Survey&quot; href='https://uriuxn.ca1.qualtrics.com/jfe/form/SV_2fTdSmgpchX943P?SOURCE=StackOverflow' rel='nofollow'>The Data Science\\Machine Learning&nbsp;Study</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/285252?reset=False&amp;ra=1xFd0np8eBQA&amp;oqs=a%3D1xFd0np8eBQA%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div>            <h4>About User Research International</h4>            <div><p>We use your experience to improve upon the products you use. Whether it be the latest video game or productivity tools, we value your experience.&nbsp;</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Paid research studies</span>                            </li>                            <li>                                <span></span>                                <span>Improving tech</span>                            </li>                            <li>                                <span></span>                                <span>Getting  your feedback and experience</span>                            </li>                            <li>                                <span></span>                                <span>Meeting researchers working directly on the products you use</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5Bf5UupuSaWNoI6SMVhqCw",
    "url": "https://stackoverflow.com/jobs/293751/software-developer-3d-ar-vr-oaktree-technologies-gmbh?a=1AvVyUM1uire&so_medium=Talent&so_source=TalentApi",
    "title": "Software Developer 3D/AR/VR at Oaktree Technologies GmbH (Hamburg, Germany) ",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:c++/c/16",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:game-developer/gamedev/13",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:numerical-methods/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opencv/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=21, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=13, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Oaktree Technologies GmbH",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Software Developer 3D/AR/VR</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Graphics/Game Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Oaktree Technologies GmbH | Hamburg, Germany<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+01:00) Berlin +/- 4 hours</span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>Hamburg, Germany.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div>c++</div><div>python</div><div>javascript</div><div>emscripten</div><div>vulkan</div>                <h4>Job description</h4>                <div><p>In this role, you will be part of a multi-disciplinary international team and help us develop consumer-facing products. Your focus lies on writing well-maintainable software in the space of computer vision, computer graphics, and augmented reality.</p><p>The perfect applicant understands typical challenges and solution approaches for simulations, unbiased and biased rendering as well as augmented reality applications, especially regarding measuring distances in the real world and the limits of precision.</p><p><strong>Responsibilities</strong></p><ul><li>Develop robust software for rendering, computer vision or combinations thereof</li><li>Make use of standard software components like IRay and&nbsp;similar renderers</li></ul><p><strong>Requirements</strong></p><ul><li>S. or M.S. degree in Computer Science or a related technical field</li><li>Fluency in C++ required. Experience in JavaScript, WebAssembly and emscripten a plus</li><li>Solid theoretical foundations in various areas of computing, including algorithms &amp; data structures, numerical methods, computer graphics etc.</li><li>Ability to operate autonomously and effectively with only high-level direction</li><li>Experience in OpenCV and rendering APIs (OpenGL, Direct3D, Vulkan, Metal, …)</li><li>Collaborative, positive, team-oriented mindset</li><li>Solid English skills, German a plus</li></ul><p><strong>What we offer</strong></p><ul><li>Competitive salary and a secure job at a well-funded company</li><li>Small, independent company with a large diversity of tasks and flat hierarchy</li><li>A modern workplace with various amenities and an international setup</li><li>We're open to remote work, but we haven't established the details yet - we're&nbsp;interested in finding a good setup, so let's talk about it!</li></ul>                </div>            <div>        <a href='https://oaktree-jobs.personio.de/job/131807' rel='nofollow'>                        Apply now        </a></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "jDtIlw8XT-eCrWjhT-7Jgg",
    "url": "https://stackoverflow.com/jobs/292501/machine-learning-engineer-qntfy?a=1A5W78LakW1W&so_medium=Talent&so_source=TalentApi",
    "title": "Machine Learning Engineer at Qntfy  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/16",
      "DBG_TECH1:k/t/w:scikit-learn/python/10",
      "DBG_TECH1:techWeightMap:{python=14, other=0, dotnet=0, c=0, mobile=0, go=13, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Qntfy",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 120000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 90k - 120k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Machine Learning Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Qntfy | No office location<br></div><h4>Technologies</h4><div>python</div><div>scikit-learn</div><div>pytorch</div><div>docker</div><div>kubernetes</div>                <h4>Job description</h4>                <div><p>Qntfy is looking for a talented and highly motivated ML Engineer to join our team. ML Engineers are responsible for building systems at the crossroads of data science and distributed computing. You will do a little bit of everything: from tuning machine learning models, to profiling distributed applications, to writing highly scalable software. We use technologies like Kubernetes, Docker, Kafka, gRPC, and Spark. You aren’t a DevOps, but an understanding of how the nuts and bolts of these systems fit together is helpful and you aren't a data scientist, but understanding how models work and are applied is just as important.</p><p><strong>U.S. Citizenship Required</strong> <strong>Responsibilities</strong></p><ul><li>Collaborate with data scientists to get their models deployed into production systems.</li><li>Develop and maintain systems for distributed model training and evaluation.</li><li>Design and implement APIs for model training, inference, and introspection.</li><li>Build tools for testing, benchmarking, and deploying analytics at scale.</li><li>Interface with the technical operations team to understand analytic performance and operational behavior.</li><li>Write and test code for highly available and high volume workloads.</li></ul><p><strong>Qualifications</strong></p><ul><li>BS or Master’s degree in Computer Science, related degree, or equivalent experience.</li><li>5+ years experience with software engineering, infrastructure design, and/or machine learning.</li><li>Familiarity with Python and machine learning frameworks, paricularly Scikit-learn, Tensorflow, and Pytorch.</li><li>Experience with distributed machine learning using tools like Dask, Tensorflow, Kubeflow, etc.</li><li>Write well-structured, maintainable, idiomatic code with good documentation.</li><li>Strong work-ethic and passion for problem solving.</li></ul><p><strong>Preferred Qualifications</strong></p><ul><li>Machine learning API development competencies.</li><li>Golang development experience.</li><li>Container orchestration and optimization knowledge.</li><li>Proficiency designing, implementing, and operating large-scale distributed systems.</li><li>Prior experience working in a distributed (fully remote) organization.</li></ul><p>Qntfy is committed to fostering and supporting a creative and diverse environment. Qntfy is an equal opportunity employer, and as such will consider all qualified applicants for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.</p>                </div>            <div>        <a href='https://jobs.lever.co/qntfy/463fd368-8757-42d6-a45b-22634c032c8e?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Qntfy</h4>            <div><p>Qntfy is a primarily remote company,&nbsp;with employees working across the United States.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "K5IbOK5aTaqHVGiqFBJH7Q",
    "url": "https://stackoverflow.com/jobs/290564/software-engineer-rho-ai?a=1zrF0Xcvrji0&so_medium=Talent&so_source=TalentApi",
    "title": "Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/22",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=62, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Data Science, Software Development / Engineering</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Rho AI | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>single-page-application</div><div>sql</div><div>nosql</div><div>docker</div>                <h4>Job description</h4>                <div><p>Rho AI’s data-driven products &amp; services are used in a wide range of industries,&nbsp;with a growing focus on sustainable systems (e.g. energy, water, climate,&nbsp;waste). We value pragmatic solutions and have cultivated a modern technology&nbsp;stack that combines software development (python microservices, react&nbsp;frontends), infrastructure automation (docker, kubernetes), and machine&nbsp;learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p><p>As a member of the software engineering team, you will:</p><ul><li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li><li>Join a group of talented and congenial team members where you will be respected in your software design decisions and take ownership of the systems that you build.</li><li>Learn from and collaborate with senior engineers and co-founders.</li><li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li></ul><p>Sound interesting? We are hiring for a variety of experience levels, so all are welcome to apply. We are&nbsp; interested in hearing from candidates who have publicly available open-source and/or technical writing examples and are looking to&nbsp;take their next step in their professional careers.&nbsp; Please reach out if:</p><p><strong>You have:</strong></p><ul><li>(Must) Good communication skills for technical and non-technical audiences.</li><li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li><li>(Must) Proficient on all backend layers - databases, services and APIs.</li><li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li><li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li><li>(Should) Have experience working within a microservices oriented architecture.</li><li>(Nice) Built systems that process large amounts of data and/or traffic.</li><li>(Nice) Strong computer science principles, and/or algorithmic skills.</li><li>(Nice) Experience with machine learning applications.</li></ul><p>&nbsp;<strong>You would like these perks:</strong></p><ul><li>Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.</li><li>Work with a highly engaged team, learn together, and make decisions that impact the whole company.</li><li>Benefits, including health insurance and 401k.</li></ul><p>&nbsp;<strong>You meet these criteria:</strong></p><ul><li>You are seeking a full-time job.</li><li>You reside in the United States.</li><li>You are authorized / eligible to work for any company in the United States.</li><li>You are in a continental US time zone, or willing to align your schedule.</li></ul><p><strong>To get an interview, you must supply:</strong></p><ul><li>A cover letter that explains why you are 1) <em>specifically interested</em> in Rho AI as a company and 2) a <em>good fit</em> for this particular position.</li><li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/290564?reset=False&amp;ra=1zrF0Xcvrji0&amp;oqs=a%3D1zrF0Xcvrji0%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Rho AI</h4>            <div><p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p><p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p><p><strong>Work at Rho AI</strong></p><p>Rho AI is a remote-first organization, where you will work with a talented group of data scientists, engineers and thought leaders&nbsp;to harness the power of data science to propel projects with a positive world impact. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p><p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Work from anywhere in the world with flexible work schedules.</span>                            </li>                            <li>                                <span></span>                                <span>Health insurance &amp; FSA accounts</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salaries along with 401k</span>                            </li>                            <li>                                <span></span>                                <span>4 weeks of PTO</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "w1LTj2MISlCejik9vEPOaw",
    "url": "https://stackoverflow.com/jobs/286534/data-science-course-mentor-thinkful-inc?a=1y5RHQddlqU0&so_medium=Talent&so_source=TalentApi",
    "title": "Data Science Course Mentor at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=50, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Science Course Mentor</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>sql</div><div>python</div><div>Click here to apply</div><div>Click here to apply&nbsp;</div>                <h4>Job description</h4>                <div><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply</a><strong>Who We Are </strong><br>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;<br><br><strong>The Position</strong>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;Students enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed technologists. As a Course Mentor, you will support students by acting as an advisor, counselor, and support system as they complete the course and land their first industry job. To achieve this, you will engage with students using the below range of approaches, known as Engagement Formats. Course Mentors are expected to provide support across all formats when needed.&nbsp;<ul><li><strong>Mentor Sessions: </strong>Meet with students 1-on-1 in online video sessions to provide technical and professional support as the student progresses through the curriculum.</li><li><strong>Group Sessions: </strong>Host online video sessions on topics of your expertise (in alignment with curriculum offerings) for groups of student seeking live support between mentor sessions.&nbsp;</li><li><strong>Grading: </strong>Reviewing student checkpoints submissions and delivering written feedback, including analysis of projects and portfolios.&nbsp;</li><li><strong>Technical Coaching: </strong>Provide in-demand support to technical questions and guidance requests that come to the Technical Coaching team through text and video in a timely manner. This team also provides the TA support for immersive programs.&nbsp;</li><li><strong>Assessments &amp; Mock Interviews:</strong> Conduct 1-on-1 mock interviews and assessments via video calls and provide written feedback to students based on assessment rubrics.&nbsp;</li></ul>In addition to working directly with students, Course Mentors are expected to maintain an environment of feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.<strong>Requirements</strong><ul><li>Minimum of 1 year professional experience as a Data Scientist or demonstrated expertise with data visualizations and machine learning at an industry level</li><li>Proficiency in SQL, Python</li><li>Professional experience with Hadoop and Spark a plus</li><li>Excellent written and verbal communication</li><li>High level of empathy and people management skills</li><li>Must have a reliable, high-speed Internet connection</li></ul><strong>Benefits</strong><ul><li>This is a part-time role (10-25 hours a week)</li><li>Fully remote position, with the option to work evenings and weekends in person in 22 US cities</li><li>Community of 500+ like-minded Educators looking to impact others and keep their skills sharp</li><li>Full access to all of Thinkful Courses for your continued learning</li><li>Grow as an Educator</li></ul><br><strong>Apply</strong><br>If you are interested in this position please provide your resume and a cover letter explaining your interest in the role.Thinkful can only hire candidates who are eligible to work in the United States.We stand against any form of workplace harassment based on race, color, religion, sexual orientation, gender identity or expression, national origin, age, disability, or veteran status. Thinkful provides equal employment opportunities to all employees and applicants. If you're talented and driven, please apply.<br><br>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming<a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply&nbsp;</a>                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0mBDRn2vSbeib1Hs34t1Uw",
    "url": "https://stackoverflow.com/jobs/285363/senior-software-engineer-data-hotjar?a=1xHw6mESIywU&so_medium=Talent&so_source=TalentApi",
    "title": "Senior Software Engineer, Data at Hotjar  ",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/2",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/2",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:macos/apple/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=2, bigdata-ml=8, ruby=0, apple=2, java=0, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hotjar",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "EUR",
      "minValue": 70000,
      "maxValue": 90000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "EUR 70k - 90k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Software Engineer, Data</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Database Administrator</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Data &amp; Analytics, SaaS, Web Technology</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Hotjar | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+01:00) Amsterdam +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>postgresql</div><div>apache-kafka</div><div>amazon-kinesis</div><div>tableau</div><div>python</div>                <h4>Job description</h4>                <div><p><strong>Note:</strong>&nbsp;Although this is a remote position, we are only looking for candidates in European / African timezones between UTC-1 and UTC+3.</p><p>At Hotjar we’re on a mission to build the leading user feedback and analytics platform, with our product being used by over 500,000 sites in 190 countries. As part of our Business Intelligence team, you'll work on the exciting challenges that come with large-scale web traffic and analytics.</p><p>We work in an agile and highly collaborative environment, 100% remotely, and challenge the norms of&nbsp;<a href='https://www.hotjar.com/blog/effective-leadership' rel='nofollow'>traditional business leadership</a>. Our focus is on true transparency and respect.</p><p>We're looking for enthusiastic and resourceful data engineers who are passionate about turning data into insights. You want to help teams make data-informed decisions and take data-informed actions, you have a curious mindset, and you are motivated to understand our business better.</p><p><strong>You will:</strong></p><ul><li><p>Take end-to-end responsibility for designing, building, and maintenance of batch and real-time data pipelines and data solutions.</p></li><li><p>Choose and manage tools and technologies to build and support a robust data infrastructure.</p></li><li><p>Be responsible for the data modelling and schema design of our data warehouse.</p></li><li><p>Identify bottlenecks and improve the performance of all our data pipelines.</p></li><li><p>Ensure all necessary monitoring and backup solutions are in place.</p></li><li><p>Be one of the primary points of contact within the organization for data pipelines, ETL processes, and complex queries required by the product or for business intelligence purposes.</p></li></ul><p><strong>Requirements</strong></p><ul><li>Strong experience using distributed streaming platforms such as Apache Kafka or Amazon Kinesis.</li><li><p>Strong experience developing ETLs and data pipelines using Apache Spark 2.0.0 or higher.</p></li><li><p>Strong experience with data modelling for data warehousing use-cases, design patterns, and building highly scalable and secure solutions.</p></li><li><p>Experience with Python, PostgreSQL, and Amazon Redshift.</p></li><li><p>Experience with Hadoop, plus distributions like EMR, Cloudera or Hortonworks.</p></li><li><p>Experience with workflow management tools such as Airflow, Luigi or similar.</p></li><li><p>Experience with end-to-end testing of data pipelines.</p></li><li><p>A desire to work in a respectful, transparent, and transparent work environment, following Hotjar’s&nbsp;<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269942884/Hotjar+Core+Values' rel='nofollow'>company values</a>,&nbsp;<a href='https://careers.hotjar.com/' rel='nofollow'>culture&nbsp;</a>and&nbsp;<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/269779142/Working+at+Hotjar' rel='nofollow'>ways of working</a></p></li><li><p>Will submit to a background check, confidentially processed by our third-party partner.</p></li></ul><p><strong><strong>Plus points:</strong></strong></p><ul><li><p>Knowledge of data visualization and reporting tools such as Tableau</p></li><li><p>Experience with Elasticsearch and Redis</p></li><li><p>Experience with Segment (CDI)</p></li><li><p>Experience with distributed architectures and microservices.</p></li><li><p>Experience with cloud services (e.g. AWS, GCP, Azure), Containerization, configuration management and infrastructure automation.</p></li></ul><p><strong>What we offer</strong></p><ul><li><p>A remote and accomplished diverse and international team.</p></li><li><p>A chance to positively enhance people’s experience online and make the web a better place.</p></li><li><p>Annual learning and development budget</p></li><li><p>Several<a href='https://hotjar.atlassian.net/wiki/spaces/REC/pages/158105691/Our+Perks' rel='nofollow'>&nbsp;perks</a>&nbsp;designed for your well-being and a healthy work-life balance. (Holiday Budget, Wellbeing Allowance, Working Together Budget, 16 weeks paid parental leave, and much more)</p></li></ul><p><strong>Compensation Range</strong>&nbsp;</p><p>The budgeted compensation range for this role is €70,000 to €90,000 annually. Ranges are based on market research and are equitable to other roles within Hotjar. The actual compensation offered will be based on relative experience. At this time we are only able to provide official employment status to those located in Malta and Germany (for candidates who don’t require visa sponsorship). All other team members will join as full-time consultants and will be responsible for paying any taxes or applicable fees where they reside.</p>                </div>            <div>        <a href='https://careers.hotjar.com/o/senior-software-engineer-data-emea/?source=Stackoverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Hotjar</h4>            <div><p>Hotjar is a rapidly growing startup that is giving thousands of website owners the tools needed to discover how their visitors are really using their website. We are looking for passionate and ambitious developers who can help us shape the product and company while growing with us.</p><p><strong>Culture at Hotjar:</strong></p><p>Headquartered on the beautiful island of Malta, in the “heart” of the Mediterranean, Hotjar is a young startup that embraces remote working and personal development.</p><p>Hotjar’s culture is driven by transparency, respect, open discussion, collaboration and blunt and direct feedback. In fact, we’re obsessed with communicating with our users as well as within the team. We hate bureaucracy and slow moving organizations –&nbsp;but we’re suckers for well-defined processes. We love lean, iterative improvements and success is measured by the value we create for our users.</p><p><strong>The Perks:</strong></p><ul><li><strong>Remote &amp; Flexible.</strong> Work from anywhere within a European timezone.&nbsp;</li><li><strong>Ample Time Off.&nbsp;</strong>All team members get 40 days of paid planned leave/year, plus 10 sick days/year and time off to attend conferences / events.</li><li><strong>Collaborate with prestigious organizations.</strong> Imagine what it will feels like to be part of a product that is used by companies like Time Inc., Nintendo, Lloyd's Bank, Pingdom, Booking.com, Intuit and the Red Cross.</li><li><strong>Only the best hardware and software</strong>. Mac, PC or Linux –&nbsp;we will get you equipped with the best hardware and software available, of your own choice.</li><li><strong>Home Office budget.</strong> Every Hotjar team member receives a €4000 home office setup budget, with a yearly €500 top-up thereafter. Upgrade your desk, chair, screens or buy any peripherals you might need.</li><li><strong>Personal Development budget.</strong> Everyone receives a free Kindle as well as direct management of their own personal development yearly budget of €1,000. Buy books, short courses or magazine subscriptions.</li><li><strong>Holiday budget.</strong> A spend of €2,000/year for each team mate to spend relaxing and recharging on holiday.</li><li><strong>Work Together budget.</strong> Even though we're remote, we don't underestimate the value of getting together in person sometimes. Each team member has €2,000/year to spend on travelling to work with other Hotjarians.</li><li><strong>Working Space Allowance.</strong> Decide how you want to spend your monthly €200, whether it's on a co-working space, working from a coffee shop, getting your favourite coffee delivered to your home office, etc.</li><li><strong>Wellbeing Allowance.</strong> €200/month to spend on your wellbeing, be that physical, mental or spiritual.</li><li><strong>Work with a very talented team.</strong> Our team has an impressive background building and optimizing products and businesses around the globe.</li><li><strong>Make a difference.</strong> Hotjar is ‘democratizing’ site analytics and feedback by making them affordable and easy to use for everyone around the world. We call it the ‘Hotjar revolution’.</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>€4,000 Home Office Budget, topped up €500/year</span>                            </li>                            <li>                                <span></span>                                <span>100% Remote</span>                            </li>                            <li>                                <span></span>                                <span>Free Kindle Paperwhite, Fitbit, Headset and Reading Pack</span>                            </li>                            <li>                                <span></span>                                <span>€1,000 Annual Personal Development Budget</span>                            </li>                            <li>                                <span></span>                                <span>€200 Monthly Well Being Allowance</span>                            </li>                            <li>                                <span></span>                                <span>40 days leave annually</span>                            </li>                            <li>                                <span></span>                                <span>Two company retreats each year</span>                            </li>                            <li>                                <span></span>                                <span>€2,000 Annual Holiday Budget</span>                            </li>                            <li>                                <span></span>                                <span>€200 Monthly Working Space Allowance</span>                            </li>                            <li>                                <span></span>                                <span>€2,000 Annual Work Together Budget</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ikgkih8-RKOgGYibVWIEKw",
    "url": "https://stackoverflow.com/jobs/160144/platform-engineer-for-containers-giant-swarm-gmbh?a=RHQYJlgM27C&so_medium=Talent&so_source=TalentApi",
    "title": "Platform Engineer for Containers at Giant Swarm GmbH  ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(work,remot) 3W 3W(OR(wherev,whenev,where), OR(want,comfort))",
      "DBG_TECH1:k/t/w:distributed-database/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "Giant Swarm GmbH",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Platform Engineer for Containers</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Giant Swarm GmbH | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+01:00) Berlin +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>go</div><div>kubernetes</div>                <h4>Job description</h4>                <div><p><strong><strong>We are looking for a Platform Engineer for Containers</strong></strong></p><p><strong><strong>Your Job:</strong></strong></p><ul><li>You will be responsible for architecting and building distributed systems</li><li>You will use a wide variety of open source technologies and tools</li><li>You take part for testing, metrics, continuous integration</li></ul><p><strong><strong>Requirements</strong>:</strong></p><ul><li>You have experience with more than one language and a strong architectural background. One of these languages is Go.</li><li>You love to automate things and you are used to deploy in production multiple times a day</li><li>You are a profound Linux user</li><li>You have&nbsp;hands-on experience with&nbsp;kubernetes, prometheus and docker are a bonus point</li><li>You prefer to build your applications as multiple services instead of a monolith</li><li>You know the concepts of CAP theorem, paxos/raft concensus, distributed databases and message passing</li><li>We (and our customers) are currently mostly distributed around Europe (around UTC), thus, your main timezone&nbsp;needs to be between -2UTC to +2UTC to ensure better communication.</li></ul><p><br><br></p><p><strong><strong>Why we think this position is worth applying for (challenge us!)</strong></strong></p><ul><li>Impact, Impact, Impact! We are a remote-first organization with a growing team from 15+ European countries. Every new team member changes the team. This is great! People who know things we don’t are highly welcomed.</li><li>“It's better to ask forgiveness than permission” (Paolini) - sure, it’s not 100% like this, but we have a strong culture of failure which is part of our agile mindset. We don’t do things like in the guidebook. You can try things out!</li><li>We play a key role in our customer's digital transformation. We have partnered up with Amazon Web Services and Microsoft to provide our solution on their cloud platforms - more will follow.</li><li>We serve some of Europe's leading organizations and are talking to many more.</li></ul>                </div>                        <h4>About Giant Swarm GmbH</h4>            <div><p><strong><strong>WHY Giant Swarm?</strong></strong></p><p>We'd like to give you a glimpse on what working with us is like:</p><p><strong><strong>Self-organization</strong></strong></p><p>Creative work needs freedom and openness. We encourage you to do your work wherever and whenever you want. We expect passion and encourage sustainability. If you need rest, take it. We don't count holidays - we count outcome.</p><p><strong><strong>Teamwork</strong></strong></p><p>Our ambitious goals are only achievable as a team. Everybody’s input is highly welcome and appreciated. Although sometimes rules and processes are necessary, we try to keep them as lean as possible. Always question the status quo and find new ways of collaboration and teamwork.</p><p><strong><strong>Learning</strong></strong></p><p>Learning is mandatory and fun at the same time. If you realize you want to expand your knowledge in a specific area, we support you with conferences, books etc.</p><p><strong><strong>Basics</strong></strong></p><p>We offer fair (transparent and open) salaries with benefits like choosing your own laptop and a monthly perk compensation. Additionally, you will participate in our stock options program. Currently our team members have more children than we are employees. So family friendliness is a must.</p><p>We don't hiring job descriptions, we hire humans. :) We welcome applications from everybody, regardless of ethnic or national origin, religion, gender identity, sexual orientation or age.</p><p>Even though English is our company language, we also welcome CVs/applications in German.</p><p>Interested? Questions? Contact Larissa.</p>            </div>        <div>        <a href='https://giantswarm.breezy.hr/p/08874e59c0cc-platform-engineer-for-containers' rel='nofollow'>                        Apply now        </a></div>                    <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>unlimited holidays</span>                            </li>                            <li>                                <span></span>                                <span>fair and transparent open salaries</span>                            </li>                            <li>                                <span></span>                                <span>familiy friendlyness is a must</span>                            </li>                            <li>                                <span></span>                                <span>choose the time you want to work</span>                            </li>                            <li>                                <span></span>                                <span>choose the devices you want to work with</span>                            </li>                            <li>                                <span></span>                                <span>remote work possible</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "3IOo-n5nQzqFagOTjKFCsA",
    "url": "https://stackoverflow.com/jobs/282622/r-developer-yougov?a=1wMwwd9rlHhe&so_medium=Talent&so_source=TalentApi",
    "title": "R Developer at YouGov  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=15, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "YouGov",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>R Developer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Market research, Web Technology</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>501–1k people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: YouGov | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 4 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>r</div><div>shiny</div><div>python</div><div>etl</div>                <h4>Job description</h4>                <div><p><span>Crunch.io, part of the YouGov PLC, is seeking a talented, motivated, and versatile human to help lead the development of our R data science products. Crunch provides a modern platform for survey data analysis, and a central feature of our product is the ability to manipulate and analyze datasets stored in the cloud using R. As senior R developer, you will have three main responsibilities. First, you will work with the rest of our team to design and implement novel features that deliver real value and change our clients’ workflows for the better. Second, as the primary point of contact between our R user community and the development team, you will serve as their voice in product development. And third, you will often directly help clients manipulate and explore data using Crunch, including helping clients design and implement workflows that incorporate Crunch.&nbsp;&nbsp;</span></p><p><strong>Key responsibilities:</strong></p><ul><li><span>Teaching users how to work with the library through documentation and direct conversations.</span></li><li><span>Writing scripts that help clients implement Crunch and make it a part of their workflow, including ETL, data analysis, and outputs.&nbsp;&nbsp;</span></li><li><span>Developing and maintaining our core R packages, including new feature design, comprehensive testing, and documentation</span></li><li><span>Supporting our community of R users by responding to feature requests and triaging bug reports</span></li><li><span>Evangelizing our product and educating our R user base by contributing to our technical blog and helping enrich our support documentation</span></li><li><span>Translating API speak to R that feels natural and native</span></li><li><span>Engaging with and contributing to the broader open source R ecosystem</span></li></ul><p><span>Depending on your interests and skills, there are opportunities to get involved in:</span></p><ul><li><span>API design: developing good conventions that enable our platform to scale and make it easy for client applications to consume them</span></li><li><span>JavaScript development, helping our frontend developers implement features you've utilized in R</span></li><li><span>Product management, building on your interactions with our users to shape our product roadmap and feature design</span></li><li><span>Python development, ranging from implementing APIs you need for the R packages, to&nbsp; statistical modeling, numerical computing, machine learning, and natural language processing</span></li></ul><p><span>In any given week, you might implement an R interface for a new API our backend has added, write a blog post introducing that new feature, track down a bug report from a user, write a test that reproduces the issue, and assist customers in implementing Crunch via the Crunch R packages.&nbsp;</span></p><p><strong>Qualifications:</strong></p><ul><li><span>Expert-level skills in R, including experience delivering code that others rely on to do their work. Prior experience creating and maintaining R packages is highly valued.</span></li><li><span>Serious commitment to high development standards, including comprehensive testing, in whatever language you're working</span></li><li><span>Demonstrated ability to work with a team of peers, understanding and respecting the responsibilities and expertise developers, designers, QA folks, and others bring to the project</span></li><li><span>Eagerness to take ownership of projects and deliver results on schedule</span></li><li><span>Experience in a &quot;data science&quot;, such as social science, market research, or data visualization, is a plus.</span></li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/282622?reset=False&amp;ra=1wMwwd9rlHhe&amp;oqs=a%3D1wMwwd9rlHhe%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About YouGov</h4>            <div><p>YouGov works with the world's leading brands and organisations to understand what people think.</p><p><strong>Powered&nbsp;by Digital Development</strong></p><p>Our Global Dev group is a tight group of seven teams comprised of about 40 developers based globally in the UK, Poland, USA and beyond.</p><p>The teams coordinate on efforts to build applications and innovate in data collection, survey authoring, profile data management, integration, data analytics, content management, and other areas.</p><p>These applications drive the&nbsp;opinion data engine of YouGov; empowering the biggest and the best organisations around the world with accurate information about what the world thinks. Enabling these organisations to make effective predictions based on what their audience or stakeholders think.</p><p>We believe the more people are able to participate in the decisions made by the institutions that serve them, the better those decisions will be.</p><p><strong>Diverse as the Audience we work with</strong></p><p>YouGov is part of Stonewall's Global Diversity Champions Framework.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Flexibility</span>                            </li>                            <li>                                <span></span>                                <span>Best Equipment</span>                            </li>                            <li>                                <span></span>                                <span>Salary + Bonus</span>                            </li>                            <li>                                <span></span>                                <span>Well-being at Work</span>                            </li>                            <li>                                <span></span>                                <span>Various lifestyle benefits</span>                            </li>                            <li>                                <span></span>                                <span>Culture of Learning</span>                            </li>                            <li>                                <span></span>                                <span>Pension (401K in the USA)</span>                            </li>                            <li>                                <span></span>                                <span>Employee Assistance</span>                            </li>                            <li>                                <span></span>                                <span>Games and Social Events</span>                            </li>                            <li>                                <span></span>                                <span>Good Holiday allowance</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "u8JQajI0QMGJi2y_KwWeWg",
    "url": "https://stackoverflow.com/jobs/265031/data-platform-engineer-heetch?a=1qSKVWcse6xq&so_medium=Talent&so_source=TalentApi",
    "title": "Data Platform Engineer at Heetch  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:avro/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=11, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Heetch",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Platform Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>System Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Carsharing, Marketplace, Transportation</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Heetch | No office location<br></div><h4>Technologies</h4><div></div><div>kafka</div><div>prestodb</div><div>apache-spark</div><div>airflow</div><div>amazon-redshift</div>                <h4>Job description</h4>                <div><p><strong>⚠️<u>Read before applying:</u></strong></p><p>We're a young company iterating over our remote culture so for now, we're only working with people in locations where the time zone is:&nbsp;<strong>-3 hours &gt; Paris time zone&nbsp;&lt;&nbsp;+3 hours</strong></p><p><strong>Data Engineering Team @Heetch</strong></p><p>Our team's mission is to help the company generate confident insights, make better decisions and build data-driven products. We believe the data platform is the digital nervous system of Heetch and that empowering everyone in the company with data access is critical to our business success. As a new sub-team within Data Engineering, the Data Infrastructure team is dedicated to designing, building and scaling our data platform and the underlying data infrastructure.</p><p><strong>What will be your role?</strong></p><p>You will enable Data Scientists, Data Analysts, and Operations teams, tailor the data platform to their needs and empower them to solve challenging ML and analytics problems. If you're experienced, passionate and interested in leading the transformation of our data infrastructure, we would love to talk to you!</p><p><strong>Does it sound like you?</strong></p><ul><li>You've architected, built, scaled, tuned and maintained large-scale distributed systems in a production environment, specifically on top of AWS.</li><li>You've got proven experience working with data technologies that power data platforms (e.g.: Spark, Presto, Kafka, Airflow, Avro, Redshift, ElasticSearch, etc.).</li><li>You've led DevOps topics such as CI/CD, containerization, monitoring, etc. in a data ecosystem.</li><li>You display strong coding skills in Python and Scala with a focus on maintainability, scale, and automation.</li><li>You love to work autonomously and take on unconstrained problems.</li><li>You can drive a vision, estimate the associated tasks and plan from development to delivery.</li><li>You take pride in sharing and gathering knowledge through documentation, advocacy and getting soaked in stakeholders use cases.</li></ul><p><strong>What will you do?</strong></p><ul><li>Build frameworks, libraries, and abstractions to enable easy and reliable data processing, ingestion and exposition</li><li>Automate data pipeline and services deployment and configuration management</li><li>Support, manage and handle operations on cloud-based data technologies (e.g., clusters, serverless applications, APIs, databases)</li><li>Monitor the health of the data platform through automation</li><li>Handle periodic on-call rotations</li><li>Allow data engineering and data science to execute their pipelines through workflow management</li></ul><p><strong>What will be your challenges?</strong></p><ul><li>Build the next generation of our data platform using open source big data technologies such as Kafka, Kafka Streams, Airflow, Spark, Metacat and Kubernetes</li><li>Enable data scientists to test and productionize various ML models to enhance the performance of our marketplace</li><li>Craft robust infrastructure foundations to support API-based data access including finatra microservices and AWS Lambda functions</li><li>Support, manage and handle operations on our MPP databases (Redshift, Presto)</li><li>Design change data capture from PostgreSQL databases to feed the data lake</li><li>Simplify data integration with Apache Gobblin</li><li>Enable dataset discovery, metadata exploration, and change notification</li><li>Unlock acceptance testing with Airflow, Spark, and Cucumber</li></ul><p><strong>What's next?</strong></p><p>If your application is selected, the process will be composed of 4 steps:</p><ol><li>Non-technical interview with the Engineering Manager of your potential team (1h30)</li><li>Take home assignment (~5 days deadline)</li><li>Interview with your future teammates (1h)</li><li>Day on site (Paris) to meet your future stakeholders</li></ol><p>Check out our<a href='https://eng.heetch.com/' rel='nofollow'>&nbsp;Engineering Blog</a>&nbsp;and follow our&nbsp;<a href='https://twitter.com/heetcheng' rel='nofollow'>twitter</a>&nbsp;:) You can also have a look at our open-source projects and contributions&nbsp;<a href='https://oss.heetch.com/' rel='nofollow'>here</a></p>                </div>            <div>        <a href='https://jobs.lever.co/heetch/707af0c6-48ff-4426-8caa-5faa8ef9e9ae?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Heetch</h4>            <div><p>Heetch is a mobility app with a simple mission: We want people to enjoy going out.<br>Every night and every day, our drivers are doing their best to make their rides unforgettable and friendly! We are focused on young people's expectations and are competing within a fast-paced market.</p><p>The service launched in Paris in September 2013 has been growing ever since, with thousands of daily rides in France, Belgium, and Morocco. With more than 1 million users in Europe, we are proud to be one of the fastest growing French startups!</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Full remote and flexible ways of working</span>                            </li>                            <li>                                <span></span>                                <span>Paid conferences attendance/travel</span>                            </li>                            <li>                                <span></span>                                <span>Code Retreat</span>                            </li>                            <li>                                <span></span>                                <span>2 company seminars</span>                            </li>                            <li>                                <span></span>                                <span>Travel budget to visit your co-workers</span>                            </li>                            <li>                                <span></span>                                <span>Heetch Credits</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "7hTM7DMwQRy6WyWrVJ8AWQ",
    "url": "https://stackoverflow.com/jobs/260456/data-engineer-supermercato24?a=1plD2abNscz6&so_medium=Talent&so_source=TalentApi",
    "title": "Data Engineer at Supermercato24  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:macos/apple/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:windows/dotnet/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=32, ruby=0, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Supermercato24",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Database Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Information Technology</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Supermercato24 | No office location<br></div><h4>Technologies</h4><div></div><div>mysql</div><div>data-warehouse</div><div>etl</div><div>bigdata</div><div>infrastructure</div>                <h4>Job description</h4>                <div><p><strong>Who are we looking for:</strong></p><p>We are looking for a savvy Data Engineer to join our growing tech team.</p><p>You will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.</p><p>The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.</p><p><strong>Roles and Responsibilities:</strong></p><ul><li>you will build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other big data technologies</li><li>you will design and model data structures to help analyzing our business and technical data</li><li>you will support existing processes running in production</li><li>you will work together with people from other key areas to assist with data-related technical issues and support their data infrastructure needs</li></ul><p><strong>Skills &amp; Requirements</strong></p><ul><li>knowledge in relevant engineering best practices, data management fundamentals, data storage principles, and be current with recent advances in distributed systems as it pertains to data storage and computing</li><li>2+ years of experience in designing, building and maintaining data architecture(s) and infrastructure(s), both relational and non-relational</li><li>2+ years of maintaining data warehouse systems and working on large scale data transformation using SQL, Hadoop, Hive, or other Big Data technologies; experience with ETL tools is a plus</li><li>2+ years of data modeling experience, and able to use data models to improve the performance of software services</li><li>experience with Cloud Based Solution (AWS Redshift, GCP Big Query) and programming language (Python, Java) is a plus</li><li>experience communicating with colleagues from engineering, analytics, and business backgrounds</li><li>degree in Engineering, Math, Statistics, Computer Science, or related discipline or equivalent experience is a plus.</li><li>be able to legally work in Europe (you are the holder of a EU Passport or you are the holder of EU residency permit or you are the holder of a Schengen Work Visa)</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/260456?reset=False&amp;ra=1plD2abNscz6&amp;oqs=a%3D1plD2abNscz6%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Supermercato24</h4>            <div><p>Supermercato24 was founded in 2014 and got multiple startup awards.</p><p>It is now a multi-million well-funded startup with top Italian investors such as Innogest and 360 Capital Partner. We are also creating innovative partnerships with blue chip companies such as Samsung and Enel.</p><p>We aim at making grocery shopping online easy, fast and convenient.</p><p>We want to empower everyone with avant-garde technology and doing things that were deemed impossible until few moments ago.</p><p>We want to change the world and give back all the time and efforts that everyone now spends in picking, queuing and delivering his own groceries at home.</p><p>We want to do this to allow people to spend their time on what really matters: life.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Free coffee</span>                            </li>                            <li>                                <span></span>                                <span>Ping Pong</span>                            </li>                            <li>                                <span></span>                                <span>Stock Options</span>                            </li>                            <li>                                <span></span>                                <span>Budget for education</span>                            </li>                            <li>                                <span></span>                                <span>Work Laptop (Mac/Linux/Windows)</span>                            </li>                            <li>                                <span></span>                                <span>Fresh fruit every week</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours and location</span>                            </li>                            <li>                                <span></span>                                <span>Free happy hour every two weeks</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "bOZf7AiVQhGp9eVS51Wivg",
    "url": "https://stackoverflow.com/jobs/275807/lead-machine-learning-engineer-yougov?a=1uuOU7z1rrZS&so_medium=Talent&so_source=TalentApi",
    "title": "Lead Machine Learning Engineer at YouGov (Warsaw, Poland) ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:numpy/python/10",
      "DBG_TECH1:k/t/w:pandas/python/10",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:scipy/python/5",
      "DBG_TECH1:techWeightMap:{python=34, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=38, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "YouGov",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "EUR",
      "minValue": 50000,
      "maxValue": 70000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "EUR 50k - 70k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Lead Machine Learning Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Market research, Web Technology</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>501–1k people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: YouGov | Warsaw, Poland<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+01:00) Warsaw </span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>Warsaw, Poland.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div></div><div>etl</div><div>python</div><div>pandas</div><div>numpy</div><div>pytorch</div>                <h4>Job description</h4>                <div><p>We don’t just collect data, we connect data. YouGov is an international data and analytics group. Our value chain is a virtuous circle consisting of a highly engaged online panel, innovative data collection methods, powerful analytics technology, delivery of high-margin syndicated data products, expert insights and an authoritative media presence. Our core offering of opinion data is derived from our highly participative panel of 6 million people worldwide who provide us with live, continuous streams of data. We capture these streams of data via our variety of data collection platforms and collect them together in the YouGov Cube, our unique connected data library.</p><p>Working as part of the Data Science team, you will collaborate with and coordinate data-minded people to convert vast troves of raw consumer data into meaningful insight by developing and deploying of machine learning models, automated ETL applications, RESTful microservices and browser-based user interfaces.&nbsp;</p><p><strong>What will I be doing day to day?</strong></p><ul><li>Build new data science products for internal and external clients</li><li>Collaborate to design automated analytical solutions (e.g. fraud detection, prevention)</li><li>Optimise applications to increase performance, reliability and test coverage</li><li>Help to streamline the feature engineering and optimise the pipelines</li><li>Curate and promote best collaborative processes within the data science domain</li><li>Train and mentor team members to enable them to be their best</li></ul><p><strong>What do I need to bring with me?</strong></p><ul><li>Proficiency in Python as well as Scikit-Learn, Pandas, NumPy, SciPy, Tensorflow, PyTorch.</li><li>Have knowledge in building substantial ETL pipelines</li><li>Parallel computing/programming experience</li><li>Experience with Agile, TDD and DevOps development lifecycle</li><li>Enjoy solving complex technical problems, and supporting others to do so</li><li>Familiar with both old and new technologies and aware of the problems they purport to solve, and willing to keep up-to-date</li><li>Can work within a cross-functional team with both, technical and non-technical colleague</li></ul><p><strong>Any additional info:</strong></p><p>This role can either be based in our Warsaw tech hub, or be 100% remote.</p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/275807?reset=False&amp;ra=1uuOU7z1rrZS&amp;oqs=a%3D1uuOU7z1rrZS%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About YouGov</h4>            <div><p>YouGov works with the world's leading brands and organisations to understand what people think.</p><p><strong>Powered&nbsp;by Digital Development</strong></p><p>Our Global Dev group is a tight group of seven teams comprised of about 40 developers based globally in the UK, Poland, USA and beyond.</p><p>The teams coordinate on efforts to build applications and innovate in data collection, survey authoring, profile data management, integration, data analytics, content management, and other areas.</p><p>These applications drive the&nbsp;opinion data engine of YouGov; empowering the biggest and the best organisations around the world with accurate information about what the world thinks. Enabling these organisations to make effective predictions based on what their audience or stakeholders think.</p><p>We believe the more people are able to participate in the decisions made by the institutions that serve them, the better those decisions will be.</p><p><strong>Diverse as the Audience we work with</strong></p><p>YouGov is part of Stonewall's Global Diversity Champions Framework.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Flexibility</span>                            </li>                            <li>                                <span></span>                                <span>Best Equipment</span>                            </li>                            <li>                                <span></span>                                <span>Salary + Bonus</span>                            </li>                            <li>                                <span></span>                                <span>Well-being at Work</span>                            </li>                            <li>                                <span></span>                                <span>Various lifestyle benefits</span>                            </li>                            <li>                                <span></span>                                <span>Culture of Learning</span>                            </li>                            <li>                                <span></span>                                <span>Pension (401K in the USA)</span>                            </li>                            <li>                                <span></span>                                <span>Employee Assistance</span>                            </li>                            <li>                                <span></span>                                <span>Games and Social Events</span>                            </li>                            <li>                                <span></span>                                <span>Good Holiday allowance</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Vziq3RbpSuK4krVKxIjBPw",
    "url": "https://stackoverflow.com/jobs/293763/data-science-immersion-instructor-thinkful-inc?a=1Awb234tYlqM&so_medium=Talent&so_source=TalentApi",
    "title": "Data Science Immersion Instructor at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Data Science Immersion Instructor</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>python</div><div>sql</div>                <h4>Job description</h4>                <div><p><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxKysN8PShIUd' rel='nofollow'>Apply here</a></p><ul><li>Education</li><li>Remote</li><li>Contract</li></ul><strong>Job Description</strong>Students enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed software developers. As a Data Science Immersion Course Instructor, you will deliver high quality live workshop content based on the Data Science curriculum, preparing students to successfully transition careers.&nbsp;In addition to working directly with students, Instructors are expected to maintain an environment of regular, candid feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.<strong>Responsibilities</strong><ul><li><br>Delivers high quality workshops based on the curriculum materials, and provides live demos when appropriate, to supplement written materials and content to provide students with the skills and knowledge to get their first job</li><li>Support students by answering questions and providing guidance as they work independently or in pairs on assignments during the class day</li><li>Maintains and updates the daily and weekly student syllabus which outlines the required homework and assignments, and deadlines for assessments and projects.</li><li>Works with the other Format Leads for engagement formats (Mentor Sessions, Group Sessions, Grading, Technical Coaching, Mock Interviews/Assessments) to ensure that consistent experience is happening for students in immersive courses<br><br></li></ul><strong>Requirements</strong><ul><li>8 hours a day, 5 days a week.</li><li>Available to instruct Monday through Friday 10am-2:00pm ET</li><li>Available to spend up to 4 hours a day prepping for workshops and updating course materials.</li><li>Strong expertise with Python, SQL, statistics, supervised and unsupervised learning, and topics such as NLP, deep learning (using Tensorflow and Keras), or big data (using spark, AWS, and hadoop)</li><li>Expertise with Data Structures and Algorithms, and comfort explaining these topics.&nbsp;</li><li>Ability to explain complicated topics clearly and without jargon</li><li>Strong written and verbal communication skills</li><li>High level of detail orientation and an exceptional work ethic</li><li>Enjoy working with people, not just putting your head down and working</li><li>Must have a reliable, high-speed Internet connection</li><li>Minimum 3-4 years of professional data science experience</li></ul><strong>Compensation and Benefit</strong><ul><li>Contract position with a collaborative team</li><li>Ability to work remotely with partially flexible hours&nbsp;</li><li>Access to all available course curriculum for personal use</li><li>Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry</li></ul><br>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxKysN8PShIUd' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kK4DKnawTVC3n8U_nsVDpA",
    "url": "https://stackoverflow.com/jobs/280659/software-engineer-search-platform-wikimedia-foundation-inc?a=1w7HTTWMJDnW&so_medium=Talent&so_source=TalentApi",
    "title": "Software Engineer, Search Platform at Wikimedia Foundation, Inc.  ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/8",
      "DBG_TECH1:k/t/w:java/mobile/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:php/php/15",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=10, mobile=4, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=11, gamedev=0, php=15, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TECH1/php",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java",
      "php"
    ],
    "hiringOrganization": {
      "name": "Wikimedia Foundation, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 9:30:24 PM",
    "validThrough": "Sep 16, 2019 9:30:24 PM",
    "crawled": "Sep 9, 2019 9:30:24 PM",
    "content": "<h3><span>Software Engineer, Search Platform</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Education Technology, eLearning, Non-Profit</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                            </div>                    </div>                <div>Company: Wikimedia Foundation, Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>java</div><div>php</div>                <h4>Job description</h4>                <div><p><strong>Summary</strong></p><p>Our small team is passionate about making knowledge discoverable. We are responsible for Wikidata Query Service (a graph database that allows users to run arbitrary SPARQL queries on Wikidata) and for the search engine used on Wikipedia and its sister projects.</p><p>We are looking for a software engineer to help us bring the Search Platform team to the next level.</p><p>We use open-source tools as much as possible, and always open source our own work. Java, Python, PHP, and Scala make up most of our code, but we value using the right tool for the job. Our world is vast and can be complicated, so we value communication, enthusiasm, and an eagerness to learn.</p><p><strong>You are responsible for:</strong></p><ul><li>Work and communicate clearly and effectively within a small team that spans multiple time zones</li><li>Help maintain, scale, and extend query services at the Wikimedia Foundation — this includes the Wikidata Query Service (WDQS) and our Elasticsearch-based search engine</li><li>Improve the integration of Search, Wikidata Query Service, and the MediaWiki platform</li></ul><p><strong>Skills and Experience:</strong></p><ul><li>Good working knowledge of software design principles</li><li>Good understanding of how to scale applications, in terms of load, complexity, and performance</li><li>Ability to work in a Linux server environment</li><li>Write code in Java and PHP that stands the test of time</li><li>Demonstrated experience in large-scale Java applications</li><li>Be willing to travel occasionally - sometimes internationally - for team and organizational meetings</li><li>Proficient English speaker</li></ul><p><strong>Additionally, we’d love it if you have:</strong></p><ul><li>Degree in computer science, statistics, math, physics or other quantitative discipline; equivalent experience learned hands-on on the job also works</li><li>Experience with graph databases</li><li>Experience working on open source, collaborative development projects</li><li>Understanding of free culture / free software / open source principles</li><li>Exposure to applied machine learning (ML), deep learning, or natural language processing (NLP)</li><li>Familiarity with statistics</li><li>Experience with an internet software environment operating at scale; for example, messaging platforms that process hundreds of thousands of events per second</li><li>Big thumbs ups if you are a contributor to Wikipedia</li></ul><p><em>Show us your stuff! If you have any existing open-source software that you've developed (this could be your own software or patches to other packages), please share the URLs for the source. Links to GitHub, etc. are especially useful.</em>&nbsp;&nbsp;</p><p><strong>The Wikimedia Foundation is...&nbsp;</strong></p><p>...the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p><p><strong><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></strong></p><p><strong>U.S. Benefits &amp; Perks*</strong></p><ul><li>Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)</li><li>The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more</li><li>The 401(k) retirement plan offers matched contributions at 4% of annual salary</li><li>Flexible and generous time off - vacation, sick and volunteer days, plus 19 paid holidays - including the last week of the year.</li><li>Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.</li><li>For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program</li><li>Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses</li><li>Telecommuting and flexible work schedules available</li><li>Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax</li><li>Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people</li></ul><p><strong><em>*Eligible international workers' benefits are specific to their location and dependent on their employer of record</em></strong></p><p><strong>More information</strong></p><p><a href='https://wikimediafoundation.org/' rel='nofollow'><strong>WMF<br></strong></a><a href='https://wikimediafoundation.org/news/' rel='nofollow'><strong>Blog<br></strong></a><a href='https://meta.wikimedia.org/wiki/Strategy/Wikimedia_movement/2017' rel='nofollow'><strong>Wikimedia 2030<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimedia_Foundation_Medium-term_plan_2019' rel='nofollow'><strong>Wikimedia Medium Term Plan<br></strong></a><a href='https://wikimediafoundation.org/2018/08/30/diversity-inclusion-numbers/' rel='nofollow'><strong>Diversity and inclusion information for Wikimedia workers, by the numbers<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimania_2019' rel='nofollow'><strong>Wikimania 2019<br></strong></a><a href='https://annual.wikimedia.org/2017/' rel='nofollow'><strong>Annual Report - 2017</strong></a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/280659?reset=False&amp;ra=1w7HTTWMJDnW&amp;oqs=a%3D1w7HTTWMJDnW%26so_medium%3DTalent%26so_source%3DTalentApi' rel='nofollow'>Apply now</a></div>            <h4>About Wikimedia Foundation, Inc.</h4>            <div><p><strong>The Wikimedia Foundation is...</strong></p><p>...the nonprofit organization that supports Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared&nbsp;knowledge,&nbsp;and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive&nbsp;<a href='https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&amp;uselang=en&amp;utm_medium=wmfWikiLink&amp;utm_source=B_FAQ&amp;utm_campaign=C_FAQ' rel='nofollow'>financial support</a>&nbsp;from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p><p><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Fully paid premiums for medical, dental &amp; vision insurance premiums</span>                            </li>                            <li>                                <span></span>                                <span>401(k) with 4% matching contribution</span>                            </li>                            <li>                                <span></span>                                <span>7-12 weeks parental leave with 100% pay + lactation room</span>                            </li>                            <li>                                <span></span>                                <span>Wellness Program ($1800 annual) to promote wellness &amp; personal growth</span>                            </li>                            <li>                                <span></span>                                <span>Pre-tax savings plans for Transportation &amp; Parking</span>                            </li>                            <li>                                <span></span>                                <span>Flexible work schedules and remote working options</span>                            </li>                            <li>                                <span></span>                                <span>Pet Friendly office</span>                            </li>                            <li>                                <span></span>                                <span>Commitment to diversity &amp; inclusion throughout the employee lifecycle</span>                            </li>                            <li>                                <span></span>                                <span>12 days vacation, 19 days holiday, 2 days volunteer work and more!</span>                            </li>                            <li>                                <span></span>                                <span>Lean more at https://wikimediafoundation.org/wiki/Work_with_us</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "iVP1AgbVSeCh3n542A0ZOg",
    "url": "https://jobmote.com/job/71343/database-engineer-remote/",
    "title": "Database Engineer (Remote)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=0, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "August Consulting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 10:29:42 AM",
    "validThrough": "Sep 12, 2019 10:29:42 AM",
    "crawled": "Sep 9, 2019 3:06:27 PM",
    "content": "<div>Job Title: Sr. Database Engineer Location: Rancho Cordova, CA 95670 (Remote) Duration: 6-Months to hire Interview Process: Phone &amp; In Person Required Skills: 10 years related work experience in managing and administering Oracle, MySQL, Postgres databases 3 years related work experience in managing and administering RDS databases on AWS or Azure. E.g. Aurora RDS. 1 year related work experience in containerization like Docker with Kubernetes, AWS EKS, PCF, etc. Position Summary: The Senior Engineer DBA provides expertise, mentoring, and leadership in the areas of database installation, upgrades, patches, tuning, performance monitoring, troubleshooting, database deployments, container management, support and documentation of standards, environments and procedures for the administration of all supported environments. Job Responsibilities: Sr. engineer will be responsible for leading technical assignments within the team Responsible for reporting and managing deliverables within the team Define monitoring requirements for databases and lead efforts for continual improvements &amp; proactive monitoring Automate or improve SOP and maintenance tasks. Act as a technical SME during escalated P1/P2 issues Participate in database deployments and approved changes into the environment Independently perform DB installation, cloning &amp; migration Troubleshoot, track and resolve complex database issues, identify recurring problems and apply fixes Track and resolve database related requests from users, and escalate as necessary Apply regular and proactive database patches and updates Perform proactive space &amp; growth management for databases Responsible for designing sound backup and recovery policies and procedures Experience Required Bachelor s degree in a related field or an equivalent combination of training and experience. 10 years related work experience in managing and administering Oracle, MySQL, Postgres databases 3 years related work experience in managing and administering RDS databases on AWS or Azure. E.g. Aurora RDS. 1 year related work experience in containerization like Docker with Kubernetes, AWS EKS, PCF, etc. Proficient in writing and maintaining Unix shell scripts to automate system tasks Thorough understanding of architectural elements required to support large installations and maintain high availability such as database clustering and replication In-depth knowledge of administration in a UNIX (Solaris) or Linux (RHEL) command-line environment. Able to work in fast paced environments and have understanding of programming environments Proactive, can-do attitude whose actions work toward continuous process improvement Superior analytical, troubleshooting, knowledge sharing, collaborative and mentoring skills Must be able to write effective technical documents and reports as a primary focus of daily duties Excellent communication ability (verbal, written, and presentation) and an effective team player Experience supporting all phases of the system development life cycle including development, testing, QA and production. Must exercise effective judgment and follow established procedures in support of production, 24x7, and other critical environments Relevant industry certifications preferred Knowledge of government sponsored health care programs and systems preferred Physical Requirements: Ability to sit for up to 80% of time Ability to lift or carry objects up to 10 lbs. Frequent use of computer, telephone, and office equipment (copier, fax, scanner) - provided by Dice<br> Associated topics: data architect, data integration, data management, data quality, data scientist, data warehouse, database administrator, mongo database, sybase, teradata</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Ny-VdiSCRCW7Mw543DHPOw",
    "url": "https://stackoverflow.com/jobs/294783/data-scientist-remote-united-states-crisp?a=1ARnYqnxarOo",
    "title": "Data Scientist - [Remote] - [United States] at Crisp  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:jvm/java/26",
      "DBG_TECH1:k/t/w:kotlin/mobile/5",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:k/t/w:velocity/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=5, go=0, nodejs=1, bigdata-ml=37, ruby=0, apple=0, java=34, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Crisp",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 3:06:26 PM",
    "validThrough": "Sep 16, 2019 3:06:26 PM",
    "crawled": "Sep 9, 2019 3:06:26 PM",
    "content": "<h3><span>Data Scientist - [Remote] - [United States]</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Computer Software, Food &amp; Beverage</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Crisp | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>data-science</div><div>time-series</div><div>forecasting</div>                <h4>Job description</h4>                <div><p>Here at Crisp, we value the strength in teamwork, and strongly believe that it’s the key to Crisp’s success. By bringing together bright, motivated creators, wherever they live and work, we are leveraging humanity’s diversity of experience and background in order to understand the challenges facing our food supply, and solve them together. Come join us, and help build the type of business you’d like to be a part of.</p><p>We are a remote-first company which means we give you the opportunity to solve challenges in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of empowerment, personal impact and career growth.</p><p>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turn previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more.</p><p>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;<em>and</em>&nbsp;science of analytics - not only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data can help us further bolster our conclusions.&nbsp;You love engaging with customers, learning about their challenges and then diving into the data to see how to solve them!</p><p><strong>Signs of a great candidate</strong></p><ul><li><strong>Collaborative.</strong>&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to help us grow together.</li><li><strong>Customer focused.</strong>&nbsp;User experience trumps everything. You understand that a product will have little value if customers don't enjoy using it.</li><li><strong>Disciplined and reliable.</strong>&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early.</li><li><strong>Appreciative of honest feedback.</strong>&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You view feedback given to you as an opportunity to get better and strive to do the same for others.</li><li><strong>Work smarter and harder.</strong>&nbsp;You often identify a problem, design a solution and bring it to a state of completion - with others, or even on your own. You are fluent with your toolchain and can deliver well-designed, well-tested production-ready features quickly. You find ways of eliminating or automating stuff that is uninteresting or wasteful, rather than complaining about them.</li><li><strong>Analytical and practical mind.</strong>&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed. You strive for correct solutions, but know what actually matters and when to make compromises. You know when to ship and when to optimize.</li></ul><p><strong>Crisp’s tech stack</strong></p><ul><li><strong>Statically typed, modern languages.</strong>&nbsp;We use TypeScript and Kotlin, but knowledge of them is not a requirement and we’re happy to help you come up to speed.</li><li><strong>Continuous deployment.</strong>&nbsp;Code is never far from being deployed to production, because if it’s not in production, it’s not solving problems in the real world. Our branch time spans are short, and features under development are hidden behind feature flags.</li><li><strong>JVM based back-end.</strong>&nbsp;The JVM has a robust, rich ecosystem of libraries and tools that we’re leveraging to help us focus on building solutions, not tool-chains.</li><li><strong>Cloud first.</strong>&nbsp;As a services offering in the 21st century, the cloud isn’t the future, it’s the present. We’re fully invested in using the features offered by our cloud provider in order to minimize technical debt and maximize productivity.</li><li><strong>Micro-services.</strong>&nbsp;Not for the sake of the buzz, but when they make sense. By adopting a modern, thoughtful services architecture we’re able to scale organizationally, reduce technical debt, and maintain a high, sustained velocity.</li></ul><p>We are building a team of developers with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific background, experience or geographical location. Instead we’re looking for individuals that are capable, reliable, and hoping to grow along with us. Do you have strengths you can share? If so, we’d love to hear from you!</p>                </div>            <div>        <a href='https://crisp.recruiterbox.com/jobs/fk03hx7?source=StackoverflowJobPosting' rel='nofollow'>                        Apply now        </a></div>            <h4>About Crisp</h4>            <div><p>Our main goals with Crisp are easy to explain: We want to build a company that we would like to&nbsp;<em>enjoy&nbsp;</em>spending the rest of our careers in, that has a positive impact on the world and that will outlast us.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Fully remote</span>                            </li>                            <li>                                <span></span>                                <span>Excellent health insurance and benefits</span>                            </li>                            <li>                                <span></span>                                <span>Founders with proven track record</span>                            </li>                            <li>                                <span></span>                                <span>Well funded (by founders)</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0Y5h_GBJQk6KQfCAQ_Nz7w",
    "url": "https://weworkremotely.com/remote-jobs/ukufu-technical-lead-mobile-machine-learning",
    "title": "Ukufu: Technical Lead - Mobile & Machine Learning",
    "tags": [
      "DBG:surround``OR(abl,will,challeng,flexibl,experi,get,prefer) 2W 2N(work,remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:php/php/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=5, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Ukufu",
      "sameAs": "http://ukufu.com"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 8:23:07 AM",
    "validThrough": "Sep 16, 2019 8:23:07 AM",
    "crawled": "Sep 9, 2019 9:06:23 AM",
    "content": "<h3> Technical Lead - Mobile &amp; Machine Learning </h3><div><ul><li>Flexible/remote work friendly environment</li><li>Greenfield project</li><li>Technology first company</li><li>Work with exciting AI &amp; mobile tech</li><li>Join an experienced tech &amp; product team</li></ul><div><br></div><div>Ukufu* (pronounced oo - koo - foo) is a new AI powered content aggregation mobile application for professionals. Ukufu version 1.0 is set for a soft-launch in late September.&nbsp; <br><br>We recently closed a round of seed funding from a couple of smart and supportive investors, and we are excited for the next stage of our journey! <br><br>Watch a short message from our CEO:<br><a href='https://www.youtube.com/watch?v=ABE_3NQRb5E&amp;feature=youtu.be' rel='nofollow'>https://www.youtube.com/watch?v=ABE_3NQRb5E<br><br></a>Our mission is bold: <br><br>Build an intelligence layer around the 10 000 English news-related content pieces that get published every day.&nbsp; Then use this layer to power an easy-to-use category based content aggregation app that helps professionals efficiently consume content across multiple content sources.<br><br>We want to enable a content consumption experience that is simple to use, yet comprehensive in depth and breadth of content. <br><br>We are already 3 months into our journey. You can view a working prototype of our mobile application here:<br><a href='https://www.youtube.com/watch?v=z0Fp2HDH7SU' rel='nofollow'>https://www.youtube.com/watch?v=z0Fp2HDH7SU</a>&nbsp;<br><br>Over the next 6 - 12 months, we will be focussed on stage 1, working closely with users to build something amazing that we can then scale up in stage 2.&nbsp;<br><br>Our headquarters are in the Sydney CBD but we have team members around the world.&nbsp; This role can be on-site, remote or a mix of both. Our distributed team structures requires all team members to be flexible around time zones. Each role also has minimum daily crossover time requirements.<br><br>Our remote-friendly work culture and processes have been in place for a couple of years (our team used to work together on a product that reached over 4 million users) and our distributed team structure is working well.&nbsp; All team members are required to ensure there is a<br><br></div><div>We work hard at fostering a focused and friendly workplace, where team members are able to do their best work.</div><div><br></div><div>We are looking for someone with outstanding technical experience, a mature attitude and a preference for working with a small smart team, to join us in the role of Technical Lead at Ukufu.</div><div><br></div><div>This role includes hands-on development work as well as mentoring, building out the team when applicable, code reviews and systems architectural design. You will work directly with the CEO as well as the development and product team.<br><br>Our team of 8 currently consists of 3 engineers (excluding the Tech Lead).&nbsp; We aim to add 4 new engineers (excluding the Tech lead) over the next couple of months.&nbsp; These 7 engineers will fall under your leadership.<br><br>Our non-engineering team members include a Design Lead and Product Manager who you will work closely with.&nbsp;<br><br>Our current stack includes Flutter, Python, PHP, Kubernetes and AWS.</div><div><br></div><div><br>The Role<br><br></div><ul><li>Strategise with the business and product teams to determine priorities and goals</li><li>Lead technical discussions and decisions&nbsp;</li><li>Advocate best practice software engineering principles within the team</li><li>Drive process in an agile environment</li><li>Fill the role of a Scrum master, directing various ceremonies, e.g. Planning sessions, retrospectives, Sprint showcases, etc</li><li>Ensure a constant operational awareness of the platform health and team effectiveness</li><li>Identify gaps in team capabilities and be involved in the hiring process</li><li>Analyse data in order to help identify areas for improvement in the product, process and team</li><li>Mentor the team in both engineering and process-related areas</li><li>Actively developing the application</li><li>Assist on occasion with various technical tasks relating to different legacy products</li></ul><div><br>Requirements<br><br></div><ul><li>At least 10 years of relevant experience in a software development role.</li><li>Experience designing and building complex software solutions and related infrastructure</li><li>Experience building, configuring and maintaining a mobile-related application stack.</li><li>Strong background in OO development with a proficient understanding of fundamental principles such as TDD, DDD, SOLID, DRY and KISS.</li><li>Familiarity working with Amazon AWS services (e.g. RDS, DMS, S3, EC2, CloudWatch, CloudSearch, ElasticSearch, etc).</li><li>Working experience with Linux.</li><li>Experience with system monitoring tools.</li><li>Familiarity with popular server software packages (MySQL, PostgreSQL)</li><li>Mature attitude</li><li>Experience leading and managing a technical team</li><li>Excellent written and verbal skills</li><li>Exceptional attention to detail and the ability to manage multiple high priority projects and tasks</li><li>Passion for solving complex technical problems</li><li>Enjoy working in a fast-moving environment</li></ul><div><br></div><div><br>Bonus Skills<br><br></div><ul><li>Strong working knowledge of the latest Machine Learning techniques and technologies</li><li>Mobile application development experience</li><li>Experience with Dart or Flutter</li><li>DevOps experience</li><li>Experience building an online product</li><li>Has contributed to open source projects (provide examples if available)</li><li>Comprehensive understanding and experience with system security</li><li>Relevant University degree</li></ul><div><br></div><div>Our application process usually includes an initial chat with the CEO, one technical task, then a chat with 2-3 additional team members. &nbsp;<br><br><br>To apply for this role, please apply via the Recruitee link only.&nbsp;<br><br><br></div><div>* Ukufu comes from the Zulu word Ukufunda, which means “to learn”.&nbsp;</div><div><br></div><div><br></div></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kmtRw2JwQqCkfDwo-pCPZQ",
    "url": "https://remoteok.io/jobs/74963",
    "title": "Data Analyst",
    "tags": [
      "DBG:surround``OR(oper,collabor) 2W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=7, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Osmosis",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 9, 2019 5:25:19 AM",
    "validThrough": "Sep 16, 2019 5:25:19 AM",
    "crawled": "Sep 9, 2019 6:06:28 AM",
    "content": "<span></span> <span><h4>Osmosis</h4></span> <br> <h3>Data Analyst</h3> <div>  <div>   \\nOverview\\n\\nOur rapidly scaling medical education technology company is seeking a passionate Data Analyst to join our team. In this role, you will be working with the product, marketing, content, and operations teams to help us build the most joyful, effective learning platform in the medical education space.\\n\\nThis is a hands-on position in a unique remote, start-up environment, so we are looking for a candidate who is not afraid to roll up their sleeves to do the work and to collaborate with team members across the organization.\\n\\nAbout Osmosis\\n\\nOur mission is to “Empower the world’s clinicians &amp; caregivers with the best learning experience possible.”&nbsp;To this end, we have an audience of more than a million current &amp; future clinicians as well as patients and family members. Our members of the Osmosis learning platform and video library &nbsp;use the product to learn efficiently &amp; excel in classes, board exams, and in the clinic.&nbsp;\\n\\nWe are a team of creative, approachable, and driven entrepreneurs, researchers, and clinicians who are passionate about improving healthcare and education. At Osmosis, we collaborate remotely and value highly-motivated problem solvers who manage their time efficiently, communicate earnestly, work effectively, and understand the importance of life-work balance. &nbsp;We do everything we can to make sure our teammates are successful personally and professionally.\\n\\nAbout the Role\\n\\nAs a Data Analyst, you will turn data into information, information into insight and insight into business decisions. You’ll develop analysis and reporting capabilities as well as monitor performance and quality control plans to identify improvements. Your primary responsibility will be to work with stakeholders across business functions including product, growth, marketing, and operations to build analytics products that enable data-driven decision making. You will guide analytics projects from discovery to solution and help us raise the bar for how we should apply our data to business decisions. In this role, you will be expected to:&nbsp;\\n\\n\\n* Complete analysis projects with business stakeholders to monitor the health of the business and help the business make data-driven strategic, product, and operational decisions\\n\\n* Develop and own business intelligence dashboards, visualizations, and reports to provide ongoing tracking and insights to the team\\n\\n* Build and improve advanced analytical models for product and business use cases\\n\\n* Collaborate with data engineer to improve data architecture and maintain a robust and accurate data warehouse\\n\\n* Acquire data from primary or secondary data sources and maintain databases/data systems\\n\\n* Identify, analyze, and interpret trends or patterns in complex data sets\\n\\n* Discover ways to use analytics to support team members across the business to yield action through data-driven decision making\\n\\n\\n\\n\\nQualifications\\n\\n\\n* 2-4 years experience managing data analysis projects. eCommerce or SaaS experience is a plus.\\n\\n* Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\\n\\n* Excel at composing concise efficient SQL queries, writing reports and presenting findings with data visualization tools.\\n\\n* Experience using a cloud data warehouse environment (such as BigQuery)\\n\\n* Experience with Python and pandas is a plus.\\n\\n* Working knowledge of business statistics and probability.\\n\\n* Ability to build trust and communicate insights effectively with a variety of business stakeholders across analytical levels.\\n\\n* Desire to be a partner to business stakeholders with a shared goal of using analytics and insights to drive the business forward.\\n\\n* Communicator. Excellent communication skills and a willingness to give and receive feedback.\\n\\n* Driven. Proactive and self-driven problem-solving with sharp attention to detail.\\n\\n* Iterative. You deliver results quickly with iteration, instead of waiting for perfection.&nbsp;\\n\\n* Adaptable. You are flexible and versatile with projects, goals, and strategies. You move quickly with change and stay open-minded\\n\\n* Entrepreneurial. You are a proven executor and work with urgency to produce excellent results with limited time and resources\\n\\n* Lifelong learner. You are actively consuming content (podcasts, blogs, books, etc) and applying these learnings in your work to make sure you are as effective as possible.&nbsp;\\n\\n* Passion for Osmosis’s mission to provide your future clinicians the best education so they can provide you and your loved ones the best care.\\n\\n\\n\\n\\nOsmosis is an equal opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status or other status protected by law.\\n\\nTo apply, please submit the following to&nbsp;   <span>[email&nbsp;protected]</span>:&nbsp;\\n\\n\\n* Resume\\n\\n* Portfolio of any relevant work\\n\\n* Answers to the following questions (50 words or less for each question):\\n\\n\\n\\n\\n* What was an interesting data problem you worked on within the last year? How did you identify and address it?\\n\\n* Describe a situation where you did not have access to all of the data needed to triage a problem or analyze a situation, and how you adapted to it.\\n\\n* Based solely on what you see on osmosis.org, how would you measure customer lifetime value for Osmosis?\\n\\n\\n\\nIncomplete applications will not be considered.  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "bwLvpebyRw-osLQiFOEywA",
    "url": "https://jobmote.com/job/70354/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 8, 2019 10:07:27 PM",
    "validThrough": "Sep 11, 2019 10:07:27 PM",
    "crawled": "Sep 9, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote || <br><br> #LI-AR1 <br><strong>#IND123</strong> <br> #GLDR2</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "CMIyo9jfSqSRbtAEOIQx3Q",
    "url": "https://jobmote.com/job/70347/senior-artificial-intelligence-ai-technology-engineer-remote/",
    "title": "Senior Artificial Intelligence (AI) Technology Engineer- Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/14",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=14, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 8, 2019 10:07:27 PM",
    "validThrough": "Sep 11, 2019 10:07:27 PM",
    "crawled": "Sep 9, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>We have an exciting opportunity for a technologist who will architect, build and maintain technology infrastructure for the AI community, with accountability for delivering highly available and scalable services, developing appropriate and timely solutions for daily issues, as well as executing the Travelers AI platform strategy<br><br>The level of work required is considered advanced with ability to under minimal supervision. This job does not have direct reports. <br>The role scope requires an extensive knowledge of on-premise (private), off-premise (public) and hybrid cloud models along with cloud implementation service models (laaS, PaaS and SaaS).<br><br>Successful candidate will have working knowledge of tools and techniques used by Data Scientists and a general understanding of the business our AI area is supporting. This individual will work with a team to deliver a platform that meets the needs of the ongoing transformation in the industry.<br><br>Under general supervision, demonstrates a thorough understanding of the activities performed related to engineering support, installation and/or operations of infrastructure technologies. Plans at an operational level designing and developing technology solutions interfacing with appropriate customers, management and technical resources. Facilitates and/or participates in the design, development, and implementation of large complex technology solutions supporting one or more business and/or technology areas. Develops and implements appropriate solutions that may involve multiple platforms, databases, software/hardware technologies and tools. Strong ability to multi-task in an environment of changing priorities. This job is a team lead.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Enabling of on demand compute, high performance compute(HPC), purpose drive compute, self service</li> <li>Develop, enhance, and operate scalable and highly available components for Kubernetes-based container platform</li> <li>Build automation tools and frameworks for on-demand deployment environments, infrastructure</li> </ul> provisioning and service management<ul><li>Work with stakeholders to obtain and translate requirements into technical implementations</li> <li>Integrate existing legacy systems with proposed systems by identifying gaps between the current and future state, and leading the development and implementation of solutions</li> <li>Oversee and develop continuous delivery framework and tools</li> <li>Introduce orchestration framework tailored to user community needs</li> <li>Setup framework for infrastructure as code and automation</li> <li>Create and maintain technical documentation for designs</li> <li>Provide timely/responsive technical support both within and across departments and applications including rotational on call support</li> <li>Automate as much work as possible minimizing manual steps and improving security.</li> <li>Work to harden, enhance, document, establish process and generally improve the operability and supportability of our systems in the cloud.</li> <li>Evaluate new tools and technologies through POCs and propose solutions for implementation</li> <li>Participate in an on-call rotation for the critical platform(s) your team provides to the company</li> <li>Continually improve reliability and optimize performance of our production systems</li> <li>Concentrate on the technical design, and operation of cloud-based platforms (AWS, Azure, Google Cloud, etc.)</li> <li>Lead automation efforts to minimize manual work and ensure transparency in all aspects of the secure cloud ecosystem</li> </ul><br> Evaluates systems specifications regarding customer requirements, transforming specifications into cost-effective, technically correct solutions. Prioritizes work and manages projects within established budget objectives and customer priorities. Responsible for establishing and managing to established quality control and security protocols. Provides the division, department and business area management with timely and accurate information regarding the status and performance of the assigned project(s). Leverages technology to develop, redesign and/or implement optimal technology solutions. Builds, leverages, and maintains effective alliances across technical and business community. Interacts with customers to achieve efficient, effective results. Multi-tasks, prioritizes according to business priorities and production availability requirements. Other duties as assigned.<br><br>Minimum Qualifications<br>High School diploma or equivalent required. 3 years of experience in Technology required.<br><br>Education, Work Experience &amp; Knowledge<br>Education and Experience:<ul><li>Bachelor's degree in Computer Science, Information Systems, or equivalent background or experience</li> <li>3+ years working with cloud based platforms (AWS, Azure, Google Cloud, etc.) in an enterprise environment</li> <li>5+ years software engineering experience in a team based environment</li> </ul><br>Desired skills and knowledge also include:<ul><li>Debugging AI / ML workloads</li> <li>Experience integrating legacy platforms and applications with cloud based systems</li> <li>Linux (Rhel, Ubuntu) expertise</li> <li>Experience with various programming languages (Java, JavaScript, Python, etc.)</li> <li>Full understanding of security, access, monitoring, scalability, capacity, and life cycle management</li> <li>Understanding of storage and the advantage and disadvantages for various storage approaches</li> <li>Understanding of basic networking concepts</li> <li>Experience with Kubernetes, Docker</li> <li>Experience with infrastructure as code tools (CloudFormation, Azure Resource Manager, Terraform, etc.)</li> <li>Experience with system configuration tools (Chef, Puppet, Ansible, etc.)</li> <li>Advanced knowledge of cloud based platforms AWS, Azure, Google Cloud, etc.</li> </ul><br><br>Job Specific &amp; Technical Skills &amp; Competencies<br>Advanced knowledge of one or more of the following technical skills: cloud based platforms AWS, Azure, Google Cloud, etc<br><br>Environmental/Work Schedules/Other<br>Weekend work hours, Overnight work hours , Holiday work hours (Federal and religious) - only as needed<br><br>Physical Requirements<br>Operates standard office equipment and Sitting (can stand at will)<br><br>Licensing or Certificates<br>N/A<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br>To apply for this position please <b>CLICK HERE</b> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Y2NmZ5nMQC-rP4UQl31yYQ",
    "url": "https://jobmote.com/job/70342/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 8, 2019 10:07:27 PM",
    "validThrough": "Sep 11, 2019 10:07:27 PM",
    "crawled": "Sep 9, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "4zR5iSu0SMSaKYVlO9YxSA",
    "url": "https://jobmote.com/job/70341/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 8, 2019 10:07:27 PM",
    "validThrough": "Sep 11, 2019 10:07:27 PM",
    "crawled": "Sep 9, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "q9bU4El2TuuRwiKYuvVq_Q",
    "url": "https://stackoverflow.com/jobs/294599/data-analyst-osmosis?a=1ANyLHOup2AE",
    "title": "Data Analyst at Osmosis  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Osmosis",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 55000,
      "maxValue": 70000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 55k - 70k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 8, 2019 11:30:24 PM",
    "validThrough": "Sep 15, 2019 11:30:24 PM",
    "crawled": "Sep 8, 2019 11:30:25 PM",
    "content": "<h3><span>Data Analyst</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                    </div>                <div>Company: Osmosis | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>sql</div><div>python</div><div>r</div><div>google-bigquery</div><div>saas</div>                <h4>Job description</h4>                <div><p><strong>Overview</strong></p><p>Our rapidly scaling medical education technology company is seeking a passionate Data Analyst to join our team. In this role, you will be working with the product, marketing, content, and operations teams to help us build the most joyful, effective learning platform in the medical education space.</p><p>This is a hands-on position in a unique remote, start-up environment, so we are looking for a candidate who is not afraid to roll up their sleeves to do the work and to collaborate with team members across the organization.</p><p><strong>About Osmosis</strong></p><p>Our mission is to “<em>Empower the world’s clinicians &amp; caregivers with the best learning experience possible.”&nbsp;</em>To this end, we have an audience of more than a million current &amp; future clinicians as well as patients and family members. Our members of the Osmosis learning platform and video library &nbsp;use the product to learn efficiently &amp; excel in classes, board exams, and in the clinic.&nbsp;</p><p>We are a team of creative, approachable, and driven entrepreneurs, researchers, and clinicians who are passionate about improving healthcare and education. At Osmosis, we collaborate remotely and value highly-motivated problem solvers who manage their time efficiently, communicate earnestly, work effectively, and understand the importance of life-work balance. &nbsp;We do everything we can to make sure our teammates are successful personally and professionally.</p><p><strong>About the Role</strong></p><p>As a Data Analyst, you will turn data into information, information into insight and insight into business decisions. You’ll develop analysis and reporting capabilities as well as monitor performance and quality control plans to identify improvements. Your primary responsibility will be to work with stakeholders across business functions including product, growth, marketing, and operations to build analytics products that enable data-driven decision making. You will guide analytics projects from discovery to solution and help us raise the bar for how we should apply our data to business decisions. In this role, you will be expected to:&nbsp;</p><ul><li>Complete analysis projects with business stakeholders to monitor the health of the business and help the business make data-driven strategic, product, and operational decisions</li><li>Develop and own business intelligence dashboards, visualizations, and reports to provide ongoing tracking and insights to the team</li><li>Build and improve advanced analytical models for product and business use cases</li><li>Collaborate with data engineer to improve data architecture and maintain a robust and accurate data warehouse</li><li>Acquire data from primary or secondary data sources and maintain databases/data systems</li><li>Identify, analyze, and interpret trends or patterns in complex data sets</li><li>Discover ways to use analytics to support team members across the business to yield action through data-driven decision making</li></ul><p><strong>Qualifications</strong></p><ul><li>2-4 years experience managing data analysis projects. eCommerce or SaaS experience is a plus.</li><li>Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.</li><li>Excel at composing concise efficient SQL queries, writing reports and presenting findings with data visualization tools.</li><li>Experience using a cloud data warehouse environment (such as BigQuery)</li><li>Experience with Python and pandas is a plus.</li><li>Working knowledge of business statistics and probability.</li><li>Ability to build trust and communicate insights effectively with a variety of business stakeholders across analytical levels.</li><li>Desire to be a partner to business stakeholders with a shared goal of using analytics and insights to drive the business forward.</li><li>Communicator. Excellent communication skills and a willingness to give and receive feedback.</li><li>Driven. Proactive and self-driven problem-solving with sharp attention to detail.</li><li>Iterative. You deliver results quickly with iteration, instead of waiting for perfection.&nbsp;</li><li>Adaptable. You are flexible and versatile with projects, goals, and strategies. You move quickly with change and stay open-minded</li><li>Entrepreneurial. You are a proven executor and work with urgency to produce excellent results with limited time and resources</li><li>Lifelong learner. You are actively consuming content (podcasts, blogs, books, etc) and applying these learnings in your work to make sure you are as effective as possible.&nbsp;</li><li>Passion for Osmosis’s mission to provide your future clinicians the best education so they can provide you and your loved ones the best care.</li></ul><p>Osmosis is an equal opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status or other status protected by law.</p><p><strong>To apply, please submit the following to&nbsp;<a href='mailto:careers@osmosis.org' rel='nofollow'>careers@osmosis.org</a>:&nbsp;</strong></p><ul><li>Resume</li><li>Portfolio of any relevant work</li><li>Answers to the following questions (50 words or less for each question):</li></ul><ol><li>What was an interesting data problem you worked on within the last year? How did you identify and address it?</li><li>Describe a situation where you did not have access to all of the data needed to triage a problem or analyze a situation, and how you adapted to it.</li><li>Based solely on what you see on osmosis.org, how would you measure customer lifetime value for Osmosis?</li></ol><p><em>Incomplete applications will not be considered.</em></p>                </div>            <div>        <a href='https://help.osmosis.org/en/articles/3291253-data-analyst' rel='nofollow'>                        Apply now        </a></div>            <h4>About Osmosis</h4>            <div><p><strong>About Osmosis</strong></p><p>Our mission is to “<em>Empower the world’s clinicians &amp; caregivers with the best learning experience possible.”&nbsp;</em>To this end, we have an audience of more than a million current &amp; future clinicians as well as patients and family members. Our members of the Osmosis learning platform and video library &nbsp;use the product to learn efficiently &amp; excel in classes, board exams, and in the clinic.&nbsp;</p><p>We are a team of creative, approachable, and driven entrepreneurs, researchers, and clinicians who are passionate about improving healthcare and education. At Osmosis, we collaborate remotely and value highly-motivated problem solvers who manage their time efficiently, communicate earnestly, work effectively, and understand the importance of life-work balance. &nbsp;We do everything we can to make sure our teammates are successful personally and professionally.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "oV_n1-MfQieEEaw2Uj5pFA",
    "url": "https://remoteok.io/jobs/74959",
    "title": "Senior Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 100000,
      "maxValue": 120000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 100k - 120k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 7, 2019 8:06:42 AM",
    "validThrough": "Sep 14, 2019 8:06:42 AM",
    "crawled": "Sep 7, 2019 9:06:30 AM",
    "content": "<span></span> <span><h4>Creative Commons</h4></span> <br> <h3>Senior Data Engineer</h3> <div>  <div>   \\nCreative Commons is working on a project to index every piece of content that's openly licensed online and making it searchable and discoverable through CC Search and the CC Catalog API. The Senior Data Engineer reports to the Director of Engineering and is responsible for building and maintaining the data that powers those products (the CC Catalog). This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners. All the code we write is open source and we’re a 100% remote team.\\n\\nPrimary responsibilities\\n\\n\\n* Architect, build, and maintain the existing CC Catalog, including:\\n\\n\\n\\n* Ingesting content from new and existing sources of CC-licensed and public domain works.\\n\\n* Scaling the catalog to support billions of records and various media types.\\n\\n* Implementing resilient, distributed data solutions that operate robustly at web scale.\\n\\n* Automating data pipelines and workflows.\\n\\n* Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.\\n\\n\\n\\n* Augment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.\\n\\n* Build an open source community around the CC Catalog, including:\\n\\n\\n\\n* Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.\\n\\n* Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor.\\n\\n* Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.\\n\\n\\n\\n* Collaborate with other outside communities, companies, and institutions to further Creative Commons’ mission.\\n\\n\\n\\n\\nQualifications and requirements\\n\\n\\n* Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization\\n\\n* Proficiency with Python\\n\\n* Proficiency with Apache Spark or similar tools\\n\\n* Experience with cloud computing platforms (AWS or similar)\\n\\n* Experience with Apache Airflow or other workflow management software\\n\\n* Experience with machine learning or interest in picking it up\\n\\n* Fluent in English\\n\\n* Excellent written and verbal communication skills\\n\\n* Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure\\n\\n* Curiosity and a desire to keep learning\\n\\n* Commitment to consumer privacy and security\\n\\n* Nice to have (but not required):\\n\\n\\n\\n* Experience with contributing to or maintaining open source software\\n\\n* Experience with web crawling\\n\\n* Experience with Docker\\n\\n\\n\\n\\n\\n\\nDiversity &amp; inclusion\\n\\nWe believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.\\n\\nWork environment and location\\n\\nCreative Commons is a fully-distributed organization — we have no central office. This position is in a remote working environment and you can be anywhere in the world as long as you’re available for meetings between 2 PM to 8 PM UTC. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.\\n\\nSalary and benefits\\n\\nCreative Commons is a leading non-profit employer, offering competitive salaries and benefits, including health and wellness plans, annual retirement contributions, and a positive, supportive work environment. We offer competitive salary in the range for this position from $100,000 - $120,000 USD, commensurate with relevant skills, experience, and location.\\n\\nHow to apply\\n\\nPlease email your cover letter and resume as a single PDF to “   <span>[email&nbsp;protected]</span>” with the subject heading of “Data Engineer / [Last Name].” Phone calls and messages will not be returned.  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "hqdI0TrWRk6jVV_EYw8Uvw",
    "url": "https://stackoverflow.com/jobs/294515/senior-data-engineer-creative-commons?a=1ALOtLJh0HDO",
    "title": "Senior Data Engineer at Creative Commons  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=5, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 100000,
      "maxValue": 120000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 100k - 120k /Year"
    },
    "employmentType": "UNSET",
    "published": "Sep 7, 2019 3:06:25 AM",
    "validThrough": "Sep 14, 2019 3:06:25 AM",
    "crawled": "Sep 7, 2019 3:06:25 AM",
    "content": "<h3><span>Senior Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                            </div>                    </div>                <div>Company: Creative Commons | No office location<br></div><h4>Technologies</h4><div>python</div><div>apache-spark</div><div>postgresql</div><div>amazon-web-services</div>                <h4>Job description</h4>                <div><p>Creative Commons is working on a project to index every piece of content that's openly licensed online and making it searchable and discoverable through <a href='https://search.creativecommons.org/' rel='nofollow'>CC Search</a> and the <a href='https://api.creativecommons.engineering/' rel='nofollow'>CC Catalog API</a>. The Senior Data Engineer reports to the Director of Engineering and is responsible for building and maintaining the data that powers those products (the <a href='https://github.com/creativecommons/cccatalog' rel='nofollow'>CC Catalog</a>). This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners. All the code we write is open source and we’re a 100% remote team.</p><p><strong>Primary responsibilities</strong></p><ul><li>Architect, build, and maintain the existing CC Catalog, including:</li><ul><li>Ingesting content from new and existing sources of CC-licensed and public domain works.</li><li>Scaling the catalog to support billions of records and various media types.</li><li>Implementing resilient, distributed data solutions that operate robustly at web scale.</li><li>Automating data pipelines and workflows.</li><li>Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.</li></ul><li>Augment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.</li><li>Build an open source community around the CC Catalog, including:</li><ul><li>Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.</li><li>Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor.</li><li>Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.</li></ul><li>Collaborate with other outside communities, companies, and institutions to further Creative Commons’ mission.</li></ul><p><strong>Qualifications and requirements</strong></p><ul><li>Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization</li><li>Proficiency with Python</li><li>Proficiency with Apache Spark or similar tools</li><li>Experience with cloud computing platforms (AWS or similar)</li><li>Experience with Apache Airflow or other workflow management software</li><li>Experience with machine learning or interest in picking it up</li><li>Fluent in English</li><li>Excellent written and verbal communication skills</li><li>Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure</li><li>Curiosity and a desire to keep learning</li><li>Commitment to consumer privacy and security</li><li>Nice to have (but not required):</li><ul><li>Experience with contributing to or maintaining open source software</li><li>Experience with web crawling</li><li>Experience with Docker</li></ul></ul><p><strong>Diversity &amp; inclusion</strong></p><p>We believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.</p><p><strong>Work environment and location</strong></p><p>Creative Commons is a fully-distributed organization — we have no central office. This position is in a remote working environment and you can be anywhere in the world as long as you’re available for meetings between 2 PM to 8 PM UTC. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.</p><p><strong>Salary and benefits</strong></p><p>Creative Commons is a leading non-profit employer, offering competitive salaries and benefits, including health and wellness plans, annual retirement contributions, and a positive, supportive work environment. We offer competitive salary in the range for this position from $100,000 - $120,000 USD, commensurate with relevant skills, experience, and location.</p><p><strong>How to apply</strong></p><p>Please email your cover letter and resume as a single PDF to “<a href='mailto:jobs@creativecommons.org' rel='nofollow'>jobs@creativecommons.org</a>” with the subject heading of “Data Engineer / [Last Name].” Phone calls and messages will not be returned.</p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/294515?reset=False&amp;ra=1ALOtLJh0HDO&amp;oqs=a%3D1ALOtLJh0HDO' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Creative Commons</h4>            <div><p>Creative Commons (CC) is a United States-based nonprofit 501(c)3 organization that provides open content copyright licenses, public domain tools, and resources on copyright and information literacy in the digital age. Our free, easy-to-use copyright licenses provide a simple, standardized way for all creators, authors, and producers of knowledge assets and cultural works to give the public permission to share and use their works on conditions of their choice. CC licenses work in tandem with copyright, allowing creators to easily and legally change copyright terms from the default of “all rights reserved” to “some rights reserved” to best suit their needs.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "8Vs5DAM7SUuMkvvl5qLIkA",
    "url": "https://jobmote.com/job/70227/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 5, 2019 10:07:44 PM",
    "validThrough": "Sep 8, 2019 10:07:44 PM",
    "crawled": "Sep 6, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "d6OGt6cTTZKEFsAcMLMmjg",
    "url": "https://jobmote.com/job/70226/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 5, 2019 10:07:44 PM",
    "validThrough": "Sep 8, 2019 10:07:44 PM",
    "crawled": "Sep 6, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "d_oFh_r6QGGftPOvKeCIHQ",
    "url": "https://remoteok.io/jobs/74897",
    "title": "Data Science Immersion Instructor",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=64, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 5, 2019 3:29:36 AM",
    "validThrough": "Sep 12, 2019 3:29:36 AM",
    "crawled": "Sep 5, 2019 4:06:30 AM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Immersion Instructor</h3> <div>  <div>   \\nApply here\\n\\n\\n* Education\\n\\n* Remote\\n\\n* Contract\\n\\n\\n\\n\\n\\n\\nJob Description\\nStudents enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed software developers. As a Data Science Immersion Course Instructor, you will deliver high quality live workshop content based on the Data Science curriculum, preparing students to successfully transition careers.&nbsp;\\n\\nIn addition to working directly with students, Instructors are expected to maintain an environment of regular, candid feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.\\n\\nResponsibilities\\n\\n\\n* \\nDelivers high quality workshops based on the curriculum materials, and provides live demos when appropriate, to supplement written materials and content to provide students with the skills and knowledge to get their first job\\n\\n* Support students by answering questions and providing guidance as they work independently or in pairs on assignments during the class day\\n\\n* Maintains and updates the daily and weekly student syllabus which outlines the required homework and assignments, and deadlines for assessments and projects.\\n\\n* Works with the other Format Leads for engagement formats (Mentor Sessions, Group Sessions, Grading, Technical Coaching, Mock Interviews/Assessments) to ensure that consistent experience is happening for students in immersive courses\\n\\n\\n\\n\\n\\n\\nRequirements\\n\\n\\n* 8 hours a day, 5 days a week.\\n\\n* Available to instruct Monday through Friday 10am-2:00pm ET\\n\\n* Available to spend up to 4 hours a day prepping for workshops and updating course materials.\\n\\n* Strong expertise with Python, SQL, statistics, supervised and unsupervised learning, and topics such as NLP, deep learning (using Tensorflow and Keras), or big data (using spark, AWS, and hadoop)\\n\\n* Expertise with Data Structures and Algorithms, and comfort explaining these topics.&nbsp;\\n\\n* Ability to explain complicated topics clearly and without jargon\\n\\n* Strong written and verbal communication skills\\n\\n* High level of detail orientation and an exceptional work ethic\\n\\n* Enjoy working with people, not just putting your head down and working\\n\\n* Must have a reliable, high-speed Internet connection\\n\\n* Minimum 3-4 years of professional data science experience\\n\\n\\n\\n\\nCompensation and Benefit\\n\\n\\n* Contract position with a collaborative team\\n\\n* Ability to work remotely with partially flexible hours&nbsp;\\n\\n* Access to all available course curriculum for personal use\\n\\n* Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry\\n\\n\\n\\n\\nAt this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5j0qWdYCQs-isY7_NTOWFg",
    "url": "https://jobmote.com/job/69084/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 4, 2019 10:07:47 PM",
    "validThrough": "Sep 7, 2019 10:07:47 PM",
    "crawled": "Sep 5, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "u3GE8XcARBqchJvkeMkJGw",
    "url": "https://jobmote.com/job/69054/data-scientist-remote-arizona-phone-skype/",
    "title": "Data Scientist\\\\\\ Remote/Arizona(Phone, Skype )",
    "tags": [
      "DBG:surround``remot 4W OR(skype, slack)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Key Business Solutions, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 4, 2019 10:07:46 PM",
    "validThrough": "Sep 7, 2019 10:07:46 PM",
    "crawled": "Sep 5, 2019 3:06:25 AM",
    "content": "<div><p><strong>Data Scientist</strong></p><p><strong>Remote/Arizona</strong></p><p><strong>18+ Months</strong></p><p> </p><p>Phone, Skype</p><p> </p><p>Skill Matrix:</p><p>Up to 50% travel, SQL, R, Python, R&amp;D exp.</p><p> </p><p><strong>Regards,<br></strong> <strong> <br></strong> <strong>Krishna</strong></p><p> </p><p><strong>Key Business Solutions, Inc.</strong></p><p> </p><p><strong>|| Office: Ext 226|| Fax: </strong></p><p> </p><p><strong></strong></p><p> </p><p><strong>Note: This email is not intended to be a solicitation. Please accept our apologies and reply in the subject heading with REMOVE to be removed from our Mailing list.</strong></p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qA-cZQZ_S7qYN6QjodvDpA",
    "url": "https://remoteok.io/jobs/74890",
    "title": "Software Developer 3D AR VR",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:numerical-methods/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opencv/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=13, mobile=0, go=0, nodejs=1, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Oaktree Technologies",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 5, 2019 1:12:57 AM",
    "validThrough": "Sep 12, 2019 1:12:57 AM",
    "crawled": "Sep 5, 2019 2:06:30 AM",
    "content": "<span></span> <span><h4>Oaktree Technologies</h4></span> <br> <h3>Software Developer 3D AR VR</h3> <div>  <div>   \\nIn this role, you will be part of a multi-disciplinary international team and help us develop consumer-facing products. Your focus lies on writing well-maintainable software in the space of computer vision, computer graphics, and augmented reality.\\n\\nThe perfect applicant understands typical challenges and solution approaches for simulations, unbiased and biased rendering as well as augmented reality applications, especially regarding measuring distances in the real world and the limits of precision.\\n\\nResponsibilities\\n\\n\\n* Develop robust software for rendering, computer vision or combinations thereof\\n\\n* Make use of standard software components like IRay and&nbsp;similar renderers\\n\\n\\n\\n\\nRequirements\\n\\n\\n* S. or M.S. degree in Computer Science or a related technical field\\n\\n* Fluency in C++ required. Experience in JavaScript, WebAssembly and emscripten a plus\\n\\n* Solid theoretical foundations in various areas of computing, including algorithms &amp; data structures, numerical methods, computer graphics etc.\\n\\n* Ability to operate autonomously and effectively with only high-level direction\\n\\n* Experience in OpenCV and rendering APIs (OpenGL, Direct3D, Vulkan, Metal, …)\\n\\n* Collaborative, positive, team-oriented mindset\\n\\n* Solid English skills, German a plus\\n\\n\\n\\n\\nWhat we offer\\n\\n\\n* Competitive salary and a secure job at a well-funded company\\n\\n* Small, independent company with a large diversity of tasks and flat hierarchy\\n\\n* A modern workplace with various amenities and an international setup\\n\\n* We're open to remote work, but we haven't established the details yet - we're&nbsp;interested in finding a good setup, so let's talk about it!\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "HUIG3_sHTpq0_AQkthJURw",
    "url": "https://stackoverflow.com/jobs/293763/data-science-immersion-instructor-thinkful-inc?a=1Awb234tYlqM",
    "title": "Data Science Immersion Instructor at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 4, 2019 9:30:24 PM",
    "validThrough": "Sep 11, 2019 9:30:24 PM",
    "crawled": "Sep 4, 2019 9:30:24 PM",
    "content": "<h3><span>Data Science Immersion Instructor</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>python</div><div>sql</div>                <h4>Job description</h4>                <div><p><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxKysN8PShIUd' rel='nofollow'>Apply here</a></p><ul><li>Education</li><li>Remote</li><li>Contract</li></ul><strong>Job Description</strong>Students enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed software developers. As a Data Science Immersion Course Instructor, you will deliver high quality live workshop content based on the Data Science curriculum, preparing students to successfully transition careers.&nbsp;In addition to working directly with students, Instructors are expected to maintain an environment of regular, candid feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.<strong>Responsibilities</strong><ul><li><br>Delivers high quality workshops based on the curriculum materials, and provides live demos when appropriate, to supplement written materials and content to provide students with the skills and knowledge to get their first job</li><li>Support students by answering questions and providing guidance as they work independently or in pairs on assignments during the class day</li><li>Maintains and updates the daily and weekly student syllabus which outlines the required homework and assignments, and deadlines for assessments and projects.</li><li>Works with the other Format Leads for engagement formats (Mentor Sessions, Group Sessions, Grading, Technical Coaching, Mock Interviews/Assessments) to ensure that consistent experience is happening for students in immersive courses<br><br></li></ul><strong>Requirements</strong><ul><li>8 hours a day, 5 days a week.</li><li>Available to instruct Monday through Friday 10am-2:00pm ET</li><li>Available to spend up to 4 hours a day prepping for workshops and updating course materials.</li><li>Strong expertise with Python, SQL, statistics, supervised and unsupervised learning, and topics such as NLP, deep learning (using Tensorflow and Keras), or big data (using spark, AWS, and hadoop)</li><li>Expertise with Data Structures and Algorithms, and comfort explaining these topics.&nbsp;</li><li>Ability to explain complicated topics clearly and without jargon</li><li>Strong written and verbal communication skills</li><li>High level of detail orientation and an exceptional work ethic</li><li>Enjoy working with people, not just putting your head down and working</li><li>Must have a reliable, high-speed Internet connection</li><li>Minimum 3-4 years of professional data science experience</li></ul><strong>Compensation and Benefit</strong><ul><li>Contract position with a collaborative team</li><li>Ability to work remotely with partially flexible hours&nbsp;</li><li>Access to all available course curriculum for personal use</li><li>Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry</li></ul><br>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxKysN8PShIUd' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "sfdP-phBQKSV-loxWLeaBw",
    "url": "https://stackoverflow.com/jobs/293751/software-developer-3d-ar-vr-oaktree-technologies-gmbh?a=1AvVyUM1uire",
    "title": "Software Developer 3D/AR/VR at Oaktree Technologies GmbH (Hamburg, Germany) ",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:c++/c/16",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:game-developer/gamedev/13",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:numerical-methods/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opencv/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=21, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=13, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Oaktree Technologies GmbH",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 4, 2019 7:30:24 PM",
    "validThrough": "Sep 11, 2019 7:30:24 PM",
    "crawled": "Sep 4, 2019 7:30:24 PM",
    "content": "<h3><span>Software Developer 3D/AR/VR</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Graphics/Game Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Oaktree Technologies GmbH | Hamburg, Germany<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+01:00) Berlin +/- 4 hours</span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>Hamburg, Germany.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div>c++</div><div>python</div><div>javascript</div><div>emscripten</div><div>vulkan</div>                <h4>Job description</h4>                <div><p>In this role, you will be part of a multi-disciplinary international team and help us develop consumer-facing products. Your focus lies on writing well-maintainable software in the space of computer vision, computer graphics, and augmented reality.</p><p>The perfect applicant understands typical challenges and solution approaches for simulations, unbiased and biased rendering as well as augmented reality applications, especially regarding measuring distances in the real world and the limits of precision.</p><p><strong>Responsibilities</strong></p><ul><li>Develop robust software for rendering, computer vision or combinations thereof</li><li>Make use of standard software components like IRay and&nbsp;similar renderers</li></ul><p><strong>Requirements</strong></p><ul><li>S. or M.S. degree in Computer Science or a related technical field</li><li>Fluency in C++ required. Experience in JavaScript, WebAssembly and emscripten a plus</li><li>Solid theoretical foundations in various areas of computing, including algorithms &amp; data structures, numerical methods, computer graphics etc.</li><li>Ability to operate autonomously and effectively with only high-level direction</li><li>Experience in OpenCV and rendering APIs (OpenGL, Direct3D, Vulkan, Metal, …)</li><li>Collaborative, positive, team-oriented mindset</li><li>Solid English skills, German a plus</li></ul><p><strong>What we offer</strong></p><ul><li>Competitive salary and a secure job at a well-funded company</li><li>Small, independent company with a large diversity of tasks and flat hierarchy</li><li>A modern workplace with various amenities and an international setup</li><li>We're open to remote work, but we haven't established the details yet - we're&nbsp;interested in finding a good setup, so let's talk about it!</li></ul>                </div>            <div>        <a href='https://oaktree-jobs.personio.de/job/131807' rel='nofollow'>                        Apply now        </a></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UmfqiBGmQG-6NUORywINeA",
    "url": "https://stackoverflow.com/jobs/293627/senior-type-system-engineer-luna?a=1AtlHRHh98be",
    "title": "Senior Type-System Engineer at Luna (Kraków, Poland) ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:haskell/other/5",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:scala/java/9",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=2, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Luna",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 40000,
      "maxValue": 120000,
      "info": "Equity",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 40k - 120k /Year | Equity"
    },
    "employmentType": "UNSET",
    "published": "Sep 4, 2019 3:06:25 PM",
    "validThrough": "Sep 11, 2019 3:06:25 PM",
    "crawled": "Sep 4, 2019 3:06:25 PM",
    "content": "<h3><span>Senior Type-System Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>System Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Cloud Computing, Data Science, Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Luna | Kraków, Poland<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Kraków, Poland.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                            <div>                                    <span>Relocation Assistance:</span>                                    <span>Yes</span>                                </div>                        </div>                    </div>                <h4>Technologies</h4><div></div><div>java</div><div>scala</div><div>truffle</div><div>graalvm</div><div>types</div>                <h4>Job description</h4>                <div><p><strong>Senior Type-System Engineer</strong><br><a href='https://luna-lang.org' rel='nofollow'>Luna</a> is looking for a senior type-system engineer to help build the next generation interpreter and runtime for Luna, a project said by Singularity University to have the potential to change the lives of one-billion people. If you have strong technical skills and a passion for all things compiler, then this role could be the one for you.<br><br>As a type-system engineer you'll work as part of the compiler team to design and implement Luna's new type system, including its underlying theory, type-checker, and inference engine. This wok is _intrinsic_ to Luna's evolution, and will provide you with the opportunity to collaborate with a world-class team of engineers, community managers, and business developers (with experience at Bloomberg, GitHub, PayPal, to name a few), making your mark on Luna's future.<br><br><strong>What You'll Do<br></strong>As a senior type-system engineer, you'll be working on the design and development of Luna's new type-system, in conjunction with the rest of the compiler team, to help support the language's evolution. This will involve:</p><ul><li>Determining and formalising the theoretical underpinnings of the new type system in a way as to ensure its soundness.</li><li>Both theoretical and practical treatments of the theory behind Luna's type system.</li><li>Working with the broader compiler team to implement the type-checking and type-inference engines as part of the greater interpreter.</li><li>Using the type-system's information to improve the interpreter's functionality and performance, as well as how it interacts with the users.</li></ul><p><strong>The Skills We're Looking For</strong><br>We have a few particular skills that we're looking for in this role:</p><ul><li>Practical and rich experience writing code in a functional programming language such as Haskell or Scala, including experience with type-level programming techniques (3+ years).</li><li>Experience working with the theory behind powerful type systems, including row types, type-checking and type-inference algorithms, and dependently-typed systems.</li><li>Practical experience building real-world type-systems, including facilities for both type-checking and inference.</li><li>An awareness of the UX impacts of type-systems, and a willingness to minimise their often-intrusive nature.</li><li>Practical experience in building large and complex software systems.</li></ul><p>It would be a big bonus if you had:</p><ul><li>Experience writing Java and Scala code, as these will be used to implement the type-system.</li><li>Experience in writing comprehensive regression tests for both type-inference and type-checking systems.</li></ul><p>Avoid <a href='https://www.forbes.com/sites/womensmedia/2014/04/28/act-now-to-shrink-the-confidence-gap/' rel='nofollow'>the confidence gap</a>. You don't have to match <em>all</em> of the skills above to apply!<br><br><strong>Who You'll Work With</strong><br>You'll be joining a distributed, multi-disciplinary team that includes people with skills spanning from compiler development to data-science. Though you'll have your area to work on, our internal culture is one of collaboration and communication, and input is always welcomed.<br><br>We firmly believe that only by working <em>together</em>, rather than putting our team members in their own boxes, can we create the best version of Luna that can be.<br><br><strong>The Details</strong><br>As part of the Luna team you'd be able to work from anywhere, whether that be at home, or on the go! We have team members distributed across the world, from San Francisco, to London, to Kraków. We welcome remote work and flexible schedules, or you can work from the Kraków office (or our planned SF office) if you'd like. We can provide competitive compensation and holiday, as well as the possibility<br>of equity as time goes on.<br><br><strong>How To Apply?</strong><br>Send us an email at <a href='mailto:jobs@luna-lang.org' rel='nofollow'>jobs@luna-lang.org</a>, and tell us a little bit about yourself and why you think you'd be a good fit for the role! You can also tell us about:</p><ul><li>Some of your past work or projects.</li><li>Why you'd like to work on Luna, and where you imagine Luna being in 5 years.</li><li>The most important features of a team that you'd like to work in.</li><li>Whether you take pride in your ability to communicate clearly and efficiently with your team.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/293627?reset=False&amp;ra=1AtlHRHh98be&amp;oqs=a%3D1AtlHRHh98be' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Luna</h4>            <div><p><strong>About Luna</strong><br>Luna is an award-winning general-purpose programming language and data-science platform, selected by NASA and Singularity University as a technology with the potential to impact the lives of one-billion people worldwide. It spans the entire stack, from high-level visualisation and communication, to the<br>nitty-gritty of running backend services in a single language. With inbuilt capabilities for visualisation and a dual-syntax architecture, the possibilities are limitless.<br><br>At Luna, we have a world-class team, with developers, community managers, and business developers from all walks of life and backgrounds, and work in close collaboration with industry advisers such as Robert Gentleman, the creator of the R programming language and computational biologist at 23andMe, and Edward Kmett, a skilled language designer and machine intelligence researcher at MIRI.<br><br>We welcome anybody to our team, as long as you have the desire and drive to see Luna succeed.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Team built around the Humility, Respect, and Trust ideology.</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours, possible part / full time remote work.</span>                            </li>                            <li>                                <span></span>                                <span>Work in a small team of world-class engineers and make impact on Luna.</span>                            </li>                            <li>                                <span></span>                                <span>Competitive compensation + possibility of equity as time goes on.</span>                            </li>                            <li>                                <span></span>                                <span>Equality, diversity &amp; inclusion.</span>                            </li>                            <li>                                <span></span>                                <span>We've got standing desks in our office (no one uses them though :P).</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "8cvhgidGQhy-huOZiDxj6Q",
    "url": "https://jobmote.com/job/68963/remote-python-data-engineer/",
    "title": "Remote Python Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/10",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 401000,
      "maxValue": 401000,
      "info": "",
      "unit": "DAY",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 401k /Day"
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 10:07:45 PM",
    "validThrough": "Sep 6, 2019 10:07:45 PM",
    "crawled": "Sep 4, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>AWS, Kinesis, Lambda, Snowflake, Python 3.6/3.7, S3, Data Management, Data Ingestion, Data Processing, IOT<br><br>If you are a Remote Python Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>Previous experience providing robust and reliable data management techniques; massaging, optimizations for aggregating/reading performantly.<br>Familiar with developing solutions that scale to meet scenarios of high-velocity data ingestion and processing.<br>Be a core player in collaborations with the team(s) to identify new and useful ways to package and present data to clients<br>A deep understanding of distributed programming concepts and are able to identify the patterns necessary for a scalable, robust, and reliable service.<br>Ability to reason about performance benefits and tradeoffs in software and infrastructure design decisions as they relate to preventing data loss and recovering from failure.<br>Comfortable with contributing to a collaborative development environment both within the team and across the organization. We are true full stack since we are from silicon to the cloud, so there are several teams with which to interact and collaborate.<br>Create and communicate tests that need to exist to prevent regressions and find performance bottlenecks.<br>Know what metrics need to be created or monitored to alert on abnormal operation and to aid in capacity/scale planning.<br>Desire to automate processes to keep the team moving efficiently and safely.<br><br>Tech Stack:<br><br>Modern Python (3.6/3.7) and Go<br>AWS primitives for an event based architecture<br>CI/CD, automation for infrastructure and code, and observability/instrumentation are first class citizens<br><br>What's In It for You<br><br>Full Remote! <br>Monthly hack days<br>Health, Dental, and Vision benefits<br>21 days PTO + separate sick day quota<br>401K plan<br>Amazingly talented team!So, if you are a Remote Python Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Udm2nxzDRp6skiq-6--kOA",
    "url": "https://jobmote.com/job/68967/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 10:07:46 PM",
    "validThrough": "Sep 6, 2019 10:07:46 PM",
    "crawled": "Sep 4, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "D0UkskvkSQK3MfJ9U2GDGA",
    "url": "https://jobmote.com/job/68966/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 10:07:46 PM",
    "validThrough": "Sep 6, 2019 10:07:46 PM",
    "crawled": "Sep 4, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "anlr-TKvT-ubZMjVR0Ed3w",
    "url": "https://jobmote.com/job/68935/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 10:07:44 PM",
    "validThrough": "Sep 6, 2019 10:07:44 PM",
    "crawled": "Sep 4, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5d4OkeIMQKOKMcS9pqPMUg",
    "url": "https://jobmote.com/job/68934/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 10:07:44 PM",
    "validThrough": "Sep 6, 2019 10:07:44 PM",
    "crawled": "Sep 4, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "knDiRGcYQRm-07dzd8S0pw",
    "url": "https://unicornhunt.io/jobs/senior-data-scientist-at-ourpath",
    "title": "Senior Data Scientist",
    "tags": [
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG_TECH1:k/t/w:animation/gamedev/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=8, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "OurPath",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 6:48:50 PM",
    "validThrough": "Sep 10, 2019 6:48:50 PM",
    "crawled": "Sep 3, 2019 7:31:43 PM",
    "content": "<p>We’re looking for a senior data scientist who is passionate about making a positive difference in the world.</p><ul><li>Full-time, in-house</li><li>London</li></ul><h4> 1 The Problem </h4><p>Type 2 diabetes and obesity are huge problems, both for the millions of people that suffer from lifestyle diseases, as well as healthcare systems like the NHS.</p><p>In the UK we spend almost 10% of the NHS budget on treating type 2 diabetes alone (£9 billion/year). What’s shocking is almost all of this is avoidable, 80-90% in fact.</p><p>How? Through sustained lifestyle and weight loss. It sounds so simple, but in reality is much harder to achieve at scale.</p><h4> 2 OurPath </h4><p>OurPath provide a digital lifestyle improvement programme that is proven to help people improve their lifestyle and lose weight, which ultimately reduces their risk for conditions such as type 2 diabetes.</p><p>The programme incorporates evidence-based education, health coaches, peer group support, and digital tracking tools. Everything is delivered digitally through phone and web apps.</p><p>The quickest way to understand what we do is watch this very short 1 min animation:&nbsp;https://vimeo.com/199648301</p><p>We were the first digital behavioural change programme to be commissioned by the NHS – we’re now expanding rapidly having won a few big national contracts (both in diabetes prevention and management).</p><p>Alongside our NHS work, we also offer the programme directly to consumers – you can buy the programme on our website if you’re looking to make a healthy lifestyle change and lose weight. Our direct-to-consumer channel is essentially a competitor to the likes of Weight Watchers and Slimming World.</p><p>About us: We are now a team of 50 – consisting of ex-strategy consultants, dietitians, designers, and developers. We believe OurPath is a fun place to work with an informal, non-bureaucratic, and agile working environment. Finally, we will provide endless amounts of poor jokes and sub-standard humour. Just so you know.</p><p>Some of our national press:</p><p><a href='https://techcrunch.com/2018/08/10/ourpath-raises-3m-in-round-led-by-connect-ventures-to-reverse-type-2-diabetes/' rel='nofollow'>TechCrunch</a></p><p><a href='https://www.wired.co.uk/article/ourpath-diabetes-app-roche-nhs-partnership' rel='nofollow'>Wired</a></p><h4> 3 The role </h4><p>We are looking for a senior data scientist, not only to help us build and grow our product but also our data team.</p><p>What you’ll do:</p><ul><li><strong>Help junior analysts</strong> deliver insightful analysis to discover areas of opportunity that shape the product roadmap.</li><li><strong>Lead the development</strong> of new data-driven product features.</li><li><strong>Work with product</strong> to design and analyse product tests.</li><li><strong>Work with engineering</strong> to ensure that good ETL processes are in place to deliver clean and accurate data to team members.</li><li><strong>Collaborate with members of all teams</strong> to ensure that data is easily accessible to answer business decisions and drive the decision-making process.</li></ul><h4> 4 Person Specification </h4><p>Required:</p><ul><li>Experience querying databases and using statistical computer languages</li><li>Coding knowledge and experience with several languages (Python/R required)</li><li>Experience in Machine Learning applications</li></ul><p>Nice to have:</p><ul><li>Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks</li><li>Strong knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications</li><li>Experience managing a team of data analysts/scientists.</li></ul><h4>   5 What can we offer you? </h4><ul><li>You’ll be able to <strong>provide direct input</strong> into how we should improve our product and the development of OurPath.</li><li>You’ll get to <strong>work with amazing, friendly, smart colleagues</strong> all incredibly passionate about solving the type 2 diabetes epidemic.</li><li>You’ll have <strong>autonomy and responsibility</strong> for your work direction; we also offer a flexible working environment where you can work from home when you need to.</li><li>We have <strong>regular company-sponsored socials</strong> (pub drinks, team dinners, board games and movie nights) that’ll allow you to catch up and make friends outside of your team.</li><li>We all have a <strong>thirst for knowledge</strong> and have regular Lunch&amp;Learn sessions to help us expand our knowledge base; the product team also get together and run quarterly Hackathons.</li></ul><h4> 6 To Apply </h4><p>This position is available to start immediately, so please send your CV and email via this application page: https://workable.com/j/B45EE2ECED</p><p>We’ll be interviewing on a rolling basis, so the quicker you can apply the better.</p><p>If Ben doesn’t respond within 7 days then he’s not intentionally being rude but please assume it’s probably a no for now.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZZzZ11wSTG6H1zNpCX9BAQ",
    "url": "https://remote.co/job/data-scientist-8/",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:macos/apple/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=2, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Vivint Smart Home",
      "sameAs": "https://www.vivint.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 3:54:50 PM",
    "validThrough": "Sep 10, 2019 3:54:50 PM",
    "crawled": "Sep 3, 2019 4:07:22 PM",
    "content": "<h3>Data Scientist at <span>Vivint Smart Home</span></h3><div><span><i></i> Remote</span>        </div><div>            <ul><li>Lehi, UT</li><li><strong>USA-Remote Location</strong></li><li><strong>Full time</strong></li><li>R111302</li></ul><p><strong>Job Description</strong></p><p>Our mission is to redefine the home experience through intelligently designed products and services delivered to every home by people who care.</p><p><strong>Who Are We:</strong></p><p>Vivint Smart Home is the leading provider of smart home services in North America. Vivint delivers an integrated smart home system with in-home consultation, professional installation and support delivered by its Smart Home Pros, as well as 24-7 customer care and monitoring. Dedicated to redefining the home experience with intelligent products and services, Vivint serves more than one million customers throughout the U.S. and Canada. Vivint is the largest tech employer in Utah, a certified Great Place to Work, and one of <em>Fast Company</em>‘s World’s 50 Most Innovative Companies for 2017.</p><p><strong>The Role:</strong></p><p>As a Data Scientist you will be expected to analyze data and publish insights that improve Vivint’s product experience and provide recommendations on future products. The primary data sources for analysis include web analytics, mobile applications, and IOT devices.</p><p><strong>What you will be working on:</strong></p><ul><li>Join a team of data scientists and engineers working on key insights for managing the day to day business and aligning for growth.</li><li>Communicate with the product teams to generate requirements and present results that help key stakeholders make effective decisions.</li><li>Work in a fast-paced, self-directed, agile environment.</li><li>Using a “problem statement” structure, clearly define the desired outcome, including analytic results and resulting actions.</li><li>Work on home automation projects that you actually get to use in your home.</li><li>Use analytical rigor to ensure that the business trusts the generated insights.</li></ul><p><strong>What we’re looking for:</strong></p><ul><li>Experience with timestamped event data and common data transformations.</li><li>Experience with data visualization tools like Tableau.</li><li>Highly analytical with strong, demonstrated problem solving and critical thinking capabilities</li><li>An understanding of statistical analysis and familiarity with core statistical functions.</li><li>Experience with any of the following technologies is a plus<ul><li>Hadoop</li><li>Datameer</li><li>Tableau</li></ul></li></ul><p><strong>Minimum Qualifications:</strong></p><ul><li><strong>Bachelors Degree in a Quantitative field (Math, Statistics, Engineering, Computer Science)</strong></li><li>4+ years work experience.</li><li>Data modeling experience</li></ul><p><strong>Why Vivint:</strong></p><ul><li>Free catered lunch/snacks/drinks; new menu daily</li><li>Paid holidays and flexible paid time away</li><li>Your choice between Mac or PC</li><li>Employee pricing on smart home products</li><li>Casual dress code</li><li>Onsite gym</li><li>Onsite health clinic</li><li>Medical/dental/vision/life coverage</li></ul><p><strong>What We Stand For:</strong></p><ul><li>Honesty and Integrity Come First</li><li>Do the right thing</li><li>Customer Obsession is Our Advantage</li><li>A relentless passion to serve the customer</li><li>Innovation is Essential</li><li>Today’s innovation is tomorrow’s lifeblood</li><li>We Win Together</li><li>Individuals win games: teams win championships</li><li>Exceptional is Expected</li><li>Talk is cheap: create value, not just motion</li><li>We Give Back</li><li>Helping people is core to our DNA</li></ul>        </div><div>        <a href='https://vivint.wd5.myworkdayjobs.com/en-US/vivintjobs/job/Lehi-UT/Data-Scientist_R111302' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eY6I2j5aRuKHbfjO2INRUA",
    "url": "http://workinstartups.com/job-board/job/84034/graduatejunior-data-scientist-immediate-start-at-jesey-ai/",
    "title": "Graduate/Junior Data Scientist (immediate start)",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(abl,will,challeng,flexibl,experi,get,prefer) 2W 2N(work,remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jesey Ai",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 9:26:11 AM",
    "validThrough": "Sep 10, 2019 9:26:11 AM",
    "crawled": "Sep 3, 2019 11:06:34 AM",
    "content": "<p class=&quot;p1&quot;>We&rsquo;re solving a global issue worth $1 trillion loss of health productivity as a small London team from IBM, NHS and PWC using machine learning. Since our inception (Y-combinator Startup School AW18 and now part of WeWork Labs programme) our mission and community have since grown stronger, so we are now building a team of rockstar engineers to support our growth and scale plans. We are looking for a passionate technical lead engineer with strong front/backend skills and experience in shipping quality applications.</p><br /><p class=&quot;p1&quot;><strong>Benefits </strong></p><br /><ul class=&quot;ul1&quot;><br /><li class=&quot;li1&quot;>Competitive Package</li><br /><li class=&quot;li1&quot;>Equity incentive</li><br /><li class=&quot;li1&quot;>Flexible remote/work-life balance inc vacations</li><br /><li class=&quot;li1&quot;>International travel opportunity</li><br /><li class=&quot;li1&quot;>An energetic team with flat hierarchy</li><br /><li class=&quot;li1&quot;>High growth with opportunity for career development</li><br /><li class=&quot;li1&quot;>WeWork&rsquo;s Central London tech community</li><br /><li class=&quot;li1&quot;>Wellness/mentor plans</li><br /><li class=&quot;li1&quot;>Free fruit, breakfast, coffee and beer</li><br /><li class=&quot;li1&quot;>Shower and bike locker in the office Tasks</li><br /></ul><br /><p class=&quot;p1&quot;><strong>Role</strong></p><br /><ul><br /><li class=&quot;p1&quot;>Collaborate with engineers to maximize data and create statistical and predictive models to solve problems.</li><br /><li class=&quot;p1&quot;>Demonstrated an ability to bridge the gap between the theoretical and the practical.</li><br /><li class=&quot;p1&quot;>Drive ideation and innovation with a contribution to optimising data capture and analytics.</li><br /><li class=&quot;p1&quot;>Build, test and or develop software tools for others to use and interpret data.</li><br /><li class=&quot;p1&quot;>Support feature prototyping and utilize best practices to write production-grade code.</li><br /><li class=&quot;p1&quot;>Deploy Artificial Intelligence theories from various Machine Learning (ML) models and algorithms whilst making use of data engineering. (Experience with chatbots would be a bonus)</li><br /></ul><br /><p><strong>Please reply for a September interview.</strong></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "JGOm5BhWTMyLxsjQDmTDfw",
    "url": "http://workinstartups.com/job-board/job/84031/full-stack-engineer-for-digital-health-startup-at-jesey-ai/",
    "title": "Full stack engineer for digital health startup",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(abl,will,challeng,flexibl,experi,get,prefer) 2W 2N(work,remot)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jesey Ai",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 3, 2019 9:16:38 AM",
    "validThrough": "Sep 10, 2019 9:16:38 AM",
    "crawled": "Sep 3, 2019 11:06:34 AM",
    "content": "<p class=&quot;p1&quot;>We&rsquo;re solving a global issue worth $1 trillion loss of health productivity as a small London team from IBM, NHS and PWC using machine learning. Since our inception (Y-combinator Startup School AW18 and now part of WeWork Labs programme) our mission and community have since grown stronger, so we are now building a team of rockstar engineers to support our growth and scale plans. We are looking for a passionate technical lead engineer with strong front/backend skills and experience in shipping quality applications.</p><br /><p class=&quot;p1&quot;><strong>Benefits </strong></p><br /><ul class=&quot;ul1&quot;><br /><li class=&quot;li1&quot;>Competitive Package</li><br /><li class=&quot;li1&quot;>Equity incentive</li><br /><li class=&quot;li1&quot;>Flexible remote/work-life balance inc vacations</li><br /><li class=&quot;li1&quot;>International travel opportunity</li><br /><li class=&quot;li1&quot;>An energetic team with flat hierarchy</li><br /><li class=&quot;li1&quot;>High growth with opportunity for career development</li><br /><li class=&quot;li1&quot;>WeWork&rsquo;s Central London tech community</li><br /><li class=&quot;li1&quot;>Wellness/mentor plans</li><br /><li class=&quot;li1&quot;>Free fruit, breakfast, coffee and beer</li><br /><li class=&quot;li1&quot;>Shower and bike locker in the office Tasks</li><br /></ul><br /><p class=&quot;p1&quot;><strong>Role</strong></p><br /><ul class=&quot;ul1&quot;><br /><li class=&quot;li1&quot;>Ownership of the product architecture across the full stack ensuring key technological and architectural decisions are met with good code working closely with the co-founder team.</li><br /><li class=&quot;li1&quot;>Lead both frontend and backend software development, design and code reviews.</li><br /><li class=&quot;li1&quot;>Be involved in building disruptive, cutting-edge technology by enhancing our proprietary algorithms.</li><br /><li class=&quot;li1&quot;>Help the team overcome any roadblocks to planned development in collaboration with the product owner.</li><br /><li class=&quot;li1&quot;>Set the technology culture for new engineer hires and collaborate with the distributed development team to support efficient, timely development.</li><br /></ul><br /><p class=&quot;p3&quot;>&nbsp;</p><br /><p class=&quot;p1&quot;><strong>Please reply for a September interview.</strong></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rmZQl_tsR4ihrU0NhQ0kIw",
    "url": "https://jobmote.com/job/67779/senior-data-etl-engineer-remote/",
    "title": "Senior Data ETL Engineer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jersey/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 2, 2019 10:07:30 PM",
    "validThrough": "Sep 5, 2019 10:07:30 PM",
    "crawled": "Sep 3, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>SQL, AWS, ETL<br><br>We are one of the most successful technology start-ups in the Philadelphia/New Jersey region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. <br><br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.<br><br>We need a Senior ETL Data Engineer to help us transform how consumers interact with real estate data.<br><br>What You Will Be Doing<br><br>- Recommend and implement data processing tools and technologies<br>- Extract, transform and load data pipelines from end to end<br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info<br>- Create, develop and document data mapping rules from multiple sources<br>- Develop continuous process movements<br><br>What You Need for this Position<br><br>- 5+ yrs experience<br>- ETL<br>- SQL / PostgreSQL<br>- AWS<br>- BSCS or related degree<br><br>What's In It for You<br><br>- Competitive Pay<br>- FULL REMOTE!So if you are a Senior Data ETL Engineer with relevant experience, please apply today! Interviews are occurring this week!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kd_HfQJxTFyl7mfR9aFMjQ",
    "url": "https://jobmote.com/job/67769/rf-blue-prism-technical-lead-remote/",
    "title": "RF Blue Prism Technical Lead - REMOTE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``remot 3W onli",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "GeoLogics Corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 2, 2019 10:07:30 PM",
    "validThrough": "Sep 5, 2019 10:07:30 PM",
    "crawled": "Sep 3, 2019 3:06:24 AM",
    "content": "<div><p> <strong>RPA/Blue Prism Technical Lead needed --- Location: REMOTE</strong></p> <p> <strong>US CITIZENS ONLY - NO 3RD PARTY CANDIDATES</strong> </p> <p> </p> <p>I am working with <strong>Raytheon</strong> and they are looking for an <strong>RPA Technical Lead</strong>. This is a long-term contract position and can be worked <strong>REMOTELY</strong>. You must be a <strong>US Citizen</strong> to apply. </p> <p> </p> <p> <strong>Hourly rate:</strong> OPEN (w2 or c2c -- no 3rd party candidates)</p> <p> </p> <p> <strong>Accountabilities</strong></p> <ul><li> <strong>Improved efficiencies through standardization, process, reuse and continuous improvement </strong></li> <li> <strong>Improved sustainability of technology through technical standards/quality</strong></li> <li> <strong>Accountable for developer &amp; Bot Builder onboarding, training and competency development</strong></li></ul><p> <strong> </strong></p> <p> <strong>Key Responsibilities</strong></p> <ul><li>Establishes &amp; drives development standards, reuse and best practices</li> <li>Establishes standard architecture and repeatable design patterns</li> <li>Drives Configuration Management best practices</li> <li>Oversees design &amp; code review processes; Design/Code review approval</li> <li>Responsible for developer training, enablement &amp; coaching (COE delivery)</li> <li>Facilitates Developer Forum &amp; Interaction</li> <li>Monthly development metrics</li> <li>Tracks Object/Asset tracking (reusable assets /grading approach)</li> <li>Risk &amp; Opportunity management</li> <li>Escalation management</li> <li>Federated model technical review, enablement, coaching, code/design reviews</li> <li>Partners with COE for technical roadmap development</li></ul><p> </p> <p> <strong>Knowledge &amp; Skills</strong></p> <ul><li> <strong>This is a Lead role</strong></li> <li> <strong>Strong understanding of RPA technologies and solutions and underlying IT services</strong></li> <li> <strong>Extensive knowledge of RPA platforms (Blue Prism)</strong></li> <li>Knowledge of advanced process automation capabilities (Chatbot, Machine Learning, BPM etc.)</li> <li>Experience in rolling out large IT implementation programs</li> <li>Innovative mindset to push next-generation thinking </li> <li>Rapid problem solving ability</li> <li>Agile delivery experience</li></ul><p> </p> <p> <strong>Critical Program Collaboration Responsibilities</strong></p> <ul><li>Connection point to broader IT organization</li> <li>Provides guidance on the best fit technology across the automation spectrum</li> <li>Investigates emerging technologies in the automation domain</li> <li>Ensures close collaboration with IT Security to standards, governance and compliance</li> <li>Supports Program Manager with Business &amp; IT alignment</li> <li>Attends and provide technical guidance to Architecture Review team</li> <li>Improves release process</li> <li>Evaluates opportunities and/or roadmap for Dev Ops</li> <li>Drives consistent metrics collection and reporting</li> <li>Works to grow the Federated model</li> <li>Enables BOT value retention / business value realization</li> <li>Consults on technical components needed for the robots to run</li> <li>Escalates L2 &amp; L3 support issues as needed</li></ul><p>If interested in learning more about this position, please email your resume to and I will call back with more information.</p> <p> </p> <p>Best Regards,</p> <p> </p> <p> <strong>Sam Gephart</strong></p> <p> <strong>IT Recruiter</strong></p> <p> <strong>GeoLogics Corporation</strong></p> <p> <strong> (toll free)</strong></p> <p></p> <p> </p> <p> </p> <p> </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Iz4ufeAzSO-h8W_WUFWVuQ",
    "url": "https://jobmote.com/job/67759/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 2, 2019 10:07:29 PM",
    "validThrough": "Sep 5, 2019 10:07:29 PM",
    "crawled": "Sep 3, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xn8RdpFWSheJh1uzaE9o-g",
    "url": "https://news.ycombinator.com/item?id=20859684",
    "title": "Monadic | (Senior) Software Engineer | Berlin | Remote OK | Full time | http://monadic.xyz ...",
    "tags": [
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:haskell/other/5",
      "DBG_TECH1:k/t/w:rust/other/5",
      "DBG_TECH1:techWeightMap:{python=0, other=10, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/other",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "other"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 2, 2019 5:30:28 PM",
    "validThrough": "Sep 9, 2019 5:30:28 PM",
    "crawled": "Sep 2, 2019 6:23:51 PM",
    "content": "Monadic | (Senior) Software Engineer | Berlin | Remote OK | Full time | <a href='http://monadic.xyz' rel='nofollow'>http://monadic.xyz</a><p>We're hiring a couple of experienced protocol &amp; backend engineers who &lt;3 free software, to work on a decentralized code collaboration and incentivization platform for FOSS. We work mainly in rust and haskell, are remote friendly and based in Berlin. Salary is flat and generous for the EU. Send me an e-mail at alexis@monadic.xyz with your CV or open-source work if interested!</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "quJR02xATCW_KCqcbPkRlQ",
    "url": "https://news.ycombinator.com/item?id=20859634",
    "title": "Sense https://sense.com | Multiple Positions | Cambridge, MA | Onsite & Remote | Full-time ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:embedded-linux/embedded/16",
      "DBG_TECH1:k/t/w:embedded/c/4",
      "DBG_TECH1:k/t/w:embedded/embedded/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:signal-processing/bigdata-ml/32",
      "DBG_TECH1:k/t/w:signal-processing/embedded/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=68, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=80, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/embedded",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "embedded"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Sep 2, 2019 5:22:27 PM",
    "validThrough": "Sep 9, 2019 5:22:27 PM",
    "crawled": "Sep 2, 2019 6:23:51 PM",
    "content": "Sense <a href='https://sense.com' rel='nofollow'>https://sense.com</a> | Multiple Positions | Cambridge, MA | Onsite &amp; Remote | Full-time<p>Sense is trying to make a difference in climate change by making an engaging product which changes your relationship to your home.  Get insights into how your appliances use energy, know what's on without smart appliances or IoT hubs, get alerts or automate your home if you like, or just sit back and save some money and energy.</p><p>We have an incredibly productive cross-functional technology team, doing nearly everything in-house: electrical &amp; mechanical engineering, embedded linux, DSP, cloud backend, data science and machine learning, mobile and full-stack web.  This means there's incredible opportunities for personal growth.  Basically anything you're interested in learning about, there are experts in-house.</p><p>Sound interesting?  Join our team:</p><p>* Product Manager</p><p>* Engineering Manager</p><p>* Data Annotator</p><p>* Senior Manufacturing Engineer</p><p>* Digital Marketing Operations Analyst</p><p><a href='https://sense.workable.com/' rel='nofollow'>https://sense.workable.com/</a></p><p>Touch base with me if you want to chat about any of these positions.  I'm currently spending my time working on our embedded platform, from linux drivers through DSP, data science through cloud connectivity, but I can put you in touch with folks from other areas of the stack if you want to learn more.</p><p>No recruiters.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "PbBjh2tXRjmgpV38TbS5jQ",
    "url": "https://jobmote.com/job/67371/informatica-architect-100-remote/",
    "title": "Informatica Architect(100% REMOTE)",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:sql-server/dotnet/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=2, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "HCL Global Systems",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 31, 2019 10:07:59 PM",
    "validThrough": "Sep 3, 2019 10:07:59 PM",
    "crawled": "Sep 1, 2019 3:06:25 AM",
    "content": "<div><p>Hi,</p> <p>Hope you are doing great..!!</p> <p> </p> <p> <strong>Position : Informatica Architect </strong></p> <p> <strong>Location: Brown,WI((100% REMOTE)</strong></p> <p> <strong>Projected 9 month contract; opportunity to extend</strong></p> <p> </p> <p> <strong>Job Description: </strong></p> <p>&quot;The Informatica Architect will provide data strategy and governance oversight for a focused portion of the Ameriprise information architecture, ensuring that projects and programs within the portfolio are supported by the appropriate data deliverables. Responsible for developing information architecture solutions that are aligned with the objectives and standards of the enterprise data management strategy and enable optimal performance, stability, and extensibility.</p> <p> <strong> </strong></p> <p> <strong>Major areas of accountability</strong>:</p> <ul><li>Act as the subject matter expert in key data areas (e.g. data integration, data quality, master data, metadata management). Develop and build strong relationships, using effective communication skills to influence and accomplish strategic information architecture objectives that are in alignment with business strategies. Communicate, educate and ensure adherence to sound data management principles.</li> <li>Work with project managers and architects to develop the approach and cost estimates required for project level information architecture deliverables. Assess and facilitate engagement of other data management services (DBA and data integration) as needed for projects. Provide high level tracking of project progress with respect to data architecture deliverables. Ensure project time and cost commitments are met.</li> <li>Create data architecture for projects (conceptual model, integration model, sourcing) in alignment with the portfolio and enterprise information architecture. Apply an enterprise vision to projects and identify requirements that impact the long-term information architecture.</li> <li>Create and maintain logical and physical data models that support business and technical requirements. Perform data profiling and analysis to ensure alignment of actual data to the model and to business requirements.</li> <li>Create and maintain the process and standards for managing logical and physical data models. Develop toolset practices and procedures to facilitate enforcement of the process. Ensure project compliance with the process.</li> <li>Analyze business processes, operational applications and source data to understand dependencies, anomalies and implicit business rules that impact data management and quality.</li> <li>Contribute to the development and evolution of the enterprise information architecture. Recommend changes and improvements for managing and communicating the architecture.</li> <li>Provide governance oversight to ensure project adherence to information architecture strategy, principles, standards, policies and procedures throughout all project phases. Partner with other architects to ensure alignment and integration across portfolio boundaries and promote an enterprise focus on data management. Review information architecture deliverables throughout development process to ensure quality &amp; traceability to requirements and adherence to all plans &amp; standards.</li></ul><p> </p> <p> </p> <p> <strong>Required Qualifications: </strong></p> <ul><li>Bachelor s degree in Engineering, Computer Science, Mathematics or related field; or related work experience.</li> <li>5-7 years of relevant experience providing DWBI architectural direction and support.</li> <li>Demonstrated expertise with Informatica PowerCenter, Informatica PowerExchange Change Data Capture, SQL Server, SQL Server Analysis Services, and PowerBI.</li> <li>Logical and physical data modeling experience using the Entity Relationship Diagram (ERD) methodology.</li> <li>Demonstrated expertise in data architecture concepts (e.g. model management, meta-data management, data governance).</li> <li>Experience delivering concurrent, large DWBI projects at all phases-from project definition through design and delivery.</li> <li>Demonstrated proficiency in requirements gathering and analysis processes and methodologies.</li> <li>Experience developing a DWBI strategy and working within and influencing the associated policies. Preferred Qualifications:</li> <li>Ability to effectively interact (written and verbal) with all levels of technology and business partners.</li> <li>Financial Services industry specific knowledge that includes working knowledge of industry data standards and architectures. Experience creating and maintaining data models for the Personal Lines Property &amp; Casualty Industry.</li> <li>Demonstrated proficiency with ER/Studio Data Architect and/or SAP PowerDesigner</li></ul><p> </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "N9_u7ZTIR_ClCHH9lnCPOg",
    "url": "https://jobmote.com/job/67358/big-data-analyst-telecommute/",
    "title": "Big Data Analyst - Telecommute",
    "tags": [
      "DBG:surround``3N(telecommut, posit) NOT fulltim",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UnitedHealth Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 31, 2019 10:07:59 PM",
    "validThrough": "Sep 3, 2019 10:07:59 PM",
    "crawled": "Sep 1, 2019 3:06:25 AM",
    "content": "<div><br>Challenge brings out the best in us. It also attracts the best. That's why you'll find some of the most amazingly talented people in health care here. Bring your skills and talents to a role where you'll have the opportunity to make an impact on a huge scale. This is the place to do your life's best work.(sm)You'll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary Responsibilities:Design, code, test, document, and maintain high-quality and scalable analytic solutionsIdentify gaps and opportunities for improvement of existing solutionsDefine and develop APIs for integration with various data sources in the enterpriseAnalyze customer requirements with respect to current solutionMake accurate development effort estimates to assist management in project and resource planningParticipate in code reviews and assistance for junior analysts Collaborate with management, quality assurance, architecture, and other development teamsWrite technical documentation and participate in production supportKeep skills up to date through ongoing self-directed trainingThe ideal candidate will be a self-starter who can learn things quickly who is enthusiastic, active, and eager to learn.<br><br><b>Required Qualifications:</b>Bachelor's degree in a technical field, or equivalent experience5+ years of hands-on Software Development experience3+ years of development experience with (Java or Scala), and Web Services2+ years of experience in big data technologies like Spark, Cassandra, Hadoop, etc2+ years of experience in messaging (Kafka preferred), NoSQL databases (Cassandra/Hbase preferred), Docker, Kubernetes 2+ years of previous relational database experience Understanding of service oriented architecture (SOA) conceptsExperience with Agile/SCRUM methodology/best practices Experience and successful track-record of learning new tools and technologies and leveraging these on integration and implementation projects Preferred Qualifications:Experience in infrastructure services on at least one major cloud platform (Azure preferred)Advanced degree in a technical field Healthcare industry experience Formal training and/or certification in any of the above-mentioned tools and technologies Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)*All Telecommuters will be required to adhere to UnitedHealth Group's Telecommuter Policy.Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.Job Keywords: Big Data Analyst, telecommute, telecommuter, telecommuting, work from home, travel, remote<br><br><b>Job Title: </b> Big Data Analyst - Telecommute <br><b>Shift: </b> Day Job <br><b>Travel: </b> No <br><b>Business: </b> OI Business Operations <br><b>Family: </b> Analytics <br><b>Telecommuter Position: </b> Yes <br><b>Job Level: </b> Individual Contributor <br><b>Overtime Status: </b> Exempt <br><b>Posted Date: </b> 7/24/2019 <br><b>City: </b> Schaumburg <br><b>State: </b> IL <br><b>Country: </b> United States <br><b>Department: </b> Optum Enterprise Analytics<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XSdWxdJLRgeHpQwTNgxp8Q",
    "url": "http://workinstartups.com/job-board/job/83709/operations-associate-data-analyst-at-disperseio/",
    "title": "Operations Associate / Data Analyst",
    "tags": [
      "DBG:surround``10W(work, offic, dai)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``work 2W from 2W home 4W OR(staff,cowork,offic,posit)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:vba/dotnet/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=26, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Disperse.io",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 30000,
      "maxValue": 36000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 30k - 36k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 9:55:39 PM",
    "validThrough": "Aug 29, 2019 9:55:39 PM",
    "crawled": "Aug 31, 2019 11:06:31 AM",
    "content": "<section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>DESCRIPTION</h2><br /><p>Disperse is a VC-backed artificial intelligence construction startup focused on improving on-site productivity with the help of computer vision. Our goal is to ultimately re-imagine the way building projects are planned, delivered and operated.</p><br /><p>We're currently working on some of the largest building projects in London (e.g. Renzo Piano&rsquo;s Shard Place, Wood Wharf) and have grown from 5 to 35 people over the past year. We have ambitions to expand significantly, which means that we are looking for passionate and enthusiastic talent to join the team.</p><br /><p>We move at a high speed, and will provide you with immense opportunities for initiative, creativity and leadership.&nbsp;<strong><a class=&quot;external&quot; href='https://workable.com/nr?l=http%3A%2F%2Fwww.disperse.io%2Fteam%2F' rel='nofollow noreferrer noopener'>Our proudly diverse, international team is based in London, Sarajevo and Yereva</a></strong><a class=&quot;external&quot; href='https://workable.com/nr?l=http%3A%2F%2Fwww.disperse.io%2Fteam%2F' rel='nofollow noreferrer noopener'><strong>n</strong></a>, and has a wealth of experience from construction management to computer vision and robotics.</p><br /><p>&nbsp;</p><br /><p><strong>THE ROLE</strong></p><br /><p>We are looking for an organised and proactive problem-solver to join our fast-growing team in London as an Operations Associate. This role sits within our global delivery team who are the bridge between our product and customers, and drive the deployment and maintenance of our solution across our construction sites and support our customers throughout their customer journey. You will be helping the team tackle a breadth of operational challenges and problems from helping launch our product on new projects to driving process improvement and innovation to execute on our long-term roadmap.</p><br /><p>&nbsp;</p><br /><p><strong>Responsibilities:</strong></p><br /><ul><br /><li>Helping ensure the on-time delivery and implementation of our solution across our customers</li><br /><li>Investigating and resolving customer issues and their root causes</li><br /><li>Driving operational excellence to improve and maintain our project delivery processes and tools</li><br /><li>Designing and implementing best practices and standardised work processes</li><br /><li>Providing ad-hoc support for other areas of team operations</li><br /><li>Working on data-related challenges, and collecting, aggregating and analysing data across different data streams to meet individual customer needs</li><br /><li>Co-operating closely with other teams to drive key project delivery milestones and product releases</li><br /></ul><br /><p>&nbsp;</p><br /><p><strong>Our culture</strong></p><br /><p>Ask anyone at Disperse what they love most about working here, and they'll probably tell you &quot;it's the people!&quot;, &quot;the team, of course&quot;, &quot;the people and the Hedwig owls in the offices&quot;.</p><br /><p>As clich&eacute;d as it may sound, we're very proud of the people we have and the close-knit, family culture we've built across London, Sarajevo and Yerevan. Despite the distances, we're united through the passion with which we approach our goals and the fun that we have along the way. We always look out for each other, no matter what. The following should give you a good idea what type of culture you'd be joining:</p><br /><ul><br /><li>We encourage proactivity and taking full ownership of problems and initiatives. We don't believe in micromanagement. Instead, we let you pave your own path and give you the space to continuously learn and grow even if it means taking a few detours.</li><br /><li>We support each other. If a process breaks or if you're struggling, you can always count on the people around you and the people far away from you, to help you get back on track.</li><br /><li>We run on feedback: direct and transparent praise and constructive criticism, communicated with the best of intentions. There is no other way to learn!</li><br /><li>Ideas and approaches are always judged on merit rather than source. We welcome discussions and challenges. This way everyone makes a tremendous impact no matter the role</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>REQUIREMENTS</h2><br /><p>You should apply if:</p><br /><ul><br /><li>You're available for an immediate start</li><br /><li>You ideally have 1-2 years of full-time work experience</li><br /><li>You think analytically; you love working with data and extracting insights to make strong business cases</li><br /><li>You're a problem solver; you don&rsquo;t accept the status quo and are always looking for creative solutions.</li><br /><li>You're organised and methodological with a keen attention to detail</li><br /></ul><br /><ul><br /><li>You pick up new skills and information quickly</li><br /><li>You have a track record of achievement</li><br /></ul><br /><p>&nbsp;</p><br /><p>Useful but not essential:</p><br /><ul><br /><li>SQL, Python and/or VBA experience</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>BENEFITS</h2><br /><ul><br /><li>Salary of &pound;30,000 - &pound;36,000 per annum</li><br /><li>Friendly, open and transparent culture</li><br /><li>You'll get to join a passionate startup with proven traction on its scaling journey</li><br /><li>Flexible working hours / ability to work from home</li><br /><li>Awesome startup office in&nbsp;<a class=&quot;external&quot; href='https://workable.com/nr?l=https%3A%2F%2Fwww.theofficegroup.co.uk%2Foffice%2F2-stephen-street%2F%3Futm_source%3Dgoogle%26utm_medium%3Dlocal%26utm_campaign%3D2-stephen-street' rel='nofollow noreferrer noopener'>Central London, Fitzrovia</a></li><br /><li>25 days&rsquo; holiday plus all bank holidays</li><br /><li>Free coffee</li><br /><li>Regular socials, and team retreats to amazing destinations (Tbilisi, Kiev... Where next?)</li><br /></ul><br /><p><strong><br />The process</strong></p><br /><p><br />The interview process will involve:</p><br /><ol><br /><li>A review of your application;</li><br /><li>A 15-minute chat where we can learn more about each other;</li><br /><li>Homework assignment for us to get a sense of how you tackle problems;</li><br /><li>Two rounds of background and cultural chats with the team.</li><br /><li>Final round to iron out any remaining questions</li><br /></ol><br /><p>&nbsp;</p><br /><p>This process should take around two weeks, depending on diaries.</p><br /></section>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "KSQM0grtQLOCuKeFWhGFhQ",
    "url": "https://jobmote.com/job/66621/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 30, 2019 10:07:25 PM",
    "validThrough": "Sep 2, 2019 10:07:25 PM",
    "crawled": "Aug 31, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote || <br><br> #LI-AR1 <br><strong>#IND123</strong> <br> #GLDR2</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Uxufe4AGSjOg3iD5iIe6eg",
    "url": "https://jobmote.com/job/66604/data-analyst-remote/",
    "title": "Data Analyst (Remote)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:sql-server/dotnet/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=2, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Pelican Technology Partners",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 30, 2019 10:07:25 PM",
    "validThrough": "Sep 2, 2019 10:07:25 PM",
    "crawled": "Aug 31, 2019 3:06:25 AM",
    "content": "<div>Remote Data Analyst / Data Management Position Title: Data Analyst ***This position is NOT available for Corp to Corp placement*** Position Description:We are currently seeking a Data Analyst that will perform data analysis tasks across multiple projects. This position will be involved with hands-on data analysis. The Data Analyst will work closely with the Data Governance and Data Management leadership as well as Data Project Coordinators. They will serve a cross-functional role in the organization, working closely with business and technology application leads to ensure good data quality and to ensure data is successfully integrated to various applications. Must have a proven ability to work with limited supervision while supporting the team to ensure the clients will receive successful results. Responsibilities:Provide a single point of contact for data management activities relating to migration and transition projects. Work with Data Governance and Data Management leads to ensure that data quality metric standards are met and adhered to for all migration and transition projects.Recognize opportunities to improve the migration and transition project process and communicate their ideas to the leads of Data Governance and Data Management.Provide input to existing and new data standards.Work closely with on-account teams to gather all data needs, including mastered data, while adhering to data standards. Qualifications:Strong data analytical and profiling skills and ability to identify potential issues proactively and formulate solutionsKnowledge of Data Governance, Data Integration and Data Management projects.Ability to define data requirementsGood experience with SQL especially with SQL Server; good understanding of databases, tables and application integration functionalityCapable of running data base scripts and validating resultsExperience in managing data related tasksExcellent ability to research data issues and provide resolutionHigh level of attention to detail and accuracy and ability to make effective decisions and solve problems Ability to collaborate across many levels within a team, organization and with clients Excellent verbal and written communication skills. The ability to lead productive discussions via conference calls.Comfortable working remote and being conscience of carefully communicating via email, instant messaging, and WebEx meetings.Past experience with Real Estate data is highly desired.Software Tools: Informatica, SQL Server, Excel, Word, Power Point, Visio, SharePoint Compensation:Along with an attractive base Compensation, Comprehensive Benefits include Medical, Dental, and Life Insurance Location: Remote</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pWgxdgjCRS67HsH_xoJxRg",
    "url": "https://remoteok.io/jobs/74822",
    "title": "Machine Learning Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/12",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=7, other=0, dotnet=0, c=0, mobile=0, go=13, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Qntfy",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 31, 2019 2:03:14 AM",
    "validThrough": "Sep 7, 2019 2:03:14 AM",
    "crawled": "Aug 31, 2019 2:06:29 AM",
    "content": "<span></span> <span><h4>Qntfy</h4></span> <br> <h3>Machine Learning Engineer</h3> <div>  <div>   \\nQntfy is looking for a talented and highly motivated ML Engineer to join our team. ML Engineers are responsible for building systems at the crossroads of data science and distributed computing. You will do a little bit of everything: from tuning machine learning models, to profiling distributed applications, to writing highly scalable software. We use technologies like Kubernetes, Docker, Kafka, gRPC, and Spark. You aren’t a DevOps, but an understanding of how the nuts and bolts of these systems fit together is helpful and you aren't a data scientist, but understanding how models work and are applied is just as important. U.S. Citizenship Required Responsibilities\\n\\n\\n* Collaborate with data scientists to get their models deployed into production systems.\\n\\n* Develop and maintain systems for distributed model training and evaluation.\\n\\n* Design and implement APIs for model training, inference, and introspection.\\n\\n* Build tools for testing, benchmarking, and deploying analytics at scale.\\n\\n* Interface with the technical operations team to understand analytic performance and operational behavior.\\n\\n* Write and test code for highly available and high volume workloads.\\n\\n\\n\\n\\nQualifications\\n\\n\\n* BS or Master’s degree in Computer Science, related degree, or equivalent experience.\\n\\n* 5+ years experience with software engineering, infrastructure design, and/or machine learning.\\n\\n* Familiarity with Python and machine learning frameworks, paricularly Scikit-learn, Tensorflow, and Pytorch.\\n\\n* Experience with distributed machine learning using tools like Dask, Tensorflow, Kubeflow, etc.\\n\\n* Write well-structured, maintainable, idiomatic code with good documentation.\\n\\n* Strong work-ethic and passion for problem solving.\\n\\n\\n\\n\\nPreferred Qualifications\\n\\n\\n* Machine learning API development competencies.\\n\\n* Golang development experience.\\n\\n* Container orchestration and optimization knowledge.\\n\\n* Proficiency designing, implementing, and operating large-scale distributed systems.\\n\\n* Prior experience working in a distributed (fully remote) organization.\\n\\n\\n\\n\\nQntfy is committed to fostering and supporting a creative and diverse environment. Qntfy is an equal opportunity employer, and as such will consider all qualified applicants for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Z19C8jKHQ_GLxBfGQZ4cWQ",
    "url": "https://stackoverflow.com/jobs/292504/senior-data-scientist-remote-global-wallethub?a=1A5ZYVkMsrMk",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=84, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 30, 2019 8:30:25 PM",
    "validThrough": "Sep 6, 2019 8:30:25 PM",
    "crawled": "Aug 30, 2019 8:30:25 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div><div>artificial-intelligence</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</li><li>Although we appreciate your interest in working with us, due to the high number of applications we receive, we will only be able to respond to successful applicants.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/292504?reset=False&amp;ra=1A5ZYVkMsrMk&amp;oqs=a%3D1A5ZYVkMsrMk' rel='nofollow'>Apply now</a></div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "sLUKWtKNQqyoSZTAksiF2w",
    "url": "https://stackoverflow.com/jobs/292501/machine-learning-engineer-qntfy?a=1A5W78LakW1W",
    "title": "Machine Learning Engineer at Qntfy  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/16",
      "DBG_TECH1:k/t/w:scikit-learn/python/10",
      "DBG_TECH1:techWeightMap:{python=14, other=0, dotnet=0, c=0, mobile=0, go=13, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Qntfy",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 120000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 90k - 120k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 30, 2019 8:30:25 PM",
    "validThrough": "Sep 6, 2019 8:30:25 PM",
    "crawled": "Aug 30, 2019 8:30:25 PM",
    "content": "<h3><span>Machine Learning Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Qntfy | No office location<br></div><h4>Technologies</h4><div>python</div><div>scikit-learn</div><div>pytorch</div><div>docker</div><div>kubernetes</div>                <h4>Job description</h4>                <div><p>Qntfy is looking for a talented and highly motivated ML Engineer to join our team. ML Engineers are responsible for building systems at the crossroads of data science and distributed computing. You will do a little bit of everything: from tuning machine learning models, to profiling distributed applications, to writing highly scalable software. We use technologies like Kubernetes, Docker, Kafka, gRPC, and Spark. You aren’t a DevOps, but an understanding of how the nuts and bolts of these systems fit together is helpful and you aren't a data scientist, but understanding how models work and are applied is just as important.</p><p><strong>U.S. Citizenship Required</strong> <strong>Responsibilities</strong></p><ul><li>Collaborate with data scientists to get their models deployed into production systems.</li><li>Develop and maintain systems for distributed model training and evaluation.</li><li>Design and implement APIs for model training, inference, and introspection.</li><li>Build tools for testing, benchmarking, and deploying analytics at scale.</li><li>Interface with the technical operations team to understand analytic performance and operational behavior.</li><li>Write and test code for highly available and high volume workloads.</li></ul><p><strong>Qualifications</strong></p><ul><li>BS or Master’s degree in Computer Science, related degree, or equivalent experience.</li><li>5+ years experience with software engineering, infrastructure design, and/or machine learning.</li><li>Familiarity with Python and machine learning frameworks, paricularly Scikit-learn, Tensorflow, and Pytorch.</li><li>Experience with distributed machine learning using tools like Dask, Tensorflow, Kubeflow, etc.</li><li>Write well-structured, maintainable, idiomatic code with good documentation.</li><li>Strong work-ethic and passion for problem solving.</li></ul><p><strong>Preferred Qualifications</strong></p><ul><li>Machine learning API development competencies.</li><li>Golang development experience.</li><li>Container orchestration and optimization knowledge.</li><li>Proficiency designing, implementing, and operating large-scale distributed systems.</li><li>Prior experience working in a distributed (fully remote) organization.</li></ul><p>Qntfy is committed to fostering and supporting a creative and diverse environment. Qntfy is an equal opportunity employer, and as such will consider all qualified applicants for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.</p>                </div>            <div>        <a href='https://jobs.lever.co/qntfy/463fd368-8757-42d6-a45b-22634c032c8e?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Qntfy</h4>            <div><p>Qntfy is a primarily remote company,&nbsp;with employees working across the United States.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "FLnx55NfS92T1L1M1vOwNA",
    "url": "https://remote.co/job/coding-specialist-11/",
    "title": "Coding Specialist",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=1, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "nThrive",
      "sameAs": "https://www.nthrive.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 29, 2019 5:29:53 PM",
    "validThrough": "Sep 5, 2019 5:29:53 PM",
    "crawled": "Aug 29, 2019 6:24:02 PM",
    "content": "<h3>Coding Specialist at <span>nThrive</span></h3><div><span><i></i> Remote</span>        </div><div>            <p><strong>Job ID: </strong>2019-26531</p><p><strong>Employment Type: </strong><strong>Full Time</strong></p><p><strong>Hours Per Week: </strong>40 hours</p><p><strong>Onsite Work Schedule Details: </strong><strong>M-F 8-4:30pm should be flexible to work weekends and holidays as needed</strong></p><p><strong>City: </strong><strong>Remote</strong></p><p><strong>Overview</strong></p><p>The Coding Specialist will work closely with HIM and other support departments to reimburse healthcare claims. This individual will utilize specialized medical classification software to assign procedure and diagnosis codes for insurance billing as well as review claims data to ensure that assigned codes meet required legal and insurance rules and that required signatures and authorizations are in place before submission.</p><p><strong>Responsibilities</strong></p><ul><li>Selects and sequences ICD-10, and/or CPT/HCPCS codes for designated patient types which may include but are not limited to: Ancillary (Diagnostic)/ Recurring; Hospital, Clinic; Physician Pro Fee; Technical Fee or Evaluation and Management.</li><li>Reviews and analyzes clinical records to ensure that APC assignments accurately reflect the diagnoses/procedures documented in the clinical record.</li><li>Abstracts clinical data from the record after documentation review to ensure that it is adequate and appropriate to support diagnoses, procedures and discharge disposition is selected.</li><li>May act as a resource with client staff for data integrity, clarification and assistance in understanding and determining appropriate and compliant coding practices including provider queries.</li><li>Maintains strict patient and provider confidentiality in compliance with all federal, state, and hospital laws and guidelines for release of information.</li><li>Maintain current working knowledge of ICD-10 and/or CPT/HCPCS and coding guidelines, government regulations, protocols and third-party requirements regarding coding and/or billing.</li><li>Participate in continuing education activities to enhance knowledge, skills, and maintain current credentials.</li><li>Supports nThrive’s Compliance Program by adhering to policies and procedures pertaining to HIPAA, FDCPA, FCRA, and other laws applicable to nThrive’s business practices. This includes: becoming familiar with nThrive’s Code of Ethics, attending training as required, notifying management or nThrive’s Helpline when there is a compliance concern or incident, HIPAA-compliant handling of patient information, and demonstrable awareness of confidentiality obligations.</li></ul><p><strong>Qualifications</strong></p><ul><li><strong>Active RHIA, RHIT, CCS</strong></li><li>3+ years of recent and relevant hands-on coding experience including active production coding</li><li>Ability to consistently code at 95% threshold for both accuracy and quality while maintaining client-specific and nThrive production standards</li><li>Proficient computer knowledge including MS Office (Outlook, Word, Excel, Power Point)</li><li>Must display excellent interpersonal and problem-solving skills with all levels of internal and external customers</li><li>Candidates must successfully pass pre-employment coding test</li><li>Cable or DSL high-speed, wired Internet Connection</li></ul><p><strong>About nThrive</strong></p><p><strong>Be Inspired. Ignite Change. Transform Health Care.</strong><br>From Patient-to-Payment, nThrive provides all the technology, advisory expertise, services, analytics and education programs health care organizations need to thrive in the communities they serve. Our colleagues share a united passion to help health care organizations strengthen their financial position, which translates to accessible, quality care for all. This passion fuels our drive to innovate and participate in community outreach through the nThrive CARES program. Our colleagues are encouraged to think differently and empowered to make a lasting impact that ensures our health care providers, and our world, are healthy and productive.</p>        </div><div>        <a href='https://careers-nthrive.icims.com/jobs/26531/coding-specialist/job' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SDmblLl3QbaNm6su6qwOTw",
    "url": "https://stackoverflow.com/jobs/265031/data-platform-engineer-heetch?a=1qSKVWcse6xq",
    "title": "Data Platform Engineer at Heetch  ",
    "tags": [
      "DBG:surround``OR(no,no W central) W offic",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:avro/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=11, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Heetch",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 29, 2019 1:06:24 PM",
    "validThrough": "Sep 5, 2019 1:06:24 PM",
    "crawled": "Aug 29, 2019 1:06:24 PM",
    "content": "<h3><span>Data Platform Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>System Administrator</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Carsharing, Marketplace, Transportation</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Heetch | No office location<br></div><h4>Technologies</h4><div></div><div>kafka</div><div>prestodb</div><div>apache-spark</div><div>airflow</div><div>amazon-redshift</div>                <h4>Job description</h4>                <div><p><strong>⚠️<u>Read before applying:</u></strong></p><p>We're a young company iterating over our remote culture so for now, we're only working with people in locations where the time zone is:&nbsp;<strong>-3 hours &gt; Paris time zone&nbsp;&lt;&nbsp;+3 hours</strong></p><p><strong>Data Engineering Team @Heetch</strong></p><p>Our team's mission is to help the company generate confident insights, make better decisions and build data-driven products. We believe the data platform is the digital nervous system of Heetch and that empowering everyone in the company with data access is critical to our business success. As a new sub-team within Data Engineering, the Data Infrastructure team is dedicated to designing, building and scaling our data platform and the underlying data infrastructure.</p><p><strong>What will be your role?</strong></p><p>You will enable Data Scientists, Data Analysts, and Operations teams, tailor the data platform to their needs and empower them to solve challenging ML and analytics problems. If you're experienced, passionate and interested in leading the transformation of our data infrastructure, we would love to talk to you!</p><p><strong>Does it sound like you?</strong></p><ul><li>You've architected, built, scaled, tuned and maintained large-scale distributed systems in a production environment, specifically on top of AWS.</li><li>You've got proven experience working with data technologies that power data platforms (e.g.: Spark, Presto, Kafka, Airflow, Avro, Redshift, ElasticSearch, etc.).</li><li>You've led DevOps topics such as CI/CD, containerization, monitoring, etc. in a data ecosystem.</li><li>You display strong coding skills in Python and Scala with a focus on maintainability, scale, and automation.</li><li>You love to work autonomously and take on unconstrained problems.</li><li>You can drive a vision, estimate the associated tasks and plan from development to delivery.</li><li>You take pride in sharing and gathering knowledge through documentation, advocacy and getting soaked in stakeholders use cases.</li></ul><p><strong>What will you do?</strong></p><ul><li>Build frameworks, libraries, and abstractions to enable easy and reliable data processing, ingestion and exposition</li><li>Automate data pipeline and services deployment and configuration management</li><li>Support, manage and handle operations on cloud-based data technologies (e.g., clusters, serverless applications, APIs, databases)</li><li>Monitor the health of the data platform through automation</li><li>Handle periodic on-call rotations</li><li>Allow data engineering and data science to execute their pipelines through workflow management</li></ul><p><strong>What will be your challenges?</strong></p><ul><li>Build the next generation of our data platform using open source big data technologies such as Kafka, Kafka Streams, Airflow, Spark, Metacat and Kubernetes</li><li>Enable data scientists to test and productionize various ML models to enhance the performance of our marketplace</li><li>Craft robust infrastructure foundations to support API-based data access including finatra microservices and AWS Lambda functions</li><li>Support, manage and handle operations on our MPP databases (Redshift, Presto)</li><li>Design change data capture from PostgreSQL databases to feed the data lake</li><li>Simplify data integration with Apache Gobblin</li><li>Enable dataset discovery, metadata exploration, and change notification</li><li>Unlock acceptance testing with Airflow, Spark, and Cucumber</li></ul><p><strong>What's next?</strong></p><p>If your application is selected, the process will be composed of 4 steps:</p><ol><li>Non-technical interview with the Engineering Manager of your potential team (1h30)</li><li>Take home assignment (~5 days deadline)</li><li>Interview with your future teammates (1h)</li><li>Day on site (Paris) to meet your future stakeholders</li></ol><p>Check out our<a href='https://eng.heetch.com/' rel='nofollow'>&nbsp;Engineering Blog</a>&nbsp;and follow our&nbsp;<a href='https://twitter.com/heetcheng' rel='nofollow'>twitter</a>&nbsp;:) You can also have a look at our open-source projects and contributions&nbsp;<a href='https://oss.heetch.com/' rel='nofollow'>here</a></p>                </div>            <div>        <a href='https://jobs.lever.co/heetch/707af0c6-48ff-4426-8caa-5faa8ef9e9ae?lever-origin=applied&amp;lever-source%5B%5D=StackOverflow' rel='nofollow'>                        Apply now        </a></div>            <h4>About Heetch</h4>            <div><p>Heetch is a mobility app with a simple mission: We want people to enjoy going out.<br>Every night and every day, our drivers are doing their best to make their rides unforgettable and friendly! We are focused on young people's expectations and are competing within a fast-paced market.</p><p>The service launched in Paris in September 2013 has been growing ever since, with thousands of daily rides in France, Belgium, and Morocco. With more than 1 million users in Europe, we are proud to be one of the fastest growing French startups!</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Full remote and flexible ways of working</span>                            </li>                            <li>                                <span></span>                                <span>Paid conferences attendance/travel</span>                            </li>                            <li>                                <span></span>                                <span>Code Retreat</span>                            </li>                            <li>                                <span></span>                                <span>2 company seminars</span>                            </li>                            <li>                                <span></span>                                <span>Travel budget to visit your co-workers</span>                            </li>                            <li>                                <span></span>                                <span>Heetch Credits</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LYttcGq0Rt6k-sZD90LnTQ",
    "url": "https://jobmote.com/job/66472/remote-python-data-engineer/",
    "title": "Remote Python Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/10",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 401000,
      "maxValue": 401000,
      "info": "",
      "unit": "DAY",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 401k /Day"
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:36 PM",
    "validThrough": "Aug 31, 2019 10:07:36 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>AWS, Kinesis, Lambda, Snowflake, Python 3.6/3.7, S3, Data Management, Data Ingestion, Data Processing, IOT<br><br>If you are a Remote Python Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>Previous experience providing robust and reliable data management techniques; massaging, optimizations for aggregating/reading performantly.<br>Familiar with developing solutions that scale to meet scenarios of high-velocity data ingestion and processing.<br>Be a core player in collaborations with the team(s) to identify new and useful ways to package and present data to clients<br>A deep understanding of distributed programming concepts and are able to identify the patterns necessary for a scalable, robust, and reliable service.<br>Ability to reason about performance benefits and tradeoffs in software and infrastructure design decisions as they relate to preventing data loss and recovering from failure.<br>Comfortable with contributing to a collaborative development environment both within the team and across the organization. We are true full stack since we are from silicon to the cloud, so there are several teams with which to interact and collaborate.<br>Create and communicate tests that need to exist to prevent regressions and find performance bottlenecks.<br>Know what metrics need to be created or monitored to alert on abnormal operation and to aid in capacity/scale planning.<br>Desire to automate processes to keep the team moving efficiently and safely.<br><br>Tech Stack:<br><br>Modern Python (3.6/3.7) and Go<br>AWS primitives for an event based architecture<br>CI/CD, automation for infrastructure and code, and observability/instrumentation are first class citizens<br><br>What's In It for You<br><br>Full Remote! <br>Monthly hack days<br>Health, Dental, and Vision benefits<br>21 days PTO + separate sick day quota<br>401K plan<br>Amazingly talented team!So, if you are a Remote Python Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "uDjEPJNdS_KRStI5DzcJBw",
    "url": "https://jobmote.com/job/66466/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:36 PM",
    "validThrough": "Aug 31, 2019 10:07:36 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ckaBQ6BGTC6kpevAkIJVUA",
    "url": "https://jobmote.com/job/66450/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:35 PM",
    "validThrough": "Aug 31, 2019 10:07:35 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0HPnOrrvSQ6mLCho93p6aw",
    "url": "https://jobmote.com/job/66449/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 10:07:35 PM",
    "validThrough": "Aug 31, 2019 10:07:35 PM",
    "crawled": "Aug 29, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xXyA0yeoTMGWh0yus9689g",
    "url": "https://remoteok.io/jobs/74767",
    "title": "Data Engineer Attribution",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Security Scorecard - We are revolutionizing the cybersecurity industry",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 28, 2019 8:00:40 PM",
    "validThrough": "Sep 4, 2019 8:00:40 PM",
    "crawled": "Aug 28, 2019 8:30:29 PM",
    "content": "<span></span> <span><h4>Security Scorecard - We are revolutionizing the cybersecurity industry</h4></span> <br> <h3>Data Engineer Attribution</h3> <div>  <div>   \\nAbout The Role\\n\\nThe Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.\\n\\n&nbsp;Requirements:\\n\\n\\n* 3+ years of experience with:\\n\\n\\n* Scala or Python, both preferred\\n\\n* Distributed systems (e.g. Spark, Hadoop)\\n\\n\\n\\n\\n\\n* Database systems (e.g. Postgres, MySQL)\\n\\n* Experience with the following is preferred:\\n\\n\\n* IP (v4/v6) allocation and addressing conventions\\n\\n* DNS conventions and best practices\\n\\n* Anti-abuse investigations\\n\\n\\n\\n\\n\\n* Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)\\n\\n\\n\\n\\nTraits\\n\\n\\n* Comfortable working as part of a distributed team\\n\\n* Excellent communication and teamwork skills\\n\\n* Ability to make data driven decisions\\n\\n* Ability to do independent research\\n\\n\\n\\n\\nInterview Process\\n\\n\\n* Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.\\n\\n* Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.\\n\\n* 1-2 technical interviews with data engineer and data science team members via video or in person. 1-1.5 hours for both.\\n\\n* Final meeting with engineering leadership via video or in person. 1 hour.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "sKKzedE6RSy9unM7O3LTXw",
    "url": "http://workinstartups.com/job-board/job/83721/go-backend-developer-london-uk-at-tabeo/",
    "title": "Go Backend Developer - London, UK",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/9",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=9, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "Tabeo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 1:38:04 PM",
    "validThrough": "Aug 30, 2019 1:38:04 PM",
    "crawled": "Aug 28, 2019 2:06:35 PM",
    "content": "<p>About Tabeo</p><br /><p>Our mission is to make healthcare more accessible and affordable. Tabeo builds payments and business tools for medical professionals. We&rsquo;re helping independent dental practices and large hospital groups create new, digital patient experiences.</p><br /><p>In the last 12 months, we&rsquo;ve grown the number of our partners delivering care from 30 to 600 in the UK. Our team plans to expand its network to 2,000 in the next 12 months. By December, our revenue will be 50x higher than for the same period last year.&nbsp;</p><br /><p><br />What will you do</p><br /><p>You will work on important parts of our back-end. This will include (but not limited to) our TabeoSprint CQRS/ES architecture framework as well as several microservices that utilise it. Your input will be valuable to enhancing and improving the framework and existing microservices as well as designing and developing new microservices.</p><br /><p>You will wear many hats, have lots of challenges, and if you're the type that loves grokking and learning on a dime, then you'll love the scope of what you can contribute to on a daily basis. You will be expected to come up with great ideas to push our code to the next level and we&rsquo;ll give you the opportunity to do so.</p><br /><p>You&rsquo;ll work closely with</p><br /><p>Hisham, Marcin and Peter. You will be expected to be based and work in the office in London with Hisham who will introduce you to the existing codebase.</p><br /><p><br />How we work</p><br /><p>We&rsquo;re using agile methodology through SCRUM based on 2 week sprints. Our team is completely international and so at work we speak only English. Our team is also partly distributed so you must be comfortable working with remote colleagues.</p><br /><p>How you&rsquo;ll fit in</p><br /><p>You have 2-4 years of programming experience in at least one popular programming language.<br />You have experience working with Go or willing to learn it.<br />You are familiar with cloud services (GCP, AWS).<br />You know how to use Docker.<br />You know how to use Git.<br />You have a good understanding of SQL.<br />You have good experience creating RESTful APIs.<br />You know design patterns.<br />You&rsquo;re a quick learner.<br />You speak and write good English.<br />You&lsquo;re a team player with a good sense of humour.<br />You love researching new topics and ways of doing things.<br />You love passing on your knowledge to your colleagues.</p><br /><p>Our stack that you&rsquo;ll be working with</p><br /><p>Go<br />Google Cloud Platform<br />Docker<br />Kubernetes<br />PostgreSQL<br />Apache Kafka<br />... and many others</p><br /><p><br />What we offer</p><br /><p>Competitive salary (based on experience)<br />Work with awesome people<br />Competitive vacation policy<br />Flexible working, at home, away or in office<br />Private health insurance<br />Life insurance and disability benefits<br />Regular team events<br />Free coffee, drinks, fruits, muesli and snacks<br />&pound;2,000 budget per year for your personal development<br />Start date: next 3 months</p><br /><p>If you&rsquo;re interested, please send us an email to jobs@tabeo.co.uk with your CV and a short intro.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "b6C0XpRfQ_a076vGnkVjoQ",
    "url": "https://jobmote.com/job/66369/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GLnmbS2cT9CqGMen4J0Cug",
    "url": "https://jobmote.com/job/66368/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "A2ckNrvERiqqF8Gdbs_L1g",
    "url": "https://jobmote.com/job/66367/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "7F38o8pqRnmtFqBs-OI5KQ",
    "url": "https://jobmote.com/job/66366/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 10:07:37 PM",
    "validThrough": "Aug 30, 2019 10:07:37 PM",
    "crawled": "Aug 28, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZJXg6zEfRZuLEC_Kjm_GeQ",
    "url": "https://remoteok.io/jobs/74747",
    "title": "Senior Data Engineer",
    "tags": [
      "DBG:surround``2N(remot,work) 3W OR(encourag, avail, environ)",
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "50% remote",
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 11:03:34 PM",
    "validThrough": "Sep 3, 2019 11:03:34 PM",
    "crawled": "Aug 27, 2019 11:30:30 PM",
    "content": "<span></span> <span><h4>Creative Commons</h4></span> <br> <h3>Senior Data Engineer</h3> <span></span> <span>verified</span> <br> <span>From Pacific time zones to Eastern time zones</span> <div>  <div>   \\nCreative Commons is building a “front door” to the growing universe of openly licensed and public domain content through CC Search and the CC Catalog API. The Senior Data Engineer reports to the Director of Engineering and is responsible for CC Catalog, the open source catalog that powers those products. This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners.\\n\\n**Diversity &amp; inclusion**\\n\\nWe believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.\\n\\n**Work environment and location**\\n\\nCreative Commons is a fully-distributed organization - we have no central office. This position is available to applicants working in the range of the Eastern to Pacific time zones, in a remote working environment. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.\\n\\n\\n\\n# Responsibilities\\n **Primary responsibilities**\\nArchitect, build, and maintain the existing CC Catalog, including:\\n* Ingesting content from new and existing sources of CC-licensed and public domain works.\\n* Scaling the catalog to support billions of records and various media types.\\n* Implementing resilient, distributed data solutions that operate robustly at web scale.\\n* Automating data pipelines and workflows.\\n* Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.\\n\\nAugment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.\\n\\nBuild an open source community around the CC Catalog, including:\\n* Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.\\n* Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor. \\n* Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.\\n\\nCollaborate with other outside communities, companies, and institutions to further Creative Commons’ mission. \\n\\n# Requirements\\n\\n* Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization\\n* Proficiency with Python\\n* Proficiency with Apache Spark\\n* Experience with cloud computing platforms such as AWS\\n* Experience with Apache Airflow or other workflow management software\\n* Experience with machine learning or interest in picking it up\\n* Fluent in English\\n* Excellent written and verbal communication skills\\n* Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure\\n* Curiosity and a desire to keep learning\\n* Commitment to consumer privacy and security\\n\\nNice to have (but not required):\\n* Experience with contributing to or maintaining open source software\\n* Experience with web crawling\\n* Experience with Docker\\n \\n\\n#Salary\\n100000 -120000\\n \\n\\n#Location\\n- From Pacific time zones to Eastern time zones   <br>  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pzqZKamwQMGx7bkZQ4tIXA",
    "url": "https://remote.co/job/senior-data-analyst-2/",
    "title": "Senior Data Analyst",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:vba/dotnet/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=8, c=0, mobile=0, go=3, nodejs=1, bigdata-ml=50, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Bill.com",
      "sameAs": "https://www.bill.com/"
    },
    "salary": {
      "currency": "USD",
      "minValue": 25,
      "maxValue": 50,
      "info": "",
      "unit": "HOUR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 25 - 50 /Hour"
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 6:58:25 PM",
    "validThrough": "Sep 3, 2019 6:58:25 PM",
    "crawled": "Aug 27, 2019 7:31:37 PM",
    "content": "<h3>Senior Data Analyst at <span>Bill.com</span></h3><div><span><i></i> Remote</span>         | <span> Freelance </span></div><div>            <ul><li><strong>(Contract / Remote)</strong></li><li><strong>REMOTE-USA</strong></li><li><strong>PRODUCT &amp; UX – PRODUCT MANAGEMENT</strong></li><li><strong>TEMPORARY / CONTRACTOR</strong></li></ul><p><strong>About Bill.com</strong></p><p>Bill.com is a leader in financial process automation for small businesses and mid-size companies. Making it simple to connect and do business, the Bill.com Back Office Cloud digitizes, automates and simplifies legacy payment and financial processes. With an integrated, end-to-end platform, Bill.com leverages artificial intelligence to reduce manual work, and provides a cloud workspace to help run your business anytime, anywhere. The company partners with many of the largest U.S. financial institutions, more than 70% of the top 100 U.S. accounting firms, and major accounting software providers. Bill.com manages more than $70B in annual payment volume across ACH, virtual cards, checks, and international payments. The company has offices in Palo Alto, California and Houston, Texas.</p><p><strong>Mission:</strong></p><p>The Sr. Growth Analyst reports into the growth team with responsibilities around coming up with data-driven insights, helping develop hypotheses, and measuring experiments. Part of this role is tactical; you’ll be responsible for finding data and putting it into a reportable format for the team. The other part is strategic; you’ll be a thought partner in establishing the direction for our experimentation. Additionally, this role supports the product organization, so finding and reporting on product performance will be an important part of this job.</p><p><strong>This is a remote, contract role. Pay rate is $25 – $50 per hour dependent on experience and location.</strong></p><p><strong>Responsibilities:</strong></p><ul><li>Data discovery: You’ll be responsible for finding the data we need to evaluate product performance. This data spans our analytics tools, CRM databases, backend databases, and support tools.</li><li>Analysis: You’ll identify, analyze, and interpret trends or patterns in complex data sets</li><li>Document: You’ll fill in our documentation gaps as you discover missing documentation around data sources, column descriptions, etc.</li><li>Thought partner: You’ll use your insights to help provide direction for our growth strategy.</li></ul><p><strong>Professional Experience/Background to be successful in this role:</strong></p><ul><li>Experienced: You have experience finding data and producing reports. Lots of it. And you enjoy the technical challenges of getting the data. SQL is a second language for you. You can debate the merits of Excel’s more esoteric functions. You have a minimum of 5 years of experience in a related field.</li><li>Curious: But you are also relentlessly inquisitive about the data. Creating a report inspires new questions that you itch to answer. For you, there’s always another question that leads to another insight. You love getting caught in this cycle.</li><li>Careful: You know how easy it is for data to mislead you so you’ve developed an instinct for double-checking and triangulating against suspicious results.</li><li>Communication: You are an excellent communicator, both verbally and in written form. You can make an analytical argument, and you can present complex data in an understandable way.</li><li><strong>Bachelor’s Degree:</strong>&nbsp;<strong>Relevant subjects include statistics, economics, data science, computer science, business.</strong></li></ul><p><strong>Extra points if you…</strong></p><ul><li>Stats: Have experience with R and multivariate regressions</li><li>Data Science: Have spent time with Matlab / Octave</li><li>Data pipeline experience: Have experience moving data around (e.g., ETL) and auditing data pipelines.</li><li>Programming: Have a working knowledge of Python, VBA, or Javascript.</li><li><strong>Masters Degree:</strong>&nbsp;<strong>Have a masters degree in statistics, data science, computer science, or business.</strong></li></ul><p><strong>Expected Outcomes in 3 months:</strong></p><ul><li>Learn Bill.com’s data models. Become fluent with our schemas. Understand our analytics tools. Know where to go to get the data we need.</li><li>Build high-level reports for each of our growth metrics (e.g., acquisition, activation, retention, etc).</li><li>Run 5-10 drill-down analyses in key areas.</li><li>Contribute meaningfully in discussions around growth hypotheses.</li></ul><p><strong>Outcomes expected in 6 months:</strong></p><ul><li>Become a data authority for at least one analytics area (e.g., activation).</li><li>Actively propose data-driven growth hypotheses on an ongoing basis</li></ul><p><strong>Bill.com Culture:</strong></p><ul><li>Humble – No ego</li><li>Fun – Celebrate the moments</li><li>Authentic – We are who we are</li><li>Passionate – Love what you do</li><li>Dedicated – To each other and the customer</li></ul>        </div><div>        <a href='https://jobs.lever.co/bill/98e7f172-4b47-48f1-abad-ae4ff791d30b' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IYSgzebBRH-5gzzz-m5ISw",
    "url": "https://remote.co/job/software-engineer-computer-vision/",
    "title": "Software Engineer, Computer Vision",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/32",
      "DBG_TECH1:k/t/w:cuda/bigdata-ml/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:opencv/bigdata-ml/8",
      "DBG_TECH1:k/t/w:opengl/c/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=12, other=0, dotnet=0, c=13, mobile=0, go=0, nodejs=0, bigdata-ml=67, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/West"
    ],
    "tagsNames1": [
      "US Pacific time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Williams-Sonoma",
      "sameAs": "https://www.williams-sonomainc.com"
    },
    "salary": {
      "currency": "USD",
      "minValue": 12,
      "maxValue": 16,
      "info": "",
      "unit": "WEEK",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 12 - 16 /Week"
    },
    "employmentType": "UNSET",
    "published": "Aug 27, 2019 5:38:25 PM",
    "validThrough": "Sep 3, 2019 5:38:25 PM",
    "crawled": "Aug 27, 2019 6:24:08 PM",
    "content": "<h3>Software Engineer, Computer Vision at <span>Williams-Sonoma</span></h3><div><span><i></i> Remote</span>         | <span> Entry-level </span> | <span> Freelance </span> | <span> Part-time </span></div><div>            <p><strong>Requisition Number:</strong> SS-16507<br><strong>Area of Interest:</strong> Information Technology<br><strong>Organization:</strong> Corporate<br><strong>Brand/Division:</strong> Shared Services<br><strong>Position Type: Part-time</strong></p><p><strong>JOB DESCRIPTION</strong><br><strong>Location: San Jose, CA (Non-California Residents can work Remote from anywhere within the United States)</strong></p><p><strong>Terms: 12-16-week contract on a Williams-Sonoma, Inc. W2 (Non-exempt)</strong></p><p><strong>Hours:</strong><br>Monday — Friday; 20-hours max per week (part-time)<br><strong>Work hours: anytime between 8 AM — 7 PM Pacific Time; up to 8 paid hours max per day; 20 paid hours max per week</strong></p><p><strong>About Outward, Inc.</strong><br>Outward, Inc. HQ is based in San Jose, CA and is a wholly-owned subsidiary of Williams Sonoma, Inc.</p><p>At Outward Inc. our vision is to ‘lower the friction’ with regards to all aspects of the customer journey for our parent company and our retail customers. We do this by offering new technology solutions that enable new experiences and top-notch visualizations of their products. We are continuously pushing the boundaries of how 3D and AR/ VR technologies will drive the next generation shopping experience. Through our portfolio of premium lifestyle brands — our mission is to deepen consumer connections with the products that matter and deliver an innovative experience.</p><p><strong>Summary:</strong><br>We’re looking for talented software engineer to work part-time (20-hours max per week) for our applied Research &amp; Development Group located in San Jose, CA. The best candidate will assist us in making new visual experiences through research and software engineering. The R&amp;D group works on problems in imaging, computer vision, graphics, and machine learning. Some areas of interest are:</p><ul><li>Computer Vision: multiple view geometry, point cloud reconstruction</li><li>Deep Learning</li><li>Physically based rendering, global illumination</li><li>Graphics pipelines</li><li>Machine learning, DNNs</li></ul><p><strong>REQUIREMENTS AND QUALIFICATIONS</strong><br><strong>We will like to meet you because…</strong></p><ul><li><strong>You have a BSc Degree in CS, EE, Applied Math or similar field</strong></li><li>You have skills in design and implementation of algorithms</li><li>You have strong software engineering skills in Python or C++</li><li>You have experience with scientific libraries such as NumPy, scikit-learn, image manipulation libraries like OpenCV, Machine learning frameworks like Tensorflow, PyTorch</li><li>You have strong communication skills</li><li>You have GPGPU programming knowledge – OpenGL, CUDA, etc.</li><li>You have practical experience with modern CNN architectures</li></ul><p><strong>Estimated Start date(s) &amp; additional Information:</strong><br>September 9, 2019 (or sooner) through December 20, 2019 (up to 16-weeks max)<br>If you work more than 5-hours per day, you are required by the state of California to take a 30-minute lunch break</p><p>This position Will Not offer Visa Sponsorship or relocation assistance.</p><p>Outward, Inc. is an Equal Opportunity Employer.<br>Outward, Inc. will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the California Fair Employment Act (AB 1008), or other applicable state or local laws and ordinances.</p><p>Williams-Sonoma, Inc. is an Equal Opportunity Employer.</p><p>Williams-Sonoma, Inc. will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance, or other applicable state or local laws and ordinances.</p>        </div><div>        <a href='https://careers.williams-sonomainc.com/williams-sonoma-inc/job/San-Jose-Temporary-Software-Engineer-Computer-Vision-(Outward,-Inc_)-CA-95101/586135500/?&amp;utm_source=remote.co' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "K-VUBdWkT2G7v68W7C2QyA",
    "url": "https://jobmote.com/job/66196/senior-data-etl-engineer-remote/",
    "title": "Senior Data ETL Engineer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jersey/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 26, 2019 10:07:37 PM",
    "validThrough": "Aug 29, 2019 10:07:37 PM",
    "crawled": "Aug 27, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>SQL, AWS, ETL<br><br>We are one of the most successful technology start-ups in the Philadelphia/New Jersey region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. <br><br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.<br><br>We need a Senior ETL Data Engineer to help us transform how consumers interact with real estate data.<br><br>What You Will Be Doing<br><br>- Recommend and implement data processing tools and technologies<br>- Extract, transform and load data pipelines from end to end<br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info<br>- Create, develop and document data mapping rules from multiple sources<br>- Develop continuous process movements<br><br>What You Need for this Position<br><br>- 5+ yrs experience<br>- ETL<br>- SQL / PostgreSQL<br>- AWS<br>- BSCS or related degree<br><br>What's In It for You<br><br>- Competitive Pay<br>- FULL REMOTE!So if you are a Senior Data ETL Engineer with relevant experience, please apply today! Interviews are occurring this week!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YbCzoZaUQUO2fR9wD0f8zw",
    "url": "https://jobmote.com/job/66173/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 26, 2019 10:07:37 PM",
    "validThrough": "Aug 29, 2019 10:07:37 PM",
    "crawled": "Aug 27, 2019 3:06:24 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XSMpkAVyQXi6w4-b20XjLg",
    "url": "https://jobmote.com/job/65021/aws-big-data-cloud-engineer-remote-flexibility-philadelphia/",
    "title": "AWS Big Data Cloud Engineer - Remote Flexibility - Philadelphia",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b>AWS Big Data Cloud Engineer - REMOTE FLEXIBILITY - Philadelphia - Full Time - Negotiable Salary</b><br><br>My client is an AWS advanced consulting partner that is certified in big data, machine learning, artificial intelligence, education competencies, and DevOps. They are a U.S. based company that is in the process of building out their Canadian team, so the opportunity to grow into a directing position is now! In this role, you will be designing big data, mobile, and web solutions for premier brands worldwide. As well as, providing valuable insights and solutions to customers based on their needs and requirements.<br> They are offering a competitive base salary, performance based bonuses, the opportunity to work with the latest technologies and tooling's of your choice, and the ability to learn and grow directly from former Amazon Directors!<br> The ideal candidate for this role is some who has strong cloud computing experience on AWS, willing to travel, and has great people skills.<br><br><b>Qualifications/Requirements</b>:<ul><li>Demonstrated hands on experience in building Distributed Big Data Solutions (ingesting, processing, caching, logging, monitoring)</li><li>Strong development experience in Big Data processing engines (preference: Spark on EMR)</li><li>Demonstrated expertise in Cloud Computing on AWS (EC2, EMR, Redshift, Data Pipeline)</li><li>Expertise in NoSQL and SQL</li><li>Strong experience in altering ETL processes</li><li>Strong written and oral communication skills</li><li>Ability to travel up to 50%</li><li>Ability to meet tight deadlines in high pressured environments</li></ul><b>Benefits</b>:<ul><li>Competitive Base Salary</li><li>Performance based bonuses</li><li>REMOTE FLEXIBILITY</li><li>Ability to work with the latest technologies of your choice</li><li>Clear opportunities to grow</li><li>Learn side by side from former AWS Directors</li><li>Ability to receive AWS Certifications</li><li>Never focused on one technology or tooling</li><li>Excellent company culture</li><li>Premium Healthcare</li><li>UNLIMITED PTO</li><li>Transportation Reimbursement</li><li>FAST HIRING PROCESS</li></ul> Interviews are now underway and the process is moving extremely fast! If you or someone you may know could be interested in this opportunity APPLY NOW! For guaranteed IMMEDIATE consideration!<br> To apply, contact me via email: [Click Here to Email Your Resum?] ; phone: (212)- ; or LinkedIn message. Upon conversation, please be able to provide an updated CV.<br> Jefferson Frank is the global leader in Amazon Web Services recruiting. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.<br> At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Wwra45h_QzqVF5O1meBe0g",
    "url": "https://jobmote.com/job/64989/hadoop-developer-remote/",
    "title": "Hadoop Developer - REMOTE",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:k/t/w:mahout/java/5",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Skiltrek LLC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b> ****Location: Jacksonville Beach FL or Remote**** </b><br><br><b> Job Title: Hadoop Developer </b><br><br><b> Long Term Contract ? 12 months + </b><b><br><br><b> W2 only - (No C2C) </b></b><br><br><b> Sign On Bonus! </b><br><br><b>Work Auth: USC / GC / GC EAD only</b><br><br><b> ****Location: Jacksonville Beach FL or Remote**** </b><b><br><br><b> Change your lifestyle move near the beach! Jacksonville voted in the top 3 most affordable cities in the US! Cost of living calculator: </b></b><br><br><b> Job Description: </b><br> We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.<br><br><b> Responsibilities </b><br><br>? Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities<br> ? Implementing ETL process using APACHE NIFI<br> ? Monitoring performance and advising any necessary infrastructure changes<br> ? Defining data retention policies<br> ? Proficient with Spark and SparkR.<br><br><b> Skills and Qualifications: </b><br> ? Proficient understanding of distributed computing principles.<br> ? Proficiency with ETL infrastructure such as Nifi, Talend.<br> ? Management of Hadoop cluster, with all included services such as Hive,HBase,mapReduce and Sqoop<br> ? Ability to solve any ongoing issues with operating the cluster and identifying performance bottlenecks.<br> ? Proficiency with Hadoop v2, MapReduce, HDFS<br> ? Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.<br> ? Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala<br> ? Experience with Spark and SparkR<br> ? Experience with integration of data from multiple data sources<br> ? Experience with NoSQL databases, such as HBase, Cassandra, MongoDB<br> ? Knowledge of various ETL techniques and frameworks, such as Flume<br> ? Experience with various messaging systems, such as Kafka.<br> ? Experience with Big Data Client toolkits, such as Mahout, SparkML, or H2O<br> ? Good understanding of Lambda Architecture, along with its advantages and drawbacks<br> ? Experience with Cloudera/MapR/Hortonworks</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tFvCNDPRTj-Qro-O4MLaFg",
    "url": "https://jobmote.com/job/64988/hadoop-developer-remote/",
    "title": "Hadoop Developer - REMOTE",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:k/t/w:mahout/java/5",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/10",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Skiltrek LLC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:29 PM",
    "validThrough": "Aug 28, 2019 10:07:29 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><b> ****Location: Jacksonville Beach FL or Remote**** </b><br><br><b> Job Title: Hadoop Developer </b><br><br><b> Long Term Contract ? 12 months + </b><b><br><br><b> W2 only - (No C2C) </b></b><br><br><b> Sign On Bonus! </b><br><br><b>Work Auth: USC / GC / GC EAD only</b><br><br><b> ****Location: Jacksonville Beach FL or Remote**** </b><b><br><br><b> Change your lifestyle move near the beach! Jacksonville voted in the top 3 most affordable cities in the US! Cost of living calculator: </b></b><br><br><b> Job Description: </b><br> We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.<br><br><b> Responsibilities </b><br><br>? Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities<br> ? Implementing ETL process using APACHE NIFI<br> ? Monitoring performance and advising any necessary infrastructure changes<br> ? Defining data retention policies<br> ? Proficient with Spark and SparkR.<br><br><b> Skills and Qualifications: </b><br> ? Proficient understanding of distributed computing principles.<br> ? Proficiency with ETL infrastructure such as Nifi, Talend.<br> ? Management of Hadoop cluster, with all included services such as Hive,HBase,mapReduce and Sqoop<br> ? Ability to solve any ongoing issues with operating the cluster and identifying performance bottlenecks.<br> ? Proficiency with Hadoop v2, MapReduce, HDFS<br> ? Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.<br> ? Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala<br> ? Experience with Spark and SparkR<br> ? Experience with integration of data from multiple data sources<br> ? Experience with NoSQL databases, such as HBase, Cassandra, MongoDB<br> ? Knowledge of various ETL techniques and frameworks, such as Flume<br> ? Experience with various messaging systems, such as Kafka.<br> ? Experience with Big Data Client toolkits, such as Mahout, SparkML, or H2O<br> ? Good understanding of Lambda Architecture, along with its advantages and drawbacks<br> ? Experience with Cloudera/MapR/Hortonworks</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "jkHsHSW4QV-jv2E8YL5GFA",
    "url": "https://jobmote.com/job/64980/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 10:07:28 PM",
    "validThrough": "Aug 28, 2019 10:07:28 PM",
    "crawled": "Aug 26, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rLmIy81lT96La8xNVHlEJg",
    "url": "https://remoteok.io/jobs/74708",
    "title": "Data Engineer Productionize Statistical Models",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SecurityScorecard",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 9:16:15 AM",
    "validThrough": "Sep 1, 2019 9:16:15 AM",
    "crawled": "Aug 25, 2019 10:06:28 AM",
    "content": "<span></span> <span><h4>SecurityScorecard</h4></span> <br> <h3>Data Engineer Productionize Statistical Models</h3> <div>  <div>   \\nAbout The Role\\n\\nThe Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.\\n\\nThis position is&nbsp;either in our HQ in NYC or remote in North America.\\n\\nTechnical Skills and Experience\\n\\n\\n* 3+ years of experience with:\\n\\n\\n* Scala or Python, both preferred\\n\\n* Distributed systems (e.g. Spark, Hadoop)\\n\\n\\n\\n\\n\\n* Database systems (e.g. Postgres, MySQL)\\n\\n* Experience with the following is preferred:\\n\\n\\n* IP (v4/v6) allocation and addressing conventions\\n\\n* DNS conventions and best practices\\n\\n* Anti-abuse investigations\\n\\n\\n\\n\\n\\n* Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)\\n\\n\\n\\n\\nTraits&nbsp;\\n\\n\\n* Comfortable working as part of a distributed team\\n\\n* Excellent communication and teamwork skills\\n\\n* Ability to make data driven decisions\\n\\n* Ability to do independent research\\n\\n\\n\\n\\nInterview Process\\n\\n\\n* Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.\\n\\n* Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.\\n\\n* 1-2 technical interviews with data engineer and data science team members via video or in person.&nbsp;45 minutes each.\\n\\n* Final meeting with engineering leadership via video or in person. 1 hour.\\n\\n\\n\\n\\n&nbsp;About SecurityScorecard\\n\\nAt SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.\\n\\nBacked by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Yka_Pd9GRvKhw0eJ5xtkyw",
    "url": "https://stackoverflow.com/jobs/290942/data-engineer-productionize-statistical-models-securityscorecard?a=1zzwjFzYHPyM",
    "title": "Data Engineer: productionize statistical models at SecurityScorecard (New York, NY) ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SecurityScorecard",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 25, 2019 4:06:24 AM",
    "validThrough": "Sep 1, 2019 4:06:24 AM",
    "crawled": "Aug 25, 2019 4:06:24 AM",
    "content": "<h3><span>Data Engineer: productionize statistical models</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Cybersecurity, SaaS</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: SecurityScorecard | New York, NY<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time +/- 4 hours</span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>New York, NY.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                            <div>                                    <span>Visa Sponsorship:</span>                                    <span>Yes</span>                                </div>                                                    </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>postgresql</div><div>apache-spark</div><div>scala</div><div>networking</div>                <h4>Job description</h4>                <div><p><strong>About The Role</strong></p><p>The Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.</p><p>This position is&nbsp;either in our HQ in NYC or remote in North America.</p><p><strong>Technical Skills and Experience</strong></p><ul><li>3+ years of experience with:<ul><li>Scala or Python, both preferred</li><li>Distributed systems (e.g. Spark, Hadoop)</li></ul></li><li>Database systems (e.g. Postgres, MySQL)</li><li>Experience with the following is preferred:<ul><li>IP (v4/v6) allocation and addressing conventions</li><li>DNS conventions and best practices</li><li>Anti-abuse investigations</li></ul></li><li>Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)</li></ul><p><strong>Traits&nbsp;</strong></p><ul><li>Comfortable working as part of a distributed team</li><li>Excellent communication and teamwork skills</li><li>Ability to make data driven decisions</li><li>Ability to do independent research</li></ul><p><strong>Interview Process</strong></p><ul><li>Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.</li><li>Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.</li><li>1-2 technical interviews with data engineer and data science team members via video or in person.&nbsp;45 minutes each.</li><li>Final meeting with engineering leadership via video or in person. 1 hour.</li></ul><p>&nbsp;<strong>About SecurityScorecard</strong></p><p>At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.</p><p>Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.</p>                </div>            <div>        <a href='https://grnh.se/b15dc2e61' rel='nofollow'>                        Apply now        </a></div>            <h4>About SecurityScorecard</h4>            <div><p><strong>About SSC</strong></p><p>At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.</p><p>Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Unlimited PTO</span>                            </li>                            <li>                                <span></span>                                <span>Health Benefits Starting Day One</span>                            </li>                            <li>                                <span></span>                                <span>401k</span>                            </li>                            <li>                                <span></span>                                <span>Education Stipend</span>                            </li>                            <li>                                <span></span>                                <span>Learning and Development</span>                            </li>                            <li>                                <span></span>                                <span>Stocked Kitchen</span>                            </li>                            <li>                                <span></span>                                <span>Remote Work Options</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "mjoCf5KVSC-swz8w0TArwQ",
    "url": "https://jobmote.com/job/64940/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "yOsAdJokTdahVwR25TDVDQ",
    "url": "https://jobmote.com/job/64923/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "stBIIgNdQQC0CWsPJTsXsw",
    "url": "https://jobmote.com/job/64920/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "k-Q0W8eRRzSOYfWDuih8zg",
    "url": "https://jobmote.com/job/64919/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 24, 2019 10:07:31 PM",
    "validThrough": "Aug 27, 2019 10:07:31 PM",
    "crawled": "Aug 25, 2019 3:06:24 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "QKvFNuG2QjW9eOrwebJuGQ",
    "url": "https://jobmote.com/job/64819/remote-data-engineer/",
    "title": "REMOTE - Data Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:c#/c/4",
      "DBG_TECH1:k/t/w:c#/dotnet/10",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=10, c=4, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 10:07:37 PM",
    "validThrough": "Aug 26, 2019 10:07:37 PM",
    "crawled": "Aug 24, 2019 3:06:24 AM",
    "content": "<div>Minimum Required Skills:<br>Power BI, SQL, ETL, Azure, Data Factory, Databricks, PowerShell, Ssis, C#, Blob Storage<br><br>If you are a REMOTE - Data Engineer with experience, please read on!<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- Power BI<br>- SQL<br>- ETL<br>- Azure<br>- Data Factory<br>- Databricks<br>- PowerShell<br>- Ssis<br>- C#<br>- Blob StorageSo, if you are a REMOTE - Data Engineer with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "iNstO8tSTcCfbhemy1whUg",
    "url": "https://stackoverflow.com/jobs/290839/senior-data-scientist-remote-global-wallethub?a=1zxnx6wxdfxu",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=84, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 6:23:00 PM",
    "validThrough": "Aug 30, 2019 6:23:00 PM",
    "crawled": "Aug 23, 2019 6:23:00 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div><div>artificial-intelligence</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>Although we appreciate your interest in working with us, due to the high number of applications we receive, we will only be able to respond to successful applicants.</strong></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/290839?reset=False&amp;ra=1zxnx6wxdfxu&amp;oqs=a%3D1zxnx6wxdfxu' rel='nofollow'>Apply now</a></div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-KlB0J-IQdm7qZdcc5AJqw",
    "url": "https://www.remoteage.com/remote-jobs/big-data-engineer-data-scientist/",
    "title": "Big Data Engineer/ Data Scientist",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=64, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Natsoft",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 11:06:59 AM",
    "validThrough": "Aug 30, 2019 11:06:59 AM",
    "crawled": "Aug 23, 2019 11:07:34 AM",
    "content": "<h3>            Big Data Engineer/ Data Scientist        </h3><div>United States, Indiana</div><div>Company: Natsoft<p></p></div><div>                    <h4>Overview</h4>                    <p>Greeting, </p><p></p><p>I represent Natsoft Corporation, a leading IT staffing organization. I am part of a team responsible for servicing a major client of ours that is a world leader in IT services.</p><p></p><p>Job Title<strong>: </strong><strong>Big Data Engineer/ Data Scientist</strong></p><p>Location: Dallas, TX </p><p>Duration : Long Term</p><p></p><p><strong>Experience in </strong>HDP/CDH Hadoop Admin, Data Scientist, Sqoop, Oozie, Hive, Pig Latin, Spark, Sql, Stored Procs, Hive, Impala</p><p></p><p>Let me know for any further information.</p><p><strong> </strong></p><p><strong> </strong></p><p><strong>Thanks &amp; Regards,</strong></p><p><strong>Amit</strong></p><p><strong>Sr.US IT Recruiter </strong></p><p>Natsoft Corporation | 27 Worlds Fair Dr,Somerset,NJ 08873</p><p>Phone: | Email: | |</p><p></p><p>NATSOFT CORPORATION is a certified Minority Business Enterprise (MBE) Global Software Consulting, Application Development, Staffing and Remote Infrastructure Company. MBE certified by the States of NJ, PA &amp; City of Houston.</p><p></p><p> – provided by Dice</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?%2fSJhHUD47wcM9lAoX82EPgg' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "BtbARtvtQemE9yBve-KGsQ",
    "url": "https://remoteok.io/jobs/74683",
    "title": "Software Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 23, 2019 5:00:46 AM",
    "validThrough": "Aug 30, 2019 5:00:46 AM",
    "crawled": "Aug 23, 2019 5:06:31 AM",
    "content": "<span></span> <span><h4>Rho AI</h4></span> <br> <h3>Software Engineer</h3> <div>  <div>   \\nRho AI’s data-driven products &amp; services are used in a wide range of industries,&nbsp;with a growing focus on sustainable systems (e.g. energy, water, climate,&nbsp;waste). We value pragmatic solutions and have cultivated a modern technology&nbsp;stack that combines software development (python microservices, react&nbsp;frontends), infrastructure automation (docker, kubernetes), and machine&nbsp;learning (scikit-learn, pytorch) into a developer-friendly CICD flow.\\n\\nAs a member of the software engineering team, you will:\\n\\n\\n* Develop products and services for advanced machine learning applications in interesting and important problem spaces.\\n\\n* Join a group of talented and congenial team members where you will be respected in your software design decisions and take ownership of the systems that you build.\\n\\n* Learn from and collaborate with senior engineers and co-founders.\\n\\n* Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.\\n\\n\\n\\n\\nSound interesting? We are hiring for a variety of experience levels, so all are welcome to apply. We are&nbsp; interested in hearing from candidates who have publicly available open-source and/or technical writing examples and are looking to&nbsp;take their next step in their professional careers.&nbsp; Please reach out if:\\n\\nYou have:\\n\\n\\n* (Must) Good communication skills for technical and non-technical audiences.\\n\\n* (Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.\\n\\n* (Must) Proficient on all backend layers - databases, services and APIs.\\n\\n* (Must) A collaborative attitude oriented around craftsmanship and team success.\\n\\n* (Should) An interest in systems thinking &amp; enjoy stitching components together.\\n\\n* (Should) Have experience working within a microservices oriented architecture.\\n\\n* (Nice) Built systems that process large amounts of data and/or traffic.\\n\\n* (Nice) Strong computer science principles, and/or algorithmic skills.\\n\\n* (Nice) Experience with machine learning applications.\\n\\n\\n\\n\\n&nbsp;You would like these perks:\\n\\n\\n* Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.\\n\\n* Work with a highly engaged team, learn together, and make decisions that impact the whole company.\\n\\n* Benefits, including health insurance and 401k.\\n\\n\\n\\n\\n&nbsp;You meet these criteria:\\n\\n\\n* You are seeking a full-time job.\\n\\n* You reside in the United States.\\n\\n* You are authorized / eligible to work for any company in the United States.\\n\\n* You are in a continental US time zone, or willing to align your schedule.\\n\\n\\n\\n\\nTo get an interview, you must supply:\\n\\n\\n* A cover letter that explains why you are 1) specifically interested in Rho AI as a company and 2) a good fit for this particular position.\\n\\n* A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "CizYbGStR8qwCgy03cHxyg",
    "url": "https://jobmote.com/job/64515/staff-software-engineer-backend-remote-sensing-raster-pipelines/",
    "title": "Staff Software Engineer, Backend (Remote Sensing / Raster Pipelines)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "The Climate Corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 10:07:32 PM",
    "validThrough": "Aug 25, 2019 10:07:32 PM",
    "crawled": "Aug 23, 2019 3:06:27 AM",
    "content": "<div>The Climate Corporation is revolutionizing the agriculture industry with a platform and products that are helping the world's farmers sustainably increase productivity with digital tools. As the industry leader, we're working to ensure we're the most connected platform in Agriculture. Through our partnerships, farmers can exchange data between the Climate FieldView™ platform and our partner connected solutions in just minutes. <br><br> We have an opportunity for a Staff Engineer position in our Geospatial Algorithms Engineering Group to work with a team of highly experienced computer vision and remote sensing software engineers to help us enhance and expand our satellite and drone imagery processing systems. We ingest, archive and process vast amounts of multi-spectral space-borne, air-borne, and unmanned imagery along with vector data that help our customers manage farming activities at a global scale. As a Staff Engineer in our team, you will be tasked with the design and implementation of high-performance satellite image processing systems and the operationalization of remote sensing algorithms. The core of this work is to expand our back-end capabilities and to build out systems to generate on-demand, analysis-ready datasets. Your contributions will help the team deliver high-quality, near-real-time actionable information to our customers and help them make data-driven decisions. If you are passionate about innovation and excited about helping us transform agriculture and develop a platform that helps farmers sustainably increase their productivity,. we would love to talk to you! <br><br><strong>What You Will Do:</strong> <ul><li>Benchmark, analyze, and deploy raster and vector based algorithms built on remotely sensed datasets</li><li>Drive the development of raster processing pipelines with a focus on data provenance, validation, traceability, and error propagation</li><li>Analyze system and product requirements to design optimal and scalable system architectures</li><li>Participate and support the verification and validation of production algorithms</li><li>Document architectural designs, changes, and configuration control processes</li><li>Perform technical risk management and mitigation.</li> <li>Coach and mentor junior team members in data-intensive system design.</li> <li>Drive collaboration and coordination of across-teams work</li><li>Improve our software engineering processes towards the continuous improvement of reliability, scalability, and maintainability of all our systems</li> </ul><strong>Basic Qualifications:</strong> <ul><li>At least 8 years of demonstrable experience in building highly-reliable production software systems.</li><li>Solid understanding of functional programming, object-oriented design, data structures, complexity analysis, design, verification, and validation techniques.</li><li>Solid understanding of computer science and computer vision fundamentals.</li> </ul><strong>Additional Preferred Qualifications:</strong> <ul><li>Experience working with AWS-based systems in production</li><li>Experience using Scrum best practices in software development projects</li><li>Experience writing reliable and maintainable code in Scala and/or Java</li><li>Experience in operationalizing algorithms at large scale against large data stores</li><li>Experience working with and contributing to the open source software community for geospatial software and analysis</li><li>Excellent leadership skills with high integrity, work ethics, humility, and self-awareness.</li><li>Excellent ability to present complex technical information in a clear and concise manner.</li><li>Ability to handle multiple, competing priorities in a fast-paced development environment.</li><li>Passion for computer vision, raster data processing, geospatial engineering, and derivation of information rich data products.</li> <li>Experience working with systems processing and manipulating petabytes of imagery data.</li> </ul><strong>What We Offer:</strong> <br><br> Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers. <br><br> We provide competitive salaries and some of the best perks in the industry, including: <ul><li>Superb medical, dental, vision, life, disability benefits, and a 401k matching program</li><li>A stocked kitchen with a large assortment of snacks &amp; drinks to get you through the day</li><li>Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used</li><li>We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hack-a-thons to encourage participation and growth in both community involvement and career development</li> </ul> We also hinge our cultural DNA on these five values: <ul><li>Inspire one another</li><li>Innovate in all we do</li><li>Leave a mark on the world</li><li>Find the possible in the impossible</li><li>Be direct and transparent</li> </ul> Learn more about our team and our mission: <br><br> The Climate Corporation - The Technology Behind Making A Difference <br><br> or visit <br><br><strong>As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. If you need assistance or accommodation due to a disability, you may contact us at</strong> <strong></strong> <br><br><strong>#LI-DR1</strong></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Am5IDqKoQpSK0lKCyuIFtg",
    "url": "http://workinstartups.com/job-board/job/83711/computer-vision-engineer-at-disperseio/",
    "title": "Computer Vision Engineer",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=88, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Disperse.io",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 50000,
      "maxValue": 65000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 50k - 65k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 10:26:40 PM",
    "validThrough": "Aug 29, 2019 10:26:40 PM",
    "crawled": "Aug 22, 2019 11:30:31 PM",
    "content": "<section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>DESCRIPTION</h2><br /><p><strong>About us</strong></p><br /><p>Disperse is a VC-backed artificial intelligence construction startup focused on improving on-site productivity with the help of computer vision. Our goal is to ultimately re-imagine the way building projects are planned, delivered and operated.</p><br /><p>We're currently working on some of the largest building projects in London (e.g. Renzo Piano&rsquo;s Shard Place, Wood Wharf) and have grown from 5 to 35 people over the past year. We have ambitions to expand significantly, which means that we are looking for passionate and enthusiastic talent to join the team.</p><br /><p>We move at a high speed, and will provide you with immense opportunities for initiative, creativity and leadership.&nbsp;<strong><a class=&quot;external&quot; href='https://workable.com/nr?l=http%3A%2F%2Fwww.disperse.io%2Fteam%2F' rel='nofollow noreferrer noopener'>Our proudly diverse, international team is based in London, Sarajevo and Yerevan</a></strong>, and has a wealth of experience from construction management to computer vision and robotics.</p><br /><p><strong>Your role</strong></p><br /><p>We are looking for a highly motivated and passionate Computer Vision Engineer to join our growing team. Someone who is excited at the prospect of applying deep knowledge and expertise to shape the future of the construction industry and to have a direct impact on productivity.</p><br /><p>As part of your role, you will collaborate with our Computer Vision scientists and the wider Engineering team to both use and craft state-of-the-art deep learning algorithms to creatively solve real-world problems in the construction sector. You will be given lots of responsibility, driving projects which could involve implementing cutting edge algorithms and integrating these into our workflows and core software.</p><br /><p>If you&rsquo;re eager to apply Computer Vision and Machine Learning to real-world problems and would like to work with a world-class team of researchers and engineers, this role is a superb opportunity for you.</p><br /><p><strong>Our culture</strong></p><br /><p>Ask anyone at Disperse what they love most about working here, and they'll probably tell you &quot;it's the people!&quot;, &quot;the team, of course&quot;, &quot;the people and the Hedwig owls in the offices&quot;.</p><br /><p>As clich&eacute;d as it may sound, we're very proud of the people we have and the close-knit, family culture we've built across London, Sarajevo and Yerevan. Despite the distances, we're united through the passion with which we approach our goals and the fun that we have along the way. We always look out for each other, no matter what. The following should give you a good idea what type of culture you'd be joining:</p><br /><ul><br /><li>We encourage proactivity and taking full ownership of problems and initiatives. We don't believe in micromanagement. Instead, we let you pave your own path and give you the space to continuously learn and grow even if it means taking a few detours.</li><br /><li>We support each other. If a process breaks or if you're struggling, you can always count on the people around you and the people far away from you, to help you get back on track.</li><br /><li>We run on feedback: direct and transparent praise and constructive criticism, communicated with the best of intentions. There is no other way to learn!</li><br /><li>Ideas and approaches are always judged on merit rather than source. We welcome discussions and challenges. This way everyone makes a tremendous impact no matter the role.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>REQUIREMENTS</h2><br /><p>You should apply if:</p><br /><ul><br /><li>You have a MSc degree or PhD in Machine Learning, Computer Vision, Computer Science, or a related quantitative field</li><br /></ul><br /><ul><br /><li>You have hands on experience using machine learning and computer vision.</li><br /><li>You have good coding skills in Python with experience using one of: Tensorflow, PyTorch, or similar.</li><br /><li>You have experience in managing projects with large datasets</li><br /><li>You have experience of working in an autonomous team</li><br /><li>You have strong communication skills - you can summarise the complex, liaise with your fellow Computer Vision engineers, and explain your work in simple terms to your other colleagues.</li><br /><li>You're a problem solver and analytical thinker; you don&rsquo;t accept the status quo and are always looking for creative solutions.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><h2 class=&quot;section__header&quot;>BENEFITS</h2><br /><ul><br /><li>Pro rata salary of &pound;50,000 - &pound;65,000 per annum plus generous option package</li><br /><li>Friendly, open and transparent culture.</li><br /><li>You'll get to join a passionate startup with proven traction on its scaling journey.</li><br /><li>Flexible working hours / ability to work from home.</li><br /><li>Regular mentoring and feedback.</li><br /><li>Awesome start-up office in&nbsp;<a class=&quot;external&quot; href='https://workable.com/nr?l=https%3A%2F%2Fwww.theofficegroup.co.uk%2Foffice%2F2-stephen-street%2F' rel='nofollow noreferrer noopener'>Central London, Fitzrovia</a></li><br /><li>25 days' holiday plus all bank holidays.</li><br /><li>Free coffee.</li><br /><li>Regular socials and team retreats to exotic destinations (Tibilisi, Sarajevo,...Where next?)</li><br /></ul><br /><p>&nbsp;</p><br /><p><strong>The process</strong></p><br /><p>The interview process will involve:</p><br /><ol><br /><li>A review of your application;</li><br /><li>A 20-minute chat where we both can learn more about each other;</li><br /><li>Homework assignment for us to get a sense of how you tackle problems;</li><br /><li>Two rounds of on-site technical and cultural chats with the team. If you are not currently based in London, we would be happy to speak with you over video chat;</li><br /><li>Final round to iron out any remaining questions you may have.</li><br /></ol><br /><p>This process should take around two weeks, depending on diaries.</p><br /></section>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "e_kxDViWRgyjw76_5zGK7g",
    "url": "https://stackoverflow.com/jobs/290564/software-engineer-rho-ai?a=1zrF0Xcvrji0",
    "title": "Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/22",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=54, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 11:30:24 PM",
    "validThrough": "Aug 29, 2019 11:30:24 PM",
    "crawled": "Aug 22, 2019 11:30:24 PM",
    "content": "<h3><span>Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                    </div>                <div>Company: Rho AI | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>python</div><div>single-page-application</div><div>sql</div><div>nosql</div><div>docker</div>                <h4>Job description</h4>                <div><p>Rho AI’s data-driven products &amp; services are used in a wide range of industries,&nbsp;with a growing focus on sustainable systems (e.g. energy, water, climate,&nbsp;waste). We value pragmatic solutions and have cultivated a modern technology&nbsp;stack that combines software development (python microservices, react&nbsp;frontends), infrastructure automation (docker, kubernetes), and machine&nbsp;learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p><p>As a member of the software engineering team, you will:</p><ul><li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li><li>Join a group of talented and congenial team members where you will be respected in your software design decisions and take ownership of the systems that you build.</li><li>Learn from and collaborate with senior engineers and co-founders.</li><li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li></ul><p>Sound interesting? We are hiring for a variety of experience levels, so all are welcome to apply. We are&nbsp; interested in hearing from candidates who have publicly available open-source and/or technical writing examples and are looking to&nbsp;take their next step in their professional careers.&nbsp; Please reach out if:</p><p><strong>You have:</strong></p><ul><li>(Must) Good communication skills for technical and non-technical audiences.</li><li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li><li>(Must) Proficient on all backend layers - databases, services and APIs.</li><li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li><li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li><li>(Should) Have experience working within a microservices oriented architecture.</li><li>(Nice) Built systems that process large amounts of data and/or traffic.</li><li>(Nice) Strong computer science principles, and/or algorithmic skills.</li><li>(Nice) Experience with machine learning applications.</li></ul><p>&nbsp;<strong>You would like these perks:</strong></p><ul><li>Work from anywhere in the US! Rho AI is a tight-knit, fully distributed team.</li><li>Work with a highly engaged team, learn together, and make decisions that impact the whole company.</li><li>Benefits, including health insurance and 401k.</li></ul><p>&nbsp;<strong>You meet these criteria:</strong></p><ul><li>You are seeking a full-time job.</li><li>You reside in the United States.</li><li>You are authorized / eligible to work for any company in the United States.</li><li>You are in a continental US time zone, or willing to align your schedule.</li></ul><p><strong>To get an interview, you must supply:</strong></p><ul><li>A cover letter that explains why you are 1) <em>specifically interested</em> in Rho AI as a company and 2) a <em>good fit</em> for this particular position.</li><li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/290564?reset=False&amp;ra=1zrF0Xcvrji0&amp;oqs=a%3D1zrF0Xcvrji0' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Rho AI</h4>            <div><p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p><p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p><p><strong>Work at Rho AI</strong></p><p>Rho AI is a remote-first organization, where you will work with a talented group of data scientists, engineers and thought leaders&nbsp;to harness the power of data science to propel projects with a positive world impact. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p><p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ugYHfLiiRC284ohrXYVVIA",
    "url": "https://www.remoteage.com/remote-jobs/data-lead-software-developer-remote-considered-3/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 22, 2019 9:22:37 AM",
    "validThrough": "Aug 29, 2019 9:22:37 AM",
    "crawled": "Aug 22, 2019 10:07:24 AM",
    "content": "<h3>            Data Lead Software Developer-remote considered        </h3><div>United States, Connecticut</div><div>Company: Travelers Insurance<p></p></div><div>                    <h4>Overview</h4>                    <p>Company Information<br>Solid reputation, passionate people and endless opportunities. That’s Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers – and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br></p><ul> <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul> <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others’ views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p><p></p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?Epk0ZMC5PtRX7kTbNMCTdAz' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MaY0cOzlS9ipKYJcwvNTCg",
    "url": "https://remote.co/job/chatbot-a-i-developer/",
    "title": "Chatbot A.I. Developer",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR( australia, japan, newzealand)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(europ, european, europeanunion)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Asia"
    ],
    "tagsNames1": [
      "Asia time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Day Translations",
      "sameAs": "https://www.daytranslations.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 21, 2019 6:30:55 PM",
    "validThrough": "Aug 28, 2019 6:30:55 PM",
    "crawled": "Aug 21, 2019 7:31:22 PM",
    "content": "<h3>Chatbot A.I. Developer at <span>Day Translations</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>Category:</strong>&nbsp;<strong>Software Development<br>Job Type: Full-Time</strong></p><p>Day Translations is a global translation and interpreting company. We help improve worldwide communication through accurate, localized translations, interpretation and outsourcing services, and a wide variety of tailored language solutions for individuals, organizations, and businesses of all sizes.</p><p><strong>About the Chatbot AI developer position</strong></p><p><strong>Location</strong>:<strong>&nbsp;Remote (America, Europe, Middle East, Australia, and Asia)</strong></p><p><strong>Reports to</strong>: DevOps Manager</p><p>Day Translations seeks a qualified Chatbot AI developer. This position provides a great opportunity for an individual who has knowledge and experience working with Chatbot AI-enabled implementations. Day Translations is on a journey to transform its technology landscape from an older to newer, cutting edge conversational bot. We are looking for a Developer who can build bot which communicates clearly in multiple languages and in a more human approach with users in creative ways. Unlike the traditional bots being just concentrated on the business services, it should communicate by understanding the context through NLP or other good approaches.</p><p>You will code, test, and debug new and existing implementations. If you enjoy the challenge of working in a fast-paced, dynamic environment and have a passion for software development and engineering, this is the place for you.</p><p><strong>Job duties and responsibilities:</strong></p><ul><li>Chatbot and web services design, development, testing and maintenance</li><li>Design, development and unit testing prior to delivering the final product to the Lead Manager</li><li>Delivery of solutions aligned with expectations, on time, within budget, and with anticipated business value</li><li>Work as a member of our Agile Scrum team and technical experts, including programmers, UX designers, and project managers to design new products, or scale existing solutions</li><li>Design and develop plug and play cross-platform solutions along with API across multiple channels</li></ul><p><strong>Requirements:</strong></p><ul><li>Proven prior experience with good portfolio in developing AI-based Chatbots and other applications is must</li><li>Ability to effectively communicate technical information to non-technical team members.</li><li>Ability to effectively communicate written and verbally with customers, peers, and management.</li><li>Must be able to work cooperatively and effectively in an agile team environment.</li><li>Experience developing and implementing Bots</li><li>Experience in Conversational AI platforms/frameworks like IBM Watson, Tensorflow, Pandorabots, Dialogflow etc. for enterprises using ML and Deep Learning</li><li>Experience with bot text to speech and vice versa transformation incorporation</li><li>Experience with bot multi-lingual utilization (preferred)</li><li>Knowledgeable of Cloud services, methodologies and best practices (Amazon and Google preferred)</li></ul><p><strong>Candidates should be prepared to take additional tests/interviews.</strong></p>        </div><div>        <a href='https://day-translations.breezy.hr/p/2025b48dfbf4?source=remote.co' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j5PqydDBQZCl3Ot6ehLxWw",
    "url": "https://jobmote.com/job/64201/enterprise-architect-london-or-remote-70k-100k-bonus-benfits/",
    "title": "Enterprise Architect-LONDON or REMOTE-£70K-£100K+Bonus+Benfits",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:embedded/c/1",
      "DBG_TECH1:k/t/w:embedded/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=1, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/embedded",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "embedded"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 70000,
      "maxValue": 100000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 70k - 100k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 20, 2019 10:07:31 PM",
    "validThrough": "Aug 23, 2019 10:07:31 PM",
    "crawled": "Aug 21, 2019 3:06:24 AM",
    "content": "<div>Job Title: Enterprise Architect <br><br>Location: London OR Remote<br><br>Salary: Up to £70,000 - £100,000 - Flexible Dependent on experience + Benefits (Including 20% bonus)<br><br>Position: Permanent <br><br>Our client is a multinational leader in the managed services sector specifically related to the Telecom and Technology sectors. They work with some of the largest and most successful companies out there, so this is a great opportunity to work among industry experts.<br><br>You will be joining the IT Services division focused on global and managed services including enterprise networking, cloud networking, wireless, communications and workplace services. Being a modern and forward-thinking company, my client offer flexible hours, remote working as well as an excellent salary and benefits package. The division you will be joining is growing rapidly so this is a great time to join the teams.<br><br>This is a customer facing role, so we are looking for someone that ideally has customer facing experience in a global or regional service ideally including presales, managed service frameworks, commercial and contract experience. <br><br>Your key skills should include the following:<br><br>Essential<br><br>Customer facing experience<br>Experience working on large strategic customer accounts as an architect<br>Good understanding of cloud and digital concepts<br>Experience working with virtual teams including service architects, project management, engineers and service management<br>Strong understanding of managed services, global service desks, and ITIL concepts<br>Experience with large deals and contract negotiation (Ideally £10 Million+)<br>Experience building complex cost models<br>Comfortable delivering presentations to customers at a senior level<br>Experience working with PS subject matter experts<br>Experience working and designing multinational / global servicesDesirable <br><br>Some experience working with major clients in the retail and / or hospitality industries<br>Technical or operations background<br>ITIL3 foundation or similar<br>May have one or more other industry certification such as Prince2, PMP and /or technical accreditations e.g Cisco or similarThis role would suit someone from a similar background such as a service management consultant, senior service designer, senior service architect or enterprise architect for manager services / service management.<br><br>How to APPLY:-<br><br>If you are interested in finding out more about this opportunity, please submit your CV via the link provided and I will contact you shortly for a confidential discussion.<br><br>Cubiq Recruitment is recognised as a trusted supplier of permanent, contract and interim recruitment services to the technology and manufacturing sectors.<br><br>Our teams of specialist recruiters operate across the following engineering and commercial disciplines; mechanical engineering, electrical engineering, controls &amp; instrumentation, embedded software &amp; electronics, quality &amp; manufacturing, product design and project, programme &amp; operations management</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "at1O9cneQ-yv6mUnMPfakw",
    "url": "https://jobmote.com/job/63917/principal-data-scientist-100-remote-or-chesterbrook-pa-or-cambridge/",
    "title": "Principal Data Scientist (100% Remote or Chesterbrook, PA or Cambridge",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=0, go=0, nodejs=0, bigdata-ml=30, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Dell Technologies",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 10:07:32 PM",
    "validThrough": "Aug 22, 2019 10:07:32 PM",
    "crawled": "Aug 20, 2019 3:06:25 AM",
    "content": "<div>Are you in need of a one-of-a-kind opportunity? How about the challenge of uncovering hidden insights to drive new business value for customers from one of world's largest, and growing, store of meta-data created from a cloud integration platform? Dell Boomi is the first and still the industry's 1 Integration Platform as-a Service that enables customers to develop and execute data integrations that access, transform, and move data between clouds, between clouds and on-premise applications, and between on-premise applications.Meta-data is continually being generated as users develop new application integrations, capturing the relationships for every application being accessed, the data mapping definitions created, as well as meta-data being generated that captures every aspect of the execution of the integration. Dell Boomi already offers value-add to its users today where some of this meta-data is what we call crowd-sourced. But we know that there is so much more to unleash from this meta-data, developer behaviors, execution characteristics, correlations of common integrations across our customer-base world-wide.We are looking for data scientists to work on machine learning, data mining, and statistical modeling for predictive and prescriptive enterprise analytics. Successful candidates will be expected to understand and investigate state of the art techniques in advanced machine learning and statistical modeling, and also design, develop, and deploy state-of-art, scalable systems for innovative analytics applications. Applicants will be expected to work with a diverse, large set of data sources sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights.ResponsibilitiesResearch, design, prototype and deliver robust and scalable models based on machine learning, data mining, and statistical modeling to answer key business problems, to improve the product, to increase and optimize customer experiences, and other business outcomesAssess the effectiveness and accuracy of new data sources and data gathering techniquesDevelop custom data models and algorithms to apply to data setsBuild cost effective tools and support structures needed to analyze data, perform elements of data cleaning, feature selection and feature engineering and organize experiments in conjunction with best practicesWork with development teams &amp; business groups to ensure models can be implemented as part of a delivered solution replicable across many clientsPresent findings to stakeholders to drive improvements and solutions from concept through to deliveryKeep abreast of the latest developments in the field by continuous learning and proactively champion promising new methods relevant to the problems at handCollaborate closely with university partners and other scientists and engineers in a multidisciplinary work environmentPreferred Qualifications:Master's in computer science with 5 years of experience in related field.Demonstrated history of driving and delivering analytics models and solutionsDeep knowledge of fundamentals of machine learning, data mining and statistical predictive modeling, and extensive experience applying these methods to real world problemsStrong problem-solving skills with an emphasis on product development.Experience working with and creating data architectures.Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacksStrong skills in software prototyping and engineering with expertise in applicable programming and analytics languages (Python, R, C/C++) and various open source machine learning and analytics packages to generate deliverable modules and prototype demonstrations of their workDesired interdisciplinary skills include big data technologies, ETL, statistics and causal inference, Deep Learning, modeling and simulationBreadth of skills and experience in machine learning - diverse types of data and sources, different types of learning models, diverse learning settingsAbility and inclination to work in multi-disciplinary environments, and a passion for ideas realized in practiceDemonstrated ability to propose novel solutions to problems, performing experiments to show feasibility of their solutions, and working to refine the solutions into a real-world contextStrong analytical, written, and verbal communication skillsBenefits We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities - all to create a compelling and rewarding work environment.Apply now Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.&quot;LI Priority&quot;&quot;DCAM1&quot;Full time<p>by Jobble</p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "cOUpqD7hSiOK9hTHTty6aA",
    "url": "https://remoteok.io/jobs/74594",
    "title": "Data Science Curriculum Writer",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=100, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 9:41:35 PM",
    "validThrough": "Aug 26, 2019 9:41:35 PM",
    "crawled": "Aug 19, 2019 10:30:31 PM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Curriculum Writer</h3> <div>  <div>   \\nPlease Apply Here\\n\\nEducation | Remote, USA | Contract\\n\\nWho We Are Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;thinkful.com. Job Description Thinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp; Responsibilities\\n\\n\\n* Consistently deliver content that meets spec and is on time to support our program launch roadmap\\n\\n* Create daily lesson plans consisting of&nbsp;\\n\\n* Presentation decks that instructors use to lecture students on a given learning objective\\n\\n* Instructor notes that instructors use alongside&nbsp;\\n\\n* Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture\\n\\n* Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform\\n\\n* Creates code assets to support lesson plans, student activities, and written curriculum content\\n\\n* Iterates on deliverables based on user feedback\\n\\n\\n\\n\\nRequirements\\n\\n\\n* 3+ years of hands-on Data Science industry experience&nbsp;\\n\\n* Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning\\n\\n* Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)\\n\\n* Collaborative.You enjoy partnering with people and have excellent project management skills and follow through\\n\\n* Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations\\n\\n\\n\\n\\nCompensation and Benefit\\n\\n\\n* Contract position with a collaborative team\\n\\n* Ability to work remotely with flexible hours&nbsp;\\n\\n* Access to all available course curriculum for personal use\\n\\n* Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry\\n\\n* At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\n\\n\\n\\n\\nApply Here:\\n\\nhttps://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_MB6GpF6S1evdfbpKztX3g",
    "url": "http://workinstartups.com/job-board/job/83539/aimachine-learning-lead-at-digitalbridge/",
    "title": "AI/Machine Learning Lead",
    "tags": [
      "DBG:surround``OR(employe,develop,engin) 4W 4N(OR(&quot;not&quot;,no,doesn't),matter,OR(countri,locat,live,resid))",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/56",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:layout/frontend/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=1, bigdata-ml=84, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=6}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalBridge",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 19, 2019 2:27:22 PM",
    "validThrough": "Aug 26, 2019 2:27:22 PM",
    "crawled": "Aug 19, 2019 4:06:32 PM",
    "content": "<section class=&quot;section section--text&quot;><br /><p>DigitalBridge is seeking a lead for the AI/Machine Learning team to lead the company&rsquo;s research and development efforts. At DigitalBridge, we are developing a platform that guides consumers in developing beautiful living spaces, no matter how little design experience they have. We are using cutting-edge computer vision and machine learning technology to enhance our software and make it as smart as possible. We are active in the area of recommendation systems, optimisation for layout planning and computer vision for scene understanding.</p><br /><p>The role includes a mixture of people management and tech lead responsibilities. We are looking for someone who has experience managing small teams in a fast-paced environment. At the same time, we are looking for someone who has deep technical knowledge of machine learning and computer vision techniques and is able to give direction as well as guidance.</p><br /></section><br /><section class=&quot;section section--text&quot;><br /><p><strong>What does the opportunity look like day-to-day?</strong></p><br /><ul><br /><li>Align the business&rsquo;s R&amp;D efforts with business and product objectives.</li><br /><li>Management of the research team to define and deliver research objectives.</li><br /><li>Deliver robust, working technology that solves computer vision and machine learning problems.</li><br /><li>Represent the company&rsquo;s technological development to external clients and the public.</li><br /></ul><br /><p><strong>What you will bring to the team:</strong></p><br /><ul><br /><li>PhD in an area related to computer vision and machine learning.</li><br /><li>Proven background in developing and productising robust solutions to computer vision and machine learning problems.</li><br /><li>Deep knowledge in deep learning and convolutional neural networks.</li><br /><li>Some experience in leading a machine learning/computer vision team.</li><br /><li>Some experience with Python and/or C++.</li><br /><li>Excellent verbal and written communication skills.</li><br /><li>A positive attitude, self-motivation and strive to improve constantly.</li><br /></ul><br /><p><strong>It would be great if you also have:</strong></p><br /><ul><br /><li>Experience in presenting your work to a large audience.</li><br /><li>Experience in writing patents and scientific papers.</li><br /></ul><br /></section><br /><section class=&quot;section section--text&quot;><br /><p><strong>We offer:</strong></p><br /><ul><br /><li>Great offices!</li><br /><li>A relaxed and informal working environment</li><br /><li>Central Manchester location (Manchester Science Park)</li><br /><li>Working with a diverse, talented team</li><br /><li>Competitive Salary</li><br /><li>Open holidays</li><br /><li>Pension scheme</li><br /><li>Health insurance</li><br /><li>Share options</li><br /><li>Flexible working</li><br /><li>Kitchen with free coffee, drinks, cereal and fruit</li><br /><li>Great social activities</li><br /></ul><br /></section>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LbpdJdYcSpmIf8LEc3ycBA",
    "url": "https://jobmote.com/job/62653/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 18, 2019 10:07:27 PM",
    "validThrough": "Aug 21, 2019 10:07:27 PM",
    "crawled": "Aug 19, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SA7Dn9-ZStWwWvXeaYiwuA",
    "url": "https://jobmote.com/job/62652/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 18, 2019 10:07:27 PM",
    "validThrough": "Aug 21, 2019 10:07:27 PM",
    "crawled": "Aug 19, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li></ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience as a Data Scientist</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "NLTuK688TcCRrTSrkpWu1Q",
    "url": "https://jobmote.com/job/62587/remote-data-analyst/",
    "title": "REMOTE Data Analyst",
    "tags": [
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Advance Search",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:33 PM",
    "validThrough": "Aug 20, 2019 10:07:33 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>Our client is a fast growing provider of messaging and commerce solutions for automotive dealers and is looking for passionate and creative developers to join our team to build the next generation of automotive commerce technology. You will work directly with our wonderful development team to support our existing technology and build the future of automotive.</p> <p> </p> <p> <br>This is a full-time position. Very fun work environment with a team that is passionate about learning and delivering great software products. It s important that you fit with the team and culture, as we work closely together on a daily basis.</p> <p> </p> <p> <br>You will use our data set to look for insights that will help make a material impact for our business and our customers. Additionally you will work with other developers and business units to build reports and solve problems by analyzing relevant data and producing actionable insights.</p> <p> </p> <p>We expect to see:</p> <p> </p> <p> </p> <ul><li><ul><li>Understanding of descriptive statistics</li></ul></li></ul><p> </p> <ul><li><ul><li>Understanding of web technologies</li></ul></li></ul><p> </p> <ul><li><ul><li>Data visualization skills</li></ul></li></ul><p> </p> <ul><li><ul><li>Some experience with SQL</li></ul></li></ul><p> </p> <ul><li><ul><li>Experience with R or Python is a big plus</li></ul></li></ul><p> </p> <ul><li><ul><li>Passion for numbers ;)</li></ul></li></ul><p> </p> <p> </p> <p> <br>What we offer</p> <p> </p> <p> </p> <ul><li><ul><li>Work remotely from home</li></ul></li></ul><p> </p> <ul><li><ul><li>Competitive salary</li></ul></li></ul><p> </p> <ul><li><ul><li>Working with a passionate team</li></ul></li></ul><p> </p> <ul><li>Autonomy and responsibility in a fast moving company</li></ul> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ztvkx50iSq-bnjlrh1miLQ",
    "url": "https://jobmote.com/job/62636/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:34 PM",
    "validThrough": "Aug 20, 2019 10:07:34 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IPW0_B_0QBaQFZfH5AiFuw",
    "url": "https://jobmote.com/job/62635/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 10:07:34 PM",
    "validThrough": "Aug 20, 2019 10:07:34 PM",
    "crawled": "Aug 18, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_f7mFbtwTn2GsxWzeV-fYA",
    "url": "https://stackoverflow.com/jobs/284120/data-analyst-amida-technology-solutions?a=1xhFG5jNbocw",
    "title": "Data Analyst at Amida Technology Solutions (Washington, DC) ",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Amida Technology Solutions",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:24 PM",
    "validThrough": "Aug 24, 2019 1:06:24 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Data Analyst</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                    </div>                <div>Company: Amida Technology Solutions | Washington, DC<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                                                        <div>                                    <span>Office Location:</span>                                    <span>Washington, DC.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div>scientist</div>                <h4>Job description</h4>                <div><p>Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact.</p><p>Our team is comprised of creative, forward thinkers who are passionate about using cutting edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high growth environment that values fresh ideas, candid conversations, and authentic teamwork.</p><p>Amida is currently looking for a Data Analyst to join our team in Washington DC or from a remote location within the continental US. In this role you will work across our client engagements, providing expertise in data collection, data analysis, data mapping, data profiling, data mining and data modeling.&nbsp; You will be responsible for inspecting, cleansing, transforming and modeling data and will address issues related to data completeness and quality, as well as contribute to and produce technical and data process documentation.&nbsp;</p><p>What you will be doing:</p><ul><li>Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions</li><li>Apply analytical methodologies and principles to&nbsp;meet client needs.</li><li>Prepare forecast&nbsp;and analyze&nbsp;trends, develops and analyzes metrics, and prepares reports and recommendations related to management.</li><li>You will also be responsible&nbsp;for focusing on&nbsp;business performance, project analysis, internal control, risk assessment, and support of project objectives.</li></ul><p>What we are looking for:</p><ul><li>B.S. and/or M.S. in a quantitative field such as Computer Science, Statistics, or Mathematics</li><li>Minimum 3-5 year of recent professional experience in data science, data mining and/or data analysis</li><li>Experience in data migration to include data mapping and data profiling</li><li>Prior experience working with Healthcare data, or in the Healthcare field</li><li>Ability to conduct data profiling and predictive analysis using a variety of standard tools</li><li>Programming proficiency in a subset of Python</li><li>Experience with data visualization tools and methodologies</li><li>Ability to communicate concisely and effectively with software engineers and clients</li><li>Ability to obtain a Public Trust security clearance</li></ul><p>Preferred Skills</p><ul><li>Exposure to Amazon Web Services (AWS) and cloud-based systems</li><li>Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA)</li><li>Prior experience with metadata management to include meta tagging</li><li>Previous experience working in an Agile Team setting and using Agile management tools such as Jira</li><li>Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods</li></ul>                </div>            <div>        <a href='https://amida.applytojob.com/apply/L0IbEdxyOX/Data-Analyst?source=STCK' rel='nofollow'>                        Apply now        </a></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "E5T566WmT9CagyDiQ7h8qw",
    "url": "https://stackoverflow.com/jobs/282115/data-engineer-activestate-software?a=1wBYUO4wS9PO",
    "title": "Data Engineer at ActiveState Software (Vancouver, BC, Canada) ",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:golang/go/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:maven/java/13",
      "DBG_TECH1:k/t/w:npm/nodejs/5",
      "DBG_TECH1:k/t/w:perl/other/25",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:rubygems/ruby/8",
      "DBG_TECH1:techWeightMap:{python=12, other=25, dotnet=0, c=0, mobile=1, go=16, nodejs=7, bigdata-ml=40, ruby=10, apple=0, java=23, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/West"
    ],
    "tagsNames1": [
      "US Pacific time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "ActiveState Software",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:24 PM",
    "validThrough": "Aug 24, 2019 1:06:24 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Industry: </span>                                        <span>Computer Software, SaaS, Software Development / Engineering</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: ActiveState Software | Vancouver, BC, Canada<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-08:00) Pacific Time </span>                                </div>                                                            <div>                                    <span>Office Location:</span>                                    <span>Vancouver, BC, Canada.</span>                                        <span>Employees can also work full time from this office.</span>                                </div>                                                                                </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>docker</div><div>kafka</div><div>hadoop</div><div>microservices</div>                <h4>Job description</h4>                <div><p>ActiveState Platform - made by developers for developers! We are reinventing build engineering with an on-demand SaaS Platform and CLI tool that lets developers automate the building of any runtime environment using any open source language ecosystem on any platform. In Beta right now, we support Python and Perl and we're hiring to add more languages and packages! We’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!</p><p><strong>This position is open to full-time telecommuters anywhere in North America</strong>. You can also choose to work from our headquarters in beautiful Vancouver, BC.</p><p><strong>This position is open to both junior (including fresh out of school) and senior applicants. The salary for this position will be commensurate with your experience.</strong></p><p><strong>What You’ll be Doing</strong></p><p>As a Data Engineer, you will create and maintain a data processing pipeline to feed our automated build systems with information about various open source languages and package updates. This work includes automating processing of open source package update feeds from language repositories including PyPI (Python), CPAN (Perl), Maven (Java), NPM (JavaScript), RubyGems. You will also be creating web crawlers for eco-systems without well defined APIs.</p><p>Our day to day work practices are centered around GitHub, pull requests, code review, CI for testing, and agile development with Pivotal Tracker as our project management tool. We’re always looking to improve our practices and we expect you to help us to do so.</p><p>We’re a polyglot company building our system using Golang, Python, Elm, Javascript, Perl, Docker, Kubernetes, DCOS, CircleCI, and other modern tools. Quality is as important as speed. We’re building for the long run, so you’ll need to enjoy writing tests and documentation too.</p><p>Our team is scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Highfive for video calls and screen sharing, Pivotal Tracker, and Google Drive.</p><p>We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code.</p><p><strong>What’s in it for You</strong></p><ul><li>Working for a stable and growing company that offers the environment and personal growth potential of a start-up.</li><li>The chance to work with a smart, passionate team of people.</li><li>The chance to work on a project that will change the work lives of developers around the world.</li><li>Competitive salary, bonus, and stock option plan.</li><li>Comprehensive benefits package and health/wellness credit program.</li></ul><p><strong>Requirements</strong></p><ul><li>Experience creating and maintaining complex software systems along with the ability to design non-trivial applications and components from scratch.</li><li>The ability to write clean, well-tested code with clear documentation.</li><li>Deep experience with at least one programming language, and shallow experience with several.</li><li>Excellent written and spoken skills, both technical and non-technical. You’ll need to work closely with your developer teammates, as well as be able to have coherent conversations with people from QA, sales, marketing, and other parts of the company.</li><li>A willingness to engage in the process of defining our work through conversations with product management, other engineering teams, and the rest of the company.</li><li>The ability to help others on the team become better at their jobs through mentoring, thoughtful code reviews, and generally being a team player.</li></ul><p><strong>Assets</strong></p><p>If you have experience with any of the following please make sure to highlight it in your cover letter:</p><ul><li>Data processing technologies, including but not limited to Kafka, Hadoop, Hive, Presto, Luigi, Airflow, Storm, etc.</li><li>Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI.</li><li>Golang code, especially large code bases.</li><li>Microservices and message queues.</li><li>Docker and Kubernetes.</li><li>Perl, Python, Tcl, or Ruby, especially an understanding of their respective language communities and toolchains.</li></ul><p><strong>Working at ActiveState</strong></p><p>ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all of us.</p><p>Our company is a team of 40+ and growing, with 2/3rds of the positions in technical roles&nbsp; including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events.</p><p>Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches.</p><p><a href='https://platform.activestate.com/create-account?utm_source=stackoverflow.com&amp;utm_medium=referral&amp;utm_content=company-page&amp;utm_campaign=create-account' rel='nofollow'>Try out our Platform for free and see for yourself what we are doing!&nbsp;</a></p>                </div>            <div>        <a href='https://grnh.se/9b3144282' rel='nofollow'>                        Apply now        </a></div>            <h4>About ActiveState Software</h4>            <div><p>If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Weekly meals: Friday lunches and Monday breakfasts</span>                            </li>                            <li>                                <span></span>                                <span>Stocked kitchen: snacks, DIY lunch options, drinks and treats!</span>                            </li>                            <li>                                <span></span>                                <span>Healthy Lifestyle credit: for your and our planet's health &amp; wellness</span>                            </li>                            <li>                                <span></span>                                <span>Bonus program: annual bonus, and cash incentives for meeting goals</span>                            </li>                            <li>                                <span></span>                                <span>Benefits package: medical, dental, extended health, vision coverage</span>                            </li>                            <li>                                <span></span>                                <span>Friday games: board games, puzzles, Xbox, poker or whatever you choose</span>                            </li>                            <li>                                <span></span>                                <span>ActiveVentures: fun quarterly staff outings in and around Vancouver</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DzMfw4uUQz-NI2ZQpwKl2A",
    "url": "https://stackoverflow.com/jobs/287205/senior-data-engineer-security-scorecard-we-are?a=1yjOJpmp6XUA",
    "title": "Senior Data Engineer at Security Scorecard - We are revolutionizing the cybersecurity industry  ",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/24",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=6, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Security Scorecard - We are revolutionizing the cybersecurity industry via Source-Code Recruitment Ltd",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Senior Data Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                            </div>                    </div>                <div>Company: Security Scorecard - We are revolutionizing the cybersecurity industry via Source-Code Recruitment Ltd | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-05:00) Eastern Time </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>hadoop</div><div>apache-spark</div><div>scala</div><div>amazon-web-services</div><div>docker</div>                <h4>Job description</h4>                <div><p><strong>Why SecurityScorecard</strong></p><p>SecurityScorecard is revolutionizing the cybersecurity industry with our platform, data, and insights. We’ve built a new category of enterprise software, which enables companies to rate and understand the security risk of any company. Our customers span a variety of sectors and use cases, including compliance, cyber insurance, and vendor risk management. We are proud to be backed by Sequoia, Google Ventures, and Moody's.</p><p>SecurityScorecard is growing tremendously and targeting talent who can contribute to the next phase in our company's development. A successful Scorecarder exemplifies our S(CORE) values: Solutions Focused, Customer Centric, operate as One Team, Resilience and Embody #SecurityDNA. Your interest in making an impact in our organization and alignment with these values are as important as your skills.</p><p><strong>Opportunity</strong></p><p>The Senior Data Analytics Engineer will build meaningful analytics that inform companies of security risk. You will be working closely with our Data Science team, implementing algorithms and managing the analytic pipeline. We have over 1 PB of data, so the ideal candidate will have experience processing and querying large amounts of data.</p><p>We prefer this person to work from our NYC headquarters, but will consider remote applicants in other geographic areas.</p><p><strong>Responsibilities:</strong></p><ul><li>Manage the analytic pipeline using Spark, Hadoop, etc.</li><li>Leverage cutting-edge technologies to support new and existing and services and processes.</li><li>Quickly and efficiently design and implement in an agile environment</li><li>Work with other team members to implement consistent architecture</li><li>Drive projects through all stages of development</li><li>Actively share knowledge and responsibility with other team members and teams</li><li>Improve the effective output of the engineering team by managing quality, and identifying inconsistencies.</li></ul><p><strong>Requirements:</strong></p><ul><li>Bachelor's degree (CS, EE or Math preferred) or equivalent work experience as well as interest in a fast paced, complex environment.</li><li>5+ years of experience Scala or another functional language experience in a commercial environment (highly preferred)</li><li>3+ Experience with Spark, and the Hadoop ecosystem and similar frameworks</li><li>Familiarity with various tools such as AWS and Docker and an instinct for automation</li><li>Expert in SQL</li><li>Strong understanding of Software Architecture principles and patterns.</li><li>Experience working with 3rd party software and libraries, including open source</li><li>Experience with Postgres</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/287205?reset=False&amp;ra=1yjOJpmp6XUA&amp;oqs=a%3D1yjOJpmp6XUA' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Security Scorecard - We are revolutionizing the cybersecurity industry</h4>            <div><p>SecurityScorecard is revolutionizing the cybersecurity industry with our platform, data, and insights. We’ve built a new category of enterprise software, which enables companies to rate and understand the security risk of any company. Our customers span a variety of sectors and use cases, including compliance, cyber insurance, and vendor risk management. We are proud to be backed by Sequoia, Google Ventures, and Moody's.</p><p>SecurityScorecard is growing tremendously and targeting talent who can contribute to the next phase in our company's development. A successful Scorecarder exemplifies our S(CORE) values: Solutions Focused, Customer Centric, operate as One Team, Resilience and Embody #SecurityDNA. Your interest in making an impact in our organization and alignment with these values are as important as your skills.</p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "I5_DbnA0Q_CW89QszCFLtA",
    "url": "https://stackoverflow.com/jobs/283906/sr-software-engineer-rho-ai?a=1xddNx0BcRuU",
    "title": "Sr. Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/20",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=60, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>Sr. Software Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Data Science, Software Development / Engineering</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Rho AI | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT-06:00) Central Time +/- 2 hours</span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div></div><div>python</div><div>single-page-application</div><div>sql</div><div>nosql</div><div>docker</div>                <h4>Job description</h4>                <div><p>Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste). We value pragmatic solutions and have cultivated a modern technology stack that combines software development (python microservices, react frontends), infrastructure automation (docker, kubernetes), and machine learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p><p>As a member of the software engineering team, you will:</p><ul><li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li><li>Join a group of talented and congenial team members in an experienced individual contributor role (mix of architecting / building / mentoring), with future people management opportunities (if you like).</li><li>Lead engineering projects by collaborating with team members and customers, facilitating technology architecture decisions, driving forward work streams, and releasing high quality software.</li><li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li></ul><p><strong>You have</strong>:</p><ul><li>(Must) Been the tech lead of a project that uses a Python based stack.</li><li>(Must) Good communication skills for technical and non-technical audiences.</li><li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li><li>(Must) Worked on all layers of the stack - databases, services, and frontends.</li><li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li><li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li><li>(Should) Have experience working within a microservices oriented architecture.</li><li>(Nice) Built systems that process large amounts of data and/or traffic.</li><li>(Nice) Strong computer science principles, and/or algorithmic skills.</li><li>(Nice) Experience with machine learning applications.</li></ul><p><strong>You meet these criteria</strong>:</p><ul><li>You are seeking a full-time job.</li><li>You reside in the United States.</li><li>You are&nbsp;authorized / eligible to work for any company in the United States.</li><li>You are in a continental US time zone, or willing to align your schedule.</li></ul><p><strong>To get an interview, you must supply:<br></strong></p><ul><li>A cover letter that explains why you are 1)&nbsp;<em>specifically interested</em>&nbsp;in Rho AI as a company and 2) a&nbsp;<em>good fit</em>&nbsp;for this particular position.</li><li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/283906?reset=False&amp;ra=1xddNx0BcRuU&amp;oqs=a%3D1xddNx0BcRuU' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Rho AI</h4>            <div><p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p><p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p><p><strong>Work at Rho AI</strong></p><p>At Rho AI, you will work with a talented group of data scientists, engineers and thought leaders&nbsp;to harness the power of data science to propel projects with a positive world impact. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p><p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Work from anywhere in the world with flexible work schedules.</span>                            </li>                            <li>                                <span></span>                                <span>Health insurance &amp; FSA accounts</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salaries along with 401k</span>                            </li>                            <li>                                <span></span>                                <span>4 weeks of PTO</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "h_U7GMkmSzaN72n8Pe2Faw",
    "url": "https://stackoverflow.com/jobs/159704/remote-sr-big-data-openings-aws-hadoop-python-surge?a=RyHKuqqkVIQ",
    "title": "REMOTE Sr. Big Data Openings- AWS, Hadoop, Python at Surge  ",
    "tags": [
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:less/frontend/5",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=5}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Surge",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 17, 2019 1:06:25 PM",
    "validThrough": "Aug 24, 2019 1:06:25 PM",
    "crawled": "Aug 17, 2019 1:06:25 PM",
    "content": "<h3><span>REMOTE Sr. Big Data Openings- AWS, Hadoop, Python</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Software Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Surge | No office location<br></div><h4>Technologies</h4><div></div><div>data-analysis</div><div>python</div><div>apache-spark</div><div>amazon-web-services</div><div>bigdata</div>                <h4>Job description</h4>                <div><p>SURGE is looking for smart, self-motivated, experienced, senior automated test engineers&nbsp;who enjoy the freedom of telecommuting and flexible schedules, to work as long-term, consistent&nbsp;(40 hrs/week) independent contractors (no W2)&nbsp;on a variety of software development projects.</p><p>Experience Required:&nbsp;</p><p>Senior Big Data, Data Analysis and Data Science Openings</p><p><strong>Must be located in the US or Canada to be considered for this role. Sorry, No Visas.</strong></p><p>For immediate consideration, email resume with tech stack under each job and include your full name, cell phone number, email address and start date to: <a href='mailto:jobs@surgeforward.com' rel='nofollow'>jobs@surgeforward.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/159704?reset=False&amp;ra=RyHKuqqkVIQ&amp;oqs=a%3DRyHKuqqkVIQ' rel='nofollow'>Apply now</a></div>            <h4>About Surge</h4>            <div><p>Surge is an onshore provider of custom web, cloud, mobile, digital, and desktop software development and consulting services to clients in every industry, from hot startups to Fortune 500 companies.<br><br>Founded in 2007, and listed on the Inc. 5000 list of America’s fastest growing companies for five straight years, Surge has successfully delivered hundreds of software products, apps, and solutions to its clients using a proven agile/scrum development process combined with an elite group of North American software professionals.<br><br>Simply put, Surge offers America’s best software engineers, on demand, at rates 30-50% less than the competition.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Great Pay</span>                            </li>                            <li>                                <span></span>                                <span>Choose Your Hours</span>                            </li>                            <li>                                <span></span>                                <span>Work From Home</span>                            </li>                            <li>                                <span></span>                                <span>Work With Happy People</span>                            </li>                            <li>                                <span></span>                                <span>Zero Commute</span>                            </li>                            <li>                                <span></span>                                <span>See Your Family More</span>                            </li>                            <li>                                <span></span>                                <span>Travel While You Work</span>                            </li>                            <li>                                <span></span>                                <span>Software Provided</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "PWI0a0ffRSSVR2csuuQsOw",
    "url": "https://jobmote.com/job/62494/senior-data-etl-engineer-remote/",
    "title": "Senior Data ETL Engineer - Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:jersey/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>SQL, AWS, ETL<br><br>We are one of the most successful technology start-ups in the Philadelphia/New Jersey region....and we've only just BEGUN! We have a lean team that executes like a big company. We allow our customers to distribute branded consumer-facing native mobile and web apps focused on home search and collaboration. <br><br>We power data and services for our customers that fuel their real estate operations. Our app powers many of the most significant players in the real estate industry in North America, including leading franchisers and independent real estate firms representing over 3,000 brokerage companies and hundreds of thousands of individual agents.<br><br>We need a Senior ETL Data Engineer to help us transform how consumers interact with real estate data.<br><br>What You Will Be Doing<br><br>- Recommend and implement data processing tools and technologies<br>- Extract, transform and load data pipelines from end to end<br>- Identify and fix &quot; data bugs&quot; and improve overall quality of info<br>- Create, develop and document data mapping rules from multiple sources<br>- Develop continuous process movements<br><br>What You Need for this Position<br><br>- 5+ yrs experience<br>- ETL<br>- SQL / PostgreSQL<br>- AWS<br>- BSCS or related degree<br><br>What's In It for You<br><br>- Competitive Pay<br>- FULL REMOTE!So if you are a Senior Data ETL Engineer with relevant experience, please apply today! Interviews are occurring this week!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O33bqfH4Tt2ngOXxrahqhg",
    "url": "https://jobmote.com/job/62489/data-scientist-remote/",
    "title": "Data Scientist - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:css/frontend/6",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=2, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>DOMO, R, SQL, JavaScript, CSS, HTML, Python<br><br>If you are a Data Scientist - Remote with experience, please read on!<br><br>What You Will Be Doing<br><br>You will be responsible for helping digital businesses succeed by introducing them to BI insights that they can rely on:<br>- You will use pre-built API connections, SQL, and Domo's other ETL tools to access various databases and prepare data to be imported into Domo<br>- Develop and manage client CRM portfolios <br>- Analyze customer data to improve customer experience <br>- Assist in the preparation of sales forecasts, quotes or negotiations<br><br>What You Need for this Position<br><br>At Least 2 Years of experience and knowledge of:<br><br>- Domo**<br>- Data Analysis <br>- Data Science <br>- KPI Creation <br>- Python, R, JavaScript, HTML, and CSS<br>- API, SQL and other ETL tools<br><br>What's In It for You<br><br>- Competitive pay <br>- Flexible Schedule <br>- FULLY REMOTE*So, if you are a Data Scientist - Remote with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-eccFMG1QMmkqEOw11N8Iw",
    "url": "https://jobmote.com/job/62472/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "VjF8uLQCSuqsWmcPYGnlFA",
    "url": "https://jobmote.com/job/62465/nlu-nlp-architect-or-engineer-remote/",
    "title": "NLU NLP Architect or Engineer REMOTE",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Collabera",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Position/REQ ID: ? NLP Architect <br>Location: RTP or SJ areas, can be remote <br>Duration: 11 Months <br>? <br>MUST HAVES <br>Strong knowledge of the Machine Learning techniques around natural language<br>Experience implementing enterprise scale NLU based IVR solution(s).<br>Strong knowledge IVR based application development and Conversational IVR.<br>Experience in Dialogflow OR other NLP engine models such as<br>Good knowledge on building conversational IVR (Interactive Voice Response) flows using Dialog flow<br>Experience with machine learning techniques within NLP such as tokenization, parts of speech tagging, stemming, lemmatization, named entity recognition, sentiment analysis, TF-IDF, topic modeling, bag of words, word vectors, language modeling, seq2seq, LSTMs, Transformers <br>? <br>PLUSSES <br>Programming experience in Node JS, Python, SQL, NoSQL, Java, Graph Databases a plus<br>Strong knowledge of applicable methodologies, tools, standards, and procedures.<br>Experience in Big Data platform handling large volumes of data and have experience in data processing and storage. <br>DAY-TO-DAY <br>Implement NLU/NLP solutions to extract value from Install Base data.<br>Be the in-house NLP expert, lead NLP initiatives, review the deliverables and set standards and guideline<br>Develop design principle for developing new dialog flows.<br>Help cultivate organization-wide best practices for NLP and Coach and Mentor other members of the team<br>Deconstruct customer-agent conversations to programmatically extract concepts and relationships between concepts in various conversation scenarios.<br>Work with various business lines like? Sales and Marketing to identify opportunities for NLP and recommend them into actionable data science projects.<br>Guide the data engineers to design data pipelines to effectively store, normalize and access text data. <br>?<br><br>NLP,NLU,IVR, Dialogflow<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qltAN9MnTRytFqxPNVMv3A",
    "url": "https://jobmote.com/job/62461/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 10:07:29 PM",
    "validThrough": "Aug 19, 2019 10:07:29 PM",
    "crawled": "Aug 17, 2019 3:06:25 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9DL46nmFSQWSr3miuD9_2Q",
    "url": "https://www.remoteage.com/remote-jobs/senior-software-engineer-385/",
    "title": "Senior Software Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DeepIntent",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 16, 2019 6:21:49 AM",
    "validThrough": "Aug 23, 2019 6:21:49 AM",
    "crawled": "Aug 16, 2019 7:08:25 AM",
    "content": "<h3>            Senior Software Engineer        </h3><div>United States, New York</div><div>Company: DeepIntent<p></p></div><div>                    <h4>Overview</h4>                    <p>Our CompanyDeepIntent is a marketing technology company that helps healthcare brands strengthen communication with patients and healthcare professionals by enabling highly effective and performant digital advertising campaigns. Our healthcare technology platform, MarketMatch™, connects advertisers, data providers, and publishers to operate the first unified, programmatic marketplace for healthcare marketers. The platform’s built-in identity solution matches digital IDs with clinical, behavioral, and contextual data in real-time so marketers can qualify 1.6M+ verified HCPs and 225M+ patients to find their most clinically-relevant audiences, and message them on a one-to-one basis in a privacy compliant way. Healthcare marketers use MarketMatch to plan, activate, and measure digital campaigns in ways that best suit their business, from managed service engagements to technical integration or self-service solutions. DeepIntent was founded by Memorial Sloan Kettering alumni in 2015 and acquired by Propel Media, Inc. in 2017. We proudly serve major pharmaceutical and Fortune 500 companies out of our offices in New York, California, and India. Learn more about what we do on our website; learn about our company and culture on Glassdoor. The TeamDeepIntent’s founding team is composed of data scientists from advertising, healthcare and finance and are still actively involved in R&amp;D projects at the company. Our simple mission: create the next generation of cutting edge analytics for marketers. You will be a core asset in our pursuit of achieving this mission. The Role- Design, develop, test, deploy, maintain and improve our core bidding software.- Work closely with the Data Science, Engineering, and Product teams to implement new algorithms and optimize the code base for speed and performance.- Manage individual project priorities, deadlines and deliverables.- Work with business units on product development. Non-Technical Requirements- An enthusiastic learner who is able to keep up with various technologies.- Strong mathematical and logical skills.- A strong collaborator in small, cross-domain, distributed team environments.- 1-2+ years of advertising experience considered a plus, but not required. Technical Requirements- Bachelor’s degree in Computer Science, similar technical field of study or equivalent practical experience.- 4-7 years of experience in software development- Experience with distributed and parallel systems, developing large software systems.- Experience with one or more general purpose languages including Java, C++.- Interest and ability to learn other coding languages.- Experience performance tuning and writing low latency software.- Experience with cloud computing platforms (AWS and/or Google Cloud Platform)- Machine Learning experience is a plus, but not required.</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?Nr6wnfaWjnnyA08qisOb3As' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ut99_sPnTBmjehM-dZ_yAg",
    "url": "https://jobmote.com/job/62289/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 10:07:38 PM",
    "validThrough": "Aug 18, 2019 10:07:38 PM",
    "crawled": "Aug 16, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ps907LhhSdWlc2MBh-gZOg",
    "url": "https://jobmote.com/job/62288/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 10:07:38 PM",
    "validThrough": "Aug 18, 2019 10:07:38 PM",
    "crawled": "Aug 16, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "h6NoVN0HR3yexBvEs3nsbw",
    "url": "https://www.remoteage.com/remote-jobs/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 5:34:44 PM",
    "validThrough": "Aug 22, 2019 5:34:44 PM",
    "crawled": "Aug 15, 2019 6:23:53 PM",
    "content": "<h3>            Data Lead Software Developer-remote considered        </h3><div>United States, Connecticut</div><div>Company: Travelers Insurance<p></p></div><div>                    <h4>Overview</h4>                    <p>Company Information<br>Solid reputation, passionate people and endless opportunities. That’s Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers – and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.</p><p>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.</p><p>Primary Job Duties &amp; Responsibilities</p><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li><li>Analyze latest Big Data Analytic technologies and their innovative applications in both business intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li><li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li><li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li><li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li><li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li><li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li><li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li><li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li><li>This position is open for candidates to work remotely.</li></ul><p>Minimum Qualifications<br>A bachelor’s degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.</p><p>Education, Work Experience &amp; Knowledge</p><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li><li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (e.g. Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li><li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li><li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li><li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li><li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li><li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li><li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li><li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li><li>Experience building microservices and real-time APIs</li><li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li><li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li><li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li><li>Experience with BI tools and reporting software (e.g. Microstrategy, Cognos, Tableau etc.)</li><li>Agile project management experience, including use of agile project management tools (i.e. JIRA, Git, etc.)</li><li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li><li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li><li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li><li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li><li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li><li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li><li>Advanced IT process improvement, and problem-solving skills</li><li>Comfortable presenting to senior management</li></ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others’ views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th</p><p>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.</p><p>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.</p><p>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe</p><p>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br>To apply for this position please <b>CLICK HERE</b> </p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?isOoGJzBLh3T%2fZh8sJuFCgm' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zfq28vo9Th6OnSETshh84w",
    "url": "https://jobmote.com/job/62024/software-engineering-manager-work-from-home/",
    "title": "Software Engineering Manager (Work From Home)",
    "tags": [
      "DBG:surround``work 2W from 2W home 4W OR(staff,cowork,offic,posit)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:dotnet/dotnet/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/8",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=8, c=13, mobile=1, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "Kforce Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 15, 2019 12:21:16 PM",
    "validThrough": "Aug 18, 2019 12:21:16 PM",
    "crawled": "Aug 15, 2019 5:06:26 PM",
    "content": "<div>Kforce has been retained by one of our digital and software solutions clients based in Reston, Virginia (VA) to assist them in hiring a Software Engineering Manager to joint their team. This is a full-time, salaried position with a competitive base salary and a comprehensive benefits package. It is also a Work from Home/Remote position given the dispersed locations of their engineering, product and leadership teams.Summary:Reporting directly into the CIO, this Engineering Manager will direct a team that is responsible for development and enhancement of their flagship product that leverages social technology, artificial intelligence and real-time analytics to provide solutions to their customers.<br><br>* The ideal candidate will have prior experience as a developer<br><br>* Current experience as a manager<br><br>* Experience delivering customer-facing, commercial, enterprise software products to a B2B audience<br><br>* Well-rounded SDLC expertise in an Agile environment<br><br>Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.*Compensation Type:*Years <br> Associated topics: .net, application, c c++, develop, devops, java, matlab, perl, software engineer, software programmer</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GIx3rOKUTUKFG2yUEAw2aw",
    "url": "http://workinstartups.com/job-board/job/82589/data-analyst-manager-at-hubble/",
    "title": "Data Analyst Manager",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hubble",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 1:35:01 PM",
    "validThrough": "Jul 29, 2019 1:35:01 PM",
    "crawled": "Aug 15, 2019 2:06:34 PM",
    "content": "<p><strong>DESCRIPTION </strong></p><br /><p>Hubble is the UK&rsquo;s leading PropTech scale up; changing the face of commercial property. Our mission is to find the perfect home for every company and we&rsquo;ve built an online platform to help businesses rent, manage and share office space in London. We&rsquo;ve raised over &pound;6m in venture funding from the most respected investors in technology and real estate to make this mission a reality.</p><br /><p>As a Data Analyst you will be working closely with Data Science, Engineering and Business Operations to support all teams with day to day reporting, problem solving and using data to provide key company insights. You will work across a range of areas such as our acquisition strategies, product funnels, supply and demand dynamics, sales performance and more.</p><br /><p><strong>RESPONSIBILITIES </strong></p><br /><ul><br /><li>Own the data request process from prioritisation through to delivery.</li><br /><li>Support all departments through report creation, ad-hoc data analysis and providing key business insights and solutions.</li><br /><li>Empower all teams with the right tools to understand the data and make decisions quickly</li><br /><li>End-to-end ownership of data quality in our core datasets and data pipelines.</li><br /><li>Experiment with new tools and technologies to meet business requirements regarding performance, scaling, and data quality.</li><br /><li>Work on automating key areas of data for scale</li><br /></ul><br /><p><strong>REQUIREMENTS</strong></p><br /><ul><br /><li>Strong SQL knowledge and experience. You will need to comfortably create multiple complex queries from scratch, have knowledge of databases, Vlookups, Pivot tables, advanced Excel</li><br /><li>Excellent problem solving skills - ability to see beyond the numbers and think logically. You should have commercial understanding to come up with appropriate solutions for key areas in the business.</li><br /><li>Previous experience in a similar role, ideally in a startup environment</li><br /><li>Experience solving real problems using data analysis techniques and statistical rigour.</li><br /><li>Excellent communication skills; the ability to convey complex analysis results clearly.</li><br /></ul><br /><h3><strong>PROGRESSION</strong></h3><br /><ul><br /><li>We give an incredible amount of opportunity to take ownership and autonomy</li><br /><li>If you do well, there are opportunities to expand your role and be involved with data science and how we grow our product</li><br /><li>You will have the opportunity to learn new languages such as Python and R.</li><br /></ul><br /><p><strong>BENEFITS </strong></p><br /><p>We make sure everyone in the team is comfortable and has the best environment for them. We offer flexible hours, remote working and have a relaxed attitude to taking holiday - focusing only on whether work gets done. Benefits can be tweaked on an individual basis depending on what makes you most productive. Here are some of the things we offer:</p><br /><ul><br /><li>Remuneration competitive with industry and level of experience.</li><br /><li>Macbook, peripherals and standing desk.</li><br /><li>Expense budget &amp; travel.</li><br /><li>Noise-cancelling headphones.</li><br /><li>Spotify Premium or Apple Music.</li><br /><li>Kindle Unlimited + free technical books.</li><br /><li>Health &amp; Pension.</li><br /><li>Cycle to Work scheme.</li><br /></ul><br /><p>We truly value our people and company culture. Want to know more about why Hubble is a great place to work? Check out this<a href='https://workable.com/nr?l=https%3A%2F%2Fhubblehq.com%2Fblog%2Fhubble-best-places-to-work' rel='nofollow noreferrer noopener'>&nbsp;recent blog post</a>.</p><br /><p>Hubble is an equal opportunities employer. We are a diverse bunch of people who are committed to maintaining a welcoming culture of inclusion and equality. We encourage applications from anyone that meets the requirements for the role.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ncH4ZTBZRqmfNZqIM14rqw",
    "url": "https://jobmote.com/job/61006/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:33 PM",
    "validThrough": "Aug 17, 2019 10:07:33 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ing20FV-RI6BUQBtJ9liGg",
    "url": "https://jobmote.com/job/61041/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ADLoDrTjRtGaZTrb0RgdpA",
    "url": "https://jobmote.com/job/61040/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; </p><p>If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p><strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Bu19rQqKSSKMqTuK3qlVeg",
    "url": "https://jobmote.com/job/61027/sap-data-analyst-consultant-remote/",
    "title": "SAP Data Analyst - Consultant (REMOTE)",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "RPartners",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:07:34 PM",
    "validThrough": "Aug 17, 2019 10:07:34 PM",
    "crawled": "Aug 15, 2019 3:06:25 AM",
    "content": "<div><p> <strong>SAP Data Analyst / Architect</strong></p> <p> <strong>REMOTE / WORK FROM HOME / TELECOMMUTE options available</strong></p> <p>Our client has a product that allows their customers to access business-critical data that may be stored in many systems. Their product allows the customer to connect and combine from all of their systems into the product and have delivered, actionable, insights within seconds.</p> <p> </p> <p>They are currently starting a new initiative that entails a large scale extraction and migration of customer data that currently resides within an SAP ECC 6.0 running on DB2.</p> <p> </p> <p>This initiative has generated the need for Sr. Data Analysts / Architects with experience supporting the extraction and migration of data from an ECC 6.0 / DB2 environment.</p> <p> </p> <p>Strong experience with SAP LT Replication, ABAP and SAP Data Services (BODS) is required. Experience supporting Logistics / Distribution / Operations modules within ECC is a plus.</p> <p> </p> <p>Excellent communication skills and the ability to effectively bridge the layer between the end customers data structure(s) resident within ECC / DB2 and the Clients Development teams is critical.</p> <p> </p> <p>This is projected to be a 3-6 month initiative with the strong possibility of follow-on extension as the project scope increases.</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DHiIMxn1TeGM6uT5WDzJMg",
    "url": "https://remoteok.io/jobs/74510",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Catch Co.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 11:52:43 PM",
    "validThrough": "Aug 21, 2019 11:52:43 PM",
    "crawled": "Aug 15, 2019 12:06:30 AM",
    "content": "<span></span> <span><h4>Catch Co.</h4></span> <br> <h3>Data Engineer</h3> <span></span> <br> <span>US-only</span> <div>  <div>   **Position Overview:**\\n\\n\\nThe Catch Company is looking for a Data Engineer to support our Analytics team. The Analytics team is looking to grow and improve our analytics tech stack to enable smarter and faster business decisions, automated processes, and personalized customer experiences.\\n\\nIn this role, you will own the development and maintenance of our analytics tech stack and will be instrumental in identifying and implementing new technologies and tools to support our goals. While we already have a robust analytics / business intelligence ecosystem in place, we believe the right Data Engineer can push our team to become industry leaders in enabling smarter decision-making and personalizing our customer experience via new technologies and approaches. Our current tech stack includes: Redshift (warehouse), Fivetran/Stitch Data/custom pipelines (ETL), dbt (transformation), Looker (visualization), and a variety of other services that support one-off tools (e.g., Jupyter notebooks, Amazon EC2, etc.).\\n\\nAdditionally, we welcome both local (Chicago) and remote candidates for this role! Our analytics team is partially remote and our engineering team is fully remote.\\n\\n\\n**What makes this a special opportunity:**\\n\\nYou will have broad freedom to change and improve the way we do things as the only Data Engineer on the team\\nYou will have the opportunity to be a thought leader when it comes to selecting new technologies; you will be responsible for identifying and implementing new tools and technologies\\nYou will work with people who are eager to use data to improve our product offerings, our customer experience, and other key components of the business\\nWe place a premium on building a great culture made up of great people\\nYou will work with and learn from experienced leaders who have a track record of building successful companies\\nWe are based in Chicago’s West Loop (one of the best restaurant neighborhoods in the world), with easy access to all major public transportation systems\\n\\n\\n**Benefits:**\\n\\n&quot;Take what you need&quot; PTO Policy\\n4 additional paid days off specifically to enjoy the outdoors\\nFlexible working schedule\\nAbility to work from home if there is a need\\nMedical, Dental and Vision Insurance - We cover 85% of your premium and 50% for dependents\\nHealth Savings Account\\n401(K) plan\\nPre-Tax Commuter Benefits\\nUnlimited fruit snacks\\n\\n# Responsibilities\\n **What you will do:**\\n\\nOwn the maintenance and development of our analytics tech stack, including identifying and implementing new tools, managing utilization, and improving performance\\nModel and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it\\nRe-structure our processes for ingesting and analyzing website event data to a) Capture more usable, relevant data and b) Use technologies like Spark that allow for faster data transformation\\nBuild custom data pipelines that reliably provide clean, ready-to-analyze data and develop systems that monitor those pipelines to ensure their health\\nWork closely with our software engineers to identify new opportunities for data collection (with a focus on personalization/recommendation systems) and build the processes to make that data available in our data warehouse\\nIdentify use cases for real-time/streaming analytics and select and implement tools to support those use cases\\nResearch and surface new ideas and approaches, whether new technologies, tools, frameworks, or process improvements for the team \\n\\n# Requirements\\n**What experience you need:**\\n\\nExperience working in data engineering, data architecture, or another similar field\\nExtensive experience manipulating data using SQL\\nExperience using Git to version/manage code\\nFluency in one or more programming languages such as Python, Java, Go, etc.\\nExperience working with relational databases/data warehouses\\nFamiliarity with ETL tools\\nFamiliarity with business intelligence/visualization tools\\n[Optional/Preferred]: Experience building custom data pipelines\\n[Optional/Preferred]: Experience structuring and analyzing high volumes of website event data (e.g., impressions, views, clicks, etc.)\\nYou must be eligible to work in the United States; visa sponsorship is not available\\n\\n**What will make you successful:**\\n\\nCuriosity: Always seeking to understand “why”, always looking to make things better.\\nPassion: You are driven by a love for what you do\\nOptimism: The ability to bounce back quickly when something doesn’t work\\nAction: Knowing when to shift from planning to doing\\nHonesty: Transparency with customers, partners and teammates\\nEntrepreneurial spirit\\nData-driven mindset\\nAn interest in / passion for the outdoors (fishing knowledge not required!)\\n \\n\\n#Location\\n- US-only   <br>  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "3clwT_bPSp-ihMD6vbjEWQ",
    "url": "https://weworkremotely.com/remote-jobs/creative-commons-data-engineer",
    "title": "Creative Commons: Data Engineer",
    "tags": [
      "DBG:surround``2N(remot,work) 3W OR(encourag, avail, environ)",
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``OR(pacif, pst, pdt, western, california, losangel, sanfrancisco, paloalto, sanmateo) 3W OR(time,timezon)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=44, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "50% remote",
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Creative Commons",
      "sameAs": "https://creativecommons.org/"
    },
    "salary": {
      "currency": "USD",
      "minValue": 80000,
      "maxValue": 100000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 80k - 100k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 10:04:25 PM",
    "validThrough": "Aug 21, 2019 10:04:25 PM",
    "crawled": "Aug 14, 2019 10:30:23 PM",
    "content": "<h3> Data Engineer </h3><div><div><b><span>About this position</span></b></div><div><br></div><div><span>Creative Commons is building a “front door” to the growing universe of openly licensed and public domain content through </span><a href='https://search.creativecommons.org/' rel='nofollow'><span>CC Search</span></a><span> and the </span><a href='https://api.creativecommons.engineering/' rel='nofollow'><span>CC Catalog API</span></a><span>. The Data Engineer reports to the Director of Engineering and is responsible for </span><a href='https://github.com/creativecommons/cccatalog' rel='nofollow'><span>CC Catalog</span></a><span>, the open source catalog that powers those products. This project will unite billions of records for openly-licensed and public domain works and metadata, across multiple platforms, diverse media types, and a variety of user communities and partners.</span></div><div><br></div><div><b><span>Primary responsibilities</span></b></div><div><br></div><ul><li><span>Architect, build, and maintain the existing CC Catalog, including:</span><br><br></li><li><span>Ingesting content from new and existing sources of CC-licensed and public domain works.</span><br><br></li><li><span>Scaling the catalog to support billions of records and various media types.</span><br><br></li><li><span>Implementing resilient, distributed data solutions that operate robustly at web scale.</span><br><br></li><li><span>Automating data pipelines and workflows.</span><br><br></li><li><span>Collaborating with the Backend Software Engineer and Front End Engineer to support the smooth operation of the CC Catalog API and CC Search.</span><br><br></li></ul><div><li></li></div><div><span>Augment and improve the metadata associated with content indexed into the catalog using one or more of the following: machine learning, computer vision, OCR, data analysis, web crawling/scraping.</span></div><div><br></div><div><li></li></div><div><span>Build an open source community around the CC Catalog, including:</span></div><div><br></div><ul><li><span>Restructuring the code and workflows such that it allows community contributors to identify new sources of content and add new data to the catalog.</span><br><br></li><li><span>Guiding new contributors and potentially participating in projects such as Google Summer of Code as a mentor.</span><br><br></li><li><span>Writing blog posts, maintaining documentation, reviewing pull requests, and responding to issues from the community.</span><br><br></li></ul><div><li></li></div><div><span>Collaborate with other outside communities, companies, and institutions to further Creative Commons’ mission.</span></div><div><br></div><div><b><span>Qualifications and requirements</span></b></div><div><br></div><ul><li><span>Demonstrated experience building and deploying large scale data services, including database design and modeling, ETL processing, and performance optimization</span><br><br></li><li><span>Proficiency with Python</span><br><br></li><li><span>Proficiency with Apache Spark</span><br><br></li><li><span>Experience with cloud computing platforms such as AWS</span><br><br></li><li><span>Experience with Apache Airflow or other workflow management software</span><br><br></li><li><span>Experience with machine learning or interest in picking it up</span><br><br></li><li><span>Fluent in English</span><br><br></li><li><span>Excellent written and verbal communication skills</span><br><br></li><li><span>Ability to work independently, build good working relationships and actively communicate, contribute, and speak up in a remote work structure</span><br><br></li><li><span>Curiosity and a desire to keep learning</span><br><br></li><li><span>Commitment to consumer privacy and security</span><br><br></li><li><span>Nice to have (but not required):</span><br><br></li><li><span>Experience with contributing to or maintaining open source software</span><br><br></li><li><span>Experience with web crawling</span><br><br></li><li><span>Experience with Docker</span><br></li></ul><div><br></div><div><b><span>Diversity &amp; inclusion</span></b></div><div><br></div><div><span>We believe that diverse teams build better organizations and better services. Applications from qualified candidates from all backgrounds, including those from under-represented communities, are very welcome. Creative Commons works openly as part of a global community, guided by collaboratively developed codes of conduct and anti-harassment policies.</span></div><div><b><br></b></div><div><b><span>Work environment and location</span></b></div><div><br></div><div><span>Creative Commons is a fully-distributed organization — we have no central office. This position is available to applicants working in the range of the Eastern to Pacific time zones, in a remote working environment. You must have reasonable mobility for travel to twice-annual all-staff meetings and the CC Global Summit (a total of 3 trips per year). We provide a subsidy towards high-speed broadband access. Laptop/desktop computer and necessary resources are supplied.</span></div><div><br></div><div><b><span>Salary and benefits</span></b></div><div><br></div><div><span>Creative Commons is a leading non-profit employer, offering competitive salaries and benefits, including health and wellness plans, annual retirement contributions, and a positive, supportive work environment. We offer competitive salary in the range for this position from $80,000 to $100,000 USD, </span><span>commensurate with relevant skills, experience, and location.</span></div><div><br></div><div><b><span>How to apply</span></b></div><div><br></div><div><span>Please email your cover letter and resume as a single PDF to “jobs@creativecommons.org” with the subject heading of “Data Engineer / [Last Name].” Phone calls and messages will not be returned.</span></div><div><br></div></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "nr4Ne-_OSgSh1B7RluQeRA",
    "url": "http://workinstartups.com/job-board/job/83435/aiimage-search-at-tba/",
    "title": "AI/Image search",
    "tags": [
      "DBG:surround``OR(locat, base, resid) 3W OR(berlin, london, pari)",
      "DBG:surround``OR(oper,collabor) 2W remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=4, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TBA",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 5:45:20 PM",
    "validThrough": "Aug 21, 2019 5:45:20 PM",
    "crawled": "Aug 14, 2019 7:30:31 PM",
    "content": "<p>*********************************************************************************************************</p><br /><p>No agencies or job seekers.</p><br /><p>Entrepreneurs seeking a developer with experience of image search and machine learning.&nbsp; Innovative and unique brand marketing platform.&nbsp; Working with CEO and CTO (full-stack engineer with 20 years experience) to shape and implement key functionality to showcase to investors. Collaborative, flexible, remote working. Ideally based near London but not essential. Contact us for an exploratory chat.&nbsp;</p><br /><p>Founders: Serial entrepreneurs/tech/marketing/publishing/academic with 25 year track record and over $250m Sales and $5m in Venture Fundraising.&nbsp;</p><br /><p>*********************************************************************************************************</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "viiFpAK4SJuNTN8shtpIdQ",
    "url": "https://www.remotepython.com/jobs/19f9a17c0f8b4e63a84421a1dde5c407/",
    "title": "Machine Learning Scientist at DigitalMR",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:caffe/bigdata-ml/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/24",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:theano/bigdata-ml/8",
      "DBG_TECH1:k/t/w:torch/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=1, go=0, nodejs=0, bigdata-ml=88, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalMR",
      "sameAs": "https://www.digital-mr.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 6:23:57 PM",
    "validThrough": "Aug 21, 2019 6:23:57 PM",
    "crawled": "Aug 14, 2019 6:23:57 PM",
    "content": "<h3>Machine Learning Scientist</h3>London, United Kingdom<br>Company: DigitalMR<br>Job Type:&nbsp;Full-time<div>                              <div>                      </div>                    <p></p><p>Applications are invited for a Machine Learning Scientist who will use existing IP developed and implemented to deliver projects to DigitalMR clients. DigitalMR is a tech company with proprietary solutions for market research. Our young and diverse team uniquely combines the skill-sets of software engineers, data scientists and market researchers.  They create commercial tools and applications that collect data in smart ways, which are then turned into business actionable insights for some of the world’s most demanding clients. We are a growing company that can offer a lot of encouragement and support, looking for the right candidate to join our team.<br><br>DigitalMR is a remote-first company, with team members in various countries around the world. The successful candidate will work remotely. Occasional travel to meet collaborators and client visits may be required.</p><p><strong>Role and Responsibilities</strong></p><ul><li>Implement and evaluate models and software prototypes of machine learning processing</li><li>Train, validate and systematically test algorithms with large text and image data sets</li><li>Meet accuracy targets for sentiment and semantic analysis</li><li>Maintain relationships with relevant external collaborators and realise knowledge transfer</li><li>Work closely with a dynamic team of software engineers and market researchers to realise applications that may include sentiment, emotions, topics, and trends extraction, social propagation, and social influence</li><li>Arrange integration of tested algorithms with the company’s platforms and data systems</li><li>Document system performance and incorporate customer feedback</li><li>Other tasks assigned by the CTO/CEO</li></ul><p><strong>Qualifications, Experience &amp; Skills:</strong></p><ul><li>Masters, PhD, or equivalent experience in a quantitative field (Machine learning, Computer vision, Computer Science, Applied Mathematics, Engineering, etc.)</li><li>Track record in machine learning techniques</li><li>Familiarity with deep learning libraries such as Torch, Theano, Caffe, or PyBrain</li><li>Hands-on experience coding in one of the following: C/C++, Java, Python</li><li>Positive attitude and good interpersonal, communication and teamwork skills; a great fit with the <a href='http://www.digital-mr.com/mission-values' rel='nofollow'>company's values</a></li><li>Ability to solve complex problems in a fast-­paced environment with limited guidance</li></ul><p><strong>Desirable Skills:</strong></p><ul><li>Digital image processing / computer vision experience</li><li>Amazon EC2 familiarity</li><li>­Organisational skills both in management of time and software code in an agile framework.</li><li>Hadoop ecosystem experience</li><li>Methods for learning imbalanced datasets</li></ul><p><strong>The above role offers:</strong></p><ul><li>Employment with an award winning ­growing international company</li><li>Be a key part of very forward-thinking projects in social media analytics</li><li>­Flat structure, no bureaucracy, no red tape</li><li>Competitive salary and performance bonus</li><li>Company share options</li></ul><p></p>                      <h4>Desired Skills</h4>            <ul>                              <li><span>Artificial Intelligence</span></li>                              <li><span>Big Data</span></li>                              <li><span>Data Science</span></li>                              <li><span>Machine Learning</span></li>                          </ul>                                <h4>How to Apply</h4>            <p></p><p>Please send a copy of your CV to recruitment@digital-mr.com and click on the 'Apply' button to fill out a short application form.</p><p></p>                                <h4>Contact Info</h4>            <ul>              <li><strong>Contact Name:</strong> Brathep</li>              <li><strong>Contact Email:</strong> <a href='mailto:recruitment@digital-mr.com' rel='nofollow'>recruitment@digital-mr.com</a></li>              <li><strong>Company Website:</strong> <a href='https://www.digital-mr.com/' rel='nofollow'>https://www.digital-mr.com/</a></li>            </ul>                  </div><a href='https://forms.gle/7WAMhhZcB6kP3pF7A' rel='nofollow'>Apply</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vHwbuyU5S6yw9s3GJNjMeQ",
    "url": "https://weworkremotely.com/remote-jobs/catch-co-data-engineer",
    "title": "Catch Co: Data Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=3, nodejs=0, bigdata-ml=48, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Catch Co",
      "sameAs": "http://www.catchco.com"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 6:22:13 PM",
    "validThrough": "Aug 21, 2019 6:22:13 PM",
    "crawled": "Aug 14, 2019 6:23:04 PM",
    "content": "<h3> Data Engineer </h3><div><div><h4>DESCRIPTION</h4></div><div><strong>Position Overview:</strong><br></div><div>The Catch Company is looking for a Data Engineer to support our Analytics team. The Analytics team is looking to grow and improve our analytics tech stack to enable smarter and faster business decisions, automated processes, and personalized customer experiences.<br></div><div>In this role, you will own the development and maintenance of our analytics tech stack and will be instrumental in identifying and implementing new technologies and tools to support our goals. While we already have a robust analytics / business intelligence ecosystem in place, we believe the right Data Engineer can push our team to become industry leaders in enabling smarter decision-making and personalizing our customer experience via new technologies and approaches. Our current tech stack includes:&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Faws.amazon.com%2Fredshift%2F' rel='nofollow'>Redshift</a>&nbsp;(warehouse),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Ffivetran.com%2F' rel='nofollow'>Fivetran</a>/<a href='https://workable.com/nr?l=https%3A%2F%2Fwww.stitchdata.com%2F' rel='nofollow'>Stitch Data</a>/custom pipelines (ETL),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Fwww.getdbt.com%2F' rel='nofollow'>dbt</a>&nbsp;(transformation),&nbsp;<a href='https://workable.com/nr?l=https%3A%2F%2Flooker.com%2F' rel='nofollow'>Looker</a>&nbsp;(visualization), and a variety of other services that support one-off tools (e.g., Jupyter notebooks, Amazon EC2, etc.).<br></div><div>Additionally, we welcome both local (Chicago) and remote candidates for this role! Our analytics team is partially remote and our engineering team is fully remote.</div><div><br></div><div><strong>What makes this a special opportunity:</strong><br></div><ul><li>You will have broad freedom to change and improve the way we do things as the only Data Engineer on the team</li><li>You will have the opportunity to be a thought leader when it comes to selecting new technologies; you will be responsible for identifying and implementing new tools and technologies</li><li>You will work with people who are eager to use data to improve our product offerings, our customer experience, and other key components of the business</li><li>We place a premium on building a great culture made up of great people</li><li>You will work with and learn from experienced leaders who have a track record of building successful companies</li><li>We are based in Chicago’s West Loop (one of the best restaurant neighborhoods in the world), with easy access to all major public transportation systems</li></ul><div><span><br></span></div><div><strong>What you will do:</strong><br></div><ul><li>Own the maintenance and development of our analytics tech stack, including identifying and implementing new tools, managing utilization, and improving performance</li><li>Model and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it</li><li>Re-structure our processes for ingesting and analyzing website event data to a) Capture more usable, relevant data and b) Use technologies like Spark that allow for faster data transformation</li><li>Build custom data pipelines that reliably provide clean, ready-to-analyze data and develop systems that monitor those pipelines to ensure their health</li><li>Work closely with our software engineers to identify new opportunities for data collection (with a focus on personalization/recommendation systems) and build the processes to make that data available in our data warehouse</li><li>Identify use cases for real-time/streaming analytics and select and implement tools to support those use cases</li><li>Research and surface new ideas and approaches, whether new technologies, tools, frameworks, or process improvements for the team</li></ul><div><h4>REQUIREMENTS</h4></div><div><strong>What experience you need:</strong><br></div><ul><li>Experience working in data engineering, data architecture, or another similar field</li><li>Extensive experience manipulating data using SQL</li><li>Experience using Git to version/manage code</li><li>Fluency in one or more programming languages such as Python, Java, Go, etc.</li><li>Experience working with relational databases/data warehouses</li><li>Familiarity with ETL tools</li><li>Familiarity with business intelligence/visualization tools</li><li>[Optional/Preferred]: Experience building custom data pipelines</li><li>[Optional/Preferred]: Experience structuring and analyzing high volumes of website event data (e.g., impressions, views, clicks, etc.)</li><li>You must be eligible to work in the United States; visa sponsorship is not available</li></ul><div><span><br></span></div><div><strong>What will make you successful:</strong><br></div><ul><li><strong>Curiosity</strong>: Always seeking to understand “why”, always looking to make things better.</li><li><strong>Passion</strong>: You are driven by a love for what you do</li><li><strong>Optimism</strong>: The ability to bounce back quickly when something doesn’t work</li><li><strong>Action</strong>: Knowing when to shift from planning to doing</li><li><strong>Honesty</strong>: Transparency with customers, partners and teammates</li><li>Entrepreneurial spirit</li><li>Data-driven mindset</li><li>An interest in / passion for the outdoors (fishing knowledge not required!)</li></ul><div><h4>BENEFITS</h4></div><ul><li>&quot;Take what you need&quot; PTO Policy</li><li>4 additional paid days off specifically to enjoy the outdoors</li><li>Flexible working schedule</li><li>Ability to work from home if there is a need</li><li>Medical, Dental and Vision Insurance - We cover 85% of your premium and 50% for dependents</li><li>Health Savings Account</li><li>401(K) plan</li><li>Pre-Tax Commuter Benefits</li><li>Unlimited fruit snacks</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "FJMEMfJVRhSmyp3uIJ7_Yg",
    "url": "https://jobmote.com/job/60844/machine-learning-scientist-remote-any-country/",
    "title": "Machine Learning Scientist - REMOTE, ANY COUNTRY",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:caffe/bigdata-ml/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:express/nodejs/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:theano/bigdata-ml/8",
      "DBG_TECH1:k/t/w:torch/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=13, mobile=1, go=0, nodejs=8, bigdata-ml=66, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "DigitalMR",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 13, 2019 10:07:32 PM",
    "validThrough": "Aug 16, 2019 10:07:32 PM",
    "crawled": "Aug 14, 2019 3:06:25 AM",
    "content": "<div>Applications are invited for a Machine Learning Scientist who will use existing IP developed and implemented to deliver projects to DigitalMR clients.<p><strong>DigitalMR is a remote-first company, with team members in various countries around the world. The successful candidate will work remotely in the country they are currently based.</strong> Occasional travel to meet collaborators and client visits may be required.<br><br></p> <p><strong>Role and Responsibilities</strong></p> <ul><li>Implement and evaluate models and software prototypes of machine learning processing</li> <li>Train, validate and systematically test algorithms with large text and image data sets</li> <li>Meet accuracy targets for sentiment and semantic analysis</li> <li>Maintain relationships with relevant external collaborators and realise knowledge transfer</li> <li>Work closely with a dynamic team of software engineers and market researchers to realise applications that may include sentiment, emotions, topics, and trends extraction, social propagation, and social influence</li> <li>Arrange integration of tested algorithms with the company's platforms and data systems</li> <li>Document system performance and incorporate customer feedback</li> <li>Other tasks assigned by the CTO/CEO<br><br></li> </ul><p><strong>The above role offers:</strong> </p> <ul><li>Employment with an award winning ­growing international company</li> <li>Be a key part of very forward-thinking projects in social media analytics</li> <li>­Flat structure, no bureaucracy, no red tape</li> <li>Competitive salary and performance bonus</li> <li>Company share options</li> </ul><p><strong>Qualifications, Experience &amp; Skills:</strong></p> <ul><li>Masters, PhD, or equivalent experience in a quantitative field (Machine learning, Computer vision, Computer Science, Applied Mathematics, Engineering, etc.)</li> <li>Track record in machine learning techniques</li> <li>Familiarity with deep learning libraries such as Torch, Theano, Caffe, or PyBrain</li> <li>Hands-on experience coding in one of the following: C/C++, Java, Python</li> <li>Positive attitude and good interpersonal, communication and teamwork skills; a great fit with the company's values </li> <li>Ability to solve complex problems in a fast-­paced environment with limited guidance</li> </ul><p><strong><br>Desirable Skills:</strong></p> <ul><li>Digital image processing / computer vision experience</li> <li>Amazon EC2 familiarity</li> <li>­Organisational skills both in management of time and software code in an agile framework.</li> <li>Hadoop ecosystem experience</li> <li>Methods for learning imbalanced datasets</li> </ul><p><strong>To express your interest in this role, please click on the 'Apply' button below, and fill out this short application form .</strong></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "YeTRPbaOQGWm_9r5d7QC_g",
    "url": "https://jobmote.com/job/60827/remote-machine-learning-engineer-retail-domain/",
    "title": "REMOTE - Machine Learning Engineer - Retail Domain",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/18",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 13, 2019 10:07:31 PM",
    "validThrough": "Aug 16, 2019 10:07:31 PM",
    "crawled": "Aug 14, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Machine Learning/Data Science, retail domain experience, Python, R, Inventory Optimization, Deep Neural Networks (DNN), TensowFlow, Machine Learning Algorithms, Order Management/fulfillment systems, Cloud Platforms: AWS/GCP/Azure<br><br>If you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please read on!<br><br>Top Reasons to Work with Us<br><br>We are a technology consulting firm specializing in delivering High Performing Omni Channel Fulfillment solutions to the retail vertical. We are passionate about building best of breed enterprise applications, keen on bringing top-notch technical insight to solving business problems that is focused on customer's success by operating with integrity and building a long term relationship. Our consultants are seasoned battle-tested engineers with many years of real-world experience.<br><br>What You Will Be Doing<br><br>You will be working remote to help build and scale our internal omni-channel fulfillment platform. This will involve utilizing machine learning algorithms and standing up machine learning platforms in the cloud. We are looking for someone who can both be hands on and be involved in over-arching architectural decisions.<br><br>What You Need for this Position<br><br>MUST HAVE:<br>- BS in related field<br>- 3+ years of machine learning/data science experience<br>- Strong Retail/E-Commerce industry experience<br>- Deep Neural Networks (DNN)<br>- Tensorflow<br>- Python/R<br>- Experience with machine learning algorithms<br>- Cloud services: AWS, GCP, or Azure<br>- Order Management/fulfillment systems or Inventory Optimization<br><br>What's In It for You<br><br>- Competitive Salary DOE<br>- Comprehensive Benefits Package<br>- Generous PTO<br>- 401k with match<br>- REMOTE WORK!So, if you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6CjYnE3zRA20bgsmgjsD_Q",
    "url": "https://remoteok.io/jobs/74477",
    "title": "Senior Backend Developer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angularjs/frontend/8",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "java"
    ],
    "hiringOrganization": {
      "name": "gomo video",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 14, 2019 12:10:24 AM",
    "validThrough": "Aug 21, 2019 12:10:24 AM",
    "crawled": "Aug 14, 2019 1:06:30 AM",
    "content": "<span></span> <span><h4>gomo video</h4></span> <br> <h3>Senior Backend Developer</h3> <div>  <div>   \\nWe are looking for an experienced back-end or full-stack developer to join our remote UK team.\\n\\n\\n\\nTell me about Instilled!\\n\\nInstilled is a new learning experience platform (LXP), meaning it is the very latest breed of learning delivery tools. Despite being new to the market, Instilled is built on a mature product with a solid client base and consolidates a wealth of experience and technology from our parent group. We are a small, agile team in a much larger learning technology business that is successful and passionate about creating outstanding learning tools.\\n\\nWhat Instilled provides is a YouTube like experience for learners to discover content and progress at their own pace—it was originally a video platform, so included are a host of video features such as auto-captioning, auto-translation and commenting etc.\\n\\nWe are still in the early stages of this products transformation but we have huge aspirations and want developers that relish the opportunity to create industry-leading products.\\n\\nHow will I know this is for me?\\n\\nFirst, this is a UK-specific role.&nbsp;Candidates must be eligible to work in the UK.&nbsp;Our team does have a US component, but we are not currently hiring for&nbsp;any US roles.\\n\\nOur ideal candidate is friendly, enthusiastic and just as passionate about technology as we are. The team spans multiple offices and time-zones so a self-starter attitude and excellent communication skills are key. We know not everyone has experience of the learning industry but that’s fine, we want people that understand code. Our current tech stack is comprised of Java, Spring, PostgreSQL, AngularJS, and others. These things change though, so whilst prior experience is advantageous, the key is being able to adapt to whatever technology the task demands. We look for developers that have an opinion about how technology can be applied, but remain equally open minded about new or different approaches. Working well in a team is vital as this role will be fundamental in shaping our product architecture - clearly articulating a concept and nurturing other team members is hugely important.\\n\\nOk, sounds great! What do I do?\\n\\nThis is a unique opportunity to join a dynamic product team that is taking an impressive client list in to a whole new world of learning. If this sounds like a good fit then we would like to hear from you. Please send over a cover letter explaining why and attach your CV. Feel free to outline any achievements you are particularly proud of and include a link to code you can share. Extra points for your best joke!  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ycO0VbbyTDuohVINZMH7aQ",
    "url": "https://jobmote.com/job/60694/remote-or-on-site-reference-data-analyst-mdm-right-to-hire/",
    "title": "REMOTE or ON SITE - REFERENCE DATA ANALYST (MDM) - RIGHT TO HIRE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "SANS",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 12, 2019 10:07:28 PM",
    "validThrough": "Aug 15, 2019 10:07:28 PM",
    "crawled": "Aug 13, 2019 3:06:25 AM",
    "content": "<div><p>A Try &amp; Buy position at Major player in retirement finance. </p><p> Pay Options: IC - Self Incorporated or w2 . </p><p> Contact Susan Andaluz . call / ext.162 or email with the Job Code SA33532 or Click the Apply Now button (Sorry, NO 3rd Party (Subcontract) for this position!) . </p><p> Location: Remote or On Site (Windsor, CT - Braintree, MA - Atlanta, GA - Minneapolis, MN) </p><p> Skills required for the position: REFERENCE DATA, SQL, TIBCO EBX, ORCHESTRA NETWORK </p><p> Detailed Info: The Reference Data Analyst is a key role responsible for Enterprise Reference Data Management (RDM). </p><p> Act as business solution owner of the firms Reference Data Management (RDM) ecosystem, including tool configuration and operating processes </p><p> Working with Data Governance team to define Enterprise Reference Data Values </p><p> Map Source System Reference Data Values to the Enterprise Data Values </p><p> Act as the owner of enterprise reference data hierarchies (transaction taxonomies, industries, etc) </p><p> Accountable for data quality controls, measurement, and issue resolution </p><p> Partner with key roles, e.g. application analysts, data integration team, database administrators team, infrastructure team, and business constituents to maintain a robust and sustainable RDM system </p><p> Define detailed RDM processes, workflow tasks, data flows, and dependencies </p><p> Development/Computing Environment: For remote position, hands-on experience with Orchestra network or Tibco EBX is a must </p><p> Candidate should have good understanding of data management concepts (data governance, data modeling, data quality, data lineage, master data management, metadata management, data analytics, etc) </p><p> Strong business and technical background in the area of Master &amp; Reference Data Management </p><p> SQL proficiency </p><p> Proficiency in creating source-to-target mapping, including handling complex taxonomies </p><p> Background in finance (ideally in insurance or retirement services) </p><p> For on site position, hands-on experience with Enterprise MDM tools like Informatica, IBM, Talend, Orchestra network, Tibco EBX, etc is a plus </p><br><p> . </p><p> The position offers competitive rate for a contract and an opportunity for full scale compensation package for F/T empoyee position. </p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "hrszm0zTRHe58oUEu1UYEg",
    "url": "https://jobmote.com/job/60659/lead-data-engineer-remote-contract/",
    "title": "Lead Data Engineer - Remote - Contract",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(we,team,compani,member,employe,develop,engin,workmat) 2W work W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 12, 2019 10:07:27 PM",
    "validThrough": "Aug 15, 2019 10:07:27 PM",
    "crawled": "Aug 13, 2019 3:06:25 AM",
    "content": "<div>Jefferson Frank is looking for a highly experienced Data Engineer to work remotely for one of our well known clients. this person should be a self starter and have previous experience working remotelty<br><br>Role &amp; Responsibilities<ul><li> Develop batch and streaming data ingestion and ETL processes</li><li> Define and implement data models</li><li> Reccomend and adopt new tools and applications</li></ul>Skills &amp; Qualifications<ul><li> Previous experience using Apache Kafka for live data streaming</li><li> Data Warehousing experience preferably with Snowflake</li><li> Experiene developing NoSQL data stores</li><li> Experience developing ETL workflows</li><li> Ability to work remotely while still communicating with team members through slack</li></ul> If you are interested in this role please contact Sean Evers at or [Click Here to Email Your Resum?] <br> Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS. I understand the need for discretion and would welcome the opportunity to speak to any Big Data and cloud analytics candidates that are considering a new career or job either now or in the future. Confidentiality is of the utmost importance. For more information on available AWS Big Data Jobs as well as the cloud market, I can be contacted at [Click Here to Email Your Resum?] or by calling . Please see for more information Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice.<br><br>We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific. At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IKY57wiYTUac5TRlJ_sKhw",
    "url": "https://jobmote.com/job/59526/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>Azure Big Data Engineer (Remote Flexibility)<br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.<br> *AZURE EXPERIENCE REQUIRED<br> Skills:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience with data pipeline and workflow management tools</li></ul>Benefits:<ul><li>Medical</li><li>Dental</li><li>Vision</li><li>Family leave</li><li>PTO</li><li>Retirement Plan</li><li>Remote options</li></ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br><br><b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZL0Zu53lQP2FBnrJui_FsA",
    "url": "https://jobmote.com/job/59525/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TNrx0oWNT0KRufsggJdQvQ",
    "url": "https://jobmote.com/job/59506/aws-data-engineer-150k-remote/",
    "title": "AWS Data Engineer- $150K- REMOTE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:21 PM",
    "validThrough": "Aug 14, 2019 10:07:21 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><b>AWS Big Data Engineer</b><br> As an AWS Big Data Engineer, you will be responsible to design and develop data pipelines using AWS Big Data tools and other modern technologies. You will play a crucial role in shaping the future of the big data and analytic initiatives for many of their clients. As an AWS Big Data Engineer, you will be helping organizations migrate to the cloud, transform their business and optimize their technical investment. You will also be responsible for developing products where you see gaps in client technologies and in the market! <br><b>Location:</b> Remote<br><b>Travel</b>: 25-30%<br><b>Salary:</b> $150-180K(based on experience)<br><b>Roles and Responsibilities:</b><ul><li>Work on large-scale Data projects</li><li>Build data pipelines using AWS Cloud services</li><li>Develop Python programming to streamline processes for the data ingestion</li><li>Recommend ways to improve data quality and reliability </li><li>Build data lakes and construct data pipelines for clients</li><li>Gather client requirements </li><li>Manipulate data using Python, SQL, NoSQL, and other standard tools and methods</li></ul><b>Skills and Qualifications:</b><ul><li>Bachelor's degree in Computer Science or equivalent</li><li>Skilled in data and analytic technologies</li><li>Extensive experience with Python, Scala, or Java programming</li><li>Must have experience with SQL and NoSQL environments</li><li>Extensive knowledge and hands-on experience with Big Data platforms (Hadoop, Kafka, Spark, NiFi, HBase, etc.)</li><li>Hands on experience with AWS Cloud Services (Redshift, EC2, EMR, Kinesis, etc.)</li><li>Proficient in creating data pipelines</li><li>AWS Big Data speciality or Solutions Architect Professional Cert- a plus! </li></ul><b>Company Rewards:</b><ul><li>Competitive base salary</li><li>Health, Dental, and Vision plans</li><li>Paid vacation and holidays</li><li>Work/life Balance</li></ul><b>Contact Details:</b> Looking to fill this position immediately. If interested, please contact [Click Here to Email Your Resum?] or call .<br> Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professional on the planet. Back by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.<br> At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivaled customer experience. Work with us and you'll get the personalized experience you deserve- one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "4jJZhKU6Qveelvz-s3qSRQ",
    "url": "https://jobmote.com/job/59529/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UQHuaQWGSGy94AxCxZ6iAg",
    "url": "https://jobmote.com/job/59523/nlu-nlp-architect-or-engineer-remote/",
    "title": "NLU NLP Architect or Engineer REMOTE",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Collabera",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:22 PM",
    "validThrough": "Aug 14, 2019 10:07:22 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div>Position/REQ ID: ? NLP Architect <br>Location: RTP or SJ areas, can be remote <br>Duration: 11 Months <br>? <br>MUST HAVES <br>Strong knowledge of the Machine Learning techniques around natural language<br>Experience implementing enterprise scale NLU based IVR solution(s).<br>Strong knowledge IVR based application development and Conversational IVR.<br>Experience in Dialogflow OR other NLP engine models such as<br>Good knowledge on building conversational IVR (Interactive Voice Response) flows using Dialog flow<br>Experience with machine learning techniques within NLP such as tokenization, parts of speech tagging, stemming, lemmatization, named entity recognition, sentiment analysis, TF-IDF, topic modeling, bag of words, word vectors, language modeling, seq2seq, LSTMs, Transformers <br>? <br>PLUSSES <br>Programming experience in Node JS, Python, SQL, NoSQL, Java, Graph Databases a plus<br>Strong knowledge of applicable methodologies, tools, standards, and procedures.<br>Experience in Big Data platform handling large volumes of data and have experience in data processing and storage. <br>DAY-TO-DAY <br>Implement NLU/NLP solutions to extract value from Install Base data.<br>Be the in-house NLP expert, lead NLP initiatives, review the deliverables and set standards and guideline<br>Develop design principle for developing new dialog flows.<br>Help cultivate organization-wide best practices for NLP and Coach and Mentor other members of the team<br>Deconstruct customer-agent conversations to programmatically extract concepts and relationships between concepts in various conversation scenarios.<br>Work with various business lines like? Sales and Marketing to identify opportunities for NLP and recommend them into actionable data science projects.<br>Guide the data engineers to design data pipelines to effectively store, normalize and access text data. <br>?<br><br>NLP,NLU,IVR, Dialogflow<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "x_O3qHhgTJmNXpIfnCUyOQ",
    "url": "https://jobmote.com/job/59493/sql-data-analyst-telecommute/",
    "title": "SQL Data Analyst - Telecommute",
    "tags": [
      "DBG:surround``3N(telecommut, posit) NOT fulltim",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=1, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UnitedHealth Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 10:07:21 PM",
    "validThrough": "Aug 14, 2019 10:07:21 PM",
    "crawled": "Aug 12, 2019 3:06:24 AM",
    "content": "<div><br>No industry is moving faster than health care. And no organization is better positioned to lead health care forward. We need attention to every detail with an eye for the points no one has considered. The rewards for performance are significant. You'll help improve the health of millions. And you'll do your life's best work.(sm)<br><br>The primary role of the Data Analyst is to develop effective and high quality healthcare program integrity analytics that meet business requirements. Technical abilities include following team and industry coding best practices, data analysis, performance tuning, unit testing, and system testing support utilizing SQL, Python, and other similar tools.<br><br>You'll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.<br><br><b><br><b>Primary Responsibilities:</b></b><br><br>Develop healthcare payment integrity analytics <br>Write complex SQL queries to validate data <br>Understand data structure and content, perform query tuning <br>Support business analysts; translate business requirements to technical specifications<br><br><b><br><b>Required Qualifications:</b></b><br><br>5+ years of Data Analysis experience using SQL <br>2+ years of experience in health care payment integrity analytics and working with large data sets <br>Proficiency coding overpayment analytics using SQL <br>Knowledge of medical coding concepts (Claims data, Procedure codes, Diagnosis codes, Provider and Member data)<br><br><b><br><b>Preferred Qualifications:</b></b><br><br>Bachelor's degree or equivalent experience <br>Cognos/Tableau report development experience <br>Other tools/languages - Python, JavaScript, R, Spark<br>Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)<br><br>*All Telecommuters will be required to adhere to UnitedHealth Group's Telecommuter Policy.<br><br><b>Diversity creates a healthier atmosphere:</b> UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.<br><br>UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.<br><br><b>Job Keywords:</b> SQL Data Analyst, telecommute, telecommuter, remote, work from home<br><br><b>Job Title: </b> SQL Data Analyst - Telecommute <br><b>Shift: </b> Day Job <br><b>Travel: </b> No <br><b>Business: </b> Optum Ops-Transactions <br><b>Family: </b> Analytics <br><b>Telecommuter Position: </b> Yes <br><b>Job Level: </b> Individual Contributor <br><b>Overtime Status: </b> Exempt <br><b>Posted Date: </b> 8/9/2019 <br><b>City: </b> Eden Prairie <br><b>State: </b> MN <br><b>Country: </b> United States <br><b>Department: </b> Optum Ops-Shared Svcs Analytcs<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gKyvR_aPQjKo_E5gcxMttg",
    "url": "https://remote.co/job/backend-engineer-20/",
    "title": "Backend Engineer",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:node.js/nodejs/13",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:sass/frontend/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=15, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=18}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "Dotscience",
      "sameAs": "https://www.dotscience.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 11, 2019 8:08:24 PM",
    "validThrough": "Aug 18, 2019 8:08:24 PM",
    "crawled": "Aug 11, 2019 8:32:10 PM",
    "content": "<h3>Backend Engineer at <span>Dotscience</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>REMOTE</strong>&nbsp;London, England, United Kingdom Engineering BE-01</p><p><strong>DESCRIPTION</strong></p><p><strong>NOTE:&nbsp;This role is remote-only, and you need to be living in, and have a right to work in, one of the following countries: UK, Germany, France, Ireland or USA. We are mostly based in the UK and so the ability to co-ordinate with this timezone is needed.</strong></p><p><strong>About Dotscience</strong></p><p>Dotscience is a startup founded in 2017 and funded by DDN, the world’s largest privately-held storage company. Its mission is to build an end-to-end data science platform that holds AI accountable for its decision making.</p><p>We like to see ourselves as a very friendly and high-trust team. Because we are fully remote we are able to be flexible about parenting responsibilities and other things in life that need your attention. We co-ordinate once a day in a standup where we check in to say how things are going and tell jokes (it is part of our standup routine). The rest of the time we collaborate through GitHub, Slack, Google Hangouts and Google Docs.&nbsp;<strong>We get together in person every 6-8 weeks for a couple of days somewhere in the UK, where we socialise and build our relationships.&nbsp;</strong>We do get some work done too, but it’s mainly about face time. We try to do something fun and we mix up the venues and locations. Sometimes it’s in a WeWork, but sometimes we hire a holiday cottage and have jam sessions! We see our fair share of babies at our meetings, either in person for a visit and a cuddle, or on our video calls.</p><p>The culture in the Engineering team is very collaborative and within the company all discussions are open by default. Everyone is listened to and nobody gets a special pass to push decisions through. You would be a fit for us if you care about how and why things work, engineering quality and user value. We would be a fit for you if you want a supportive, flexible, high-trust work environment where you are encouraged to grow your role at a pace to suit you.</p><p><strong>About the role</strong></p><p>NOTE: We are looking for a number of engineers across the stack, so we’re flexible about exactly which roles we hire into regarding frontend, backend and full stack.</p><p><strong>Tech We Use</strong></p><p><strong>Front-end</strong></p><ul><li>Javascript</li><li>React</li><li>Redux</li><li>CSS</li><li>SCSS</li></ul><p><strong>Back-end</strong></p><ul><li>Go (core)</li><li>Python (knowledge of)</li><li>PostgreSQL</li><li>Javascript</li><li>Node.js</li></ul><p><strong>Infrastructure</strong></p><ul><li>Docker / Kubernetes</li><li>AWS / GCE</li><li>Gitlab / Github</li></ul><p>Aims</p><p><strong>Work with the team to:</strong></p><ul><li>Develop a product which is robust and scalable for cloud and on-premise use</li><li>Design and create services and system architecture</li><li>Ensure the product is built to deliver a good user experience</li></ul><p><strong>Responsibilities</strong></p><ul><li>Design and build our data science platform collaboratively with the team</li><li>Using tech from the list above</li><li>Collaborate through pair programming, attending meetings and being an active member in the self-organising team.</li><li>Help improve our code quality through writing unit tests, automation and performing code reviews</li><li>Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products</li><li>Work with the product and design teams to understand end-user requirements, formulate use cases, and then translate that into a pragmatic and effective technical solution</li><li>Work within the scrum framework to deliver product value to a regular cadence.</li><li>Provide support as part of a rota.</li><li>Write user documentation for the work you do.</li></ul><p><strong>REQUIREMENTS</strong></p><p><strong>Experience</strong></p><ul><li><strong>Degree-level education (or comparable experience) in STEM or another relevant area.</strong></li><li>Good understanding and plenty of practical experience in a statically typed programming language. We use Go, so we’d need you to learn it on the job if you don’t know it already.</li><li>Good understanding and plenty of practical experience in a scripting language.</li><li>Some familiarity with containers from an architectural perspective.</li></ul><p><strong>Personal skills</strong></p><ul><li>Good communication and teamwork skills.</li><li>A preference for being organised and dependable.</li><li>Keen to learn and share knowledge.</li><li>A tendency to question things, to be critical and enquiring.</li><li>Comfortable with change and pragmatic decision making.</li><li>Happy to work under time pressure occasionally.</li><li>Able to manage own time.</li><li>Know when to ask for help or input.</li><li>Know when to give feedback to others.</li></ul>        </div><div>        <a href='https://dotscience.workable.com/j/8C9F0DBB3D' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ovcQcJ0xQu2uYJok1b__tw",
    "url": "https://jobmote.com/job/59449/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "JydIJVcyQaatBSqBlfX3SA",
    "url": "https://jobmote.com/job/59447/remote-servicenow-developer/",
    "title": "Remote ServiceNow Developer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nelson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div><b>Remote ServiceNow Developer-Arlington, VA</b><br> Job Description:<br> Remote ServiceNow Developer-Arlington, VA<br> A modern fast growing digital consulting firm based in Arlington, VA is seeking a ServiceNow Developer. Voted one of the best places to work, this firm is looking for a creative individual to manage key company assets through the ServiceNow platform. You will join a team of outcome-driven ServiceNow professionals.<br> As the ServiceNow Developer you will be responsible for using the NOW platform to manage assets and having knowledge of IT Asset Management/ working with CMDB. You will be an essential technical resource to develop client solutions, track the contractual, financial, and inventory details of hardware/devices throughout the lifecycle.<br> Essential Requirements:<ul><li>3+ years' experience with ServiceNow platform</li><li>2+ years' experience with ServiceNow IT Asset Management</li><li>Knowledge of ServiceNow Discovery and CMDB</li><li>JavaScript Experience</li><li>Excellent communication skills and the ability to work within a team</li><li>Must be a U.S Citizen or Permanent Resident</li><li>Eligible for Public Trust Clearance</li><li>ServiceNow System Admin Certification / ServiceNow Implementation Specialist Certification</li></ul> This company is offering an above market rate salary and generous benefits. The firm is currently interviewing and looking to hire immediately.<br> If you think this company is a great fit for you, please send your CV to [Click Here to Email Your Resum?] and/or call . Ask for Mackenzie regarding a confidential career scanning and to further discuss the opportunity.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "iMeo1tBrTkCyoXJP-NajQQ",
    "url": "https://jobmote.com/job/59443/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UWNwpwABTt-9_xY9SgfdQA",
    "url": "https://jobmote.com/job/59442/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "CareerBuilder-US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out a foundation platform to move Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><br>100% Remote Opportunity?<ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li><li>Build Back end applications using Java, Spark/Scala, Python</li><li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li><li>Work on performance optimizations on Hbase and Solr</li><li>Work on Performance optimization on Spark Jobs and MapReduce jobs.</li><li>Ability to debug complex production scenarios</li><li>Master?s degree in Computer Science, Management Information Systems</li></ul>For immediate consideration, email your updated resume to <b>Dan Malta</b> at <b> [Click Here to Email Your Resum?] </b></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "hTWVNoHsTkexqIAgI-FR7g",
    "url": "https://jobmote.com/job/59431/big-data-engineer-remote/",
    "title": "Big Data Engineer(REMOTE)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/64",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:sql-server/dotnet/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=4, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=104, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Netserv-Applications Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 10, 2019 10:07:27 PM",
    "validThrough": "Aug 13, 2019 10:07:27 PM",
    "crawled": "Aug 11, 2019 3:06:25 AM",
    "content": "<div><b>Big Data Engineer</b><br><br>?<br><br>? 6-8 years of experience in ?data engineering with strong experience in Big Data using any Hadoop ecosystem and building Data Lakes using Hadoop<br><br>? Bachelor?s Degree in Computer Science, Engineering, and/or background in Mathematic and Statistics<br><br>? Experience on Big Data platforms (Cloudera/Horton Hadoop, Spark, HBase, Hive) , scripting using Python , Data Lakes using Hadoop<br><br>? Strong Database and Data warehousing background, Proficient with ETL tools like SSIS, Informatica and has strong SQL, PL/SQL or T-SQL skills<br><br>. Worked in data base environments like MS SQL Server, Oracle, Teradata or Netezza<br><br>. Worked in Agile project environment , good communication and leadership/team skills<br><br>. Any experience with MDM (Master Data Management) a plus<br><br>?<br><br>Location: Knoxville (REMOTE)<br><br>Start Date: Immediate<br><br>Type : Full Time<br><br>?<br><br>Visio<br><br>Technical Writing<br><br>Technical Communication<ul><li><b>Big Data Engineer</b><br><br>?<br><br>? 6-8 years of experience in ?data engineering with strong experience in Big Data using any Hadoop ecosystem and building Data Lakes using Hadoop<br><br>? Bachelor?s Degree in Computer Science, Engineering, and/or background in Mathematic and Statistics<br><br>? Experience on Big Data platforms (Cloudera/Horton Hadoop, Spark, HBase, Hive) , scripting using Python , Data Lakes using Hadoop<br><br>? Strong Database and Data warehousing background, Proficient with ETL tools like SSIS, Informatica and has strong SQL, PL/SQL or T-SQL skills<br><br>. Worked in data base environments like MS SQL Server, Oracle, Teradata or Netezza<br><br>. Worked in Agile project environment , good communication and leadership/team skills<br><br>. Any experience with MDM (Master Data Management) a plus<br><br>?<br><br>Location: Knoxville (REMOTE)<br><br>Start Date: Immediate<br><br>Type : Full Time<br><br>?</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "dr9XvYKyQKyHibwUIrDjHg",
    "url": "https://jobmote.com/job/59322/aws-data-engineer-150k-remote/",
    "title": "AWS Data Engineer- $150K- REMOTE",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=16, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 10:07:32 PM",
    "validThrough": "Aug 12, 2019 10:07:32 PM",
    "crawled": "Aug 10, 2019 3:06:25 AM",
    "content": "<div><br><br><p><strong>AWS Big Data Engineer</strong></p><br><p>As an AWS Big Data Engineer, you will be responsible to design and develop data pipelines using AWS Big Data tools and other modern technologies. You will play a crucial role in shaping the future of the big data and analytic initiatives for many of their clients. As an AWS Big Data Engineer, you will be helping organizations migrate to the cloud, transform their business and optimize their technical investment. You will also be responsible for developing products where you see gaps in client technologies and in the market! </p><br><p><strong>Location:</strong> Remote</p><br><p><strong>Travel</strong>: 25-30%</p><br><p><strong>Salary:</strong> $150-180K(based on experience)</p><br><p><strong>Roles and Responsibilities:</strong></p><br><ul><li><br></li><li>Work on large-scale Data projects<br></li><li>Build data pipelines using AWS Cloud services<br></li><li>Develop Python programming to streamline processes for the data ingestion<br></li><li>Recommend ways to improve data quality and reliability <br></li><li>Build data lakes and construct data pipelines for clients<br></li><li>Gather client requirements <br></li><li>Manipulate data using Python, SQL, NoSQL, and other standard tools and methods<br></li></ul><br><p><strong>Skills and Qualifications:</strong></p><br><ul><li><br></li><li>Bachelor's degree in Computer Science or equivalent<br></li><li>Skilled in data and analytic technologies<br></li><li>Extensive experience with Python, Scala, or Java programming<br></li><li>Must have experience with SQL and NoSQL environments<br></li><li>Extensive knowledge and hands-on experience with Big Data platforms (Hadoop, Kafka, Spark, NiFi, HBase, etc.)<br></li><li>Hands on experience with AWS Cloud Services (Redshift, EC2, EMR, Kinesis, etc.)<br></li><li>Proficient in creating data pipelines<br></li><li>AWS Big Data speciality or Solutions Architect Professional Cert- a plus! <br></li></ul><br><p><strong>Company Rewards:</strong></p><br><ul><li><br></li><li>Competitive base salary<br></li><li>Health, Dental, and Vision plans<br></li><li>Paid vacation and holidays<br></li><li>Work/life Balance<br></li></ul><br><p><strong>Contact Details:</strong> Looking to fill this position immediately. If interested, please contact or call .</p><br><p>Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professional on the planet. Back by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.</p><br><p>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivaled customer experience. Work with us and you'll get the personalized experience you deserve- one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "cP8fGO7KTWiDjZ6rcKxdsw",
    "url": "https://jobmote.com/job/59309/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 10:07:32 PM",
    "validThrough": "Aug 12, 2019 10:07:32 PM",
    "crawled": "Aug 10, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "MrDB_ac3Tu-TuM4D3KVj0w",
    "url": "https://stackoverflow.com/jobs/288152/software-engineer-create-devops-for-ai-dotscience?a=1yDvz3ma1BKM",
    "title": "Software Engineer | create 'DevOps for AI' platform & tools | 100% remote at Dotscience  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/32",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go-developer/go/13",
      "DBG_TECH1:k/t/w:go/go/15",
      "DBG_TECH1:k/t/w:golang/go/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:node.js/nodejs/65",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/12",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:shell/other/1",
      "DBG_TECH1:techWeightMap:{python=25, other=7, dotnet=0, c=0, mobile=0, go=52, nodejs=65, bigdata-ml=84, ruby=2, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/nodejs",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "nodejs"
    ],
    "hiringOrganization": {
      "name": "Dotscience via techfolk",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 60000,
      "maxValue": 80000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "GBP 60k - 80k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 8:30:25 PM",
    "validThrough": "Aug 16, 2019 8:30:25 PM",
    "crawled": "Aug 9, 2019 8:30:25 PM",
    "content": "<h3><span>Software Engineer | create 'DevOps for AI' platform &amp; tools | 100% remote</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>DevOps</span>                                    </div>                            </div>                    </div>                <div>Company: Dotscience via techfolk | No office location<br></div>                    <h4>Remote details</h4>                    <div>                        <div>                                                            <div>                                    <span>Preferred Timezone:</span>                                    <span>(GMT+00:00) London </span>                                </div>                                                                                                            </div>                    </div>                <h4>Technologies</h4><div>go</div><div>node.js</div><div>python</div><div>docker</div>                <h4>Job description</h4>                <div><p>Dotscience is hiring remote back end software engineers to help tackle some of the considerable challenges ahead in developing AI for production use. We're mainly working in Go, plus Python and Node.js and we'll support your learning if you need to cross train.</p><p>Our end-to-end machine learning toolset helps our customers stabilise and scale their AI initiatives; from development to production, we help them track full evolution of models and metrics throughout the lifecycle. Think 'DevOps for ML'.</p><p>We're hiring someone to help architect and implement data science automation solutions and tooling. We’re building from the ground up, inheriting zero legacy code. Collaborating with our product and design teams, you'll develop a product which is robust and scalable for cloud and on-premise use. You'll also help us to integrate with, and to automate, most of the major AI/ML ecosystems as we build out our tech</p><p>We'll listen to your opinions and actively encourage you to make recommendations as to how we can improve our products.</p><p>Now is an exciting time to join us; we're hiring a range of skills across the stack and can potentially shape your role in ways that build upon your strengths.&nbsp;</p><p><strong><br>Example first projects</strong></p><ul><li>Building features on the Dotscience platform that enables data scientists to create, collaborate on and to manage their workflows</li><li>Building API’s and SDK’s to support data pipelines and model deployment</li><li>Scaling the platform to support large and complex data science workloads</li><li>Maintain an operational stack and infrastructure for back end services</li></ul><p><strong>We're looking for</strong></p><ul><li>Strong back end coding skills, using a statically typed programming language - we use mainly Go (Golang), plus Python and Node.js, and can support your transition and learning</li><li>A technical understanding of building AI/ML pipelines in research or production environments</li><li>Familiarity with Containers from an architectural perspective</li><li>Familiarity with a scripting language, such as Bash, Perl, Python, Ruby, Shell etc.</li><li>Solid understanding of Computing or AI - gained from practical application, or through education&nbsp;</li><li>Familiarity with the principles of Agile, automated testing and continuous delivery</li><li>Clear desire to learn, to improve and to share knowledge with colleagues</li><li>Considering senior to principal level remote back end jobs such as: Go Developer | Golang Developer | Python Developer | Node.js Developer | Back End Engineer | Lead Engineer | AI Tools Engineer | Machine Learning Developer | Artificial Intelligence Engineer | Data Scientist | etc.</li></ul><p><strong>Current stack - we'll welcome your influence</strong></p><p>Go (Golang) | Python | Node.js | PostgreSQL | Docker | Kubernetes | AWS | GCE | GitHub | GitLab | Tensorflow</p><p><strong>Salary and benefits</strong></p><ul><li>£60,000 to £80,000+ negotiable - we're keeping an open mind</li><li>Flexible and family friendly working environment - no core hours, work at the times that suit you</li><li>Remote workers package, including fully expensed work travel costs</li><li>25 days holiday + UK national/public holidays/local benefits | private medical cover | life cover/income protection insurance | group personal pension/contributory pension | conference involvement encouraged | open source projects include <a title=&quot;Tensorflow for Dotscience&quot; href='https://github.com/dotmesh-io/jupyterlab-tensorflow' rel='nofollow'>Tensorflow for Dotscience</a> and <a title=&quot;Jupyterlab plugins&quot; href='https://github.com/dotmesh-io/jupyterlab-plugin' rel='nofollow'>Jupyterlab plugins for Dotscience</a></li></ul>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/288152?reset=False&amp;ra=1yDvz3ma1BKM&amp;oqs=a%3D1yDvz3ma1BKM' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Dotscience</h4>            <div><p>Launched July 2019, Dotscience is funded by DDN, the world’s largest privately-held storage company. We're an innovation project being run like a start-up and we're looking for someone who cares greatly about how and why things work, about engineering quality and about user value. Our aim is to help data science and ML teams to collaborate, to build and to deploy AI models effectively. We believe that building and deploying ML models should be easy, fast and safe. Our mission is to build an end-to-end data science toolset that holds AI accountable for its decision making. An entirely distributed team, we collaborate through daily stand-ups and use tools such as GitHub, Slack, Hangouts and Google Docs. We also meet up every six-eight weeks, for example at a nice holiday cottage, to get to know each other better, to hold work sprints, to enjoy downtime together, and to discuss our mission plans. We offer a supportive, flexible, high-trust work environment, where you are encouraged to grow your role at a pace to suit you.</p><p><strong>Location:</strong> remote/work from home - within the UK, France, Germany and/or the US - please note that you need to be living in, and have the right to work in, one of these countries.</p><p><strong>Even if your CV isn't ready, please talk with Vittoria at techfolk to find out more:</strong></p><p>0117 318 2447 | <a href='mailto:hello@techfolk.co.uk' rel='nofollow'>hello@techfolk.co.uk</a> | @we_are_techfolk</p><p>RECRUITERS: <span>Dotscience has selected techfolk as its exclusive recruitment partner for this position and cold calling and speculative applications are not welcomed.</span></p>            </div>        ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O7Zpst0tQb6yjFQVjPIewg",
    "url": "https://stackoverflow.com/jobs/288150/senior-data-scientist-remote-global-wallethub?a=1yDsZcj5hgAw",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 8:30:25 PM",
    "validThrough": "Aug 16, 2019 8:30:25 PM",
    "crawled": "Aug 9, 2019 8:30:25 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/288150?reset=False&amp;ra=1yDsZcj5hgAw&amp;oqs=a%3D1yDsZcj5hgAw' rel='nofollow'>Apply now</a></div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "va228XYgRD64DaJ2EJW1CQ",
    "url": "https://www.remoteage.com/remote-jobs/r14078-algorithms-software-engineer-r14078-ek/",
    "title": "R14078 Algorithms Software Engineer – R14078 EK",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:matlab/bigdata-ml/16",
      "DBG_TECH1:k/t/w:perl/other/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:signal-processing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:signal-processing/embedded/8",
      "DBG_TECH1:techWeightMap:{python=2, other=5, dotnet=0, c=10, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "BOSE CORP wants you to send your resume to bk",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 5:37:24 PM",
    "validThrough": "Aug 16, 2019 5:37:24 PM",
    "crawled": "Aug 9, 2019 6:24:55 PM",
    "content": "<h3>            R14078 Algorithms Software Engineer – R14078 EK        </h3><div>United States, Massachusetts</div><div>Company: BOSE CORP wants you to send your resume to bk<p></p></div><div>                    <h4>Overview</h4>                    <p>R14078 ALGORITHMS SOFTWARE ENGINEER – R14078<br>Location: United States – Massachusetts – Stow</p><p>Industry: Automotive<br>Job Category: Engineering – Other Engineering<br>Algorithms Software Engineer</p><p>At Bose, we are passionate about helping people reach their fullest human potential so that they can feel more, do more, and be more. Working as a member of the Software Center of Excellence team, come astonish our Bose Automotive Division, obsessed with the details about our products, with your outstanding ability to create algorithms and software for a superlative audio experience in a car.</p><p>As an Algorithms Software Engineer, you will be part of a close-knit team within the Bose Automotive Software Center of Excellence. You will help implement cutting-edge audio processing algorithms on high-end automotive processors that lead to unique and exciting audio experiences. You will work with research teams to take acoustic concepts from prototype to implementation. You will also work with audio engineers around the world to create the best sound experiences based on these implementations.</p><p>Specific responsibilities:</p><p>Build software for algorithms related to music and voice processing in MATLAB, Simulink and C<br>Create high-level designs for software frameworks for these algorithms<br>Build comprehensive unit and system tests in software to verify functionality of these algorithms<br>Required skills and experience:</p><p>MS in Electrical or Computer Engineering with an emphasis on DSP or Communications<br>Thorough knowledge of C, Matlab and a scripting language such as Perl or Python<br>5 years of experience building signal processing software<br>Preferred skills and experience</p><p>Knowledge of the theory and implementation of adaptive filtering, sub-band filtering and other advanced filtering techniques<br>Knowledge of Simulink modeling and libraries<br>Job Location</p><p>Primary location – Stow, MA<br>Remote work capability will be considered for qualifying candidate to work remotely from the Greater Chicago (IL), Austin (TX), Washington, DC, Bloomfield Hills (MI), Esslingen (Germany), Montreal (Canada) areas</p><p>COMPENSATION<br>Base Salary – $GENEROUS ***ASK FOR WHAT YOU WANT ***<br>Full-time Benefits – Full<br>Relocation Assistance Available – Possible for ideal candidate</p><p>CANDIDATE DETAILS<br>7+ to 10 years experience<br>Seniority Level – Mid-Senior<br>Management Experience Required – No<br>Minimum Education – Bachelor’s Degree<br>Willingness to Travel – Occasionally</p><p>BOSE CORP wants you to send your resume to bk</p>                                                <div>                            <a href='https://www.jobg8.com/Traffic.aspx?t9dZgA5AE6GP%2bS8h5q584Qw' rel='nofollow'>Apply for job</a>                    </div>                                    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "wCQw7zFjTXuv7lfBIopRng",
    "url": "https://news.ycombinator.com/item?id=20653780",
    "title": "Datadog | Full-time, Permanent Roles: Data Engineer | Software Engineer - Data Infra | ...",
    "tags": [
      "DBG:surround``remot 3N OR(options, avail, allow) NOT encourag",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=5, mobile=0, go=6, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 9, 2019 2:48:32 PM",
    "validThrough": "Aug 16, 2019 2:48:32 PM",
    "crawled": "Aug 9, 2019 4:09:08 PM",
    "content": "Datadog | Full-time, Permanent Roles: Data Engineer | Software Engineer - Data Infra | Distributed Systems Engineer (ALL AVAILABLE IN REMOTE US/NYC/BOSTON)<p>1) Data Engineer: Looking for engineers to work on realtime (Kafka + Kafka Connect + custom Go consumers) and batch systems (Spark on EMR + Dataproc + Luigi + Parquet + S3 and GCS) to process 100's of TBs daily - at times PB-scale per day. Apply here for BOSTON/NYC - <a href='https://grnh.se/f4127d5f1' rel='nofollow'>https://grnh.se/f4127d5f1</a> - if REMOTE US, email bryan.hughes@datadoghq.com.</p><p>2) Software Engineer - Data Infra: Engineers in our Data Infra team build and own all infrastructure required to transport, process and store data at scale. This team also owns the system that allows teams to schedule and execute their batch jobs on multiple cloud platforms in multiple regions. Apply here for BOSTON/NYC/REMOTE US - <a href='https://grnh.se/ef2ed6f51' rel='nofollow'>https://grnh.se/ef2ed6f51</a>.</p><p>3) Distributed Systems Engineer: Help us build the high-throughput, low-latency systems that power our product. These systems ingest, store, analyze, and query tens of millions of events per second from companies all over the globe. Looking for experience in Go and Python, with bits of C or other languages. Apply here for BOSTON/NYC - <a href='https://grnh.se/866fe22c1' rel='nofollow'>https://grnh.se/866fe22c1</a> - if REMOTE US, email bryan.hughes@datadoghq.com.</p><p>More details about Datadog here: <a href='https://www.datadoghq.com/' rel='nofollow'>https://www.datadoghq.com/</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "WeO8WCikQkuzk2wCFfy8iw",
    "url": "https://jobmote.com/job/58072/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 10:07:25 PM",
    "validThrough": "Aug 11, 2019 10:07:25 PM",
    "crawled": "Aug 9, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0DM6HDj4Q0aN7PaDN_GL2w",
    "url": "https://jobmote.com/job/58071/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 10:07:25 PM",
    "validThrough": "Aug 11, 2019 10:07:25 PM",
    "crawled": "Aug 9, 2019 3:06:25 AM",
    "content": "<div>Company Information<br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.<br><br>Job Summary<br>The Data Lead Software Developer will be responsible for guiding the full life cycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.<br><br>Primary Job Duties &amp; Responsibilities<br><ul><li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> <li>This position is open for candidates to work remotely.</li> </ul>Minimum Qualifications<br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.<br><br>Education, Work Experience &amp; Knowledge<br><ul><li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> <li>Experience building microservices and Real Time APIs</li> <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> <li>Advanced IT process improvement, and problem-solving skills</li> <li>Comfortable presenting to senior management</li> </ul><p>Job Specific &amp; Technical Skills &amp; Competencies<br></p><p>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.<br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.<br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.<br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.<br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.<br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th<br><br>Environmental/Work Schedules/Other<br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.<br><br>Physical Requirements<br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.<br><br>Licensing or Certificates<br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.NET Kanban/Agile/SAFe<br><br>Equal Employment Opportunity Statement<br>Travelers is an equal opportunity employer. <br><br></p></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "dHV80z7xS4aghTGmerf4dA",
    "url": "https://news.ycombinator.com/item?id=20644843",
    "title": "Neuronalys | Engineers | Lille, FRANCE | Onsite or Remote, Full-Time, VISA | www.neuronalys.ai ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/8",
      "DBG_TECH1:k/t/w:c/c/10",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:cuda/bigdata-ml/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=10, mobile=0, go=0, nodejs=0, bigdata-ml=37, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 4:23:14 PM",
    "validThrough": "Aug 15, 2019 4:23:14 PM",
    "crawled": "Aug 8, 2019 6:24:50 PM",
    "content": "Neuronalys | Engineers | Lille, FRANCE | Onsite or Remote, Full-Time, VISA | www.neuronalys.ai<p>Neuronalys is a young startup, we create private SaaS deep learning solutions.</p><p>Our main product is in beta, tested with success by French law enforcement and will be released December 2019.We plan to launch an alpha for a second product in the middle of 2020. We created the specifications with companies in the energy and aeronautic fields. They are excited and waiting for this new product.</p><p>Our team is looking forward to welcoming 3 Engineers.- (2) ML/AI Engineers (computer vision) with good knowledge in Python / C- (1) ML/AI Engineer (text analysis) with good knowledge in Python / C(CUDA, video streaming, WebRTC is a bonus)</p><p>We care about people. We are constantly trying to improve the interactions in the teams and the balance between work/life. Ask us about it at jobs@neuronalys.ai</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "omunMD51Sfy2sm7TwcGhNw",
    "url": "https://remoteok.io/jobs/74390",
    "title": "Data Science Subject Matter Expert",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=100, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 4:27:36 AM",
    "validThrough": "Aug 15, 2019 4:27:36 AM",
    "crawled": "Aug 8, 2019 5:06:29 AM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Subject Matter Expert</h3> <div>  <div>   \\nPlease Apply Here\\n\\nEducation | Remote, USA | Contract\\n\\n\\nWho We Are\\nThinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;thinkful.com.\\n\\nJob Description\\nThinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp;\\n\\nResponsibilities\\n\\n\\n* Consistently deliver content that meets spec and is on time to support our program launch roadmap\\n\\n* Create daily lesson plans consisting of&nbsp;\\n\\n* Presentation decks that instructors use to lecture students on a given learning objective\\n\\n* Instructor notes that instructors use alongside&nbsp;\\n\\n* Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture\\n\\n* Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform\\n\\n* Creates code assets to support lesson plans, student activities, and written curriculum content\\n\\n* Iterates on deliverables based on user feedback\\n\\n\\n\\n\\nRequirements\\n\\n\\n* 3+ years of hands-on Data Science industry experience&nbsp;\\n\\n* Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning\\n\\n* Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)\\n\\n* Collaborative.You enjoy partnering with people and have excellent project management skills and follow through\\n\\n* Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations\\n\\n\\n\\n\\nCompensation and Benefit\\n\\n\\n* Contract position with a collaborative team\\n\\n* Ability to work remotely with flexible hours&nbsp;\\n\\n* Access to all available course curriculum for personal use\\n\\n* Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry\\n\\n* At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nApply Here:\\n\\nhttps://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "APIITh3TSF6491Xsqlle8g",
    "url": "https://stackoverflow.com/jobs/287570/software-engineer-search-platform-wikimedia-foundation-inc?a=1yrph3USwgBG",
    "title": "Software Engineer, Search Platform at Wikimedia Foundation, Inc.  ",
    "tags": [
      "DBG:surround``2N(work, remot) 2N OR(option, allow, abl, possibl, permit)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:c/c/5",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/8",
      "DBG_TECH1:k/t/w:java/mobile/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:php/php/15",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=5, mobile=4, go=0, nodejs=0, bigdata-ml=14, ruby=0, apple=0, java=11, gamedev=0, php=15, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TECH1/php",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java",
      "php"
    ],
    "hiringOrganization": {
      "name": "Wikimedia Foundation, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 8, 2019 1:06:24 AM",
    "validThrough": "Aug 15, 2019 1:06:24 AM",
    "crawled": "Aug 8, 2019 1:06:24 AM",
    "content": "<h3><span>Software Engineer, Search Platform</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Education Technology, eLearning, Non-Profit</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                            </div>                    </div>                <div>Company: Wikimedia Foundation, Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>java</div><div>php</div><div>machine-learning</div>                <h4>Job description</h4>                <div><p><strong>Summary</strong></p><p>Our small team is passionate about making knowledge discoverable. We are responsible for Wikidata Query Service (a graph database that allows users to run arbitrary SPARQL queries on Wikidata) and for the search engine used on Wikipedia and its sister projects.</p><p>We are looking for a software engineer to help us bring the Search Platform team to the next level.</p><p>We use open-source tools as much as possible, and always open source our own work. Java, Python, PHP, and Scala make up most of our code, but we value using the right tool for the job. Our world is vast and can be complicated, so we value communication, enthusiasm, and an eagerness to learn.</p><p><strong>You are responsible for:</strong></p><ul><li>Work and communicate clearly and effectively within a small team that spans multiple time zones</li><li>Help maintain, scale, and extend query services at the Wikimedia Foundation — this includes the Wikidata Query Service (WDQS) and our Elasticsearch-based search engine</li><li>Improve the integration of Search, Wikidata Query Service, and the MediaWiki platform</li></ul><p><strong>Skills and Experience:</strong></p><ul><li>Good working knowledge of software design principles</li><li>Good understanding of how to scale applications, in terms of load, complexity, and performance</li><li>Ability to work in a Linux server environment</li><li>Write code in Java and PHP that stands the test of time</li><li>Demonstrated experience in large-scale Java applications</li><li>Be willing to travel occasionally - sometimes internationally - for team and organizational meetings</li><li>Proficient English speaker</li></ul><p><strong>Additionally, we’d love it if you have:</strong></p><ul><li>Degree in computer science, statistics, math, physics or other quantitative discipline; equivalent experience learned hands-on on the job also works</li><li>Experience with graph databases</li><li>Experience working on open source, collaborative development projects</li><li>Understanding of free culture / free software / open source principles</li><li>Exposure to applied machine learning (ML), deep learning, or natural language processing (NLP)</li><li>Familiarity with statistics</li><li>Experience with an internet software environment operating at scale; for example, messaging platforms that process hundreds of thousands of events per second</li><li>Big thumbs ups if you are a contributor to Wikipedia</li></ul><p><em>Show us your stuff! If you have any existing open-source software that you've developed (this could be your own software or patches to other packages), please share the URLs for the source. Links to GitHub, etc. are especially useful.</em>&nbsp;&nbsp;</p><p><strong>U.S. Benefits &amp; Perks*</strong></p><ul><li>Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)</li><li>The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more</li><li>The 401(k) retirement plan offers matched contributions at 4% of annual salary</li><li>Flexible and generous time off - vacation, sick and volunteer days, plus 19 paid holidays - including the last week of the year.</li><li>Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.</li><li>For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program</li><li>Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses</li><li>Telecommuting and flexible work schedules available</li><li>Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax</li><li>Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people</li></ul><p><strong><em>*Eligible international workers' benefits are specific to their location and dependent on their employer of record</em></strong></p><p><strong>More information</strong></p><p><a href='https://wikimediafoundation.org/' rel='nofollow'><strong>WMF<br></strong></a><a href='https://wikimediafoundation.org/news/' rel='nofollow'><strong>Blog<br></strong></a><a href='https://meta.wikimedia.org/wiki/Strategy/Wikimedia_movement/2017' rel='nofollow'><strong>Wikimedia 2030<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimedia_Foundation_Medium-term_plan_2019' rel='nofollow'><strong>Wikimedia Medium Term Plan<br></strong></a><a href='https://wikimediafoundation.org/2018/08/30/diversity-inclusion-numbers/' rel='nofollow'><strong>Diversity and inclusion information for Wikimedia workers, by the numbers<br></strong></a><a href='https://meta.wikimedia.org/wiki/Wikimania_2019' rel='nofollow'><strong>Wikimania 2019<br></strong></a><a href='https://annual.wikimedia.org/2017/' rel='nofollow'><strong>Annual Report - 2017</strong></a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/287570?reset=False&amp;ra=1yrph3USwgBG&amp;oqs=a%3D1yrph3USwgBG' rel='nofollow'>Apply now</a></div>            <h4>About Wikimedia Foundation, Inc.</h4>            <div><p><strong>The Wikimedia Foundation is...</strong></p><p>...the nonprofit organization that supports Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared&nbsp;knowledge,&nbsp;and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive&nbsp;<a href='https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&amp;uselang=en&amp;utm_medium=wmfWikiLink&amp;utm_source=B_FAQ&amp;utm_campaign=C_FAQ' rel='nofollow'>financial support</a>&nbsp;from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.</p><p><em>The Wikimedia Foundation is an equal opportunity employer, and we encourage people with a diverse range of backgrounds to apply.</em></p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Fully paid premiums for medical, dental &amp; vision insurance premiums</span>                            </li>                            <li>                                <span></span>                                <span>401(k) with 4% matching contribution</span>                            </li>                            <li>                                <span></span>                                <span>7-12 weeks parental leave with 100% pay + lactation room</span>                            </li>                            <li>                                <span></span>                                <span>Wellness Program ($1800 annual) to promote wellness &amp; personal growth</span>                            </li>                            <li>                                <span></span>                                <span>Pre-tax savings plans for Transportation &amp; Parking</span>                            </li>                            <li>                                <span></span>                                <span>Flexible work schedules and remote working options</span>                            </li>                            <li>                                <span></span>                                <span>Pet Friendly office</span>                            </li>                            <li>                                <span></span>                                <span>Commitment to diversity &amp; inclusion throughout the employee lifecycle</span>                            </li>                            <li>                                <span></span>                                <span>12 days vacation, 19 days holiday, 2 days volunteer work and more!</span>                            </li>                            <li>                                <span></span>                                <span>Lean more at https://wikimediafoundation.org/wiki/Work_with_us</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "p0IM97hPQ9eQxsuoHqOU9g",
    "url": "https://stackoverflow.com/jobs/287563/data-science-subject-matter-expert-thinkful-inc?a=1yrgfzf6U4wM",
    "title": "Data Science Subject Matter Expert at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:backbone.js/frontend/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/88",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:pandas/python/10",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=16, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=118, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 84000,
      "maxValue": 108000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 84k - 108k /Year"
    },
    "employmentType": "UNSET",
    "published": "Aug 7, 2019 10:30:24 PM",
    "validThrough": "Aug 14, 2019 10:30:24 PM",
    "crawled": "Aug 7, 2019 10:30:24 PM",
    "content": "<h3><span>Data Science Subject Matter Expert</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>python</div><div>machine-learning</div><div>pandas</div><div>&nbsp;thinkful.com</div>                <h4>Job description</h4>                <div><p><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow' rel='nofollow'>Please Apply Here</a></p><p>Education | Remote, USA | Contract</p><strong>Who We Are</strong>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. We provide 1-on-1 learning through our network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development, data science, and design, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit<a href='https://www.thinkful.com/' rel='nofollow'>&nbsp;thinkful.com</a>.<strong>Job Description</strong>Thinkful is launching a new immersive data science program which aims to be the best in-class remote, full-time data science program offered today. As part of this effort, we're looking for a&nbsp; data science subject matter expert to join us in executing on our content roadmap for this exciting new program. You will be creating the backbone of a new program that propels people from a background in academia and the sciences into an impactful career as Data Scientists. You'll produce written content, lesson plans including instructor notes and student activity descriptions, presentation decks, code assets, and written content, all to support our students as they learn the core skills of data science. Your work product will be extremely impactful, as it forms the core asset around which the daily experience of our students will revolve.&nbsp;<strong>Responsibilities</strong><ul><li>Consistently deliver content that meets spec and is on time to support our program launch roadmap</li><li>Create daily lesson plans consisting of&nbsp;</li><li>Presentation decks that instructors use to lecture students on a given learning objective</li><li>Instructor notes that instructors use alongside&nbsp;</li><li>Activity descriptions — these are notes describing tasks students complete together in order to advance the learning objective in a given lecture</li><li>Creates curriculum checkpoint content on specific learning objectives. In addition to the in-class experience, our students also spend time reading and completing tasks for a written curriculum hosted on the Thinkful platform</li><li>Creates code assets to support lesson plans, student activities, and written curriculum content</li><li>Iterates on deliverables based on user feedback</li></ul><strong>Requirements</strong><ul><li>3+ years of hands-on Data Science industry experience&nbsp;</li><li>Demonstrated subject matter expert in stats and probability, programming in Python, Python data science toolkit (comprised of Jupyter notebooks, Pandas, sci-kit-learn), A/B testing, supervised and unsupervised machine learning</li><li>Knowledgeable with Natural Language Processing (NLP), Big Data (Spark, Hadoop), Deep Learning/Machine Learning (keras, tensorflow)</li><li>Collaborative.You enjoy partnering with people and have excellent project management skills and follow through</li><li>Excellent writing skills. You've got a gift for writing about complicated concepts in a beginner-friendly way. You can produce high-quality prose as well as high-quality presentations</li></ul><strong>Compensation and Benefit</strong><ul><li>Contract position with a collaborative team</li><li>Ability to work remotely with flexible hours&nbsp;</li><li>Access to all available course curriculum for personal use</li><li>Membership to a global community of over 500 Software Engineers, Developers, and Data Scientists who, like you, want to keep their skills sharp and help learners break into the industry</li><li>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming<br><br></li></ul><p>Apply Here:</p><p>https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAAxHq8aIGTpRVo?trackingTag=stackOverflow</p>                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "O-ZFPj2BTaiIIpSJx-ta8A",
    "url": "https://berlinstartupjobs.com/engineering/backend-developer-borg-collective-gmbh/",
    "title": "Backend Developer // Borg Collective GmbH",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``choos 5W locat",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:django/python/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=8, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "50% remote",
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "Borg Collective",
      "sameAs": "https://hive.one"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 7, 2019 10:57:10 AM",
    "validThrough": "Aug 14, 2019 10:57:10 AM",
    "crawled": "Aug 7, 2019 11:07:24 AM",
    "content": "<h3>Backend Developer // Borg Collective</h3><div> Company:  Borg Collective <br> <br></div><div> Tags:</div><div>  <p>We are a small team building algorithms analyzing social media and the cryptocurrency space. We are trying to find ways to describe groups of people mathematically. Some groups with well defined structures are easy, such as a company, government or an army. Others are hard: such as a village, academia or an online community interested in bitcoin. We are interested in the latter.</p>  <p>We believe this project can open the doors to solving the fundamental problems in decentralized systems design.</p>  <p><strong>These will be your tasks</strong></p>  <p>As a backend developer you’ll be responsible for managing things like scheduling background tasks, building API routes for our clients, and collecting and storing data from other APIs for use in our algorithms, all the while logging and fixing errors along the way. If you like working with MVC’s transforming and moving data in creative and efficient ways, this if for you.</p>  <p>We are also constantly finding new scaling challenges as we collect more data and users and need to readjust deployment on our servers. We need to manage communication between services, backups, testing, as well as resource management such as memory.</p>  <p><strong>Skills &amp; Requirements</strong></p>  <ul>   <li>Intermediate Python</li>   <li>A history of using MVC’s like Django or Rails</li>   <li>Basic MySQL</li>   <li>Docker</li>   <li>Be the type of person who is language independent and enjoys using new tech</li>   <li>Git</li>   <li>Basic crontab</li>  </ul>  <p><strong>Bonus</strong></p>  <ul>   <li>AWS</li>   <li>NGINX</li>   <li>Kubernetes</li>   <li>Github and its services</li>  </ul>  <p><strong>We’re offering these benefits</strong></p>  <ul>   <li>Work on hard &amp; fundamental problems</li>   <li>Equity options</li>   <li>Work from home or office or a cafe (whatever you prefer!)</li>   <li>Work visa sponsorship to Germany (if you wish to relocate)</li>  </ul>  <p><strong>How we work</strong></p>  <p>We are mostly a distributed team of 5 and growing. Most of the team members are located in Europe.</p>  <ul>   <li><strong>Choose your location:</strong> It would be ideal for you to work with the team in Berlin and we are happy to sponsor a German Work Visa for you. If it is not possible for you to work from Berlin we can also offer that you work remotely.</li>   <li><strong>Regular off-sites:</strong> At least every quarter we make a point for the team to meet in person and work together for a couple of days. We typically rent a big house where we live and work for several days.</li>   <li><strong>Communication:</strong> We use the following tools at work: Slack for instant messaging Asana for task management Standup Alice (Slack bot) for weekly stand-ups 1:1 calls on per need basis</li>   <li><strong>Working time:</strong> We currently do not track your hours worked (eg. Mon-Fri 9-5) however we do expect you deliver results on tasks. We do expect that you will be available on Slack in the afternoon, Central European Time (GMT+1).</li>   <li><strong>Office:</strong> Most of us currently work remotely from home, cafés etc. and you are welcome to do the same. If you work with us in Berlin you can join us in our coworking space to get more of an “office culture”.</li>  </ul>  <p><strong>Culture of Critical Thinking</strong></p>  <p>One of the biggest risks we face is that we can fool ourselves into believing that we got something to work when we in fact did not. This is because verifying accuracy of our algorithm’s outputs takes a long time and significant infrastructure. This means that an experiment that was not well-thought through enough can lead us to wasting months of work. We cannot afford that. For this reason, it is essential that we build a culture around critical thinking and closely follow the scientific method.</p>  <p>If you are not familiar with Critical Thinking &amp; the Scientific Method, we encourage you to watch the following videos before having a chat with us:</p>  <p>Critical Thinking Course</p>  <p>Richard Feynman discussing the Scientific Method</p>  <p><strong>Big no-no’s</strong></p>  <ul>   <li>Calls to authority (“I’ve been doing this for 20 years and you’re just an intern, we’ll do it my way”; “world’s top experts agree that…”)</li>   <li>Discrediting ideas based on their public perception (“If you think that you are a X, Y, Z”)</li>  </ul>  <p>Please include your GitHub account or some kind of portfolio of works within your CV/resume.</p> </div><a href='https://hive.join.com/jobs/292604-backend-developer?pid=98c1261599ca17c51388&amp;utm_source=berlinstartupjobs&amp;utm_medium=paid&amp;utm_campaign=singlepostingstandard&amp;utm_content=backenddeveloper' rel='nofollow'>Apply for this position</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zFgtA6SRRkqYy2JGFAGa_Q",
    "url": "https://jobmote.com/job/57726/remote-machine-learning-engineer-retail-domain/",
    "title": "REMOTE - Machine Learning Engineer - Retail Domain",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/18",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 10:07:24 PM",
    "validThrough": "Aug 9, 2019 10:07:24 PM",
    "crawled": "Aug 7, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>Machine Learning/Data Science, retail domain experience, Python, R, Inventory Optimization, Deep Neural Networks (DNN), TensowFlow, Machine Learning Algorithms, Order Management/fulfillment systems, Cloud Platforms: AWS/GCP/Azure<br><br>If you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please read on!<br><br>Top Reasons to Work with Us<br><br>We are a technology consulting firm specializing in delivering High Performing Omni Channel Fulfillment solutions to the retail vertical. We are passionate about building best of breed enterprise applications, keen on bringing top-notch technical insight to solving business problems that is focused on customer's success by operating with integrity and building a long term relationship. Our consultants are seasoned battle-tested engineers with many years of real-world experience.<br><br>What You Will Be Doing<br><br>You will be working remote to help build and scale our internal omni-channel fulfillment platform. This will involve utilizing machine learning algorithms and standing up machine learning platforms in the cloud. We are looking for someone who can both be hands on and be involved in over-arching architectural decisions.<br><br>What You Need for this Position<br><br>MUST HAVE:<br>- BS in related field<br>- 3+ years of machine learning/data science experience<br>- Strong Retail/E-Commerce industry experience<br>- Deep Neural Networks (DNN)<br>- Tensorflow<br>- Python/R<br>- Experience with machine learning algorithms<br>- Cloud services: AWS, GCP, or Azure<br>- Order Management/fulfillment systems or Inventory Optimization<br><br>What's In It for You<br><br>- Competitive Salary DOE<br>- Comprehensive Benefits Package<br>- Generous PTO<br>- 401k with match<br>- REMOTE WORK!So, if you are a REMOTE - Machine Learning Engineer - Retail Domain with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "SvTvvs5vRmOMIsqLmkiEhQ",
    "url": "https://jobmote.com/job/57697/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 10:07:23 PM",
    "validThrough": "Aug 9, 2019 10:07:23 PM",
    "crawled": "Aug 7, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience as a Data Scientist</li><li>Strong ability to talk through findings and algorithms?</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "351fh48jRmu2TtWlHNpPxA",
    "url": "https://remoteok.io/jobs/74364",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Xapo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 9:28:52 PM",
    "validThrough": "Aug 13, 2019 9:28:52 PM",
    "crawled": "Aug 6, 2019 9:30:29 PM",
    "content": "<span></span> <span><h4>Xapo</h4></span> <br> <h3>Data Engineer</h3> <div>  <div>   BALANCE FOR BETTER&nbsp;\\nAt Xapo, we embrace our differences and actively foster an inclusive environment where we all can thrive. We’re a flexible, family-friendly environment, and we recognize that everyone has commitments outside of work. We have a goal of reaching gender parity and strongly encourage women to apply to our open positions. Diversity is not a tagline at Xapo; it is our foundation.\\n\\nRESPONSIBILITIES\\n\\n\\n\\n* Design and build data structures on MPP platform like AWS RedShift and or Druid.io.\\n\\n* Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.\\n\\n* Translate complex business requirements into scalable technical solutions.\\n\\n* Strong understanding of analytics needs.\\n\\n* Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.\\n\\n* Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.\\n\\n\\n\\n\\nREQUIREMENTS\\n\\n\\n* In-depth understanding of data structures and algorithms.\\n\\n* Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.\\n\\n* Experience in designing and developing ETL data pipelines.\\n\\n* Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.\\n\\n* Programming experience in building high-quality software. Skills with Python or Scala preferred.\\n\\n* Strong analytical and communication skills.\\n\\n\\n\\n\\nNICE TO HAVE SKILLS\\n\\n\\n* Work/project experience with big data and advanced programming languages.\\n\\n* Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.\\n\\n* Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).\\n\\n* Experience with or advanced courses on data science and machine learning.\\n\\n\\n\\nOTHER REQUIREMENTS\\n\\n\\n\\nA dedicated workspace.&nbsp;\\n\\n\\nA reliable internet connection with the fastest speed possible in your area.\\n\\n\\nDevices and other essential equipment that meet minimal technical specifications.\\n\\n\\nAlignment with Our Values.\\n\\n\\n\\nWHY WORK FOR XAPO?\\n\\n\\n\\nShape the Future:&nbsp;Improve lives through cutting-edge technology, work remotely from anywhere in the world\\n\\n\\nOwn Your Success:&nbsp;Receive attractive remuneration, enjoy an autonomous work culture and flexible hours, apply your expertise to meaningful work every day\\n\\n\\nExpect Excellence:&nbsp;Collaborate, learn, and grow with a high performance team.\\n\\n\\n  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kZ466qXOQFyvhdtCT0Aa2w",
    "url": "https://remote.co/job/tech-lead-senior-software-engineer/",
    "title": "Tech Lead – Senior Software Engineer",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:django/python/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=15, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=12}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Sourceress",
      "sameAs": "https://www.sourceress.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 6:31:59 PM",
    "validThrough": "Aug 13, 2019 6:31:59 PM",
    "crawled": "Aug 6, 2019 7:32:18 PM",
    "content": "<h3>Tech Lead – Senior Software Engineer at <span>Sourceress</span></h3><div><span><i></i> Remote</span>         | <span> International </span></div><div>            <p><strong>REMOTE</strong></p><p><strong>ENGINEERING</strong></p><p><strong>FULL-TIME</strong></p><p><strong>About the role</strong></p><p>As a senior software engineer, you’ll focus on owning projects from end to end. We’ll work to shield you from all other responsibilities and meetings so that you can maximally focus on solving a variety of interesting technical and business challenges.</p><p>We’re planning to double in size for each of the next two years. Fast-growing companies are often constrained by their ability to find or cultivate internal leaders (both purely technical leaders and people leaders). Accordingly, you’ll have significant autonomy in determining your projects, their requirements, and their architectures.</p><p>We’re exceptionally remote-friendly: about half of our team is remote, our San Francisco office has “portals” (a large TV, high quality microphone, and webcam) in every well-trafficked room, and remote team members even participate in lunch conversations, our book clubs, and our AI research club.</p><p><strong>About Sourceress</strong></p><p>Our mission is to help people find work that matters. We believe that the world is better when people understand the opportunities available to them. Our human-assisted AI platform delivers great results to our customers (customer quote: “I’d have a panic attack if you guys stopped existing”).</p><p>Because of this, we raised $3.5M from OpenAI researchers and Lightspeed Venture Partners at one of the highest ever valuations coming out of YC. Our team has previously sold companies, published machine learning research, has Dropbox’s former Chief of Staff, and hails from MIT, Google, Airbnb, McKinsey, etc.</p><p>Help us create a world where all 7 billion people work at jobs that they love, do things that they’re great at, and work for companies that are solving meaningful problems.</p><p><strong>Responsibilities</strong></p><ul><li>Solve the most important problems facing the business (generally by writing software, but not always!)</li><li>Minimize the complexity of the software that we create and maintain.</li><li>Continually improve your own software engineering skills (whether via side projects, classes, or whatever else works for you)</li><li>Help develop our team of talented engineers by mentoring, collaborating on projects and providing detailed code / architecture reviews.</li></ul><p><strong>Sample projects</strong></p><ul><li>For detail-oriented engineers that love to build beautiful and highly correct products: we have greenfield customer-facing product work. These users depend on and love Sourceress, and are eager to help improve the product and provide feedback to your work.</li><li>For engineers that love rapid prototyping and hate CSS: we have a variety of products for our highly-trained internal contracting team. These are critical to the magical feeling of our product and often require creative solutions and complex interfaces.</li><li>For engineers who love data, systems, and infrastructure: we’re also building a distributed model training and model scoring system. Because we care about all of the candidates in the world, we run into quite interesting infrastructure scaling problems that most startups would not hit they were much larger. As a result, a relatively small number of engineers get to solve “large” infrastructure problems end-to-end.</li><li>For engineers interested in machine learning, we have a variety of interesting problems touching a huge variety of sub-fields: NLP, deep learning, interpretability, fairness, graph-based learning, entity resolution, and much more are all relevant to our work. Engineers without prior experience but interest in learning can and will be taught the relevant skills.</li><li>For those engineers who care about clean code, developer tooling and productivity: we pride ourselves on exceptional developer tooling, and are constantly investing in our internal tools. For example: we’ve created a method that that allows us to attach a debugger to any process that has encountered an unexpected exception, <em>even in production</em>. This tool (we call it the Platinum Debugger) eliminates the time-consuming and often difficult step of reproducing the bug for about 90% of our bugs, vastly improving our productivity.</li></ul><p><strong>Requirements</strong></p><ul><li>3+ years of software engineering experience.</li><li>You’re an effective executor. You understand both the value of shipping quickly and of software craftsmanship, and have the judgment to know when to apply each. You’re capable, focused, and productive.</li><li>You’re cognizant of the multi-year consequences of your decisions.</li><li>You’r dependable. You do high-quality work, on time.</li><li>You’re incredibly smart.</li></ul><p><strong>Stack</strong></p><ul><li>Typescript (react)</li><li>Type-annotated Python 3 (django, scikit-learn, pytorch)</li><li>PostgreSQL</li><li>AWS</li></ul>        </div><div>        <a href='https://jobs.lever.co/sourceress/496094d0-1cb6-4b64-b59b-c6fdf0914709' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "_V5foCEWTCC7t6SOC0EjmQ",
    "url": "https://stackoverflow.com/jobs/287228/data-engineer-xapo?a=1ykinKqMHTjy",
    "title": "Data engineer at Xapo  ",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(you,we,employe,develop,engin,abl,workmat) 2W work 2W from 2W home",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Xapo",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 6, 2019 4:06:25 PM",
    "validThrough": "Aug 13, 2019 4:06:25 PM",
    "crawled": "Aug 6, 2019 4:06:25 PM",
    "content": "<h3><span>Data engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Senior</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Banking, Cryptocurrency, Financial Technology</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>201–500 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Xapo | No office location<br></div><h4>Technologies</h4><div></div><div>sql</div><div>amazon-web-services</div><div>etl</div>                <h4>Job description</h4>                <div><span><strong><span>BALANCE FOR BETTER</span></strong></span>&nbsp;<span>At Xapo, we embrace our differences and actively foster an inclusive environment where we all can thrive. We’re a flexible, family-friendly environment, and we recognize that everyone has commitments outside of work. We have a goal of reaching gender parity and strongly encourage women to apply to our open positions. Diversity is not a tagline at Xapo; it is our foundation.</span><span><strong>RESPONSIBILITIES<br></strong></span><ul><li><span>Design and build data structures on MPP platform like AWS RedShift and or Druid.io.</span></li><li><span>Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.</span></li><li><span>Translate complex business requirements into scalable technical solutions.</span></li><li><span>Strong understanding of analytics needs.</span></li><li><span>Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.</span></li><li><span>Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.</span></li></ul><p><span><strong><span>REQUIREMENTS</span></strong></span></p><ul><li><span>In-depth understanding of data structures and algorithms.</span></li><li><span>Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.</span></li><li><span>Experience in designing and developing ETL data pipelines.</span></li><li><span>Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.</span></li><li><span>Programming experience in building high-quality software. Skills with Python or Scala preferred.</span></li><li><span>Strong analytical and communication skills.</span></li></ul><p><span><strong>NICE TO HAVE SKILLS</strong></span></p><ul><li><span>Work/project experience with big data and advanced programming languages.</span></li><li><span>Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.</span></li><li><span>Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).</span></li><li><span>Experience with or advanced courses on data science and machine learning.</span></li></ul><span><strong><span>OTHER REQUIREMENTS</span></strong></span><ul><span>A dedicated workspace.&nbsp;</span><span>A reliable internet connection with the fastest speed possible in your area.</span><span><span>Devices and other essential equipment that meet minimal technical specifications.</span></span><span><span>Alignment with Our Values.</span></span></ul><span><strong><span>WHY WORK FOR XAPO?</span></strong></span><ul><span><strong><span>Shape the Future:</span></strong><span>&nbsp;Improve lives through cutting-edge technology, work remotely from anywhere in the world</span></span><span><strong><span>Own Your Success:</span></strong><span>&nbsp;Receive attractive remuneration, enjoy an autonomous work culture and flexible hours, apply your expertise to meaningful work every day</span></span><span><span><strong>Expect Excellence:</strong>&nbsp;</span><span>Collaborate, learn, and grow with a high performance team.</span></span></ul>                </div>            <div>        <a href='https://xapo.bamboohr.com/jobs/view.php?id=69' rel='nofollow'>                        Apply now        </a></div>            <h4>About Xapo</h4>            <div><p>Xapo is a global financial technology company built on bitcoin &amp; blockchain with a mission to enable anyone, anywhere to take control of their money. Founded in 2013 by International Entrepreneur Wences Casares (CEO) &amp; Federico Murrone (COO), Xapo has made an unparalleled investment in security infrastructure, assembled a renowned advisory board, recruited a world class team, and raised $40M from top venture capital firms in Silicon Valley &amp; the world. Are you a self-starter who shares our passion for harnessing cutting-edge technologies to impact the lives of people globally? Do you dream of growing your career at a tech startup, while not sacrificing your work-life balance? Do you wish for a job that allows you to work from home, or anywhere else in the world that you need or want to be? Are you searching for a company that appreciates your individuality, and recognizes that we all have personal and family obligations outside of work? If so, Xapo may be the place for you! Xapo employs a global, remote workforce in over fifty countries. We hire great people – and in exchange, we offer autonomy, flexibility, meaningful work, a collaborative team environment, and top tier compensation. Do the best work of your career at Xapo - and still have the time to enjoy all of life’s special moments! &nbsp; We are seeking a&nbsp;Senior Growth Data Engineer&nbsp;to join our global team. This full-time position is planned to be remote, meaning you can work from anywhere!<br><strong><br>WHY WORK FOR XAPO?</strong></p><ul><li>Attractive compensation.</li><li>Work remotely from anywhere in the world.</li><li>Collaborate, learn, and grow with a diverse, global team.</li><li>Achieve balance with our autonomous work culture and flexible hours.</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Attractive compensation &amp; equity opportunities</span>                            </li>                            <li>                                <span></span>                                <span>Remote job - work from anywhere in the world!</span>                            </li>                            <li>                                <span></span>                                <span>Flexible working hours</span>                            </li>                            <li>                                <span></span>                                <span>Autonomous work environment</span>                            </li>                            <li>                                <span></span>                                <span>Generous vacation plan</span>                            </li>                            <li>                                <span></span>                                <span>Paid leave for new parents</span>                            </li>                            <li>                                <span></span>                                <span>Collaborate with a global team across 50 countries!</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "RuCUxjZpTya46XCXrRAIgw",
    "url": "https://jobmote.com/job/57548/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:20 PM",
    "validThrough": "Aug 8, 2019 10:07:20 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "-BOKQ-kLQgKAA7j4Q45v6g",
    "url": "https://jobmote.com/job/57560/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Tlzt8gC0R-eEhYttr8VrOg",
    "url": "https://jobmote.com/job/57559/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics/Data Statistics/Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Data Analytics/Data Statistics/Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analytics/Data Statistics/Actuarial Scientist will be responsible for the following:</p> <ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection&nbsp;</li> <li>Seeking new learning from the collected data</li> <li>Taking advantage of the increasing amount of data collected from the company's new products</li> <li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li> <li>Anticipating, identifying and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>Must reside within a three hour drive of Madison, Wisconsin</li> <li>Five years of experience</li> <li>Strong ability to talk through findings and algorithms&nbsp;</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li> <li>SQL relational database experience</li> <li>Data visualization experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> </ul><p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ApveJj95RIS5A-Qe0CiOoA",
    "url": "https://jobmote.com/job/57558/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p>&nbsp;</p> <p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pz9nb0VMQOuoiyvbusQzTA",
    "url": "https://jobmote.com/job/57557/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 10:07:21 PM",
    "validThrough": "Aug 8, 2019 10:07:21 PM",
    "crawled": "Aug 6, 2019 3:06:25 AM",
    "content": "<div><p>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.&nbsp; If the successful candidate prefers to be onsite, that is also welcomed.&nbsp; The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.&nbsp;&nbsp;IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.&nbsp; The company has a history of promoting from within.</p> <p>&nbsp;</p> <p>The successful Data Analyst will be responsible for the following:</p> <ul><li>Leveraging new data collection processes and sources</li> <li>Developing and deploying innovative methods, models, and algorithms</li> <li>Utilizing statistics, algorithms, data mining, and visualization</li> <li>Interacting with all levels</li> <li>Working with Data Scientist (s) and the Product Development employees</li> <li>Anticipating, identifying, and investigating data trends</li> <li>Discovering actionable insights</li> <li>Identifying business opportunities</li> <li>Designing presentations for decision makers</li> <li>Identifying data sources</li> </ul><p>&nbsp;</p> <p>Candidates will have a minimum background consisting of the following:</p> <ul><li>A Wisconsin residence</li> <li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li> <li>SQL and relational database experience</li> <li>Data visualization tool experience</li> <li>Data analysis programming language experience</li> <li>Statistical software experience</li> <li>ETL knowledge</li> <li>Strong visual presentation skills</li> <li>An innovative mindset</li> </ul><p>&nbsp;</p> <p> <strong>Preferred</strong> but <strong>not required</strong> backgrounds will include <strong> any </strong> of the following:&nbsp;</p> <ul><li>Insurance industry experience</li> <li>Tableau experience</li> <li>Power BI experience</li> <li>SQL Server experience</li> <li>SSRS, Performance Point experience</li> <li>Python experience</li> <li>Algorithm &nbsp;experience</li> <li>AWS Cloud service experience EC2 experience</li> <li>RDS experience S3 experience</li> </ul><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Dnrn39rlS4-TjdmWTJ2a2A",
    "url": "https://news.ycombinator.com/item?id=20612109",
    "title": "Kalepa | Software Engineers | New York City, NY | ONSITE / PARTIAL REMOTE, VISA Kalepa is a New ...",
    "tags": [
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 5, 2019 9:46:05 AM",
    "validThrough": "Aug 12, 2019 9:46:05 AM",
    "crawled": "Aug 5, 2019 11:07:10 AM",
    "content": "Kalepa | Software Engineers | New York City, NY | ONSITE / PARTIAL REMOTE, VISA<p>Kalepa is a New York based, VC backed, startup building software to transform and disrupt the $1T commercial insurance market.</p><p>Engineers at Kalepa will be solving interesting and challenging problems at the intersection of big data pipelines, cutting-edge machine learning models, intuitive frontend apps, and robust infrastructure. You will be working in a small team building technology from the ground up with the latest stack.</p><p>One trillion dollars are spent globally each year on commercial insurance. However, the process for estimating the risk associated with a given business across various perils is still reliant on inefficient and inaccurate forms and research. This information asymmetry leads to a broken set of incentives and a poor experience for both businesses and insurers alike. By combining cutting edge data science, enterprise software, and insurance expertise, Kalepa is delivering precision underwriting at scale. Kalepa is turning real-world data into a complete understanding of risk.</p><p>Kalepa is led by a strong team with experiences from Facebook, APT (acquired by Mastercard for $600M in 2015), the Israel Defense Forces, MIT, Berkeley, and UPenn. We are backed by IA Ventures.</p><p>More details here: <a href='https://angel.co/company/kalepa/jobs/460333-software-engineer' rel='nofollow'>https://angel.co/company/kalepa/jobs/460333-software-enginee...</a></p><p>Contact: paul.monasterio@kalepa.co</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "i_xp-LKSStq-EVLiycoO_A",
    "url": "https://jobmote.com/job/56486/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:23 PM",
    "validThrough": "Aug 7, 2019 10:07:23 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XxXdP7T-RjqxMODCEDKBsA",
    "url": "https://jobmote.com/job/56467/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Eliassen Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out the foundation platform around Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions.<br><b>Responsibilities/Skills:</b><br><ul><li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption</li> <li>Build Back end applications using Java, Spark/Scala, Python</li> <li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda</li> <li>Work on performance optimizations on Hbase and Solr</li> <li>Work on Performance optimization on Spark Jobs and MapReduce jobs</li> <li>Ability to debug complex production scenarios</li> <li>Master?s degree in Computer Science, Management Information Systems #eg1989</li> </ul> For immediate consideration, email your updated resume to Dan Malta at [Click Here to Email Your Resum?] <br> Job ID: 321205<br><b>About Eliassen Group:</b><br> Eliassen Group provides strategic talent solutions to drive our clients? innovation and business results. Leveraging over 30 years of success, our expertise in IT staffing, Agile consulting, creative services, managed services, and life sciences enables us to partner with our clients to execute their business strategy and scale effectively. Headquartered in Reading, MA and with offices from coast to coast, Eliassen Group offers local community presence, deep networks, as well as national reach. For more information, visit .<br> Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.<br> Don?t miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a <b><em> $1,000 referral check !</em></b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j1C6VL4oR3KPcdgZbVXY8w",
    "url": "https://jobmote.com/job/56468/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.<br><br>?<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>?<br><br>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul>?<br><br><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em> any </em></b> of the following:?<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm ?experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TCCX4f3tToWrOc-Md4oy5g",
    "url": "https://jobmote.com/job/56449/remote-data-analyst/",
    "title": "Remote Data Analyst",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 4, 2019 10:07:22 PM",
    "validThrough": "Aug 7, 2019 10:07:22 PM",
    "crawled": "Aug 5, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Remote Data Analyst career opportunity can be remote as the company is very employee-oriented and family-oriented. If the successful candidate prefers to be onsite, that is also welcomed. The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure. IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day. The company has a history of promoting from within.<br><br>The successful Data Analyst will be responsible for the following:<ul><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms</li><li>Utilizing statistics, algorithms, data mining, and visualization</li><li>Interacting with all levels</li><li>Working with Data Scientist (s) and the Product Development employees</li><li>Anticipating, identifying, and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li><li>Designing presentations for decision makers</li><li>Identifying data sources</li></ul>Candidates will have a minimum background consisting of the following:<ul><li>A Wisconsin residence</li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Engineering, Mathematics, or equivalent experience</li><li>SQL and relational database experience</li><li>Data visualization tool experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li><li>Strong visual presentation skills</li><li>An innovative mindset</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em>any</em></b> of the following:<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "LTKZjw6gR1yxd98M7y4lLw",
    "url": "https://jobmote.com/job/56412/budget-business-data-analyst-remote-offsite/",
    "title": "Budget- Business Data Analyst-Remote (Offsite)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "US Information Technologies Corporation",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:24 PM",
    "validThrough": "Aug 6, 2019 10:07:24 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div>Budget- Business Data Analyst-Remote (Offsite) Location: <b>Chantilly, VA </b> Job Code: <b>899 </b> # of openings: <b>5 </b> Description<br><br>POSITION: Remote Budget - Business Data Analyst- (Offsite) Cleared<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Full-Time (40 hours per week)<br><br>Location: Remote (Offsite) Preference will be given to candidates close to the DC area.<br><br>Fully Funded Position<br><br>Length: 3 years<br><br>Required:<br><br>Active Secret or NACLC -CLEARANCE Required<br><br>Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Education: BA or BS Degree<br><br>Descriptive Job Title: Candidate Experience Level:<br><br>Business Data Analyst I (Off-Site) Entry to Mid-Level 1 to 5 years experience)<br><br>2 years experience requested.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Enterprise Business Financial Support Services- Business Data Analyst- DLA<br><br>Enterprise Systems<br><br>Government Agency, collecting and organizing information user manuals, training materials, installation guides, proposals, and reports.<br><br>Edits functional descriptions, system specifications, user manuals, special reports, performing financial and administrative tasks. preparing and/or maintaining systems, programming, and operations documentation, procedures and methods.<br><br>Maintains a current internal documentation library. Provides or coordinates special documentation services as required.<br><br>Position:<br><br>Provides support in collecting and organizing information required for preparation of user manuals, training materials, installation guides, proposals, and reports. Edits functional descriptions, system specifications, user manuals, special reports, or any other customer deliverables and documents. Provides support in performing financial and administrative tasks. Under general supervision, is responsible for preparing and/or maintaining systems, programming, and operations documentation, procedures and methods. Maintains a current internal documentation library. Provides or coordinates special documentation services as required.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><b>Must have experience in working with DOD Lifecycle management, DOD 5000.1, 5000.2, DODI 5000.02, and Guidebook. Must be in your Resume </b><br> Two (2) years experience in similar taskings.<br> Specialized experience in assembling technical documents and providing a detailed analysis of various business system functions.<br> Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Must have experience with the following programs:<br> MS Suite<br> Word<br> Excel<br> Access<br> Project Management<br> PowerPoint<br><br>Must possess IT-II security clearance or have a current National Agency Check with Local Agency Check and Credit Check (NACLC) at time of proposal submission.<br><br>Active Secret or NACLC Required<br><br>1. Collecting and organizing information<br><br>2. Prepares User manuals, training materials, installation guides, proposals, and reports.<br><br>3. Edits functional descriptions, system specifications, user manuals, special reports,<br><br>4. Performing financial and administrative tasks.<br><br>5. Preparing and/or maintaining systems, programming, and operations documentation, procedures and methods.<br><br>6. Maintains a current internal documentation library.<br><br>7. Provides or coordinates special documentation services as required.<br><br>Minimum Experience: Must be referenced in your resume to be considered.<br><br>Active Secret or NACLC -CLEARANCE Required<br><br>USIT values celebrates and enacts diversity in the workplace. USIT takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans and other protected veterans. EOE/AA/M/F/Veteran/Disability <br> USIT is an Equal Opportunity Employer (EOE). USIT provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran or disabled status. <br><b>USIT participates in E-Verify. </b><br><br>#DICE <br> #indeed <br> #CJ<br><br>USIT is an Equal Opportunity Employer (EOE). USIT provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran or disabled status. Previous Applicants: Email: Password:<br><br>If you do not remember your password click here .<br><br>Back to Search Results<br><br>New Search<br><br>- provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tdI551QKQzyowkSbfbEttQ",
    "url": "https://jobmote.com/job/56407/developer-servicenow-portal-remote/",
    "title": "Developer-ServiceNow-Portal - Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Insight Enterprises, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div><strong>Requisition Number: 73189</strong> <br><br><strong>ServiceNow-Core &amp; Portal - Remote</strong> <br><br> Insight is seeking a ServiceNow Developer with Core &amp; Portal experience. This is an opportunity where you can work 100% remote. <ul><li>Extensive knowledge of developing the ServiceNow platform.</li><li>Strong understanding of the core ITSM applications within ServiceNow along with enough understanding of the range of offered applications to speak intelligently to their use.</li><li>Excellent understanding of the ways in which ServiceNow can be configured and customized and scripting within the tool.</li><li>Knowledge of how to assess the performance of a ServiceNow environment, how to diagnose performance problems, and best practices for improving performance.</li><li>Strong communication skills, both written and verbal.</li><li>Work with business users to identify and refine business requirements and workflows.</li><li>Experience of implementing data loads into ServiceNow.</li><li>Experience of implementing inbound and outbound API integrations with ServiceNow.</li><li>Experience of implementing catalog items and workflows within ServiceNow.</li><li>Experience of implementing the Service Portal on ServiceNow.</li><li>Develop clear and concise technical and process documentation, making use of the knowledgebase module within ServiceNow.</li><li>Ensure adherence to all ITIL processes.</li><li>Identify, train and communicate best practices related to ServiceNow development and usage to customers and employees</li> </ul><strong>Desired Skills</strong> <ul><li>Bachelor's degree or Associate Degree</li><li>ServiceNow Developer / Administration Certification</li><li>At least 2+ years of experience in ServiceNow Platform Implementation.</li><li>Experience in working a large scale development work on ServiceNow</li><li>Experience in IT Service management Implementation of ServiceNow.</li><li>Ability to successfully work remotely</li> </ul> The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here. <br><br> Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com. <ul><li>Founded in 1988 in Tempe, Arizona</li><li>7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe</li><li>$7.1 billion in revenue in 2018</li><li>Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500</li><li>2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year</li><li>Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)</li><li>Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance</li> </ul> Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com. <br><br> Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law. <br><br> Posting Notes: Chicago || Illinois (US-IL) || United States (US) || None || None || Remote ||</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "INuZJpkMRvaI6vpx-u9KJA",
    "url": "https://jobmote.com/job/56389/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "3mkmxyhSSyG2qsOs1Lt5Lg",
    "url": "https://jobmote.com/job/56386/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "go",
      "python"
    ],
    "hiringOrganization": {
      "name": "Job Juncture",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 10:07:23 PM",
    "validThrough": "Aug 6, 2019 10:07:23 PM",
    "crawled": "Aug 4, 2019 3:06:25 AM",
    "content": "<div>This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented. If the successful candidate prefers to be onsite, that is also welcomed. The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure. IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day. The company has a history of promoting from within.<br><br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:<ul><li>Seeking case studies, behavioral reports and new learning from sensor data collection </li><li>Seeking new learning from the collected data</li><li>Taking advantage of the increasing amount of data collected from the company's new products</li><li>Leveraging new data collection processes and sources</li><li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li><li>Anticipating, identifying and investigating data trends</li><li>Discovering actionable insights</li><li>Identifying business opportunities</li></ul>Candidates will have a minimum background consisting of the following:<ul><li>Must reside within a three hour drive of Madison, Wisconsin</li><li>Five years of experience</li><li>Strong ability to talk through findings and algorithms </li><li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li><li>SQL relational database experience</li><li>Data visualization experience</li><li>Data analysis programming language experience</li><li>Statistical software experience</li><li>ETL knowledge</li></ul><em><b>Preferred</b></em> but <em><b>not required</b></em> backgrounds will include <b><em>any</em></b> of the following:<ul><li>Insurance industry experience</li><li>Tableau experience</li><li>Power BI experience</li><li>SQL Server experience</li><li>SSRS, Performance Point experience</li><li>Python experience</li><li>Algorithm experience</li><li>AWS Cloud service experience EC2 experience</li><li>RDS experience S3 experience</li></ul></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6zhiqTveSG6IHbAIRZLTcg",
    "url": "https://jobmote.com/job/56255/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 10:07:26 PM",
    "validThrough": "Aug 5, 2019 10:07:26 PM",
    "crawled": "Aug 3, 2019 3:06:26 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tMy9wgcLRPidltjZsJ0QRg",
    "url": "https://jobmote.com/job/56243/hadoop-administrator-l2-engineer-role-100-remote/",
    "title": "Hadoop administrator ( L2 engineer role )100% Remote",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/120",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=2, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=120, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Everest Consulting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 10:07:26 PM",
    "validThrough": "Aug 5, 2019 10:07:26 PM",
    "crawled": "Aug 3, 2019 3:06:26 AM",
    "content": "<div><p> <br>Deploying a hadoop cluster, maintaining a hadoop cluster, adding and removing nodes using cluster monitoring tool Cloudera Manager, configuring and upgrading the cloudera manager,cdh,cdsw and kafka etc</p> <p> <br>Role : L2 engineer role .</p> <p>2. Implementing, managing and administering the overall hadoop infrastructure.<br>3. Takes care of the day-to-day running of Hadoop clusters<br>4. A hadoop administrator will have to work closely with the database team, network team, BI team and application teams to make sure that all the big data applications are highly available and performing as expected.<br>5. If working with open source Apache Distribution then hadoop admins have to manually setup all the configurations- Core-Site, HDFS-Site, YARN-Site and Map Red-Site.<br>6. However, when working with hadoop distribution like Cloudera the configuration files are setup on startup and the hadoop admin need not configure them manually.<br>7. Hadoop admin is responsible for capacity planning and estimating the requirements for lowering or increasing the capacity of the hadoop cluster.<br>8. Hadoop admin is also responsible for deciding the size of the hadoop cluster based on the data to be stored in HDFS.<br>9. Ensure that the hadoop cluster is up and running all the time.<br>10. Monitoring the cluster connectivity and performance.<br>11. Manage and review Hadoop log files.<br>12. Backup and recovery tasks<br>13. Resource and security management<br>14. Troubleshooting application errors and ensuring that they do not occur again.<br>15. Assisting users on connectivity for various tools like tableau,alteryx,talend and powerbi.<br>16. CDSW upgrade,administration and monitoring<br>17. KAFKA upgrade,administration and monitoring - is managed by datascientists as of now<br>18. Shell scripting and automation.<br>19. Knowledge of python</p> <p> </p> <p>Reach:</p> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "D5yvTLslSLWAvTPtQantLA",
    "url": "https://remoteok.io/jobs/74307",
    "title": "Data Science Course Mentor",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 3, 2019 12:55:16 AM",
    "validThrough": "Aug 10, 2019 12:55:16 AM",
    "crawled": "Aug 3, 2019 1:06:30 AM",
    "content": "<span></span> <span><h4>Thinkful</h4></span> <br> <h3>Data Science Course Mentor</h3> <div>  <div>   Click here to apply\\n\\nWho We Are \\nAt Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;\\n\\nWe put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;\\n\\n\\nThe Position\\nAt Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;\\n\\nWe put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;\\n\\nStudents enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed technologists. As a Course Mentor, you will support students by acting as an advisor, counselor, and support system as they complete the course and land their first industry job. To achieve this, you will engage with students using the below range of approaches, known as Engagement Formats. Course Mentors are expected to provide support across all formats when needed.&nbsp;\\n\\n\\n\\n* Mentor Sessions: Meet with students 1-on-1 in online video sessions to provide technical and professional support as the student progresses through the curriculum.\\n\\n* Group Sessions: Host online video sessions on topics of your expertise (in alignment with curriculum offerings) for groups of student seeking live support between mentor sessions.&nbsp;\\n\\n* Grading: Reviewing student checkpoints submissions and delivering written feedback, including analysis of projects and portfolios.&nbsp;\\n\\n* Technical Coaching: Provide in-demand support to technical questions and guidance requests that come to the Technical Coaching team through text and video in a timely manner. This team also provides the TA support for immersive programs.&nbsp;\\n\\n* Assessments &amp; Mock Interviews: Conduct 1-on-1 mock interviews and assessments via video calls and provide written feedback to students based on assessment rubrics.&nbsp;\\n\\n\\n\\n\\nIn addition to working directly with students, Course Mentors are expected to maintain an environment of feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.\\n\\nRequirements\\n\\n\\n* Minimum of 1 year professional experience as a Data Scientist or demonstrated expertise with data visualizations and machine learning at an industry level\\n\\n* Proficiency in SQL, Python\\n\\n* Professional experience with Hadoop and Spark a plus\\n\\n* Excellent written and verbal communication\\n\\n* High level of empathy and people management skills\\n\\n* Must have a reliable, high-speed Internet connection\\n\\n\\n\\n\\nBenefits\\n\\n\\n* This is a part-time role (10-25 hours a week)\\n\\n* Fully remote position, with the option to work evenings and weekends in person in 22 US cities\\n\\n* Community of 500+ like-minded Educators looking to impact others and keep their skills sharp\\n\\n* Full access to all of Thinkful Courses for your continued learning\\n\\n* Grow as an Educator\\n\\n\\n\\n\\nApply\\nIf you are interested in this position please provide your resume and a cover letter explaining your interest in the role.\\n\\nThinkful can only hire candidates who are eligible to work in the United States.\\n\\nWe stand against any form of workplace harassment based on race, color, religion, sexual orientation, gender identity or expression, national origin, age, disability, or veteran status. Thinkful provides equal employment opportunities to all employees and applicants. If you're talented and driven, please apply.\\n\\nAt this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming\\n\\n\\nClick here to apply&nbsp;  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F6lztxZfQf--xM3CJQg-oQ",
    "url": "https://stackoverflow.com/jobs/286543/senior-data-scientist-remote-global-wallethub?a=1y63jbW3HY9a",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 9:30:24 PM",
    "validThrough": "Aug 9, 2019 9:30:24 PM",
    "crawled": "Aug 2, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Personal Finance</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: Wallethub | No office location<br></div><h4>Technologies</h4><div></div><div>machine-learning</div><div>r</div><div>java</div><div>python</div>                <h4>Job description</h4>                <div><p><strong>Company details</strong></p><p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p><p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p><p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p><p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p><p>Such goals include:</p><ul><li>Selecting the best financial products for your needs</li><li>Taking the right actions to improve your credit score</li><li>Anticipate your future financial health based on your current financial status and history</li></ul><p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p><p><strong>Requirements</strong></p><p>You are the ideal candidate for this job if you have:</p><ul><li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li><li>At least 5 years of experience as a Data Scientist.</li><li>Experience with databases (including NoSQL)</li><li>Experience in machine learning frameworks and libraries</li><li>Supervised and Unsupervised learning</li><li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li><li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li><li>Computer Science or Mathematics or Physics degree</li><li>Excellent communication and analytical skills</li><li>Willingness to work hard (50 hrs per week)</li><li>Very good English</li></ul><p><strong>Nice to have but not required</strong></p><ul><li>Experience with Apache Spark</li><li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li><li>R programming language</li></ul><p><strong>Responsibilities</strong></p><ul><li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li><li>Participating in the areas of architecture, design, implementation, and testing</li><li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li><li>Designing experiments, testing hypotheses, and building models</li><li>Conducting advanced data analysis and designing highly complex algorithm</li><li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li></ul><p><strong>Our Offer</strong></p><ul><li>Very competitive salary based on prior experience and qualifications</li><li>Potential for stock options after the first year</li><li>Raise and advancement opportunities based on periodic evaluations</li><li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li><li>Health benefits (in case you will be working from our office in Washington DC)</li></ul><p><strong>Notes</strong>&nbsp;</p><ul><li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li><li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li></ul><p><strong>More about WalletHub</strong></p><p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p><p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p><p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p><p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p><p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p><p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/286543?reset=False&amp;ra=1y63jbW3HY9a&amp;oqs=a%3D1y63jbW3HY9a' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About Wallethub</h4>            <div><p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Stock options</span>                            </li>                            <li>                                <span></span>                                <span>Health benefits</span>                            </li>                            <li>                                <span></span>                                <span>Work visa sponsorship</span>                            </li>                            <li>                                <span></span>                                <span>Competitive salary</span>                            </li>                            <li>                                <span></span>                                <span>Work from home</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rHldxCSQRQGnHiq2z-U_lg",
    "url": "https://stackoverflow.com/jobs/286534/data-science-course-mentor-thinkful-inc?a=1y5RHQddlqU0",
    "title": "Data Science Course Mentor at Thinkful Inc.  ",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:go/go/6",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=6, nodejs=0, bigdata-ml=50, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Thinkful Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 7:30:25 PM",
    "validThrough": "Aug 9, 2019 7:30:25 PM",
    "crawled": "Aug 2, 2019 7:30:25 PM",
    "content": "<h3><span>Data Science Course Mentor</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Junior, Mid-Level</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Online Education, Web Development</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>51–200 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Thinkful Inc. | No office location<br></div><h4>Technologies</h4><div></div><div>sql</div><div>python</div><div>Click here to apply</div><div>Click here to apply&nbsp;</div>                <h4>Job description</h4>                <div><a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply</a><strong>Who We Are </strong><br>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;<br><br><strong>The Position</strong>At Thinkful, we believe that if schools put in even half the amount of effort that students do the outcomes would be better for everyone. People would have a path to a fulfilling future, instead of being buried under debt. Employers would benefit from a workforce trained for today. And education could finally offer students a return on their investment of both money and time.&nbsp;We put in outlandish amounts of effort to create an education that offers our students a guaranteed return on their investment. we partner with employers to create a world-class curriculum built for today. We go to ends of the earth to find mentors who are the best of the best. We invest more in career services than any of our peers. We work hard to be on the ground in the cities our students are. Simply put, no other school works as hard for its students as we do.&nbsp;Students enroll in Thinkful courses to gain the valuable technical and professional skills needed to take them from curious learners to employed technologists. As a Course Mentor, you will support students by acting as an advisor, counselor, and support system as they complete the course and land their first industry job. To achieve this, you will engage with students using the below range of approaches, known as Engagement Formats. Course Mentors are expected to provide support across all formats when needed.&nbsp;<ul><li><strong>Mentor Sessions: </strong>Meet with students 1-on-1 in online video sessions to provide technical and professional support as the student progresses through the curriculum.</li><li><strong>Group Sessions: </strong>Host online video sessions on topics of your expertise (in alignment with curriculum offerings) for groups of student seeking live support between mentor sessions.&nbsp;</li><li><strong>Grading: </strong>Reviewing student checkpoints submissions and delivering written feedback, including analysis of projects and portfolios.&nbsp;</li><li><strong>Technical Coaching: </strong>Provide in-demand support to technical questions and guidance requests that come to the Technical Coaching team through text and video in a timely manner. This team also provides the TA support for immersive programs.&nbsp;</li><li><strong>Assessments &amp; Mock Interviews:</strong> Conduct 1-on-1 mock interviews and assessments via video calls and provide written feedback to students based on assessment rubrics.&nbsp;</li></ul>In addition to working directly with students, Course Mentors are expected to maintain an environment of feedback with the Educator Experience team, and to stay on top of important updates via meetings, email, and Slack. Ideal candidates for this team are highly coachable, display genuine student advocacy, and are comfortable working in a complex, rapidly changing environment.<strong>Requirements</strong><ul><li>Minimum of 1 year professional experience as a Data Scientist or demonstrated expertise with data visualizations and machine learning at an industry level</li><li>Proficiency in SQL, Python</li><li>Professional experience with Hadoop and Spark a plus</li><li>Excellent written and verbal communication</li><li>High level of empathy and people management skills</li><li>Must have a reliable, high-speed Internet connection</li></ul><strong>Benefits</strong><ul><li>This is a part-time role (10-25 hours a week)</li><li>Fully remote position, with the option to work evenings and weekends in person in 22 US cities</li><li>Community of 500+ like-minded Educators looking to impact others and keep their skills sharp</li><li>Full access to all of Thinkful Courses for your continued learning</li><li>Grow as an Educator</li></ul><br><strong>Apply</strong><br>If you are interested in this position please provide your resume and a cover letter explaining your interest in the role.Thinkful can only hire candidates who are eligible to work in the United States.We stand against any form of workplace harassment based on race, color, religion, sexual orientation, gender identity or expression, national origin, age, disability, or veteran status. Thinkful provides equal employment opportunities to all employees and applicants. If you're talented and driven, please apply.<br><br>At this time, we are unable to consider applicants from the following states: Alaska, Delaware, Idaho, New Mexico, North Dakota, South Carolina, South Dakota, West Virginia, and Wyoming<a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>Click here to apply&nbsp;</a>                </div>            <div>        <a href='https://hire.withgoogle.com/public/jobs/thinkfulcom/view/P_AAAAAAEAAADC9Bx7fyGYVv' rel='nofollow'>                        Apply now        </a></div>            <h4>About Thinkful Inc.</h4>            <div><p>Thinkful is a new type of school that brings high-growth tech careers to ambitious people everywhere. The company provides 1-on-1 learning through its network of industry experts, hiring partners, and online platform to deliver a structured and flexible education. Thinkful offers programs in web development and data science, with in-person communities in up-and-coming tech hubs around the U.S. To join the Thinkful network visit&nbsp;<a href='https://www.thinkful.com/' rel='nofollow'>thinkful.com</a>.</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Join team of 500+ developers mentoring the developers of the future</span>                            </li>                            <li>                                <span></span>                                <span>Access to top-rated curriculum</span>                            </li>                            <li>                                <span></span>                                <span>Paid position</span>                            </li>                            <li>                                <span></span>                                <span>Flexible Schedule and Hours</span>                            </li>                            <li>                                <span></span>                                <span>Remote Capability</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Zm9GHPkbQEals62eBbhHTA",
    "url": "https://remote.co/job/machine-learning-expert/",
    "title": "Machine Learning Expert",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scipy/python/5",
      "DBG_TECH1:techWeightMap:{python=17, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=46, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "PulsePoint",
      "sameAs": "https://www.pulsepoint.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 5:43:39 PM",
    "validThrough": "Aug 9, 2019 5:43:39 PM",
    "crawled": "Aug 2, 2019 6:25:02 PM",
    "content": "<h3>Machine Learning  Expert at <span>PulsePoint</span></h3><div><span><i></i> Remote</span>        </div><div>            <p><strong>Location: REMOTE</strong></p><p><strong>Note: This is a REMOTE position, reporting into our NYC home office.</strong></p><p>PulsePoint , a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.</p><p>Our organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization .</p><p><strong>The goals of the PulsePoint Data Science Engineering team:</strong></p><ul><li>Optimize and validate targeting mechanisms for specific health conditions</li><li>Improve and optimize our proprietary contextualization, and recommendation engines that handle hundreds of thousands of transactions per second, billions of times each month</li><li>Collaborate with internal Health experts to ideate and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.</li></ul><p><strong>What you will be tasked to do:</strong></p><ul><li>Research and develop user profiling models to enhance our recommendation engine to leverage both online and offline data.</li><li>Support and enhance the existing work on health user profiling, prediction, and targeting tools.</li><li>Contribute on future project on patient/physician identity for cross-device tracking, profiling and targeting.</li><li>Support existing codebases for data integration and production support for our core models.</li></ul><p><strong>What you need to be successful in this role:</strong></p><ul><li>3+ years of full-time experience working as a Statistician/ Machine Learning Engineer/ Data Scientist</li><li>Advanced knowledge of Big Data technologies such as Hadoop, Hive, and Impala</li><li>Advanced knowledge of Python using the numpy/scipy/pandas/skilearn stack</li><li><strong>MS/PhD in Astronomy, Physics, Applied Mathematics, Statistics, Machine Learning, Computer Science; or BS with several years of applied machine learning experience</strong></li></ul><p><strong>** All applicants must submit a code sample or a GitHub link to be considered **</strong></p><p>At PulsePoint , data is at the core of everything we do and Data Science is a&nbsp;<strong>high profile</strong>&nbsp;and&nbsp;<strong>high impact</strong>&nbsp;team, focusing on creating innovative solutions that rely on predictive modeling and big data analytics. We are looking for A players that have a combination of drive, focus, speed, efficiency and quality to drive statistical modeling, optimization and/or machine learning. You will be given ownership and autonomy over the research and development of your projects and will be expected to execute well and on time. We work on challenging problems that will make ads matter for people with health problems. Your work will directly influence our trajectory as a company.</p>        </div><div>        <a href='http://www.pulsepoint.com/job-board?gh_jid=1281522' rel='nofollow'>Apply for job</a>    </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5u3-HeKlTBCPsrs2qkA8tg",
    "url": "https://jobmote.com/job/56051/data-scientist-and-development-engineer-remote-ok-attractive-pay/",
    "title": "Data scientist and development engineer (remote OK) ***attractive pay*",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "infoCorvus",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 10:07:34 PM",
    "validThrough": "Aug 4, 2019 10:07:34 PM",
    "crawled": "Aug 2, 2019 3:06:25 AM",
    "content": "<div><p> </p><p><strong>Come work for a leading database company developing the next generation advanced analytical database </strong></p><p> </p><p> </p><p> </p><p><strong>Duties:</strong></p><p> </p><ul><li><ul><li>Participate in leading - not bleeding - and pragmatic applicable research and development</li></ul></li></ul><p> </p><ul><li><ul><li>Apply advanced statistical and machine learning techniques</li><li>Solve a number of challenging database problems outside the traditional arena of</li></ul></li></ul><p> </p><ul><li><ul><li>database internals and know-how</li><li>including algorithm design,</li></ul></li></ul><p> </p><ul><li><ul><li>verification,</li><li>scaling,</li></ul></li></ul><p> </p><ul><li>performance,</li><li>computational complexities, and their design and</li><li>Code implementation into services amendable to the optimal combination of offline and real-time data analysis and insight rendering.</li></ul><p><strong>Skills: </strong></p><p> </p><ul><li><ul><li>Solid theoretical, mathematical and practical working knowledge of various statistical, inferential, and machine learning models, techniques, trade-offs</li></ul></li></ul><p> </p><ul><li><ul><li>Implementation experience in cloud or on-premise , with productive fluency in multiple languages like python, R, JavaScript, visualization techniques</li><li>Basic working database knowledge</li><li>Ability to work in a team environment while also functions as an individual contributor who needs minimal handholding to know how to self-actualize, prioritize and make progress with minimal handholding.</li><li>A fast learner who s not hesitant to take on new things;</li></ul></li></ul><p> </p><ul><li><ul><li>A problem solver with analytical thinking and unwavering persistence to overcome</li><li> </li></ul></li></ul><p> </p><ul><li>Clear and good verbal and written communication skills</li></ul><p> </p><p> </p><p> </p><p><strong>Qualifications:</strong></p><p> </p><ul><li>At least 4 years of relevant hands-on experience with skills in the above areas</li><li>A successful track record in a similar role</li></ul> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2-KraVEeTiaAft0tIAMvOA",
    "url": "https://news.ycombinator.com/item?id=20588928",
    "title": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 12:23:11 AM",
    "validThrough": "Aug 9, 2019 12:23:11 AM",
    "crawled": "Aug 2, 2019 1:09:12 AM",
    "content": "Sourceress | Engineering: Machine Learning, Backend, Frontend, Managers | San Francisco | Full-time | Local or Remote | <a href='https://www.sourceress.com/jobs' rel='nofollow'>https://www.sourceress.com/jobs</a><p>We already have significant machine learning expertise, so are happy to hire great engineers without prior ML experience who are willing to learn. We strongly value personal growth, and want to help you grow into a great engineer (or engineering leader), so this approach applies to our other engineering roles as well.</p><p>Our mission is to help people find work that matters. We believe that the world is better when people understand the opportunities available to them. Our human-assisted AI platform delivers great results to our customers (customer quote: &quot;I'd have a panic attack if you guys stopped existing&quot;).</p><p>Because of this, we raised $3.5M from OpenAI researchers and Lightspeed at one of the highest ever valuations coming out of YC. Our team has previously sold companies, published machine learning research, has Dropbox's former Chief of Staff, and previously worked at Google, Airbnb, McKinsey, etc.</p><p>Qualifications:</p><p>- Do you understand the value of shipping quickly and of software craftsmanship, and have the judgment to know when to apply each?</p><p>- Do you enjoy collaborating with other developers and helping them grow?</p><p>- Do you share our values? <a href='https://www.sourceress.com/jobs#values' rel='nofollow'>https://www.sourceress.com/jobs#values</a></p><p>Stack: Python 3, Typescript, React, AWS, PostgreSQL</p><p>To Apply: <a href='https://www.sourceress.com/jobs#current-openings' rel='nofollow'>https://www.sourceress.com/jobs#current-openings</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xalH2nMgQy64LYuRZH1FjA",
    "url": "https://news.ycombinator.com/item?id=20588897",
    "title": "OnSpecta | Redwood City, CA & Warsaw, Poland | Software Engineer, Performance Engineer (HPC), ...",
    "tags": [
      "DBG:classic``&quot;open to remot&quot;",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=8, mobile=0, go=0, nodejs=0, bigdata-ml=34, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 2, 2019 12:17:21 AM",
    "validThrough": "Aug 9, 2019 12:17:21 AM",
    "crawled": "Aug 2, 2019 1:09:12 AM",
    "content": "OnSpecta | Redwood City, CA &amp; Warsaw, Poland | Software Engineer, Performance Engineer (HPC), Machine Learning Engineer | Visa<p>OnSpecta is an early-stage startup founded by successful serial entrepreneurs and deep learning experts, and was born out of MIT’s neuroscience lab. We offer a Deep Learning Server (DLS) which increases the performance of deep learning computations on Intel and ARM CPUs, GPUs and ASICs etc. We're a small team (~10), so you'll have a huge opportunity to make a difference.</p><p>We are looking for talented software performance engineers to work directly with our technical founders. If you have experience in C++ and are interested in working on cutting-edge AI/ML infrastructure tech, please reach out to us. See more at <a href='http://onspecta.com/careers.html' rel='nofollow'>http://onspecta.com/careers.html</a> We're also looking for Machine Learning Engineers (experience with Python + TensorFlow required).</p><p>Please reach out to hiring@onspecta.com and include &quot;HN: &quot; in the subject. (Note: while we're open to remote work, you must be in California's or Central/Easter Europe's timezones. Local candidates are preferred).</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "n-5sE7NDTruD_Zu3n3PTyw",
    "url": "https://news.ycombinator.com/item?id=20587710",
    "title": "SOLV3D [https://solv3d.com] | Senior Data Scientist / Developer | Calgary, AB, Canada | Full ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=36, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=4}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 10:00:00 PM",
    "validThrough": "Aug 8, 2019 10:00:00 PM",
    "crawled": "Aug 1, 2019 10:32:05 PM",
    "content": "SOLV3D [<a href='https://solv3d.com' rel='nofollow'>https://solv3d.com</a>] | Senior Data Scientist / Developer | Calgary, AB, Canada | Full-time | ONSITE preferred, however REMOTE (Canada) also welcome<p>We’re looking for a Senior Data Scientist/Developer to assist with the enhancement and expansion of SOLV3D’s leading Software as a Service (SaaS) applications. Within this role, the individual will be required to apply their experience and expertise in providing input to SOLV3D’s software development team in the design, development, testing and maintenance stages of software development. This position involves design and implementation of a new machine learning based module for our SOLV3D engine application.</p><p>Minimum qualifications:</p><p>* 6+ years of experience collaborating and working on software development projects* Bachelor’s Degree or higher in computer science/applied mathematics/GIS-related or relevant field* Solid track record of managing and delivering enterprise or start-up SaaS applications* Experience working on all levels of the technology stack – database, business logic, frontend, testing* Knowledge and experience with Git, Python, JavaScript, MySQL/MariaDB, HTML and CSS* Experience designing and developing machine learning and deep learning systems* Experience working in an Agile environment, particularly Scrum* Experience with unit testing, integration testing and TDD* Experience working with cloud providers, particularly AWS using S3, EC2, and RDS</p><p>About SOLV3DWe are a young, dynamic start-up based in in Calgary, Alberta looking to set the geomatics software world on fire with our processing, visualization and collaboration applications. We were founded on a need for professional-grade point cloud processing.</p><p>Our first product, SOLV3D engine, was born of that need, and enables users to optimize their point cloud data for effective use within their applications and workflows. Our follow-on product, SOLV3D encompass, addressed the need for a simple, easy-to-use, web-based viewer for geo-referenced data. It gives users the ability to merge together a myriad of geospatial datasets. Within a web-based environment, it enables all stakeholders to easily gain situational awareness and work together on their projects and/or AOIs, regardless of geographical location or level of expertise.</p><p>I am the CTO, so please send me your questions/resume with [HN] in the subject line to kmiller at solv3d.com</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "m7sAS6fDRCeq-OSjm7E0Tg",
    "url": "https://news.ycombinator.com/item?id=20586259",
    "title": "Thrilling | full stack/frontend engineers | full-time | REMOTE or LA, NY, SF | https:/ ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:angular/frontend/8",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:firebase/mobile/8",
      "DBG_TECH1:k/t/w:typescript/frontend/1",
      "DBG_TECH1:k/t/w:typescript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=8, go=0, nodejs=1, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/mobile",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "mobile"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:37:26 PM",
    "validThrough": "Aug 8, 2019 7:37:26 PM",
    "crawled": "Aug 1, 2019 9:32:11 PM",
    "content": "Thrilling | full stack/frontend engineers | full-time | REMOTE or LA, NY, SF | <a href='https://shopthrilling.com' rel='nofollow'>https://shopthrilling.com</a><p>At Thrilling we're helping traditional brick-and-mortar vintage apparel stores sell their clothing online for the first time. Vintage and secondhand clothing has a huge role to play in improving the environmental impact of the Fashion industry, and by partnering with local stores we can leverage their unique, curated inventories and help small business owners compete in the global economy. We aim to do good, and do well. Our name comes from the thrill of the hunt, and we're working to bring the same excitement of shopping the best vintage stores, online. Read more about us here:<a href='https://www.entrepreneur.com/amphtml/325805' rel='nofollow'>https://www.entrepreneur.com/amphtml/325805</a></p><p>We're looking for engineers 2 &amp; 3 to join me and the rest of our small and growing team to help us change the landscape of online vintage and secondhand shopping. We need hungry self-starters with some prior software dev experience. Fashion is a diverse industry and we reflect and value that at our company. Having recently closed our seed round of funding we're rapidly expanding. We've built an app for efficient uploading of products and inventory management, as well as our customer-facing ecom marketplace. In addition to building out those systems there are new ones to create that have yet to be specced. Your work will have a massive impact on our growth and success.</p><p>Here's some of the tools we use: TypeScript, Angular, Ionic, GitHub, Jira, GraphQL, Google Cloud, Heroku, Firebase, Imgix, Sketch.</p><p>Here's some of the areas we're expanding into: ML, computer vision, recommendation systems, and always, always killer UX.</p><p>If this sounds interesting, email me at tech@shopthrilling.com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xYNubIjSRxOfNIlR88uYvw",
    "url": "https://news.ycombinator.com/item?id=20586476",
    "title": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| https://www.factual.com ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 3N OR(options, avail, allow) NOT encourag",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=12, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:58:01 PM",
    "validThrough": "Aug 8, 2019 7:58:01 PM",
    "crawled": "Aug 1, 2019 9:32:11 PM",
    "content": "Factual | Software Engineers and Data Scientists | Los Angeles REMOTE| <a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a><p>Factual is currently hiring Software Engineers and Data Scientists, at all levels, in the Los Angeles office. Remote positions available for experienced candidates. Factual is the location data company that the world’s most valuable brands and technology companies trust to understand and intelligently grow their businesses. We help engineering teams, marketers and data analysts build the best digital products, deliver more impactful marketing and transform their businesses with the most accurate and comprehensive data on places and people worldwide.</p><p>There are many challenging problems to work on at all layers of the stack: data cleaning and canonicalization, storage, deduping, serving, APIs, improving data using machine learning, etc. If you love data, Factual is the place to be. Experience with Clojure, machine learning, NLP, algorithm design, or Hadoop/Spark is a plus!</p><p>You can email me personally at alexr@factual.com, or view our job postings here: <a href='https://www.factual.com/company/careers/#career' rel='nofollow'>https://www.factual.com/company/careers/#career</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "5xuxQrTtQIGPLExJL4-F2Q",
    "url": "https://news.ycombinator.com/item?id=20586166",
    "title": "play | Saalbach.com, Austria | Video, Machine Vision, AI | Remote Ok | Full-/Part-time/Co ...",
    "tags": [
      "DBG:surround``remot W OR(contractor,assist,ok)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=20, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 7:28:26 PM",
    "validThrough": "Aug 8, 2019 7:28:26 PM",
    "crawled": "Aug 1, 2019 7:32:07 PM",
    "content": "play | Saalbach.com, Austria | Video, Machine Vision, AI | Remote Ok | Full-/Part-time/Co-Creators<p>You are a Machine Visionary, Software Wizard or Master of Code?</p><p>Join us.</p><p>play is, simply put, about the beaming of emotions via video. The most beautiful medium to capture emotions, to share and beam them around the world.</p><p>What?</p><p>Just follow this super inviting “call to action”. Find out what we are working on and how we can collaborate:</p><p><a href='https://www.playsys.at/join_us/' rel='nofollow'>https://www.playsys.at/join_us/</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gXPqdyt4Ti2jwA7Yq0aSwg",
    "url": "https://news.ycombinator.com/item?id=20585019",
    "title": "Resemble AI | Toronto or Remote | Full-Time | Backend/Infra & Full-Stack Engineers Resemble AI ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot W OR(career,first)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/10",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=10, ruby=10, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:59:33 PM",
    "validThrough": "Aug 8, 2019 5:59:33 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Resemble AI | Toronto or Remote | Full-Time | Backend/Infra &amp; Full-Stack Engineers<p>Resemble AI creates high-quality synthetic voices that capture human emotion. We're a venture-backed high-growth startup that's looking to shake up an entire industry with state of the art AI.</p><p>Our product changes the way that thousands of brands, media companies, creative agencies, and game studios work with voice content.</p><p>We’re a remote-first team that thrives on flexibility and creativeness. We cover expenses for office space, equipment, and all of the other perks and benefits that make you productive. We also believe that to build an enticing product and solid team is by encouraging innovation is by enabling continuous education. That's why every other Friday is a day that you can use to work on anything you want, Resemble-related or not.</p><p>We're hiring for two roles:</p><p>Backend/Infrastructure Engineer - Looking for those that take pride in creating robust distributed systems. Most of the work is in Python and we use GCP as our cloud provider.</p><p>Full Stack Engineer - Product-driven Engineer that is able to craft end-to-end features. We work with Ruby on Rails, React, with microservices written in Python and deployed on GCP.</p><p>If interested, reach out directly to me: zohaib@resemble.ai</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zUiHGxcUTLuSFeuAi166Yg",
    "url": "https://news.ycombinator.com/item?id=20584616",
    "title": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR ...",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/frontend",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "frontend"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:23:49 PM",
    "validThrough": "Aug 8, 2019 5:23:49 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Indigo Agriculture | Software engineers (all levels) | Boston, MA | Full-time | On-site OR REMOTE | <a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a><p>================</p><p>We're the fastest growing unicorn you've never heard of [0] and was just recently named CNBCs Most Disruptive Business beating out Airbnb, Stripe, Flexport, and more [3].</p><p>Indigo is revolutionizing agtech by offering better crops to farmers through technology. Agtech is one of the most underhyped technology trends [1] and we're serving a multi-trillion dollar marketplace services industry [2].</p><p>Our group is working on the Uber for Agriculture. We're developing a Transportation network to connect farmers with preferred carriers (trucks) to help them ship millions of bushels of grain across the United States. It's like a real world Traveling Salesman Problem with even more requirements.</p><p>We're growing so fast that I have to hire another 10 engineers just for my group in 2019. Back-end, front-end, mobile... you name it, we need the help (see all of them here: <a href='https://www.indigoag.com/join-us' rel='nofollow'>https://www.indigoag.com/join-us</a> ).</p><p>Our tech stack includes AWS, Docker, Kubernetes (DevOps), Postgres (DB), Node &amp; GraphQL (back-end), React &amp; Apollo (front-end), and Python (data science / comp bio).</p><p>We also offer incredible perks. Free lunch (a rarity in Boston), massive commuter benefits (both MBTA and bicycling), fitness reimbursement, ample vacation; we really focus on and believe in both health and sustainability.</p><p>I'd be happy to tell you more, so feel free to PM me and I'll personally refer you to the company.</p><p>[0] <a href='https://www.builtinboston.com/2017/09/26/agtech-startup-indigo-boston-tech-unicorn' rel='nofollow'>https://www.builtinboston.com/2017/09/26/agtech-startup-indi...</a></p><p>[1] <a href='http://stateofstartups.firstround.com/2018/#trends-and-takes' rel='nofollow'>http://stateofstartups.firstround.com/2018/#trends-and-takes</a></p><p>[2] <a href='https://andrewchen.co/how-marketplaces-will-reinvent-the-service-economy/' rel='nofollow'>https://andrewchen.co/how-marketplaces-will-reinvent-the-ser...</a></p><p>[3] <a href='https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor-50-companies.html' rel='nofollow'>https://www.cnbc.com/2019/05/15/meet-the-2019-cnbc-disruptor...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2bUtor1zQJenVcnGvbMolQ",
    "url": "https://news.ycombinator.com/item?id=20584487",
    "title": "Moonlight | Software Engineer | REMOTE | Fulltime | https://www.moonlightwork.com Hey all - ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=2, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/go",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "go"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:13:11 PM",
    "validThrough": "Aug 8, 2019 5:13:11 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Moonlight | Software Engineer | REMOTE | Fulltime | <a href='https://www.moonlightwork.com' rel='nofollow'>https://www.moonlightwork.com</a><p>Hey all - we're hiring a remote backend developer to join the team at Moonlight. We're building LinkedIn for software developers, and companies pay us to match to job candidates. The stack is Go on Kubernetes using gRPC, MySQL, Redis, etc. Lots going on and many fun challenges, ranging from ML to real-time messaging. This role will either be our second engineering hire. I wrote everything until now - so email me if you have any questions!</p><p>More details here -&gt;</p><p><a href='https://hire.withgoogle.com/public/jobs/moonlightworkcom/view/P_AAAAAAIAAFeNB7zCTG98gQ?trackingTag=slack' rel='nofollow'>https://hire.withgoogle.com/public/jobs/moonlightworkcom/vie...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Ti-gzoRUTRGAXnVNuMTdAg",
    "url": "https://news.ycombinator.com/item?id=20584790",
    "title": "Kira Systems | Multiple Senior Software Developers | Toronto, Canada | Remote | Onsite | https: ...",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:techWeightMap:{python=0, other=5, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=6, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/other",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "other"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:39:28 PM",
    "validThrough": "Aug 8, 2019 5:39:28 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Kira Systems | Multiple Senior Software Developers | Toronto, Canada | Remote | Onsite | <a href='https://www.kirasystems.com' rel='nofollow'>https://www.kirasystems.com</a><p>Kira Systems is a powerful machine learning software that identifies, extracts, and analyzes text in your contracts and other documents. Our software is intuitive and easy-to-use to uncover relevant information for some of the largest law firms, professional services and corporate companies in the world.</p><p>We are always looking for talented people to join our team locally, remotely, and offer support for those looking to relocate to our headquarters in Toronto.</p><p>We're hiring Machine Learning Devs, Security Engineering Lead and Developers to work in all areas of our stack. Possibilities include working on Clojure web server, backend data processing services, and both our platform API and SDK. We use PostgreSQL to store our data and don’t hide SQL behind big frameworks. We also use many other popular technologies such as Go, RabbitMQ, Zookeeper, ElasticSearch, and Docker.</p><p>For more information, visit our careers page <a href='https://www.kirasystems.com/careers' rel='nofollow'>https://www.kirasystems.com/careers</a> or email us at jobs@kirasystems.com.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j8HtTOq9QKeubdb6jdY7JQ",
    "url": "https://news.ycombinator.com/item?id=20585004",
    "title": "SEEKING FREELANCER | Technical Writers, Bloggers - Machine Learning, Deep Learning, Artificial ...",
    "tags": [
      "DBG:surround``2N(anywher, remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/14",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:deep-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=42, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:58:32 PM",
    "validThrough": "Aug 8, 2019 5:58:32 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "SEEKING FREELANCER | Technical Writers, Bloggers - Machine Learning, Deep Learning, Artificial Intelligence | Remote (anywhere on the blue planet)<p>FloydHub is a YC start-up building AI infrastructure and tools. We have a popular platform with a highly satisfied and growing user base.</p><p>We are passionate about the power of artificial intelligence and truly believe these technologies will make a lasting positive impact on the world. We are doing our part to accelerate the adoption of AI by creating easy-to-use tools and by educating more people about fundamental concepts, best practices and advanced techniques in AI. Our blog plays a critical role in educating our current audience and others interested in entering the field.</p><p>We are looking for bloggers, writers, and content editors to create engaging and informative pieces for our audience.  If you are a data scientist or software engineer looking to write about your areas of expertise or what you are learning, we are still interested. This is a great opportunity for you to contribute to the biggest technology revolution since the advent of the internet and work alongside influencers in AI.</p><p>Come write for us. Come be part of the revolution.</p><p><a href='https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;utm_medium=post&amp;utm_campaign=call_for_writers_august_2019' rel='nofollow'>https://blog.floydhub.com/write-for-floydhub/?utm_source=hn&amp;...</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "l_-k_bryROqSv7bS9tQiyg",
    "url": "https://news.ycombinator.com/item?id=20585078",
    "title": "Frame Health | Senior/Lead Developer | Los Angeles or Boston | Full-time/Contract | ONSITE or ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=10, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/ruby",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "ruby"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 6:03:58 PM",
    "validThrough": "Aug 8, 2019 6:03:58 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Frame Health | Senior/Lead Developer | Los Angeles or Boston | Full-time/Contract | ONSITE or possibl REMOTE | <a href='http://framehealth.com' rel='nofollow'>http://framehealth.com</a>Frame Health brings the power of behavioral and personality science to enhance many aspects of health care, leading to better outcomes, economics, and patient happiness. Our small company has exciting partnerships with leading national healthcare organizations.We're seeking strong generalist technologists with a data science interest or background. Technologies: Ruby/Rails, Python, Javascript, and React.Please email: developerjobs@framehealth.com.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kIxRhfpdQfGNfbYRHItxCA",
    "url": "https://news.ycombinator.com/item?id=20584732",
    "title": "Citymapper | Full-time, VISA (for experienced candidates), London, REMOTE possible We need ...",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Aug 1, 2019 5:33:14 PM",
    "validThrough": "Aug 8, 2019 5:33:14 PM",
    "crawled": "Aug 1, 2019 6:24:48 PM",
    "content": "Citymapper | Full-time, VISA (for experienced candidates), London, REMOTE possible<p>We need great engineers who are up to the challenge of making cities usable.Join us and work on a daily use-case app for you and millions of city-dwellers in 40 cities around the world.Current mobility trends (scooters, electric bikes, cabs, …) are changing cities - and we are helping users to find and book the best transport options for them.  - Our multimodal transport app helps millions of people to get from A to B in our 40 cities  - Citymapper Pass is a transport only payment card covering all private and public transport with a weekly subscription (<a href='https://citymapper.com/pass' rel='nofollow'>https://citymapper.com/pass</a>)Check out our blog at <a href='https://engineering.citymapper.com' rel='nofollow'>https://engineering.citymapper.com</a> to get a better idea of what we are doing.</p><p>We are looking especially for: (Have a look on our careers page for a full list - <a href='https://citymapper.com/jobs' rel='nofollow'>https://citymapper.com/jobs</a>)Experienced backend engineers (Python, Go, AWS, …) <a href='https://citymapper.workable.com/jobs/6531' rel='nofollow'>https://citymapper.workable.com/jobs/6531</a>Data Science Engineers (data scientist working within an engineering team) <a href='https://citymapper.workable.com/jobs/40247' rel='nofollow'>https://citymapper.workable.com/jobs/40247</a>iOS Engineer <a href='https://citymapper.workable.com/jobs/7972' rel='nofollow'>https://citymapper.workable.com/jobs/7972</a></p><p>You can contact me directly at marius@citymapper.com if you have any questions (no recruiters please). Otherwise please apply through our website: <a href='https://citymapper.com/jobs' rel='nofollow'>https://citymapper.com/jobs</a></p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GXQ4RkLkT4CTvJtfpoIDRA",
    "url": "https://jobmote.com/job/54036/senior-web-developer-remote/",
    "title": "Senior Web Developer (Remote)",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=4}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blend360",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 10:07:19 PM",
    "validThrough": "Aug 3, 2019 10:07:19 PM",
    "crawled": "Aug 1, 2019 3:06:25 AM",
    "content": "<div>Dynamic, Entrepreneurial Marketing Consulting Company is seeking a Marketing Operations Manager to contribute to Financial Services Client?s customer retention strategy. If you have an entrepreneurial spirit and passion, are driven by results, solid campaign execution skills, we?re looking for you!?<br><br>C2G Partners is a successful marketing and analytics solutions company that has been ranked among Inc. Magazine?s ?Inc. 500 - 5000? list fastest growing companies in America, five out of the last six years. Our name C2G Partners means 'Committed to Growth'?, and this reflects both our desire to deliver exceptional results to our clients in helping them grow their business, as well as a strong growth culture that develops our employees and grows our company.? We aspire to be the preeminent provider of data driven marketing solutions in the industry.<br><br>The Senior Web Developer solves client problems using leading marketing technologies including solutions from Adobe, Google and Salesforce. Projects will include implementation, integration and enhancement of digital marketing tools. ??In this role, you?ll satisfy your desire for hands-on development, while exciting your entrepreneurial spirit with critical solution designs. This is a unique opportunity to help build a new division of the Data Science practice, focused on digital analytics and marketing technologies.<br><br>Key Responsibilities<ul><li>Design, document and implement technical solutions to client business questions in Adobe Experience Cloud, Google Marketing Cloud and Salesforce Marketing Cloud using relevant technical skills. Example projects may include:<ul><li>Re-architecture of existing digital marketing tools</li><li>Optimization of lead-generation efforts using Salesforce Marketing Cloud</li><li>Integration and ingestion of offline and online data in Adobe Audience Manager to deliver targeted remarketing advertisements</li><li>Implementation of tag management solutions (such as Google Tag Manager and Adobe Launch)</li></ul></li><li>Develop deep knowledge of emerging data governance, privacy, and information security regulations that affect marketing ? and understand the impact to solution offerings</li><li>Deliver high-quality projects on time and within budget in a fast-paced environment</li><li>Employ industry best practices in solution design, implementation, and testing</li></ul>The Details:<ul><li>Location: Remote (East Coast preferred)</li><li>Duration: Full-time</li><li>Travel Requirements: Up to 30-40%</li><li>Benefits: Health, Vision, Dental, 401K plan, Life Insurance, Pretax Commuter Benefits, and an incredibly supportive team cheering you on!</li></ul>Required Skills &amp; Qualifications:<ul><li>Degree in Computer Science, Engineering, MIS, or similar field</li><li>Minimum 3-5 years of hands-on experience with the following technologies:<ul><li>JavaScript (Advanced)</li><li>HTML &amp; CSS (Intermediate)</li><li>SQL, REST &amp; SOAP APIs</li></ul></li><li>Proven ability to collaborate and communicate effectively (written and oral) with both IT and marketing professionals</li><li>Ability to manage priorities across multiple projects</li></ul>Desired Skills &amp; Qualifications:<ul><li>Hands on experience with the following technologies:<ul><li>Adobe Experience Cloud solutions, particularly Analytics, Target or Audience Manager</li><li>Google Marketing Cloud, particularly GA360 and BigQuery</li><li>Tag Management technologies, especially data layer architecture and implementation</li><li>Mobile SDKs for marketing technologies</li><li>JSON</li></ul></li><li>Comfortable working in an Agile environment</li></ul>?</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "6tkFWez4R4ulv-HzHYYxCw",
    "url": "https://www.workingnomads.co/job/go/24734/",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby-on-rails/ruby/8",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:velocity/java/8",
      "DBG_TECH1:techWeightMap:{python=7, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=8, apple=0, java=11, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Toptal",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 9, 2019 12:20:02 PM",
    "validThrough": "Jul 16, 2019 12:20:02 PM",
    "crawled": "Jul 31, 2019 6:26:46 PM",
    "content": "<p><strong>About </strong><strong>Toptal</strong></p><p>Toptal is a global network of top talent in business, design, and technology that enables companies to scale their teams, on-demand. With $100+ million in annual revenue and triple-digit growth, Toptal is the&nbsp;<a href='https://www.toptal.com/careers#remote-team' rel='nofollow'>largest fully distributed workforce</a>&nbsp;in the world.</p><p>We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun (see this&nbsp;<a href='http://www.huffingtonpost.com/entry/work-from-anywhere-in-the-world_us_581a1f01e4b083aaeef76a9b?064s98zsrt19n3ik9' rel='nofollow'>video</a>&nbsp;from The Huffington Post). We see no borders, move at a fast pace, and are never afraid to break the mold</p><p><strong>Position Description</strong></p><p>At Toptal, we measure everything and always rely on data to guide all of our initiatives, including both our long-term strategy and our day-to-day operations.</p><p>As a Data Engineer, your main goal is to be one step ahead of data scientists and analysts, and support them by providing infrastructure and tools they can use to deliver end-to-end solutions to business problems that can be developed rapidly and maintained easily. This is more than building and maintaining ETL pipelines. We need innovation, creativity and solutions that will have significant impact on our velocity. We, in turn, will give you autonomy and freedom to turn your ideas into reality.</p><p><strong>Responsibilities:</strong></p><ul><li>Build scalable, highly performant infrastructure for delivering clear business insights from a variety of raw data sources.</li><li>Develop batch &amp; real-time analytical solutions, prototypes, and proofs of concept for selected solutions.</li><li>Implement complex analytical projects with a focus on collecting, managing, analyzing, and visualizing data.</li><li>Build frameworks and tools to empower our data scientists and analysts.</li><li>Be in constant communication with team members and other relevant parties and convey results efficiently and clearly.</li></ul><p><strong>Requirements:</strong></p><ul><li>Working experience with&nbsp;<strong>Python</strong>,&nbsp;<strong>Pandas</strong>. Prior experience with&nbsp;<strong>Luigi</strong>&nbsp;is a plus.</li><li>Working experience with&nbsp;<strong>Scala</strong>&nbsp;and&nbsp;<strong>Airflow</strong>&nbsp;is a big plus.</li><li>Familiarity with&nbsp;<strong>Google Cloud Platform</strong>&nbsp;(e.g.&nbsp;<strong>GCS</strong>&nbsp;and BigQuery) is a plus.</li><li>Working experience with&nbsp;<strong>Dimensional Modeling</strong>&nbsp;and&nbsp;<strong>Rails</strong>&nbsp;is a plus.</li><li>Familiarity with the basic principles of&nbsp;<strong>distributed computing</strong>&nbsp;and&nbsp;<strong>data modeling</strong>.</li><li>Extensive experience with object-oriented design and coding and testing patterns, including experience with engineering software platforms and data infrastructures. Familiarity with functional programming concepts is a plus.</li><li>Outstanding communication and interpersonal skills.</li><li>Be excited about collaborating daily with your team and other groups while working via a distributed model.</li><li>Be eager to help your teammates, share your knowledge with them, and learn from them.</li><li>Be open to receiving constructive feedback.</li><li>You must be a world-class individual contributor to thrive at Toptal.</li></ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "BcQdIIQSQCifX5atpn75wg",
    "url": "https://stackoverflow.com/jobs/141116/freelance-interview-engineer-karat?a=LkcSbeLCa0o",
    "title": "Freelance Interview Engineer at Karat  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=2, ruby=0, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/mobile",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "mobile",
      "python"
    ],
    "hiringOrganization": {
      "name": "Karat",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 50000,
      "maxValue": 160000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 50k - 160k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 6:23:01 PM",
    "validThrough": "Aug 7, 2019 6:23:01 PM",
    "crawled": "Jul 31, 2019 6:23:01 PM",
    "content": "<h3><span>Freelance Interview Engineer</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Contract</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Backend Developer, Full Stack Developer</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>Software Development / Engineering</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>VC Funded</span>                                    </div>                            </div>                    </div>                <div>Company: Karat | No office location<br></div><h4>Technologies</h4><div></div><div>technical-interviewing</div><div>data-structures</div><div>algorithm</div><div>java</div><div>python</div><div>jcs150 1</div><div>JLK 1</div><div>Kier 1</div><div>Austin Heimark 1</div>                <h4>Job description</h4>                <div><p><strong>Who is Karat?</strong> Karat is the world's leader in conducting first-round technical interviews. Our network of experienced interview engineers have conducted over 20,000 technical interviews on behalf of clients including Indeed, Pinterest, Intuit, and Citrix. We continuously analyze our interview data to get smarter and more predictive with every interview we conduct. As a result, our clients reclaim 60% of engineering hours per hire, accelerate achievement of their hiring goal by 25%, and offer an exceptional experience with 95% of candidates rating their experience as positive.</p><p><strong>Our Mission</strong> Our mission is to be the world’s interviewer. We conduct highly predictive interviews for our clients with rigor, humanity and fairness. Karat helps companies hire the engineers they need to create the future and helps ensure that engineers are in jobs that maximize their strengths.</p><p><strong>Join our community of Freelance Interview Engineers.</strong> Karat Interview Engineers are a network of experienced software engineers who are equipped with the best practices and technology required to be professional interviewers. Every interviewer in the network is an accomplished engineer. &nbsp;Our interviewers include development managers, software engineers and freelancers covering the full technology stack.</p><p><strong>Flexible, high impact work that is compensated at highly competitive rates.</strong> As an Interview Engineer, you will be compensated at highly competitive rates for your interviewing expertise. &nbsp;The time commitment is flexible---many of our interviews happen on nights and weekends. &nbsp;Some experts do 10 interviews/week while others do over 25 interviews/week. &nbsp;You can work from anywhere, anytime. &nbsp;You will sharpen your interviewing skills and transform the interviewing experience for every candidate and company. Interviews are paid at a flat rate of $100 USD per interview (60 minutes interview + up to 30 minutes for written feedback report).</p><p><strong>We are looking for experienced software engineers who believe that interviewing is a first-class job. You should possess:</strong></p><ul><li>Interviewing experience focused on evaluating fundamental computer science skills (i.e. data structures, algorithms etc.), software craftsmanship (i.e. understanding of unit testing, source control, APIs etc.), and/or specific technologies (i.e. iOS, distributed systems etc.).</li><li>Strong oral and written communication skills. Able to empathize with candidates and provide actionable feedback.</li><li>An ability to structure your schedule (i.e. you can pick certain blocks of time during the day, evenings, weekends).</li><li>A genuine desire to continuously improve the Karat service and technical interviewing.</li></ul>                </div>            <div>        <a href='https://grnh.se/1295fb4f2' rel='nofollow'>                        Apply now        </a></div>            <h4>About Karat</h4>            <div><p><strong>Interviewing is broken. &nbsp;Karat professionalizes interviewing.</strong></p><ul><li>Karat is on a mission to assess the world's talent. &nbsp;We are the first dedicated marketplace for technical interviewers. Karat's network of seasoned engineers conduct the first rounds of technical interviews for elite engineering companies. Our robust platform saves teams thousands of valuable hours while allowing them to focus on the top performing candidates. &nbsp;Karat's unique approach recognizes that people are central to the hiring process and that they can be supercharged by leveraging machine learning and our rich database of the world's interviews.</li></ul>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Flexible Hours - You own your schedule</span>                            </li>                            <li>                                <span></span>                                <span>Work from anywhere</span>                            </li>                            <li>                                <span></span>                                <span>Transparent compensation</span>                            </li>                            <li>                                <span></span>                                <span>Bonus programs</span>                            </li>                            <li>                                <span></span>                                <span>Regular company outings</span>                            </li>                            <li>                                <span></span>                                <span>Access to a world-class community of expert interviewers</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xraRxYzxSoOCfmID4wCdfg",
    "url": "http://workinstartups.com/job-board/job/82892/data-scientist-extraordinaire-at-exciting-startup-at-clikd-dating-app/",
    "title": "Data Scientist Extraordinaire at Exciting Startup",
    "tags": [
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:css/frontend/3",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:php/php/5",
      "DBG_TECH1:k/t/w:wordpress/php/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=10, embedded=0, frontend=3}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Clikd Dating App",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 31, 2019 11:41:15 AM",
    "validThrough": "Aug 7, 2019 11:41:15 AM",
    "crawled": "Jul 31, 2019 1:06:31 PM",
    "content": "<p>Here at CLiKD We are currently recruiting for an intern with attitude. We are an early stage startup we are enjoying some great traction; you may have seen us featured on/in BBC News, Evening Standard, MTV, GQ, London Live, The Telegraph, Daily Mail plus many more, and we are looking for someone to join the team at this very exciting time. Our app is called CLiKD, you can find more info at www.clikdapp.com &ndash; we have been nominated for 4 awards and won best innovation in the dating industry 2017 as well as holding the number 4 spot for the UK&rsquo;s best dating blog!<br /><br />What we are looking for:<br />People with a passion for data, algorythims and business. Your number one aim will be able to help us to improve the in app mertrics and refine our recommendations algorthim. You will be part of fun and competitive team which is seeking to make CLiKD the next big dating app. You will be managed by our business development manager but also have scope to push your own businesses ideas. If your looking to get experience, well we are a startup which believes in giving you the opportunity to try things. With over 2.5 million personality based questions already answered by our ~40,000 users we have the data to build the most powerfull recommendation algorithm in the industry and this is your chance to shape that!</p><br /><p><br />You will be a confident communicator, with strong communication skills and go-get attitude. You&rsquo;ll need to be passionate about meeting new people and happy to muck in and get involved in a range of commercial initiatives as well as provide valuable insights and guidance to our app development team.<br /><br />Whilst you&rsquo;ll be working with our Business Development Manager and the CEO, you&rsquo;ll also have independence to work on many of small projects and experience any of the wider functions of an exciting app startup , hopefully allowing you to build your own portfolio of great work.</p><br /><p><br />This role is best aimed at those looking to gain some experience, put their academic studies to practical use or maybe you have an app idea yourself and would like to see how it&rsquo;s done, as long as you are passionate about what ever you do then we want you!<br /><br />You will be required to give us 2-3 days a week though we can be flexible to extent as to the time though this will generally be expected during 9-5:30.<br /><br />The company is growing quickly and we are keen to take people with us on our exciting journey and we are currently fundraising so we hope that post fundraising we will look to hire interns who prove themselves to be asset to the company. Sadly the current position is renumerated in expenses (normally &pound;15 per day) and equity.<br /><br /><br />SKILLS:&nbsp;<br />This opportunity is for someone with the right attitude, but we do need some basics:<br />-A background in Data Science and analysis<br />-Familiarity with Amazon Red Shift, MySQL, Tableau and Segment<br />-Technically proficient in terms of using standard office equipment<br />-Excellent communicator<br />-An enthusiasm for creating business and talking to people.&nbsp;<br />-Confidence, enthusiasm and the ability to challenge conventional thinking<br />-Anything else you can bring the table is a plus! PHP, HTML, CSS, SEO, PPC, Social Media Management/Advertising, Web Design, Wordpress, Photoshop, Final Cut, etc. amazing, but by no means essential.<br /><br /><br /><br />WHAT YOU&rsquo;LL GET:&nbsp;<br />The opportunity to work for an exciting new start up, shaping the future of the CLiKD app (and the dating industry) and growing a startup.<br />The chance to work on some crazy projects: https://www.clikdapp.com/love-at-first-flight<br />The chance to work on some great community projects: https://www.clikdapp.com/loveinlondon<br />The chance to show off your creative side and work with other creatives: https://www.clikdapp.com/blog https://www.youtube.com/channel/UCBE7SuipvhPp4snKJPhhOKQ<br />A repository of portfolio work<br />The opportunity to work with a wide range of interesting entrepreneurs and awesome brands.<br />Weekly seminars from experienced professionals on a range of business topics.</p>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "XBiNwWw2QMisDh6LF_-e7Q",
    "url": "https://jobmote.com/job/53965/senior-data-architect-remote/",
    "title": "Senior Data Architect- REMOTE",
    "tags": [
      "DBG:surround``OR(work,countri,locat,contract,base,you W can) 2W anywher",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>NiFi, AWS, glue, Kinesis, ETL<br><br>If you are a Senior Data Architect (remote) with experience in AWS and ETL development/pipelines, please read on!<br><br>Located in Denver, Colorado (but this person can be located anywhere in the U.S.), we specialize in assisting our clients with their digital assets in the crypto portfolio/management space. We have been in business for a couple of years and are growing immensely. We are a tight-knit team over here so someone who enjoys working collaboratively will work great here!<br><br>We are looking for a talented Data Architect who is going to have a strong background in AWS, ETL development and Linux. Any experience with Glue, Kinesis, or Nifi is a PLUS! You will be responsible for building or architecting the infrastructure, as well as data modeling and potentially ingestion and ex-filtration of data to different sources. This is a leadership role so someone who enjoys being the most Senior on the team will like it here! Any experience in the Crypto, Blockchain, or Fiance world would also be a PLUS!<br><br>**Will require 50% travel to Denver at first, then flatten out to 25%**<br><br>What You Will Be Doing<br><br>-Working collaboratively in a team<br>-Utilizing AWS and ETL pipelines<br>-Architecting the infrastructure<br><br>What You Need for this Position<br><br>At Least 3 Years of experience and knowledge of:<br><br>- NiFi<br>- AWS<br>- glue<br>- Kinesis<br>- ETLSo, if you are a Senior Data Architect- REMOTE with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "zbp7oc8jQM25-_aGlUog9w",
    "url": "https://jobmote.com/job/53957/senior-data-quality-analyst-relocation-or-work-remote/",
    "title": "Senior Data Quality Analyst - Relocation or Work Remote",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 75000,
      "maxValue": 88000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 75k - 88k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Job DescriptionPremier global, high growth San Antonio Company is adding to the team due to growth. This well- established Company is known for its phenomenal benefits, single digit turnover, team atmosphere, internal promotion track record, and work life balance. It has an incredible reputation for being people centric and a huge contributor to the community.The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensuring that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primaryApply best-in-class testing methodologies to ensuring the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop an expertise in the Co. data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Co. data.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications and technical architecture QualificationsQualifications Bachelor's Degree (Master's preferred) 5+ years' experience; working with end-users stakeholders in testing and analytics Advanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause. Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills Excellent planning, organization and time management skills- Intense curiosity and passion for data. Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferred Experience with Total Quality Management (TQM) preferred. Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $75,000 -$88,000 plus 10% bonus, several weeks of vacation and great benefits</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "GR3Q7fLWQuOMZIA8c8tRAQ",
    "url": "https://jobmote.com/job/53954/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 10:07:26 PM",
    "validThrough": "Aug 2, 2019 10:07:26 PM",
    "crawled": "Jul 31, 2019 3:06:25 AM",
    "content": "<div>Sr. Engineer - Product development?<br><br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.<br><br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.<br><br>Check out our website below to learn more about what we do and how we help our clients.<br><br>Primary Responsibilities:<br><br>???????? Provide thought leadership in architecture, design for analytics products<br><br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements<br><br>???????? Lead cross functional product development efforts<br><br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan<br><br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines<br><br>???????? Provide technical support to assist clients and partners during and post implementation<br><br>???????? Manage development resources onsite and offshore<br><br>???????? Develop and expand our application knowledge base and best practices for delivering data products<br><br>Required Experience and Skills:<br><br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem<br><br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must<br><br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must<br><br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem<br><br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills<br><br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.<br><br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture<br><br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)<br><br>???????? Experience with NoSQL databases<br><br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.<br><br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.<br><br>???????? Experience in professional services or technical consulting with enterprise software solutions<br><br>???????? Proven ability to balance and manage multiple, competing priorities.<br><br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.<br><br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.<br><br>What We Offer:<br><br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement<br><br>???????? Global career mobility, employee recognition programs, professional development<br><br>???????? State of the art technology which allows for seamless global connectivity<br><br>???????? Rich wellness program and health incentives<br><br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately<br><br>#LI-RD1<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eXvc5tc5Re6H4f7aUYmZhA",
    "url": "https://www.remotepython.com/jobs/bab7737f42d34a1b9de7072bf785c1d7/",
    "title": "Remote Data Scientist at Toughbyte",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``work 2W wherev 2W you",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:fabric/python/8",
      "DBG_TECH1:k/t/w:kotlin/mobile/5",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=10, other=0, dotnet=0, c=0, mobile=5, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Toughbyte",
      "sameAs": "https://www.toughbyte.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 5:08:19 PM",
    "validThrough": "Aug 6, 2019 5:08:19 PM",
    "crawled": "Jul 30, 2019 5:08:19 PM",
    "content": "<h3>Remote Data Scientist</h3>Company: Toughbyte<br>Job Type:&nbsp;Full-time<div>                              <div>                      </div>                    <p></p><p>Our client is developing software to support the global food industry. The platform supports information flows within and across companies in the food value chain, enabling players in the industry to focus on their own specific tools and systems.</p><p><br>They are not building ERP systems, but rather the information fabric that can connect these systems and/or be the platform on which a new generation of ERP features can be built. Examples of such features are end-to-end tracking and tracing of foods to ensure food safety and product differentiation and new ways to trade to manage the ebbs and flow of supply and demand.<br><br>It is a remote-only company and they give their employees the opportunity to solve challenges in the global food industry while living and working wherever you are most comfortable. The company believes in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth.</p><p><strong>Requirements</strong></p><p>You have a proven track record of reading data and making solid conclusions. You know both the art <em>and</em> science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might help us further bolster our conclusions.  You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them!<br><br><strong>Must have skills:<br></strong><br></p><ul><li>Strong ML experience (not just a researcher)</li><li>Python</li><li>Strong development skills</li></ul><p><strong>Good to have skills:<br></strong><br></p><ul><li>Kotlin</li><li>Personality: communicative, independent, responsible </li><li>Teamwork </li></ul><p></p>                      <h4>Desired Skills</h4>            <ul>                              <li><span>Data Science</span></li>                              <li><span>Machine Learning</span></li>                          </ul>                                <h4>How to Apply</h4>            <p></p><p>Please send your CV to nina.shcherbakova@toughbyte.com</p><p></p>                                <h4>Contact Info</h4>            <ul>                                          <li><strong>Company Website:</strong> <a href='https://www.toughbyte.com/' rel='nofollow'>https://www.toughbyte.com/</a></li>            </ul>                  </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eX1n1odFQGCe15miRdECFw",
    "url": "https://remoteok.io/jobs/74209",
    "title": "Paid Research Study For Developers With Machine Learning Python Experience",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/14",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:techWeightMap:{python=6, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=38, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "User Research International",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 30, 2019 3:31:52 AM",
    "validThrough": "Aug 6, 2019 3:31:52 AM",
    "crawled": "Jul 30, 2019 4:06:30 AM",
    "content": "<span></span> <span><h4>User Research International</h4></span> <br> <h3>Paid Research Study For Developers With Machine Learning Python Experience</h3> <div>  <div>   <br>User Research International is a research company based out of Redmond, Washington. Working with some of the biggest companies in the industry, we aim to&nbsp;improve your experience via&nbsp;paid research studies. Whether it be the latest video game or productivity tools, we value your&nbsp;feedback and experience. We are currently conducting a research study called The Data Science\\Machine Learning Study. We are looking for current&nbsp;full-time&nbsp; Developers or Data Scientists&nbsp;who are familiar with&nbsp;Machine Learning,&nbsp;Python, and Jupyter Notebooks.This study is&nbsp;a one time study held remotely. We’re offering $200 for participation in this study. Session lengths are 1 hour. These studies provide a platform for our researchers to receive feedback. This will be a one hour open ended interview with the researcher. We want to understand how you personally create and work with machine learning models. We have included the survey link for the study below. Taking the survey will help determine if you fit the profile requirements. If you complete the survey, and you are actually a fit to the study's requirements, URI will follow up with you. I have summarized the study details below. Thank you!   <br>   <br>Study: The Data Science\\Machine Learning&nbsp;Study   <br>   <br>Gratuity: $200   <br>   <br>Session Length:&nbsp;1 hour&nbsp;   <br>   <br>Location:&nbsp;Remote via an online meeting   <br>   <br>Dates:&nbsp;August. Available&nbsp;times are located within the survey   <br>   <br>Survey: The Data Science\\Machine Learning&nbsp;Study  </div> </div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "8MTcq0kwQV-ClUKxLDqRUQ",
    "url": "https://jobmote.com/job/53741/data-engineer-remote/",
    "title": "Data Engineer (Remote)",
    "tags": [
      "DBG:surround``5N( opportun,             2N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=56, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Anonymous",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 50000,
      "maxValue": 55000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 50k - 55k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:07:27 PM",
    "validThrough": "Aug 1, 2019 10:07:27 PM",
    "crawled": "Jul 30, 2019 3:06:25 AM",
    "content": "<div>Data Engineer (Remote) - <br><br>Urgent requirement for a leading client in the travel and tourism industry looking for a Data Engineer (Remote). Even though they have been in the industry for over 25 years, they still have an innovative, entrepreneurial and start up mentality. <br><br>They are in the process of moving their data storage to scalable environment using Google Cloud Services. They are experimenting with live streaming data and improving the batch processing. <br><br>Data Engineer (Remote) - Key requirements:<br><br>Experienced Data Engineer with expertise in writing advanced SQL<br>Strong experience with Python programming<br>Proven ability to work with a variety of data infrastructure, including relational databases (e.g. DB2, MySQL), and column store (e.g. Google Big Query, Redshift)<br>Expertise in building and maintaining reliable ETL jobs<br>Experience working with Talend, Luigi or Apache Airflow.<br><br>Data Engineer (Remote) - Role and responsibility: <br><br>Responsibility to deliver the data requirements to the business<br>Migrating data pipelines from legacy platforms to the new cloud based data stack<br>Lead in solving Insurance specific challenges and delivering innovative solutions for the business<br>Learning and working with cutting-edge tech and solutions.<br><br>As a Data Engineer (Remote), you would have the opportunity to join at an exciting period of exceptional projected growth. The team move fast and deliver excellence at pace, never accepting second best.<br><br>We are looking to line up interviews as of immediately, so if you are interested in hearing more about this vacancy and organisation, please don't hesitate to apply.<br><br>Location: Remote (Required to be UK based)<br><br>Employment: Permanent<br><br>Salary: £50,000 - £55,000 (depending on experience)<br><br>Sponsorship: Not available</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "oJKxihbnTmCVeaFyWGlCng",
    "url": "https://jobmote.com/job/53728/data-engineer-remote/",
    "title": "Data Engineer (Remote)",
    "tags": [
      "DBG:surround``OR(partial,share,amen,semi) 3W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "CyberCoders",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:07:26 PM",
    "validThrough": "Aug 1, 2019 10:07:26 PM",
    "crawled": "Jul 30, 2019 3:06:25 AM",
    "content": "<div>Minimum Required Skills:<br>AWS, ETL, Data Conversion, Oracle, SQL<br><br>If you are a Data Engineer (Remote) with experience, please read on!<br><br>What You Will Be Doing<br><br> Recommend and implement data processing tools and technologies<br> Extract, transform and load data pipelines from end-to-end<br> Create, develop and document data mapping rules<br> Data cleansing and transformation<br> Write specifications from which conversion programs will be written<br> Collaborate with subject matter experts to ensure that the specifications meet the business and system requirements<br> Utilize tools and applications to analyze and convert data to a standardized format<br> Recommend and implement data processing tools and technologies to keep us at the forefront of real estate data science<br> Develop continuous process improvements<br> Identify and fix data bugs and improve the overall quality of information<br><br>What You Need for this Position<br><br> Have 3+ years of experience using data and related technologies such as SQL, Oracle, AWS and scripting languages to aggregate, gather, and manipulate data<br> Understand databases, data conversion, and data cleansing methods<br> Have experience parsing and mapping data<br> Have advanced Microsoft Excel experience<br> Are an analytical, results-driven individual with great attention to detail and excellent problem solving and critical thinking skills<br> Real Estate data experience is a plus!<br><br>What's In It for You<br><br>- Competitive Pay<br>- Partial or full remote is an option!<br>- Medical, Dental, Vision<br>- Flexible PTOSo, if you are a Data Engineer (Remote) with experience, please apply today!<br><br>Applicants must be authorized to work in the U.S.<br><br>Security Clearance will be needed - therefore, only US citizens can be considered.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!<br><br>Looking forward to receiving your resume and going over the position in more detail with you.<br><br>- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.<br><br>Looking forward to receiving your resume!<br><br>CyberCoders<br><br>CyberCoders, Inc is proud to be an Equal Opportunity Employer<br><br>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br><br>Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br><br>Copyright 1999 - 2019 . CyberCoders, Inc. All rights reserved.<br> - provided by Dice</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "L7latbTzSvykpqHSCgs42w",
    "url": "https://stackoverflow.com/jobs/285252/paid-research-study-for-developers-with-machine-user-research-international?a=1xFd0np8eBQA",
    "title": "Paid Research Study for Developers with Machine Learning + Python Experience at User Research ...",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/16",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:techWeightMap:{python=8, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=58, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "User Research International",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 29, 2019 10:30:25 PM",
    "validThrough": "Aug 5, 2019 10:30:25 PM",
    "crawled": "Jul 29, 2019 10:30:25 PM",
    "content": "<h3><span>Paid Research Study for Developers with Machine Learning + Python Experience</span>                </h3>                    <h4>About this job</h4>                    <div>                            <div>                                    <div>                                        <span>Job type: </span>                                        <span>Full-time</span>                                    </div>                                    <div>                                        <span>Experience level: </span>                                        <span>Mid-Level, Senior, Lead</span>                                    </div>                                    <div>                                        <span>Role: </span>                                        <span>Data Scientist</span>                                    </div>                            </div>                            <div>                                    <div>                                        <span>Industry: </span>                                        <span>AI Research, Market Research, Surveying</span>                                    </div>                                    <div>                                        <span>Company size: </span>                                        <span>11–50 people</span>                                    </div>                                    <div>                                        <span>Company type: </span>                                        <span>Private</span>                                    </div>                            </div>                    </div>                <div>Company: User Research International | No office location<br></div><h4>Technologies</h4><div></div><div>python</div><div>machine-learning</div><div>jupyter-notebook</div><div>data-science</div><div>jupyter-lab</div>                <h4>Job description</h4>                <div><p>User Research International is a research company based out of Redmond, Washington. Working with some of the biggest companies in the industry, we aim to&nbsp;improve your experience via&nbsp;paid research studies. Whether it be the latest video game or productivity tools, we value your&nbsp;feedback and experience. We are currently conducting a research study called The Data Science\\Machine Learning Study. We are looking for current<strong>&nbsp;full-time&nbsp; Developers or Data Scientists</strong>&nbsp;who are familiar with&nbsp;Machine Learning,&nbsp;Python, and Jupyter Notebooks.This study is&nbsp;a one time study held remotely. We’re offering <strong>$200</strong> for participation in this study. Session lengths are 1 hour. These studies provide a platform for our researchers to receive feedback. This will be a one hour open ended interview with the researcher. We want to understand how you personally create and work with machine learning models. We have included the survey link for the study below. Taking the survey will help determine if you fit the profile requirements. If you complete the survey, and you are actually a fit to the study's requirements, URI will follow up with you. I have summarized the study details below. Thank you!</p><p>Study: The Data Science\\Machine Learning&nbsp;Study</p><p>Gratuity: <strong>$200</strong></p><p>Session Length:&nbsp;1 hour&nbsp;</p><p>Location:&nbsp;Remote via an online meeting</p><p>Dates:&nbsp;August. Available&nbsp;times are located within the survey</p><p>Survey: <a title=&quot;Click here to qualify for participating in the Data Science\\Machine Learning Survey&quot; href='https://uriuxn.ca1.qualtrics.com/jfe/form/SV_2fTdSmgpchX943P?SOURCE=StackOverflow' rel='nofollow'>The Data Science\\Machine Learning&nbsp;Study</a></p>                </div>            <div>        <a href='https://stackoverflow.com/jobs/apply/285252?reset=False&amp;ra=1xFd0np8eBQA&amp;oqs=a%3D1xFd0np8eBQA' rel='nofollow'>Apply now</a></div><div>                                                                                                                                                            </div>            <h4>About User Research International</h4>            <div><p>We use your experience to improve upon the products you use. Whether it be the latest video game or productivity tools, we value your experience.&nbsp;</p>            </div>                            <h4>Benefits</h4>                    <ul>                            <li>                                <span></span>                                <span>Paid research studies</span>                            </li>                            <li>                                <span></span>                                <span>Improving tech</span>                            </li>                            <li>                                <span></span>                                <span>Getting  your feedback and experience</span>                            </li>                            <li>                                <span></span>                                <span>Meeting researchers working directly on the products you use</span>                            </li>                    </ul>                ",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ZZzeZGbSR_-rj02Z6r98yg",
    "url": "http://workinstartups.com/job-board/job/82786/cto-at-tbc/",
    "title": "CTO",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG_TECH1:k/t/w:android/java/1",
      "DBG_TECH1:k/t/w:android/mobile/2",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:ios/apple/2",
      "DBG_TECH1:k/t/w:ios/mobile/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=4, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=2, java=1, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TBC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 11:02:07 PM",
    "validThrough": "Aug 4, 2019 11:02:07 PM",
    "crawled": "Jul 29, 2019 12:06:30 PM",
    "content": "Looking for a CTO as a partner within a venture that is going through its first round of investment. Equity rather than salary at this stage. Must be prepared to get hands dirty and be able to code including Amazon Lex/Lambda and front end iOS and Android. <br />Project is secret but has a great team on board. Very cutting edge tech. Great founders and amazing proposition.<br />Looking for a CTO who wants to build something on the side as the heavy lifting has been done. A great opportunity for someone that wants to help women globally.<br />Please reply with CV. Experience of previous startup successes a bonus. Work can be remote at this stage but must be in London for meetings with the founding team. <br />We're at a stage of building MVP having full proposition, brand, UI/UX and full tech proposition established.<br />This is an opportunity for someone who can create a great future for themselves within a team that just wants to do something AMAZING!",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Z_Yxf1InSQKrpOKs362YNA",
    "url": "https://jobmote.com/job/52859/azure-big-data-engineer-remote-w-travel/",
    "title": "Azure Big Data Engineer (REMOTE) w/ Travel",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:25 PM",
    "validThrough": "Jul 31, 2019 10:07:25 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>FULLY REMOTE**<br> Sr. Data Engineer<br> Experience:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience implementing and optimizing data pipeline and workflow management tools</li><li>Spark</li><li>Data Analytics</li><li>Microsoft Business Intelligence</li><li>Power BI and Blob Storage</li><li>Azure SQL, Blob/ Lake</li><li>Wants to Travel more than 50% of the time</li><li>Data Modeling</li><li>Production experience</li></ul> Benefits:<ul><li>Competitive salary</li><li>PTO</li><li>Full Health Insurance Packages</li><li>401K+ match</li><li>Flexible Hours</li><li>Opportunity for advancement and career growth</li><li>Commuter benefits</li><li>Rewarding company culture</li><li>Bonus incentives</li><li>Ability to grow your skill set</li></ul> For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "2dYAiTMESuqEbnE533ulNg",
    "url": "https://jobmote.com/job/52843/senior-big-data-engineer-product-development-remote-us/",
    "title": "Senior Big Data Engineer - Product Development (Remote - US)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=5, c=2, mobile=0, go=0, nodejs=1, bigdata-ml=24, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "TTEC",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>Sr. Engineer - Product development?<br><br>TTEC?s Insights Platform is a cloud-based customer data platform that provides brands with a 360? view of their customers? needs, behaviors, and preferences with the insights they need to deliver a great customer experience.<br><br>The product development engineer will be responsible for development, implementation and delivery for new and ongoing client implementations of the Insights Platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.<br><br>Check out our website below to learn more about what we do and how we help our clients.<br><br>Primary Responsibilities:<br><br>???????? Provide thought leadership in architecture, design for analytics products<br><br>???????? Be an SME in technical and functional aspects of the insights platform and its integration requirements<br><br>???????? Lead cross functional product development efforts<br><br>???????? Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan<br><br>???????? Work with data scientists and business stakeholders to build the product and feature pipelines<br><br>???????? Provide technical support to assist clients and partners during and post implementation<br><br>???????? Manage development resources onsite and offshore<br><br>???????? Develop and expand our application knowledge base and best practices for delivering data products<br><br>Required Experience and Skills:<br><br>???????? Master?s in computer science or equivalent with at least 5 years of relevant experience in big data ecosystem<br><br>???????? Expert level proficiency in C#, Python, JavaScript, SQL is a must<br><br>???????? Experience in building/consuming REST APIs (JSON) and SDKs is a must<br><br>???????? Proficiency with the Azure(preferred), AWS or other cloud ecosystem<br><br>???????? Understanding of Agile Software Development Lifecycle and project planning/execution skills<br><br>???????? Ability to assess business rules, collaborate with stakeholders and perform source-to-target data mapping, design and review.<br><br>???????? Experience with processing large sets of structured, semi-structured and unstructured data and supporting systems application architecture<br><br>???????? Experience with batch and?real-time?processing frameworks (Hadoop, Apache Storm, Apache Kafka, Apache Spark etc.)<br><br>???????? Experience with NoSQL databases<br><br>???????? Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.<br><br>???????? A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.<br><br>???????? Experience in professional services or technical consulting with enterprise software solutions<br><br>???????? Proven ability to balance and manage multiple, competing priorities.<br><br>???????? Collaborative interpersonal skills and ability to work within cross-functional teams.<br><br>???????? Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.<br><br>What We Offer:<br><br>???????? Variable incentive bonus plan, 401K company match, tuition reimbursement<br><br>???????? Global career mobility, employee recognition programs, professional development<br><br>???????? State of the art technology which allows for seamless global connectivity<br><br>???????? Rich wellness program and health incentives<br><br>Lead Everyday w Do the Right Thing w?Reach for Amazing w?Seek First to Understand w Act as One w Live life Passionately<br><br>#LI-RD1<br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "IC7N0AWzSlyUl5pE1Cw6nQ",
    "url": "https://jobmote.com/job/52837/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div>Azure Big Data Engineer (Remote Flexibility)<br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.<br> *AZURE EXPERIENCE REQUIRED<br> Skills:<ul><li>Experience using languages like Python, Scala, and Java</li><li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li><li>Experience with ETL tools like SSIS, SSAS, SSRS</li><li>Some familiarity with Microsoft BI and Power BI is great as well</li><li>Experience with data pipeline and workflow management tools</li></ul>Benefits:<ul><li>Medical</li><li>Dental</li><li>Vision</li><li>Family leave</li><li>PTO</li><li>Retirement Plan</li><li>Remote options</li></ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!<br> What's in it for you?<br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.<br><br><b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "VrBoioWkTZ-olOsb2AlUjw",
    "url": "https://jobmote.com/job/52831/senior-hadoop-developer-remote-role/",
    "title": "Senior Hadoop Developer (Remote Role)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=16, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AIC (part of ACS Group)",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 28, 2019 10:07:24 PM",
    "validThrough": "Jul 31, 2019 10:07:24 PM",
    "crawled": "Jul 29, 2019 3:06:25 AM",
    "content": "<div><b>Additional Required Qualifications:</b><br>* Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures<br>* Proficiency using versioning tools<br>* Thorough knowledge of Information Technology fields and computer systems<br>* Demonstrated organizational, analytical and interpersonal skills<br>* Flexible team player<br>* Ability to manage tasks independently and take ownership of responsibilities<br>* Ability to learn from mistakes and apply constructive feedback to improve performance<br>* Must demonstrate initiative and effective independent decision-making skills<br>* Ability to communicate technical information clearly and articulately<br>* Ability to adapt to a rapidly changing environment<br>* In-depth understanding of the systems development life cycle<br>* Proficiency programming in more than one object oriented programming language<br>* Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio<br>* Proficiency using debugging tools<br>* High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy<br><br><b>Looking for some one 3-4 year experience with Hadoop/Spark ETL<br>Experienced in Agile methodologies<br>Healthcare experience is strongly preferred</b><br></div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "9F-zgQMfQZusSb0mQVwt4Q",
    "url": "https://www.remoteage.com/remote-jobs/data-engineer-true-north-11/",
    "title": "Data Engineer, True North",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:iphone/apple/2",
      "DBG_TECH1:k/t/w:iphone/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=6, c=2, mobile=3, go=0, nodejs=2, bigdata-ml=56, ruby=2, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Delaware North",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 27, 2019 1:08:59 PM",
    "validThrough": "Aug 3, 2019 1:08:59 PM",
    "crawled": "Jul 27, 2019 2:07:19 PM",
    "content": "<h3> Data Engineer, True North </h3>\n<div>\n United States, New York\n</div>\n<div>\n Company: Delaware North\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p>Our Exciting Work Environment This position will be based out of Delaware North’s new global headquarters, a state-of-the-art, 12-story, mixed-use building in downtown Buffalo, N.Y. The headquarters facility, reflective of our values, integrates the latest advances in environmental, energy conservation and office design. <br>The Opportunity At Delaware North we have a a long history of operational success and we have ambitious goals for our future growth and operating performance. These aspirations are supported by a transformative enterprise-wide initiative called True North. True North re-imagines the Delaware North operating model by creating processes and tools and providing enhanced support to our local teams that will enable us to best serve our guests, clients, and 55,000+ associates. <br> To achieve these goals, we need people like you. The True North team is hiring a Data Engineer to be part of our Data Solutions Team. <br> Data Solutions is a rapidly growing team that enables Delaware North’s vision of using data as differentiator in the hospitality industry. Our work is the foundation of company initiatives to automate business processes, gather insights, and make informed decisions. Our team uses PaaS solutions and Open Source Software to aggregate, process, catalog and distribute large data sets throughout Delaware North’s global organization, client base and partners. These foundational services empower Delaware North’s mobile, data science, business intelligence, and operational systems. Users of the Delaware North Data Platform range from NASA to several MLB, NBA, NHL, &amp; NFL teams. As a member of our team, the Data Solutions Support Engineer will provide health monitoring and unparalleled customer advocacy for Delaware North’s distributed data platform (Data Lake). <br> The Data Engineer will work closely with the Business to identify and specify opportunities for integration with existing systems in a highly resilient manner using Delaware North’s Data Platform. After the identification of business requirements, the Data Engineer will participate in various exercises to design a technical solution as well as participate in the implementation with internal team mates and off-shore resources. As implementation progresses, the Data Engineer will keep the lines of communication open with internal clients regarding solution status and address technical blockers that may arise. Additionally, the holder of this position will develop integration tests to validate solution acceptance criteria and participate in free-form experimental exercises to keep skills and team goals modernized. <br> Where you fit in:</p>\n <ul>\n  <li> Design and implement project based solutions </li>\n  <li> Implement data platform improvements and new features </li>\n  <li> Assist support team with resolution of Data Platform bug fixes </li>\n  <li> Interface with clients, vendors, and internal users of the data platform on understanding the data </li>\n  <li> Participate in group design and architecture sessions </li>\n  <li> Author documentation for standard operating procedures, knowledge base articles, etc. </li>\n </ul>\n <p> Skills &amp; experience you need:</p>\n <ul>\n  <li> Minimum 2 years of related professional experience </li>\n  <li> Bachelor’s degree in Computer Science, Information Systems or similar STEM field preferred </li>\n  <li> Experience designing and developing solutions with a modern programming language such as Python, Ruby, JavaScript, Java, C#, etc </li>\n  <li> Working knowledge of data structures and formats such as JSON and XML </li>\n  <li> Excellent organizational, oral and written communication skills </li>\n  <li> Ability to effectively collaborate with Business Users and vendors to address development issues </li>\n  <li> Ability to effectively troubleshoot and track issues through to resolution </li>\n  <li> Passion for delivering high quality and meaningful results </li>\n  <li> Technical specification and use case (story) documentation. </li>\n  <li> Such as UML, Domain and Entity Relationship Modeling, Business Process Notation </li>\n  <li> Data Persistence Methods such as NoSQL and RDBMS (MSSQL, Oracle, MySQL, MongoDB) </li>\n  <li> Familiarity with Data Mapping &amp; Transformation Techniques </li>\n </ul>\n <p> Preferred skills:</p>\n <ul>\n  <li> Familiarity with RESTful Web Services, ETL, ESB, and microservices </li>\n  <li> Integration testing and automation using a continuous integration (CI) platform (such as Jenkins, TeamCity or Bamboo) </li>\n  <li> Familiarity with cloud computing, analysis &amp; implementation experience (bonus if it relates to Amazon Web Services specifically) </li>\n  <li> Experience working with Agile methodologies </li>\n  <li> Proficiency with Unix/Linux </li>\n  <li> Experience with Configuration Management tools (such as Ansible, Chef, etc.) </li>\n </ul>\n <p> Here’s some of what you’ll get in return:</p>\n <ul>\n  <li> Join a creative and highly collaborative team that is empowered to select the right technology for the task at hand </li>\n  <li> Regularly scheduled “innovation time” to work on creative applications of new technology (doesn’t have to be work related) </li>\n  <li> Flexible work schedule, “casual Fridays”, and ability to work remotely in certain cases </li>\n  <li> Opportunity for travel to interesting field locations (small percentage of travel required) </li>\n  <li> Company paid iPhone with LTE service </li>\n  <li> Free coffee, espresso, cappuccino, fruits, and bagels </li>\n  <li> Yearly paid training, conference and certifications of your choice </li>\n  <li> Career growth – Delaware North values and invests in its family and promotes from within regularly </li>\n  <li> Benefits including health, dental, paid vacation &amp; holidays, life insurance, short &amp; long term disability, company discounts </li>\n  <li> Bonus eligibility </li>\n  <li> 401k with employer match and financial planning services </li>\n  <li> Choice of MacBook Pro or PC Ultrabook and peripherals </li>\n </ul>\n <p>Who We Are Take your career beyond the ordinary-to the extraordinary.<br> At Delaware North, you’ll love where you work, who you work with, and how your day unfolds. Whether it’s in sporting venues, casinos, airports, national parks, iconic hotels, or premier restaurants, there’s no telling where your career can ultimately take you. We empower you to do great work in a company with 100 years of success, stability and growth. If you have drive and enjoy the thrill of making things happen – share our vision, grow with us.<br> Delaware North is one of the largest privately held hospitality companies in the world. Founded in 1915 and owned by the Jacobs family for more than 100 years, Delaware North has global operations at high-profile places such as sports and entertainment venues, national and state parks, destination resorts and restaurants, airports, and regional casinos. Our 55,000 employee associates are dedicated to creating special experiences one guest at a time in serving more than a half-billion guests annually. Delaware North operates in the sports, travel hospitality, restaurant and catering, parks, resorts, gaming, and specialty retail industries and has annual revenue of about $3 billion. Learn more about Delaware North, a global leader in hospitality, at .<br> All applicants will be subject to a pre-employment background check and may be subject to a pre-employment drug test depending upon the position and/or client requirements.<br> Delaware North Companies, Incorporated and its subsidiaries consider applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status. Delaware North is an equal opportunity employer.<br> #LI-PE1<br></p> \n <div> \n  <a href='https://www.jobg8.com/ATSApply.aspx?re6gYjdkhs%2frkEJdnuzpmwq' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "bGHjqDpvRYiFLE2IeFYV3g",
    "url": "http://workinstartups.com/job-board/job/82776/graphic-designer-at-vendi-an-ai-assisted-p2p-marketplace-to-buy-and-sell-verified-phones-at-vendi/",
    "title": "Graphic Designer at vendi, an AI-assisted P2P marketplace to buy and sell verified phones",
    "tags": [
      "DBG:surround``3N( OR(feasibl,OR(consid,consider),option,occas,opportun,possibl,abil), OR(3N(remot, work),telecommut,2N(work,home)) ) NOT OR(regularli, abracadabra)",
      "DBG:surround``OR(fulltim,offer) 5W 2N(work,remot)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "vendi",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 27, 2019 9:49:56 AM",
    "validThrough": "Aug 3, 2019 9:49:56 AM",
    "crawled": "Jul 27, 2019 11:06:30 AM",
    "content": "**Intro:**\n<br>\n<br>Interested in working with an exciting young tech-startup that uses Machine Learning to create a high quality marketplace community…to become the Amazon of peer to peer? vendi is an AI-assisted marketplace for you to buy and sell quality products. We are starting with phones. We use AI to list and verify the phone for you in seconds.\n<br>\n<br>This is an awesome opportunity to work with a young and dynamic team and get a good foothold in a fast expanding startup company. You will have a possibility to grow within the team, playing a crucial role in taking the companies design to the next level. Perfect for anyone who is interested in the tech industry and even more of a plus if you have an interest in AI and Machine Learning.\n<br>\n<br>**About the role:****\n<br>\n<br>We are looking for a Graphic Designer who can support our team in our office in central London. We will also offer the opportunity to work remotely. This internship is a unique opportunity to gain insights into a new venture during the early stages of growth.\n<br>\n<br>The main contents of the role is to improve the existing design of the website, help on social media content, and the app. We need someone who learns fast, is self-motivated, proactive and multi-disciplined.\n<br>\n<br>**Your Skills**\n<br>\n<br>Uses Illustrator/Invision/Photoshop/Sketch or any similar UI Graphic Design tools.\n<br>A plus if you are knowledgeable about marketplace startups.\n<br>You are driven and have a “hands-on” mentality;\n<br>You feel comfortable handling different and multiple tasks on a daily basis;",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "j2H86qOVT8a1tH-YRR89GQ",
    "url": "https://jobmote.com/job/52569/remote-working-machine-learning-engineer-uk/",
    "title": "Remote-working Machine Learning Engineer UK",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:express/nodejs/16",
      "DBG_TECH1:k/t/w:java/java/14",
      "DBG_TECH1:k/t/w:java/mobile/7",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/28",
      "DBG_TECH1:k/t/w:neo4j/bigdata-ml/6",
      "DBG_TECH1:k/t/w:python/python/14",
      "DBG_TECH1:techWeightMap:{python=14, other=0, dotnet=0, c=0, mobile=7, go=0, nodejs=16, bigdata-ml=34, ruby=0, apple=0, java=14, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Searchability",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "GBP",
      "minValue": 60000,
      "maxValue": 60000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "GBP 60k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:07:21 PM",
    "validThrough": "Jul 29, 2019 10:07:21 PM",
    "crawled": "Jul 27, 2019 3:06:25 AM",
    "content": "<div>\n <p><strong>Remote Machine Learning Engineer - Machine Learning / Software Engineering / AWS / Python or Java</strong></p> \n <p><strong>BRAND NEW FULLY REMOTE OPPORTUNITY WITHIN AN EXCITING AND EXPANDING START-UP DEVELOPING A CUTTING-EDGE CLOUD PRODUCT!!</strong></p> \n <ul>\n  <li>Mid-level to senior candidates will be considered</li>\n  <li><strong>Full-time remote working opportunity </strong></li>\n  <li>Flexible working hours and flexible annual leave</li>\n  <li>Machine Learning / Software Engineering / AWS / Python or Java</li>\n  <li><strong>Salary up to £60,000</strong></li>\n  <li>To apply, either call <strong>/</strong> or email </li>\n </ul>\n <p>Headquartered in Southampton, we are a rapidly expanding start-up who are seeking to appoint a talented Machine Learning Engineer with solid Machine Learning / Software Engineering / AWS / Python or Java knowledge to join our team. Using cutting-edge technology, we are developing a cloud product providing scalable predictive maintenance to globally recognised clients.</p> \n <p>Sourced by <strong></strong> - your 24/7 twitter feed of latest IT vacancies across the South West!</p> \n <p><strong>WHO ARE WE? </strong></p> \n <p>Since our inception in 2014, we have continued to grow and are now a leading cloud-based software house for predictive maintenance. Driven by the Industrial IoT, We are developing cutting-edge cloud products within the manufacturing sector, focused around advanced condition monitoring and providing scalable prognostics. We fully promote a start-up vibe, based around trust and excellence. We offer remote working, flexible working hours and flexible annual leave. Now with globally recognised clients and having branched out into Europe, we are now looking to further expand our team by appointing a talented and dedicated Machine Learning Engineer with solid Machine Learning / Software Engineering / AWS / Python or Java experience.</p> \n <p><strong>WHAT WILL YOU BE DOING? </strong></p> \n <p>Immersing yourself as a key member of the engineering team, you will use your Machine Learning / Software Engineering / AWS / Python or Java skills to bring research into production. You will be building complex Machine Learning applications and regualrly be involved in Microservice architecture. You will understand information from the R&amp;D teams and be able to put this into production software. You will be building complex applications using best practices such as code reviews, continuous deployment and test-driven development. You will be utilising your knowledge of supervised and unsupervised Machine Learning techniques daily. Ideally, you will have knowledge of either MongoDB, Redis or Neo4J. Interviews are being held week beginning <strong>29th July</strong>, so please apply today to express your interest!</p> \n <p><strong>WE NEED YOU TO HAVE….</strong></p> \n <ul>\n  <li>Machine Learning / Software Engineering / AWS / Python or Java</li>\n  <li>Ideally at least 2 years' experience</li>\n  <li>Experience with supervised and unsupervised Machine Learning techniques</li>\n  <li>Experience with Microservices architecture</li>\n  <li>Experience with Linux or Docker </li>\n </ul>\n <p><strong>IT'S NICE TO HAVE….</strong></p> \n <ul>\n  <li>Experience with MongoDB, Redis or Neo4j</li>\n  <li>Familiar with scalable cloud systems</li>\n </ul>\n <p><strong>TO BE CONSIDERED….</strong></p> \n <p>Please either apply by clicking online or emailing me directly to - For further information please call me on <strong>/ </strong>. I can make myself available outside of normal working hours to suit from 7am until 10pm. If unavailable, please leave a message and either myself or one of my colleagues will respond. By applying for this role, you give express consent for us to process &amp; submit (subject to required skills) your application to our client in conjunction with this vacancy <strong>only. </strong>Also feel free to follow me on Twitter<strong> </strong>or connect with me on LinkedIn! I look forward to hearing from you.</p> \n <p><strong>KEY SKILLS: </strong></p> \n <p><strong>Machine Learning / Software Engineering / AWS / Python or Java </strong> </p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "TqR3y-SqTUSb-cyvDpHONw",
    "url": "https://jobmote.com/job/52540/remote-data-analytics-data-statistics-actuarial-scientist/",
    "title": "Remote Data Analytics / Data Statistics / Actuarial Scientist",
    "tags": [
      "DBG:surround``can 2W remot",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:go/go/3",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=1, c=0, mobile=0, go=3, nodejs=0, bigdata-ml=10, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Cameron Craig Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:07:21 PM",
    "validThrough": "Jul 29, 2019 10:07:21 PM",
    "crawled": "Jul 27, 2019 3:06:25 AM",
    "content": "<div>\n This full-time, permanent Data Analytics / Data Statistics / Actuarial Scientist career opportunity can be remote as the company is very employee-oriented and family-oriented.? If the successful candidate prefers to be onsite, that is also welcomed.? The company utilizes the very latest predictive, cloud-based technology to reduce risk exposure.??IoT (Internet of Things) and Artificial Intelligence are utilized. The company is growing and on a pace to triple its staff this year. The staff is team-oriented and highly collaborative. Employees are given leeway as to how they go about their day.? The company has a history of promoting from within.\n <br>\n <br>?\n <br>\n <br>The successful Data Analytics / Data Statistics / Actuarial Scientist will be responsible for the following:\n <ul>\n  <li>Seeking case studies, behavioral reports and new learning from sensor data collection?</li>\n  <li>Seeking new learning from the collected data</li>\n  <li>Taking advantage of the increasing amount of data collected from the company's new products</li>\n  <li>Leveraging new data collection processes and sources</li>\n  <li>Developing and deploying innovative methods, models, and algorithms utilizing statistics, algorithms, data mining, and visualization</li>\n  <li>Anticipating, identifying and investigating data trends</li>\n  <li>Discovering actionable insights</li>\n  <li>Identifying business opportunities</li>\n </ul>?\n <br>\n <br>Candidates will have a minimum background consisting of the following:\n <ul>\n  <li>Must reside within a three hour drive of Madison, Wisconsin</li>\n  <li>Five years of experience as a Data Scientist</li>\n  <li>Strong ability to talk through findings and algorithms?</li>\n  <li>A four year degree in Statistics, Actuarial Science, Computer Science, Mathematics, or equivalent</li>\n  <li>SQL relational database experience</li>\n  <li>Data visualization experience</li>\n  <li>Data analysis programming language experience</li>\n  <li>Statistical software experience</li>\n  <li>ETL knowledge</li>\n </ul>\n <em><b>Preferred</b></em> but \n <em><b>not required</b></em> backgrounds will include \n <b><em> any </em></b> of the following:?\n <ul>\n  <li>Insurance industry experience</li>\n  <li>Tableau experience</li>\n  <li>Power BI experience</li>\n  <li>SQL Server experience</li>\n  <li>SSRS, Performance Point experience</li>\n  <li>Python experience</li>\n  <li>Algorithm ?experience</li>\n  <li>AWS Cloud service experience EC2 experience</li>\n  <li>RDS experience S3 experience</li>\n </ul>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F-FvbzvIRRKfzjCmzhdXIw",
    "url": "https://www.remoteage.com/remote-jobs/big-data-engineer-54/",
    "title": "Big Data Engineer",
    "tags": [
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:computer-vision/bigdata-ml/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/72",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=122, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Oscar Technology",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 1:37:56 PM",
    "validThrough": "Aug 2, 2019 1:37:56 PM",
    "crawled": "Jul 26, 2019 2:08:14 PM",
    "content": "<h3> Big Data Engineer </h3>\n<div>\n Netherlands, Not Specified\n</div>\n<div>\n Company: Oscar Technology\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p><strong>Big Data Engineer – The Hague – Hadoop, ETL</strong></p>\n <p><strong>The Role</strong></p>\n <p>Are you a wiz at creating, managing and optimising big data infrastructures as well as developing creative data driven solutions? Do you have experience with Hadoop eco systems and your looking to work as part as one of the Netherlands most revered Data Science teams whilst earning excellent bonuses and getting 30 days holiday a year?</p>\n <p>If you’re a data engineer, your probably highly versatile… you will be expected to manage data infrastructures, develop software solutions and integrate data from various systems whilst working on creative machine learning software solutions for nationally based clients.</p>\n <p><strong>Big Data Engineer Role Requirements</strong></p>\n <ul>\n  <li>Hadoop (Minimum one year)</li>\n  <li>ETL</li>\n  <li>SQL</li>\n </ul>\n <p><strong>The Company</strong></p>\n <p>The type of company that understands that its candidates are at the fore front of its business and therefor treats them accordingly, salaries are far above average with an exceedingly good bonus, mobile phone and laptop, 8% holiday allowance on top of your salary and a great culture to work in!</p>\n <p><strong><em>Apply now;</em></strong></p>\n <p>If you’re a big data engineer with experience with Hadoop, ETL and SQL and you’re looking to work on continuously exciting projects with of the Netherlands most successful Data Science teams whilst earning a great salary and exceptional benefits then don’t waste time.</p>\n <p><strong><em>Interviews for this position will be commencing immediately, don’t miss out and submit your CV by clicking ‘apply now’!</em></strong></p>\n <p><strong>Big Data Engineer – The Hague – Hadoop, ETL</strong></p>\n <p>Oscar Technology is acting as an Employment Agency in relation to this vacancy.</p>\n <p>To understand more about what we do with your data please review our privacy policy at https://our-privacy-policy.</p>\n <p></p> \n <div> \n  <a href='https://www.jobg8.com/Traffic.aspx?YprSDCQqZZRc2eduf8Kq5Qa' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "PJ9Q5ZKvRZu-yMipAQtoGw",
    "url": "https://stackoverflow.com/jobs/284584/senior-data-scientist-remote-global-wallethub?a=1xrjQAPyAAAo",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 26, 2019 10:06:25 AM",
    "validThrough": "Aug 2, 2019 10:06:25 AM",
    "crawled": "Jul 26, 2019 10:06:25 AM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/284584?reset=False&amp;ra=1xrjQAPyAAAo&amp;oqs=a%3D1xrjQAPyAAAo' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "k7VMPt_qRM-JCVaT2hx6MA",
    "url": "https://jobmote.com/job/52469/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:07:26 PM",
    "validThrough": "Jul 28, 2019 10:07:26 PM",
    "crawled": "Jul 26, 2019 3:06:25 AM",
    "content": "<div>\n Company Information\n <br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n <br>\n <br>Job Summary\n <br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.\n <br>\n <br>Primary Job Duties &amp; Responsibilities\n <br>\n <ul>\n  <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> \n  <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> \n  <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> \n  <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> \n  <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> \n  <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> \n  <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> \n  <li>This position is open for candidates to work remotely.</li> \n </ul>\n <br>Minimum Qualifications\n <br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.\n <br>\n <br>Education, Work Experience &amp; Knowledge\n <br>\n <ul>\n  <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> \n  <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> \n  <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> \n  <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> \n  <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> \n  <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> \n  <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> \n  <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> \n  <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> \n  <li>Experience building microservices and Real Time APIs</li> \n  <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> \n  <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> \n  <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> \n  <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> \n  <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> \n  <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> \n  <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> \n  <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> \n  <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> \n  <li>Advanced IT process improvement, and problem-solving skills</li> \n  <li>Comfortable presenting to senior management</li> \n </ul>\n <br>Job Specific &amp; Technical Skills &amp; Competencies\n <br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.\n <br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.\n <br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.\n <br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.\n <br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.\n <br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th\n <br>\n <br>Environmental/Work Schedules/Other\n <br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.\n <br>\n <br>Physical Requirements\n <br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.\n <br>\n <br>Licensing or Certificates\n <br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe\n <br>\n <br>Equal Employment Opportunity Statement\n <br>Travelers is an equal opportunity employer. \n <br>To apply for this position please \n <b>CLICK HERE</b> \n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "xphu0IMHRHqKkY8FqmRxwA",
    "url": "https://jobmote.com/job/52468/data-lead-software-developer-remote-considered/",
    "title": "Data Lead Software Developer-remote considered",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:distributed-computing/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:internet-explorer/frontend/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=53, ruby=0, apple=0, java=10, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Travelers Insurance",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:07:26 PM",
    "validThrough": "Jul 28, 2019 10:07:26 PM",
    "crawled": "Jul 26, 2019 3:06:25 AM",
    "content": "<div>\n Company Information\n <br>Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.\n <br>\n <br>Job Summary\n <br>The Data Lead Software Developer will be responsible for guiding the full lifecycle of a Data solutions/products, including requirements analysis, platform selection, technical architecture design, application design and development, testing and deployment in on-premises or public Cloud Infrastructures.\n <br>\n <br>Primary Job Duties &amp; Responsibilities\n <br>\n <ul>\n  <li>Lead the design, implementation, and continuous delivery of a sophisticated data pipeline supporting development and operations</li> \n  <li>Analyze latest Big Data Analytic technologies and their innovative applications in both Business Intelligence analysis and new service offerings. Bring these insights and best practices to Big Data Projects</li> \n  <li>Provide advisory and thought leadership on the provision of analytics environments leveraging Cloud based platforms, big data technologies, including integration with existing data and analytics platforms and tools. </li> \n  <li>Design and implement scalable data architectures leveraging Hadoop, NoSQL and emerging technologies, covering on-premise or public cloud-based deployment patterns. </li> \n  <li>Define, design and implement data access patterns for multiple analytical and operational workloads, across on-premise or public Cloud based platforms </li> \n  <li>Create information solutions covering data security, data privacy, metadata management, multi-tenancy and mixed workload management across Hadoop and NoSQL platforms, spanning on-premise and Cloud based deployments </li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Provide technical leadership to project team(s) to perform design to deployment related activities, provide guidance, perform reviews, prevent and resolve technical issues.</li> \n  <li>Participate in the lean and agile development process in a fast-paced environment, from planning, scoping, estimation all the way to optimization, maintenance, and support.</li> \n  <li>This position is open for candidates to work remotely.</li> \n </ul>\n <br>Minimum Qualifications\n <br>A bachelor's degree in Computer Science or a related field, or its equivalent in work experience, and five years of programming/development experience. 1 year of experience as a technical lead required.\n <br>\n <br>Education, Work Experience &amp; Knowledge\n <br>\n <ul>\n  <li>15+ years of experience in highly available and scalable enterprise applications/services/database development preferred.</li> \n  <li>Track record of thought leadership and innovation around Big Data. Solid understanding of Cloud Computing Technologies and related emerging technology (eg Amazon Web Services EC2, Elastic MapReduce, Azure, GCP) and considerations for scalable, distributed systems and Knowledge of NoSQL platforms (Cassandra, MongoDB, HBase)</li> \n  <li>Experience with big data technologies, including Hadoop and Hadoop platform distributions: Cloudera, Hortonworks</li> \n  <li>Experience with Hadoop ecosystem tools and frameworks (Kafka, Storm, Sqoop, Spark, Hive, HBase)</li> \n  <li>Expertise in building big data software solutions on Public Cloud such as Amazon Web Services (AWS) and GCP</li> \n  <li>Proficient understanding of Underlying infrastructure for Big Data Solutions (Clustered/Distributed Computing, Storage, Data Center Networking)</li> \n  <li>Strong understanding across Cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end Cloud Infrastructure architectures and designs. </li> \n  <li>Experience with cloud-based technologies and tools especially in deployment, monitoring and operations, such as Kubernetes</li> \n  <li>Experience with Cloud native application development, Cloud deployment, and Cloud application refactoring</li> \n  <li>Experience building microservices and Real Time APIs</li> \n  <li>Experience with containerization technologies like Docker and Kubernetes to create and maintain development and production infrastructure with Docker and Kubernetes</li> \n  <li>Experience with Dev/Ops implementations (continuous delivery, version control, high availability models).</li> \n  <li>Experience with high-scale or distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, DB2, Oracle)</li> \n  <li>Experience with BI tools and reporting software (eg Microstrategy, Cognos, Tableau etc.)</li> \n  <li>Agile project management experience, including use of agile project management tools (ie JIRA, Git, etc.)</li> \n  <li>Experience in leading development teams leveraging Test Driven Development (TDD) practices</li> \n  <li>Working with Architecture to design reusable patterns to deploy to applications, provide governance around adoption, and influence application development teams on roadmaps and designs</li> \n  <li>Identifying and partnering with Infrastructure teams and AD teams to implement automation opportunities to drive down toil and reduce technical debt</li> \n  <li>Experience with planning and executing multi-year road-maps with the ability to solve complex business problems and present recommendations to senior management effectively</li> \n  <li>Expertise in working in partnership with colleagues throughout the firm, and in leading collaborative teams to achieve common goals: ability to build relationships across business groups and technology organizations</li> \n  <li>Must have excellent written, presentation, interpersonal, relationship and negotiating skills</li> \n  <li>Advanced IT process improvement, and problem-solving skills</li> \n  <li>Comfortable presenting to senior management</li> \n </ul>\n <br>Job Specific &amp; Technical Skills &amp; Competencies\n <br>Technical Knowledge: Able to perform as a lead technologist and masterfully assess and design applications, systems solutions, and interfaces for multiple systems according to business requirements. Has a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction. Demonstrates proficiency in business concepts. Demonstrates expert knowledge of applications/systems and concepts. Able to evaluate and leverage pre-existing services and frameworks.\n <br>Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Able to present complex technical concepts to audiences of varying size and level including senior leadership.\n <br>Business Knowledge &amp; Partnership: Able to develop and leverage business and/or vendor partnerships, consult on business priorities, and contribute to strategic business direction. Demonstrates ability to optimize value by identifying solutions that are aligned with current and future business objectives. Able to effectively communicate with all levels of management in business terms and describe IT capabilities and concepts in ways that the business can understand. Develops business partnerships and contributes to strategic business planning by educating and influencing customers on the most effective use of technology. Influences business priorities and optimizes value through solution identification aligned with business objectives, goals and future technology direction. Communicates in business terms, and describes IT capabilities and concepts in ways that the business can understand. Is a trusted advisor on technology business solutions.\n <br>Problem Solving &amp; Decision Making: Able to expertly diagnose root causes and solve complex problems. Able to collaborate with the business to influence best practices. Able to think broadly and strategically to identify and remove potential barriers to success and anticipate future challenges. Demonstrates ability to optimize the use of all available resources. Demonstrates sound decision making and problem resolution skills.\n <br>Team Orientation: Able to promote, maintain, and enhance partnerships across the organization to achieve objectives and engage stakeholders across multiple teams, organizations, and/or enterprise. Practices objectivity and openness to others' views. Able to recognize and support team priorities.\n <br>Leadership: Able to lead cross-functional objectives and priorities for supported business. Demonstrates the thought leadership necessary to set broad technical direction. Exhibits th\n <br>\n <br>Environmental/Work Schedules/Other\n <br>Requires weekend work hours. Requires overnight work hours. Requires holiday work hours (Federal and religious). Requires extended periods (1 or more weeks) of travel as needed. Requires travel up to 5% of time.\n <br>\n <br>Physical Requirements\n <br>Operates standard office equipment. Requires extended periods of computer use. Requires extended periods of sitting.\n <br>\n <br>Licensing or Certificates\n <br>Depends on the specific role but some examples may include: ITIL Remedy Java certification Microsoft certification.net Kanban/Agile/SAFe\n <br>\n <br>Equal Employment Opportunity Statement\n <br>Travelers is an equal opportunity employer. \n <br>To apply for this position please \n <b>CLICK HERE</b> \n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "qJwiLmdfSPGbjXewSFRLOQ",
    "url": "https://remoteok.io/jobs/74140",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``work 2W wherev 2W you",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=20, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Crisp ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 10:51:50 PM",
    "validThrough": "Aug 1, 2019 10:51:50 PM",
    "crawled": "Jul 25, 2019 11:30:31 PM",
    "content": "<span></span> \n<span><h4>Crisp</h4>&nbsp;</span> \n<br> \n<h3>Data Scientist</h3> \n<div> \n <div> \n  <br>Crisp is a remote-only company and we give our employees the opportunity to solve problems in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth. \n  <br> \n  <br>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turning previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more. &nbsp; \n  <br> \n  <br>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;and&nbsp;science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might could help us further bolster our conclusions. &nbsp;You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them! \n  <br> \n  <br>We are building a product engineering team with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific educational background, technology, experience or geographical location.&nbsp; We are however looking for specific traits in the people we work with. You might not yet be able to check all of the boxes, but at least you aspire to do so!&nbsp; \n  <br> \n  <br>Signs of a great candidate Toolbox oriented.&nbsp;Whether your background is in mathematics, statistics, machine learning, artificial intelligence, or something else, you have enough experience to intuitively shortlist tools and approaches from most of these disciplines.&nbsp; \n  <br> \n  <br>Understanding business and customer needs. &nbsp;You believe in creating models that will help the company and make short- and long-term impact, focusing on“bang-for-the-buck”.&nbsp; \n  <br> \n  <br>Performance recognized by your peers.&nbsp;Past colleagues would love to work with you again. \n  <br> \n  <br>Starter and finisher.&nbsp;You often identify a problem, design a solution and bring it to a state of completion - alone or with collaborators. You’ve worked with developers in the past, hope to continue doing so, but you would get far even without technical help. \n  <br> \n  <br>Work hard and smart.&nbsp;Your work ethic is unquestioned, and you know how to get things done so you can balance your work and personal life in a sustainable way. \n  <br> \n  <br>Disciplined and reliable.&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early. \n  <br> \n  <br>Collaborative.&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to make the team perform. \n  <br> \n  <br>Appreciation of honest feedback.&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You feedback given to as an opportunity to get better and strive to do the same for others. \n  <br> \n  <br>Analytical and practical mind.&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed.&nbsp; \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "M11C4ngDQ1q14KXYd9xBpQ",
    "url": "https://www.remotepython.com/jobs/6e7a9f42e303484d80abff58ea6952ae/",
    "title": "Sr Software Developer/Data Engineer at Pivot Bio",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Pivot Bio",
      "sameAs": "https://www.pivotbio.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 6:25:42 PM",
    "validThrough": "Aug 1, 2019 6:25:42 PM",
    "crawled": "Jul 25, 2019 6:25:42 PM",
    "content": "<h3>Sr Software Developer/Data Engineer</h3>Berkeley, California, United States\n<br>Company: Pivot Bio\n<br>Job Type:&nbsp;Full-time\n<div> \n <div> \n </div> \n <p></p>\n <p>We are seeking an experienced software engineer to design, build, and maintain tools that streamline our research and development efforts. As an essential part of our data science team this role will help our researchers develop a pipeline of products to support the agricultural community.</p>\n <p>The first responsibility of this role will be to build tools for our field team to ingest and register spatial data coming in from our field and agronomy team but has the potential to grow into a lead position managing multiple key projects.</p>\n <p>Location: Remote OK</p>\n <p>Responsibilities: Independently design and develop data, software, or technology solutions to answer scientific or business questions. Demonstrate proficiency across a range of technologies related to programming languages, data integration, data warehousing, visualization, and analytics. Collaborate with research scientists to identify and understand their analytical and informatics needs and translate these into solutions. Communicate and collaborate effectively with colleagues in varied scientific and technical roles. Maintain a working knowledge of technologies, development tools, practices, methods and libraries relevant to software engineering and data science. Present projects and systems in front of both scientific and technical audiences.</p>\n <p></p> \n <h4>Desired Skills</h4> \n <ul> \n  <li><span>Big Data</span></li> \n  <li><span>Data Science</span></li> \n </ul> \n <h4>Contact Info</h4> \n <ul> \n  <li><strong>Company Website:</strong> <a href='https://www.pivotbio.com/' rel='nofollow'>https://www.pivotbio.com/</a></li> \n </ul> \n</div>\n<a href='https://www.python.org/jobs/3985/' rel='nofollow'>Apply</a>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "1nejIQgQR7yYRE96LyhrBg",
    "url": "https://stackoverflow.com/jobs/284454/data-scientist-remote-europe-crisp?a=1xoCfYBA0oPC",
    "title": "Data Scientist - [Remote] - [Europe] at Crisp  ",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(europ, european, europeanunion) 3W OR(timezon,time)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:jvm/java/13",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=13, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/Europe"
    ],
    "tagsNames1": [
      "European time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Crisp",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 5:06:25 PM",
    "validThrough": "Aug 1, 2019 5:06:25 PM",
    "crawled": "Jul 25, 2019 5:06:25 PM",
    "content": "<h3><span>Data Scientist - [Remote] - [Europe]</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Computer Software, Food &amp; Beverage</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>VC Funded</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Crisp | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT+01:00) Central European Time - Belgrade </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n jvm\n</div>\n<div>\n postgresql\n</div> \n<h4>Job description</h4> \n<div>\n <p>Crisp is a remote-only company and we give our employees the opportunity to solve problems in the global food industry while living and working wherever you are most comfortable. We believe in transparency, diversity, merit and fostering a culture of accountability, personal impact and career growth.</p>\n <p>As a member of the first product engineering team at Crisp you have will have a unique opportunity to turning previously scattered and inconsistently structured data into directly actionable food industry insights to reduce waste, increase freshness and much more. &nbsp;</p>\n <p>You have a proven track record of reading data and making solid conclusions. You know both the art&nbsp;<em>and</em>&nbsp;science of analytics - now only do you know how to find answers in the data, you also know which questions should be asked in the first place and what data might could help us further bolster our conclusions. &nbsp;You love engaging with customers, learn about their challenges and then dive into the data to see how to solve them!</p>\n <p>We are building a product engineering team with a breadth of combined experiences so that we can collaboratively build great products. There are no hard requirements on specific educational background, technology, experience or geographical location.&nbsp; We are however looking for specific traits in the people we work with. You might not yet be able to check all of the boxes, but at least you aspire to do so!&nbsp;</p>\n <p><strong>Signs of a great candidate</strong> <strong>Toolbox oriented.&nbsp;</strong>Whether your background is in mathematics, statistics, machine learning, artificial intelligence, or something else, you have enough experience to intuitively shortlist tools and approaches from most of these disciplines.&nbsp;</p>\n <p><strong>Understanding business and customer needs. &nbsp;</strong>You believe in creating models that will help the company and make short- and long-term impact, focusing on“bang-for-the-buck”.&nbsp;</p>\n <p><strong>Performance recognized by your peers.</strong>&nbsp;Past colleagues would love to work with you again.</p>\n <p><strong>Starter and finisher.</strong>&nbsp;You often identify a problem, design a solution and bring it to a state of completion - alone or with collaborators. You’ve worked with developers in the past, hope to continue doing so, but you would get far even without technical help.</p>\n <p><strong>Work hard and smart.</strong>&nbsp;Your work ethic is unquestioned, and you know how to get things done so you can balance your work and personal life in a sustainable way.</p>\n <p><strong>Disciplined and reliable.</strong>&nbsp;We are a remote company and you enjoy the benefits of working remotely while consistently delivering what you have committed to. When you hit a snag, you communicate and reset expectations early.</p>\n <p><strong>Collaborative.</strong>&nbsp;You know that your team members’ perspectives will make your solutions better. Similarly, you use your strengths to make the team perform.</p>\n <p><strong>Appreciation of honest feedback.</strong>&nbsp;You know that the best way to learn and grow is through constructive feedback delivered kindly, but without unnecessary ambiguity. You feedback given to as an opportunity to get better and strive to do the same for others.</p>\n <p><strong>Analytical and practical mind.</strong>&nbsp;You strive for simple, precise solutions to complex problems. Complex solutions are only acceptable when absolutely needed.&nbsp;</p> \n</div> \n<div> \n <a href='https://crisp.recruiterbox.com/jobs/fk0jolc?source=StackoverflowJobPosting' rel='nofollow'> Apply now </a>\n</div> \n<h4>About Crisp</h4> \n<div>\n <p>Our main goals with Crisp are easy to explain: We want to build a company that we would like to&nbsp;<em>enjoy&nbsp;</em>spending the rest of our careers in, that has a positive impact on the world and that will outlast us.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Fully remote</span> </li> \n <li> <span></span> <span>Excellent health insurance and benefits</span> </li> \n <li> <span></span> <span>Founders with proven track record</span> </li> \n <li> <span></span> <span>Well funded (by founders)</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Ld45jq9XROGFmRC2R4WFEg",
    "url": "https://www.remoteage.com/remote-jobs/senior-data-engineer-true-north/",
    "title": "Senior Data Engineer, True North",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``OR(work,oper,anywher,remot) 3W OR(feel,creativ)",
      "DBG_TECH1:k/t/w:c#/c/2",
      "DBG_TECH1:k/t/w:c#/dotnet/5",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:iphone/apple/2",
      "DBG_TECH1:k/t/w:iphone/mobile/2",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:sql-server/dotnet/1",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=6, c=2, mobile=3, go=0, nodejs=2, bigdata-ml=56, ruby=2, apple=2, java=2, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Delaware North",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 25, 2019 1:22:20 PM",
    "validThrough": "Aug 1, 2019 1:22:20 PM",
    "crawled": "Jul 25, 2019 2:08:21 PM",
    "content": "<h3> Senior Data Engineer, True North </h3>\n<div>\n United States, New York\n</div>\n<div>\n Company: Delaware North\n <p></p>\n</div>\n<div> \n <h4>Overview</h4> \n <p>Our Exciting Work Environment This position will be based out of Delaware North’s new global headquarters, a state-of-the-art, 12-story, mixed-use building in downtown Buffalo, N.Y. The headquarters facility, reflective of our values, integrates the latest advances in environmental, energy conservation and office design. <br>The Opportunity <br> At Delaware North we have a a long history of operational success and we have ambitious goals for our future growth and operating performance. These aspirations are supported by a transformative enterprise-wide initiative called True North. True North re-imagines the Delaware North operating model by creating processes and tools and providing enhanced support to our local teams that will enable us to best serve our guests, clients, and 55,000+ associates. <br> To achieve these goals, we need people like you. The True North team is hiring a Senior Data Engineer to be part of the Data Solutions Team. <br> Data Solutions is a rapidly growing team that enables Delaware North’s vision of using data as differentiator in the hospitality industry. Our work is the foundation of company initiatives to automate business processes, gather insights, and make informed decisions. Our team uses PaaS solutions and Open Source Software to aggregate, process, catalog and distribute large data sets throughout Delaware North’s global organization, client base and partners. These foundational services empower Delaware North’s mobile, data science, business intelligence, and operational systems. Users of the Delaware North Data Platform range from NASA to several MLB, NBA, NHL, &amp; NFL teams. As a member of our team, the Data Solutions Support Engineer will provide health monitoring and unparalleled customer advocacy for Delaware North’s distributed data platform (Data Lake). <br> The Senior Data Engineer will work closely with the Business to identify and specify opportunities for integration with existing systems in a highly resilient manner using Delaware North’s Data Platform. After the identification of business requirements, the Senior Data Engineer will participate in various exercises to design a technical solution as well as participate in the implementation with internal team mates and off-shore resources. As implementation progresses, the Senior Data Engineer will keep the lines of communication open with internal clients regarding solution status and address technical blockers that may arise. Additionally, the holder of this position will develop integration tests to validate solution acceptance criteria and participate in free-form experimental exercises to keep skills and team goals modernized. <br> Where you fit in: </p>\n <ul>\n  <li> Design and implement project based solutions </li>\n  <li> Implement data platform improvements and new features </li>\n  <li> Ability to effectively collaborate with business leadership, vendor and client stakeholders to establish solution requirements and execute on technical designs and final implementation. </li>\n  <li> Assist support team with resolution of Data Platform bug fixes </li>\n  <li> Interface with clients, vendors, and internal users of the data platform on understanding the data </li>\n  <li> Participate in group design and architecture sessions </li>\n  <li> Author documentation for standard operating procedures, knowledge base articles, etc. </li>\n </ul>\n <p> Skills &amp; experience that you’ll need: </p>\n <ul>\n  <li> Minimum 5 years professional experience with the following\n   <ul>\n    <li> Designing and developing solutions with a modern programming language such as Python, Ruby, JavaScript, Java, C#, etc </li>\n    <li> Development of backend systems and services. </li>\n    <li> Full Stack and/or DevOps </li>\n    <li> Data Persistence Methods such as NoSQL and RDBMS (MSSQL, Oracle, MySQL, MongoDB) </li>\n    <li> Data structures and formats such as JSON and XML </li>\n    <li> Data Mapping &amp; Transformation Techniques </li>\n   </ul></li>\n  <li> Excellent organizational, oral and written communication skills </li>\n  <li> Collaborate with Business Users and vendors to address development issues </li>\n  <li> Troubleshoot and track issues through to resolution </li>\n  <li> Technical specification and use case (story) documentation, such as UML, Domain and Entity Relationship Modeling, Business Process Notation. </li>\n  <li> Passion for delivering high quality and meaningful results. </li>\n </ul>\n <p> Nice to have: </p>\n <ul>\n  <li> Familiarity with RESTful Web Services, ETL, ESB, and microservices </li>\n  <li> Integration testing and automation using a continuous integration (CI) platform (such as Jenkins, TeamCity or Bamboo) </li>\n  <li> Familiarity with cloud computing, analysis &amp; implementation experience (bonus if it relates to Amazon Web Services specifically) </li>\n  <li> Experience working with Agile methodologies </li>\n  <li> Experience with frontend development </li>\n  <li> Proficiency with Unix/Linux </li>\n  <li> Experience with Configuration Management tools (such as Ansible, Chef, etc.) </li>\n </ul>\n <p> Here’s some of what you’ll get in return </p>\n <ul>\n  <li> Join a creative and highly collaborative team that is empowered to select the right technology for the task at hand </li>\n  <li> Regularly scheduled “innovation time” to work on creative applications of new technology (doesn’t have to be work related) </li>\n  <li> Flexible work schedule, “casual Fridays”, and ability to work remotely in certain cases </li>\n  <li> Opportunity for travel to interesting field locations (small percentage of travel required) </li>\n  <li> Company paid iPhone with LTE service </li>\n  <li> Free coffee, espresso, cappuccino, fruits, and bagels </li>\n  <li> Yearly paid training, conference and certifications of your choice </li>\n  <li> Career growth – Delaware North values and invests in its family and promotes from within regularly </li>\n  <li> Benefits including health, dental, paid vacation &amp; holidays, life insurance, short &amp; long term disability insurance, company discounts </li>\n  <li> Bonus eligibility </li>\n  <li> 401k with employer match and financial planning services </li>\n  <li> Choice of MacBook Pro or PC Ultrabook and peripherals </li>\n </ul>\n <p>Who We Are Take your career beyond the ordinary-to the extraordinary.<br> At Delaware North, you’ll love where you work, who you work with, and how your day unfolds. Whether it’s in sporting venues, casinos, airports, national parks, iconic hotels, or premier restaurants, there’s no telling where your career can ultimately take you. We empower you to do great work in a company with 100 years of success, stability and growth. If you have drive and enjoy the thrill of making things happen – share our vision, grow with us.<br> Delaware North is one of the largest privately held hospitality companies in the world. Founded in 1915 and owned by the Jacobs family for more than 100 years, Delaware North has global operations at high-profile places such as sports and entertainment venues, national and state parks, destination resorts and restaurants, airports, and regional casinos. Our 55,000 employee associates are dedicated to creating special experiences one guest at a time in serving more than a half-billion guests annually. Delaware North operates in the sports, travel hospitality, restaurant and catering, parks, resorts, gaming, and specialty retail industries and has annual revenue of about $3 billion. Learn more about Delaware North, a global leader in hospitality, at .<br> All applicants will be subject to a pre-employment background check and may be subject to a pre-employment drug test depending upon the position and/or client requirements.<br> Delaware North Companies, Incorporated and its subsidiaries consider applicants for all positions without regard to race, color, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, or any other legally protected status. Delaware North is an equal opportunity employer.<br> #LI-PE1<br></p> \n <div> \n  <a href='https://www.jobg8.com/Traffic.aspx?00WLhg2l6rarDAF9XbGfxQu' rel='nofollow'>Apply for job</a> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "DbZo40OnTL2P40n8jyyPWA",
    "url": "https://remoteok.io/jobs/74115",
    "title": "Data Analyst",
    "tags": [
      "DBG:surround``3N(locat,remot)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:time-series/bigdata-ml/5",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Amida Technology Solutions",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 24, 2019 8:41:57 PM",
    "validThrough": "Jul 31, 2019 8:41:57 PM",
    "crawled": "Jul 24, 2019 9:30:31 PM",
    "content": "<span></span> \n<span><h4>Amida Technology Solutions</h4></span> \n<br> \n<h3>Data Analyst</h3> \n<div> \n <div> \n  <br>Amida Technology Solutions is a DC-based technology company focused on solutions for data interoperability, data utility, and data security. We create open source solutions that collect, reconcile, transform, and standardize data for business intelligence, predictive analytics, decision support, and user transactions. We specialize in taking data from inception to impact. \n  <br>Our team is comprised of creative, forward thinkers who are passionate about using cutting edge technology to make a difference in people's lives and have a positive impact on our country. We offer an entrepreneurial, high growth environment that values fresh ideas, candid conversations, and authentic teamwork. \n  <br>Amida is currently looking for a Data Analyst to join our team in Washington DC or from a remote location within the continental US. In this role you will work across our client engagements, providing expertise in data collection, data analysis, data mapping, data profiling, data mining and data modeling.&nbsp; You will be responsible for inspecting, cleansing, transforming and modeling data and will address issues related to data completeness and quality, as well as contribute to and produce technical and data process documentation.&nbsp; \n  <br>What you will be doing: \n  <br>* Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions \n  <br>* Apply analytical methodologies and principles to&nbsp;meet client needs. \n  <br>* Prepare forecast&nbsp;and analyze&nbsp;trends, develops and analyzes metrics, and prepares reports and recommendations related to management. \n  <br>* You will also be responsible&nbsp;for focusing on&nbsp;business performance, project analysis, internal control, risk assessment, and support of project objectives. \n  <br> \n  <br> \n  <br>What we are looking for: \n  <br>* B.S. and/or M.S. in a quantitative field such as Computer Science, Statistics, or Mathematics \n  <br>* Minimum 3-5 year of recent professional experience in data science, data mining and/or data analysis \n  <br>* Experience in data migration to include data mapping and data profiling \n  <br>* Prior experience working with Healthcare data, or in the Healthcare field \n  <br>* Ability to conduct data profiling and predictive analysis using a variety of standard tools \n  <br>* Programming proficiency in a subset of Python \n  <br>* Experience with data visualization tools and methodologies \n  <br>* Ability to communicate concisely and effectively with software engineers and clients \n  <br>* Ability to obtain a Public Trust security clearance \n  <br> \n  <br> \n  <br>Preferred Skills \n  <br>* Exposure to Amazon Web Services (AWS) and cloud-based systems \n  <br>* Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA) \n  <br>* Prior experience with metadata management to include meta tagging \n  <br>* Previous experience working in an Agile Team setting and using Agile management tools such as Jira \n  <br>* Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "FCqRYWOcTTyz9hd6-cc57g",
    "url": "https://jobmote.com/job/52107/data-architect-remote/",
    "title": "Data Architect - (Remote)",
    "tags": [
      "DBG:surround``fulltim 4N remot",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=26, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Feuji",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 24, 2019 11:01:33 AM",
    "validThrough": "Jul 27, 2019 11:01:33 AM",
    "crawled": "Jul 24, 2019 3:06:26 PM",
    "content": "<div>\n Title Data Architect Remote Fulltime Responsibilities Ability to understand the business requirements and to decompose for further analysis Proven track record in architecture, performance and highly-scalable Data Platform Ability to understand customer s business outcomes and to guide the customer through a Data workshop The aptitude and attitude needed to be a Trusted Advisor to the customer Understanding of various architectural patterns in Big Data Ability to operate in an agile environment Ability to actively seek out optimization approaches for Data Platform Ability to understand and articulate a problem Proven track record on Pre-sales engagements Qualifications Proven and deep knowledge of Big Data Architectural patterns Proven and deep knowledge in Batch and streaming patterns Proven experience in architecting Big Data Platform including building out data pipelines, ETL jobs, and visualization through dashboards Experience in Enterprise Data Warehouse (EDW) Deep expertise in AWS Data Analytics services Deep expertise in GCP Data Analytics services Big Data cert in AWS is a Plus Hands on experience with Python, Scala, etc. Experience with Machine Learning such as AWS SageMaker is a plus\n <br> Associated topics: data analytic, data center, data engineer, data integrity, data warehouse, data warehousing, database, etl, sql, sybase\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eL5npav9QKe78yhR-T6vPA",
    "url": "https://jobmote.com/job/51784/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:07:20 PM",
    "validThrough": "Jul 26, 2019 10:07:20 PM",
    "crawled": "Jul 24, 2019 3:06:25 AM",
    "content": "<div>\n <p>Job Description<br>The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.</p>\n <p>Responsibilities<br>Define and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architecture</p>\n <p>Qualifications<br>Bachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#<br><br>Additional Information<br>Compensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote<br></p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "utVQcAK8Rwqbmq6_fAOdag",
    "url": "https://jobmote.com/job/51783/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 90000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 90k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:07:20 PM",
    "validThrough": "Jul 26, 2019 10:07:20 PM",
    "crawled": "Jul 24, 2019 3:06:25 AM",
    "content": "<div>\n <p>Job Description<br>The ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.</p>\n <p>Responsibilities<br>Define and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architecture</p>\n <p>Qualifications<br>Bachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#<br><br>Additional Information<br>Compensation: $90,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote<br></p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "HweRHeWwRo2F6Tarxy4FDQ",
    "url": "https://stackoverflow.com/jobs/283906/senior-software-engineer-rho-ai?a=1xddNx0BcRuU",
    "title": "Senior Software Engineer at Rho AI  ",
    "tags": [
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/20",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:reactjs/frontend/8",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=60, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Rho AI",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 10:30:25 PM",
    "validThrough": "Jul 30, 2019 10:30:25 PM",
    "crawled": "Jul 23, 2019 10:30:25 PM",
    "content": "<h3><span>Senior Software Engineer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Full Stack Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data Science, Software Development / Engineering</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Rho AI | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-06:00) Central Time +/- 2 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n python\n</div>\n<div>\n single-page-application\n</div>\n<div>\n sql\n</div>\n<div>\n nosql\n</div>\n<div>\n docker\n</div> \n<h4>Job description</h4> \n<div>\n <p>Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste). We value pragmatic solutions and have cultivated a modern technology stack that combines software development (python microservices, react frontends), infrastructure automation (docker, kubernetes), and machine learning (scikit-learn, pytorch) into a developer-friendly CICD flow.</p>\n <p>As a member of the software engineering team, you are looking to:</p>\n <ul>\n  <li>Develop products and services for advanced machine learning applications in interesting and important problem spaces.</li>\n  <li>Join a group of talented and congenial team members in an experienced individual contributor role (mix of architecting / building / mentoring), with future people management opportunities (if you like).</li>\n  <li>Lead engineering projects by collaborating with team members and customers, facilitating technology architecture decisions, driving forward work streams, and releasing high quality software.</li>\n  <li>Work on all layers—designing database schemas, connecting AWS services, building python services that leverage machine learning libraries, crafting frontend features, etc.</li>\n </ul>\n <p><strong>You have</strong>:</p>\n <ul>\n  <li>(Must) Been the tech lead of a project that uses a Python based stack.</li>\n  <li>(Must) Good communication skills for technical and non-technical audiences.</li>\n  <li>(Must) Experience deploying systems with some mix of AWS/Docker/Ansible/etc.</li>\n  <li>(Must) Worked on all layers of the stack - databases, services, and frontends.</li>\n  <li>(Must) A collaborative attitude oriented around craftsmanship and team success.</li>\n  <li>(Should) An interest in systems thinking &amp; enjoy stitching components together.</li>\n  <li>(Should) Have experience working within a microservices oriented architecture.</li>\n  <li>(Nice) Built systems that process large amounts of data and/or traffic.</li>\n  <li>(Nice) Strong computer science principles, and/or algorithmic skills.</li>\n  <li>(Nice) Experience with machine learning applications.</li>\n </ul>\n <p><strong>You meet these criteria</strong>:</p>\n <ul>\n  <li>You are seeking a full-time job.</li>\n  <li>You reside in the United States.</li>\n  <li>You are&nbsp;authorized / eligible to work for any company in the United States.</li>\n  <li>You are in a continental US time zone, or willing to align your schedule.</li>\n </ul>\n <strong>To get an interview, you must supply:</strong>\n <ul>\n  <li>A cover letter that explains why you are 1)&nbsp;<em>specifically interested</em>&nbsp;in Rho AI as a company and 2) a&nbsp;<em>good fit</em>&nbsp;for this particular position.</li>\n  <li>A resume that includes: 1) your relevant professional experience, and 2) links to code samples, technical blog posts, and other examples of your work.</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/283906?reset=False&amp;ra=1xddNx0BcRuU&amp;oqs=a%3D1xddNx0BcRuU' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Rho AI</h4> \n<div>\n <p>Rho AI was founded in 2012 by a small team of entrepreneurs, engineers, and data scientists. We set out to develop custom software for professional motorsports to predict an optimal race strategy, and since then, our real-time strategy recommendations have factored heavily into multiple victories on the NASCAR circuit.</p>\n <p>Today, Rho AI’s data-driven products &amp; services are used in a wide range of industries, with a growing focus on sustainable systems (e.g. energy, water, climate, waste).&nbsp;Each project we tackle is oriented around solving real world problems by leveraging a pragmatic mix of tried-and-true and research-led data science solutions.</p>\n <p><strong>Work at Rho AI</strong></p>\n <p>At Rho AI, you will work with a talented group of data scientists, engineers and thought leaders to drive technological change through data science. You will have opportunities to apply your skills in a mix of products and services across diverse domains, and learn from and collaborate with senior members of the company.</p>\n <p>Rho AI offers a unique opportunity to show your entrepreneurial spirit, where all ideas are respected, innovation is&nbsp;rewarded, and ownership and accountability are&nbsp;embraced.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Work from anywhere in the world with flexible work schedules.</span> </li> \n <li> <span></span> <span>Health insurance &amp; FSA accounts</span> </li> \n <li> <span></span> <span>Competitive salaries along with 401k</span> </li> \n <li> <span></span> <span>4 weeks of PTO</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "F4vRKXsEQyWDi02GduUNwQ",
    "url": "https://remote.co/job/senior-r-developer/",
    "title": "Senior R Developer",
    "tags": [
      "DBG:surround``OR(work,countri,locat,contract,base,you W can) 2W anywher",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:techWeightMap:{python=13, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "Crunch.io",
      "sameAs": "https://crunch.io/index.html"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 23, 2019 6:10:02 PM",
    "validThrough": "Jul 30, 2019 6:10:02 PM",
    "crawled": "Jul 23, 2019 6:23:50 PM",
    "content": "<h3>Senior R Developer at <span>Crunch.io</span></h3>\n<div>\n <span><i></i> Remote</span> | \n <span> International </span>\n</div>\n<div> \n <p><strong>Reporting to: </strong>VP of Product<strong><br>Location: Anywhere</strong></p>\n <p>Crunch.io is seeking a talented, motivated, and versatile human to help lead the development of our R data science products. Crunch provides a modern platform for survey data analysis, and a central feature of our product is the ability to manipulate and analyze datasets stored in the cloud using R. As senior R developer, you will have three main responsibilities. First, you will work with the rest of our team to design and implement novel features that deliver real value and change our clients’ workflows for the better. Second, as the primary point of contact between our R user community and the development team, you will serve as their voice in product development. And third, you will often directly help clients manipulate and explore data using Crunch, including helping clients design and implement workflows that incorporate Crunch.</p>\n <p><strong>Key responsibilities for the position include:</strong></p>\n <ul>\n  <li>Teaching users how to work with the library through documentation and direct conversations.</li>\n  <li>Writing scripts that help clients implement Crunch and make it a part of their workflow, including ETL, data analysis, and outputs.</li>\n  <li>Developing and maintaining our core R packages, including new feature design, comprehensive testing, and documentation</li>\n  <li>Supporting our community of R users by responding to feature requests and triaging bug reports</li>\n  <li>Evangelizing our product and educating our R user base by contributing to our technical blog and helping enrich our support documentation</li>\n  <li>Translating API speak to R that feels natural and native</li>\n  <li>Engaging with and contributing to the broader open source R ecosystem</li>\n </ul>\n <p><strong>Depending on your interests and skills, there are opportunities to get involved in:</strong></p>\n <ul>\n  <li>API design: developing good conventions that enable our platform to scale and make it easy for client applications to consume them</li>\n  <li>JavaScript development, helping our frontend developers implement features you’ve utilized in R</li>\n  <li>Product management, building on your interactions with our users to shape our product roadmap and feature design</li>\n  <li>Python development, ranging from implementing APIs you need for the R packages, to statistical modeling, numerical computing, machine learning, and natural language processing</li>\n </ul>\n <p>In any given week, you might implement an R interface for a new API our backend has added, write a blog post introducing that new feature, track down a bug report from a user, write a test that reproduces the issue, and assist customers in implementing Crunch via the Crunch R packages.</p>\n <p><strong>Qualifications:</strong></p>\n <ul>\n  <li>Expert-level skills in R, including experience delivering code that others rely on to do their work. Prior experience creating and maintaining R packages is highly valued.</li>\n  <li>Serious commitment to high development standards, including comprehensive testing, in whatever language you’re working</li>\n  <li>Demonstrated ability to work with a team of peers, understanding and respecting the responsibilities and expertise developers, designers, QA folks, and others bring to the project</li>\n  <li>Eagerness to take ownership of projects and deliver results on schedule</li>\n  <li>Experience in a “data science,” such as social science, market research, or data visualization, is a plus.</li>\n </ul>\n <p>Crunch offers competitive salary; health, dental, and vision insurance; and equity options. We are a small but growing company spread from UTC+1 to +11, mostly in the Western hemisphere. Remote work is flexible and largely independent, yet highly cooperative.</p>\n <p>We are an equal-opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status.</p> \n</div>\n<div> \n <a href='https://crunch.io/jobs/senior-r-developer/' rel='nofollow'>Apply for job</a> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "gFXaswIzRu2eKZx5X9lPOg",
    "url": "https://jobmote.com/job/51649/data-quality-analyst-global-company-local-or-remote/",
    "title": "Data Quality Analyst - Global Company - Local or Remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Z&A Recruiting",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 80000,
      "maxValue": 95000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "USD 80k - 95k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 10:07:19 PM",
    "validThrough": "Jul 25, 2019 10:07:19 PM",
    "crawled": "Jul 23, 2019 3:06:26 AM",
    "content": "<div>\n Job DescriptionThe ideal candidate will be able to apply their knowledge of master, reference, and transaction data to define, develop and execute test cases that ensure Company data stores and assets are complete, of high quality, and are in alignment with Co. business process and goals.The candidate will leverage training in data analytics and SQL to develop an in-depth testing approach and work with stakeholders by creating and executing test cases in alignment with project and process goals as well as Data Governance guidelines.Driven by curiosity and a passion for data, the ideal candidate thrives in situations where they can apply their knowledge of data and testing protocols to ensure that the Company has high quality, consistent information that can be leveraged to drive business decisions. Responsible for defining and executing data-oriented testing and must possess intermediate to advanced expertise in data analytics and SQL.ResponsibilitiesDefine and execute test cases in the Oracle &amp; HADOOP environments using SQL as the primary Apply best-in-class testing methodologies to ensure the accuracy and consistency of Company data across multiple platforms.Perform root cause analysis on data errors and issues and identify the source, process, or person generating the errors.Identify data exceptions that require stewardship and work with cross-functional teams to define procedures for resolving those errors.Document test cases, execution, and results and provide metrics that demonstrate the % complete, progress to date, and remaining work.Develop expertise in the Company data, business, and processes that can be used to drive future testing initiatives and improvements in the overall quality of Company data.Act as an internal consulting resource for business partners and cross-functional projects in defining and executing test cases on new or modified data sources, stores, or processes.Translate testing results into on-going metrics and exceptions that can be used to proactively monitor data once it has been moved to production.Act as support for investigating and resolving production data issues.Develop a close collaboration with technology partners to strengthen alignment between business data applications, implications, and technical architectureQualificationsQualificationsBachelor's Degree (Master's preferred) 5+ years' experience working with end-users stakeholders in testing and in analytics rolesAdvanced analytical and quantitative skills with the ability to systematically test large and complex data sets identifying potential errors and driving to a root cause.Intermediate to advanced knowledge of SQL as a power user. Excellent communication skills with executives and other internal stakeholders Excellent planning, organization and time management skills- prioritize multiple projectsIntense curiosity and passion for data.Customer Relationship Management (CRM) Solutions, specifically Salesforce.com, preferredExperience with Total Quality Management (TQM) preferred.Healthcare industry experience preferred.Office-based (San Antonio) position OR Remote#ind123Additional InformationCompensation: $80,000 - $95,000 + 10% bonus, great benefits, several weeks of PTO. Can be local or remote\n <p>by Jobble</p>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "pls9GIA3QS2v_RBMbZEJVw",
    "url": "http://workinstartups.com/job-board/job/82589/data-analyst-at-hubble/",
    "title": "Data Analyst",
    "tags": [
      "DBG:surround``OR(thrive,benefit,comfort,hour) 3N 2N(remot,work)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Hubble",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 22, 2019 1:35:01 PM",
    "validThrough": "Jul 29, 2019 1:35:01 PM",
    "crawled": "Jul 22, 2019 5:06:34 PM",
    "content": "DESCRIPTION\n<br>\n<br>Hubble is the UK’s leading PropTech scale-up; changing the face of commercial property. Our mission is to find the perfect home for every company and we’ve built an online platform to help businesses rent, manage and share office space in London. We’ve raised over £6m in venture funding from the most respected investors in technology and real estate to make this mission a reality.\n<br>\n<br>As a Data Analyst you will be working closely with Data Science, Engineering and Business Operations to support all teams with day to day reporting, problem-solving and using data to provide key company insights. You will work across a range of areas such as our acquisition strategies, product funnels, supply and demand dynamics, sales performance and more.\n<br>\n<br>\n<br>RESPONSIBILITIES\n<br>\n<br>Own the data request process from prioritisation through to delivery.\n<br>Support all departments through report creation, ad-hoc data analysis and answering business questions by interrogating our database.\n<br>Create and maintain company dashboards.\n<br>Empower all teams with the right tools to understand the data and make decisions quickly\n<br>End-to-end ownership of data quality in our core datasets and data pipelines.\n<br>Experiment with new tools and technologies to meet business requirements regarding performance, scaling, and data quality.\n<br>Improve existing processes and make data pipelines more efficient and reliable.\n<br>\n<br>\n<br>REQUIREMENTS\n<br>\n<br>Strong SQL knowledge and experience.\n<br>Excellent problem-solving skills - ability to see beyond the numbers and think logically.\n<br>Previous experience in a similar role, ideally in a startup environment\n<br>Experience solving real problems using data analysis techniques and statistical rigour.\n<br>Excellent communication skills; the ability to convey complex analysis results clearly.\n<br>Business-minded as well as technically capable\n<br>\n<br>\n<br>BENEFITS\n<br>\n<br>We make sure everyone in the team is comfortable and has the best environment for them. We offer flexible hours, remote working and have a relaxed attitude to taking holiday - focusing only on whether work gets done. Benefits can be tweaked on an individual basis depending on what makes you most productive. Here are some of the things we offer:\n<br>\n<br>Remuneration competitive with industry and level of experience.\n<br>Macbook, peripherals and standing desk.\n<br>Expense budget &amp; travel.\n<br>Noise-cancelling headphones.\n<br>Spotify Premium or Apple Music.\n<br>Kindle Unlimited + free technical books.\n<br>Health &amp; Pension.\n<br>Cycle to Work scheme.\n<br>\n<br>Hubble is an equal opportunities employer. We are a diverse bunch of people who are committed to maintaining a welcoming culture of inclusion and equality. We encourage applications from anyone that meets the requirements for the role.",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "arfb2PbwTvqY89O5-VQ1Yw",
    "url": "https://remote.co/job/coding-specialist-9/",
    "title": "Coding Specialist",
    "tags": [
      "DBG:surround``12N(work, OR(home,remot), 5N(OR(offic,headquart,onsit), OR(dai,daili,week,weekli,month,monthli)) )",
      "DBG_TECH1:k/t/w:classification/bigdata-ml/1",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=1, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "nThrive",
      "sameAs": "https://www.nthrive.com/"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 6:03:43 PM",
    "validThrough": "Jul 26, 2019 6:03:43 PM",
    "crawled": "Jul 19, 2019 6:26:08 PM",
    "content": "<h3>Coding Specialist at <span>nThrive</span></h3>\n<div>\n <span><i></i> Remote</span> \n</div>\n<div> \n <p><strong>Job ID: </strong>2019-26481</p>\n <p><strong>Employment Type: </strong><strong>Full Time</strong></p>\n <p><strong>Hours Per Week:</strong> 40</p>\n <p><strong>Onsite Work Schedule Details:</strong> M-F 8a-4:30p</p>\n <p><strong>City: </strong><strong>Remote</strong></p>\n <p><strong>Overview</strong></p>\n <p>The Coding Specialist will work closely with HIM and other support departments to reimburse healthcare claims. This individual will utilize specialized medical classification software to assign procedure and diagnosis codes for insurance billing as well as review claims data to ensure that assigned codes meet required legal and insurance rules and that required signatures and authorizations are in place before submission.</p>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Selects and sequences ICD-10, and/or CPT/HCPCS codes for designated patient types which may include but are not limited to: Ancillary (Diagnostic)/ Recurring; Hospital, Clinic; Physician Pro Fee; Technical Fee or Evaluation and Management.</li>\n  <li>Reviews and analyzes clinical records to ensure that APC assignments accurately reflect the diagnoses/procedures documented in the clinical record.</li>\n  <li>Abstracts clinical data from the record after documentation review to ensure that it is adequate and appropriate to support diagnoses, procedures and discharge disposition is selected.</li>\n  <li>May act as a resource with client staff for data integrity, clarification and assistance in understanding and determining appropriate and compliant coding practices including provider queries.</li>\n  <li>Maintains strict patient and provider confidentiality in compliance with all federal, state, and hospital laws and guidelines for release of information.</li>\n  <li>Maintain current working knowledge of ICD-10 and/or CPT/HCPCS and coding guidelines, government regulations, protocols and third-party requirements regarding coding and/or billing.</li>\n  <li>Participate in continuing education activities to enhance knowledge, skills, and maintain current credentials.</li>\n  <li>Supports nThrive’s Compliance Program by adhering to policies and procedures pertaining to HIPAA, FDCPA, FCRA, and other laws applicable to nThrive’s business practices. This includes: becoming familiar with nThrive’s Code of Ethics, attending training as required, notifying management or nThrive’s Helpline when there is a compliance concern or incident, HIPAA-compliant handling of patient information, and demonstrable awareness of confidentiality obligations.</li>\n </ul>\n <p><strong>Qualifications</strong></p>\n <ul>\n  <li><strong>Active RHIA, RHIT, CCS</strong></li>\n  <li>3+ years of recent and relevant hands-on coding experience including active production coding</li>\n  <li>Ability to consistently code at 95% threshold for both accuracy and quality while maintaining client-specific and nThrive production standards</li>\n  <li>Proficient computer knowledge including MS Office (Outlook, Word, Excel, Power Point)</li>\n  <li>Must display excellent interpersonal and problem-solving skills with all levels of internal and external customers</li>\n  <li>Candidates must successfully pass pre-employment coding test</li>\n  <li>Cable or DSL high-speed, wired Internet Connection</li>\n </ul>\n <p><strong>About nThrive</strong></p>\n <p><strong>Be Inspired. Ignite Change. Transform Health Care.</strong><br>From Patient-to-Payment, nThrive provides all the technology, advisory expertise, services, analytics and education programs health care organizations need to thrive in the communities they serve. Our colleagues share a united passion to help health care organizations strengthen their financial position, which translates to accessible, quality care for all. This passion fuels our drive to innovate and participate in community outreach through the nThrive CARES program. Our colleagues are encouraged to think differently and empowered to make a lasting impact that ensures our health care providers, and our world, are healthy and productive.</p> \n</div>\n<div> \n <a href='https://careers-nthrive.icims.com/jobs/26482/coding-specialist/job' rel='nofollow'>Apply for job</a> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "tcklNtXcSryZxuiIN7glaA",
    "url": "https://stackoverflow.com/jobs/282773/senior-data-scientist-remote-global-wallethub?a=1wPFbjoIMtgI",
    "title": "Senior Data Scientist- Remote, Global at Wallethub  ",
    "tags": [
      "DBG:surround``OR(&quot;not&quot;,no) 3W locat W requir",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 2W hour",
      "DBG:surround``OR(no,no W central) W offic",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/56",
      "DBG_TECH1:k/t/w:java/java/4",
      "DBG_TECH1:k/t/w:java/mobile/2",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:k/t/w:svm/bigdata-ml/16",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=2, go=0, nodejs=0, bigdata-ml=82, ruby=0, apple=0, java=12, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Wallethub",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 7:06:24 AM",
    "validThrough": "Jul 26, 2019 7:06:24 AM",
    "crawled": "Jul 19, 2019 7:06:24 AM",
    "content": "<h3><span>Senior Data Scientist- Remote, Global</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Personal Finance</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Wallethub | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n java\n</div>\n<div>\n python\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Company details</strong></p>\n <p>WalletHub is one of the leading personal finance destinations in the US and rapidly growing. We're looking for a highly experienced and motivated Data Scientist for a full-time, permanent position.</p>\n <p>The main objective of the Data Science Team is to improve WalletHub's services and core product. This has a direct impact on the overall user experience.</p>\n <p>Making the right personal finance decisions by sifting through vast amounts of available information can be a daunting task for almost anyone. This is because a large number of interrelated factors need to be taken into account when making such decisions.</p>\n <p>By designing and constructing data-driven models, the Data Science Team is able to provide our users with indispensable knowledge and meaningful advice on how they can achieve their personal finance goals.</p>\n <p>Such goals include:</p>\n <ul>\n  <li>Selecting the best financial products for your needs</li>\n  <li>Taking the right actions to improve your credit score</li>\n  <li>Anticipate your future financial health based on your current financial status and history</li>\n </ul>\n <p>With these goals in mind, our Data Scientists use the latest cloud technologies and machine learning tools in order to exploit the potential of data analytics. We always have new and interesting projects on the horizon that aim to help our users reach their personal finance aspirations!</p>\n <p><strong>Requirements</strong></p>\n <p>You are the ideal candidate for this job if you have:</p>\n <ul>\n  <li>At least 8 years experience in Java, Spring and MySQL (or any relational database) and Python</li>\n  <li>At least 5 years of experience as a Data Scientist.</li>\n  <li>Experience with databases (including NoSQL)</li>\n  <li>Experience in machine learning frameworks and libraries</li>\n  <li>Supervised and Unsupervised learning</li>\n  <li>Machine learning concepts and techniques: Regularization, Boosting, Random Forests, Decision Trees, Bayesian models, Neural networks, Support Vector Machines (SVM)</li>\n  <li>Experience with the whole ETL data cycle (extract, validate, transform, clean, aggregate, audit, archive)</li>\n  <li>Computer Science or Mathematics or Physics degree</li>\n  <li>Excellent communication and analytical skills</li>\n  <li>Willingness to work hard (50 hrs per week)</li>\n  <li>Very good English</li>\n </ul>\n <p><strong>Nice to have but not required</strong></p>\n <ul>\n  <li>Experience with Apache Spark</li>\n  <li>Natural Language Processing (tokenization, tagging, sentiment analysis, entity recognition, summarization)</li>\n  <li>R programming language</li>\n </ul>\n <p><strong>Responsibilities</strong></p>\n <ul>\n  <li>Modeling complex problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques</li>\n  <li>Participating in the areas of architecture, design, implementation, and testing</li>\n  <li>Proposing innovative ways to look at problems by using data mining approaches on the set of information available</li>\n  <li>Designing experiments, testing hypotheses, and building models</li>\n  <li>Conducting advanced data analysis and designing highly complex algorithm</li>\n  <li>Applying advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems</li>\n </ul>\n <p><strong>Our Offer</strong></p>\n <ul>\n  <li>Very competitive salary based on prior experience and qualifications</li>\n  <li>Potential for stock options after the first year</li>\n  <li>Raise and advancement opportunities based on periodic evaluations</li>\n  <li>Visa sponsorship (if working from outside the US, sponsorship&nbsp;can be granted after 18 months with the company, based on performance).</li>\n  <li>Health benefits (in case you will be working from our office in Washington DC)</li>\n </ul>\n <p><strong>Notes</strong>&nbsp;</p>\n <ul>\n  <li>This position does not have a location requirement and can be performed either remotely (including from outside the U.S.) or from WalletHub’s offices in downtown Washington DC.</li>\n  <li><strong>If you're intending to work from outside the US please&nbsp;be aware this position entails working at least 50 hour per week and requires an overlap with EST business hours&nbsp;(8am - 7pm ET, including 1 hour break).</strong></li>\n </ul>\n <p><strong>More about WalletHub</strong></p>\n <p>WalletHub is a high-growth fintech company based in Washington, DC that is looking for talented, hard-working individuals to help us reshape personal finance. More specifically, we are harnessing the power of data analytics and artificial intelligence to build the brain of a smart financial advisor, whose services we’re offering to everyone for free. The WalletHub brain enables users to make better financial decisions in a fraction of the time with three unique features:</p>\n <p>1) Customized Credit-Improvement Tips: WalletHub identifies improvement opportunities and guides you through the necessary corrections.</p>\n <p>2) Personalized Money-Saving Advice: WalletHub’s savings brain constantly scours the market for load-lightening opportunities, bringing you only the best deals.</p>\n <p>3) Wallet Surveillance: Personal finance isn’t as scary with 24/7 credit monitoring providing backup, notifying you of important credit-report changes.</p>\n <p>In addition to the valuable intelligence the brain provides, WalletHub is the first and only service to offer free credit scores and full credit reports that are updated on a daily basis absent of user interaction, rather than weekly or monthly and only when a user logs in. Some other services hang their hats on free credit scores and reports, yet they’re still inferior to what WalletHub considers minor pieces to a much larger puzzle.</p>\n <p><strong>How to Apply</strong><br><br>To get our attention, all you need to do is send us a resume. If we believe that you will be a good match, we'll contact you to arrange the next steps. You can&nbsp;apply directly on Stackoverflow or email your application to&nbsp;<a href='mailto:jobs.dev@wallethub.com' rel='nofollow'>jobs.dev@wallethub.com</a></p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282773?reset=False&amp;ra=1wPFbjoIMtgI&amp;oqs=a%3D1wPFbjoIMtgI' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Wallethub</h4> \n<div>\n <p>WalletHub helps all consumers reach top financial fitness by providing:<br><br>• Free credit scores and credit reports that are updated on a daily basis.<br><br>• Free 24/7 credit monitoring and personalized advice that will help you improve your credit and save money. <br><br>• More reviews on financial products, professionals and companies than any other website.<br><br>• An extensive education center coupled with the ability to ask financial experts your money-related questions for free .</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Stock options</span> </li> \n <li> <span></span> <span>Health benefits</span> </li> \n <li> <span></span> <span>Work visa sponsorship</span> </li> \n <li> <span></span> <span>Competitive salary</span> </li> \n <li> <span></span> <span>Work from home</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "g49hsIg7TEq_JXGKoGmJjg",
    "url": "https://remoteok.io/jobs/74021",
    "title": "Software Engineers",
    "tags": [
      "DBG:surround``2N( OR(feasibl,OR(consid,consider),occas,possibl), remot)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:c++/c/16",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:techWeightMap:{python=9, other=0, dotnet=0, c=16, mobile=0, go=0, nodejs=0, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "GrammaTech",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 5:42:58 AM",
    "validThrough": "Jul 26, 2019 5:42:58 AM",
    "crawled": "Jul 19, 2019 6:06:30 AM",
    "content": "<span></span> \n<span><h4>GrammaTech</h4></span> \n<br> \n<h3>Software Engineers</h3> \n<div> \n <div> \n  <br>Overivew: \n  <br> \n  <br>Are you ready to be challenged, right from the interview process?&nbsp; Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you. \n  <br> \n  <br>GrammaTech is looking for software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Significant experience contributing to large projects, developing software, with focus on C++ and Python.&nbsp; \n  <br> \n  <br>REMOTE EMPLOYEES WILL BE CONSIDERED IF SKILLS AND EXPERIENCE MATCH. \n  <br> \n  <br>Responsibilities: \n  <br> \n  <br>A research-oriented software engineer is expected to:&nbsp; \n  <br> \n  <br> \n  <br>* Study and implement approaches drawn from academic literature or in-house design \n  <br> \n  <br>* Evaluate the resulting prototype implementation to test its value in addressing the research goals \n  <br> \n  <br>* Report results to the PI and respond by adapting the prototype to better address research goals \n  <br> \n  <br>* Contribute to presentations and written reports to keep research sponsors up to date on project progress \n  <br> \n  <br>* Prepare prototypes for demonstrations and evaluations by research sponsors \n  <br> \n  <br>* Transition prototypes into deployable products&nbsp; \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Qualifications: Required: \n  <br> \n  <br> \n  <br>* BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus. \n  <br> \n  <br>* Experience in development activities on large code bases with software design, build, and test from scratch \n  <br> \n  <br>* Familiarity with common software architectures, design patterns, and software development life cycle practices including effectively using revision control systems (git) and container technology (docker) \n  <br> \n  <br>* Knowledge of security and bug finding, capability of finding problems within software code \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Preferred: \n  <br> \n  <br> \n  <br>* MS or PhD in computer science or equivalent \n  <br> \n  <br>* Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc. \n  <br> \n  <br>* Knowledge of machine code, such as ARM, x86, or x86-64 \n  <br> \n  <br>* Static analysis for binaries and/or source code \n  <br> \n  <br>* Experience with fuzzing and sandboxing \n  <br> \n  <br>* Compiler design, compiler front-end integration, parsers \n  <br> \n  <br>* Dynamic analysis, program instrumentation, and profiling \n  <br> \n  <br>* System-administration experience, especially related to security \n  <br> \n  <br>* Malware-analysis techniques \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>About the Company: \n  <br> \n  <br>We have offices in Ithaca, NY and Madison, WI — but will consider remote employees when there is a strong match of skills and experience. \n  <br> \n  <br>Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing.&nbsp; \n  <br> \n  <br>GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.&nbsp; Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems. &nbsp;Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales. \n  <br> \n  <br>GrammaTech, Inc. is an Equal Opportunity/Affirmative Action employer.&nbsp; \n  <br> \n  <br>Members of underrepresented groups are encouraged to apply, please call 607-273-7340 if assistance is needed. \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "w38xNldaRWy1kDDu4N1Xsg",
    "url": "https://jobmote.com/job/51107/java-big-data-engineer-remote/",
    "title": "Java/Big Data Engineer - Remote",
    "tags": [
      "DBG:surround``4N( OR(look, search),     4N(OR(distribut, remot), OR(employe,develop,engin,team)) )",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:apache-flink/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/16",
      "DBG_TECH1:k/t/w:java-developer/java/13",
      "DBG_TECH1:k/t/w:java/java/6",
      "DBG_TECH1:k/t/w:java/mobile/3",
      "DBG_TECH1:k/t/w:mapreduce/bigdata-ml/5",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/6",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=3, go=0, nodejs=0, bigdata-ml=29, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "Eliassen Group",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:26 PM",
    "validThrough": "Jul 21, 2019 10:07:26 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <br>\n <br>Our client is looking for a software engineer who has expert level experience in Java and a strong background in big data technologies such as Scala, Spark, Hadoop, Kafka, RabbitMQ, Kinesis, etc. You will be part of the team that is building out the foundation platform around Big Data &amp; Analytics (some Real-time Analytics components) to the Cloud. You will be working closely with the team to implement and integrate platform services and solutions. \n <br>\n <br>\n <strong>Responsibilities/Skills: </strong>\n <br>\n <ul>\n  <li>Java development in microservice architecture, domain-driven design &amp; RESTful APIs to enable real-time data consumption </li>\n  <li>Build Back end applications using Java, Spark/Scala, Python </li>\n  <li>Big Data experience: Hadoop, Kafka, RabbitMQ, Kinesis, Spark, Hive, Nifi, Flink, AWS Lambda </li>\n  <li>Work on performance optimizations on Hbase and Solr </li>\n  <li>Work on Performance optimization on Spark Jobs and MapReduce jobs </li>\n  <li>Ability to debug complex production scenarios </li>\n  <li>Master-s degree in Computer Science, Management Information Systems #eg1989 </li>\n </ul>\n <br>\n <br>For immediate consideration, email your updated resume to Dan Malta at\n <br>\n <br>Job ID: 321205 \n <br>\n <br>\n <strong>About Eliassen Group: </strong>\n <br>\n <br>Eliassen Group provides strategic talent solutions to drive our clients- innovation and business results. Leveraging over 30 years of success, our expertise in IT staffing, Agile consulting, creative services, managed services, and life sciences enables us to partner with our clients to execute their business strategy and scale effectively. Headquartered in Reading, MA and with offices from coast to coast, Eliassen Group offers local community presence, deep networks, as well as national reach. For more information, visit .\n <br>\n <br>Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\n <br>\n <br>Don-t miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a \n <strong> <em> $1,000 referral check ! </em> </strong>\n <br> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "ptoSvXqbQ_S36a1C_57V0w",
    "url": "https://jobmote.com/job/51098/hadoop-developer-100-remote/",
    "title": "Hadoop Developer -100% REMOTE",
    "tags": [
      "DBG:surround``2W( OR(100,fulli,entir), remot)",
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG_TECH1:k/t/w:extjs/frontend/8",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/32",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=32, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=8}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "HCL Global Systems",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:26 PM",
    "validThrough": "Jul 21, 2019 10:07:26 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <p> <strong>Role: Hadoop Developer</strong></p> \n <p> <strong>Location: Jacksonville, FL (REMOTE)</strong></p> \n <p> <strong>Duration: Long Term</strong></p> \n <p> <strong>Job Description: </strong></p> \n <ul>\n  <li>Write code for moderately complex system designs. Write programs that span platforms. Code and/or create Application Programming Interfaces (APIs).</li> \n  <li>Write code for enhancing existing programs or developing new programs.</li> \n  <li>Review code developed by other IT Developers.</li> \n  <li>Provide input to and drive programming standards.</li> \n  <li>Write detailed technical specifications for subsystems. Identify integration points.</li> \n  <li>Report missing elements found in system and functional requirements and explain impacts on subsystem to team members.</li> \n  <li>Consult with other IT Developers, Business Analysts, Systems Analysts, Project Managers and vendors.</li> \n  <li> Scope time, resources, etc., required to complete programming projects. Seek review from other IT Developers, Business Analysts, Systems Analysts or Project Managers on estimates.</li> \n  <li>Perform unit testing and debugging. Set test conditions based upon code specifications. May need assistance from other IT Developers and team members to debug more complex errors.</li> \n  <li>Supports transition of application throughout the Product Development life cycle. Document what has to be migrated. May require more coordination points for subsystems.</li> \n  <li>Researches vendor products / alternatives. Conducts vendor product gap analysis / comparison.</li> \n  <li>Accountable for including IT Controls and following standard corporate practices to protect the confidentiality, integrity, as well as availability of the application and data processed or output by the application.</li> \n  <li>The essential functions listed represent the major duties of this role, additional duties may be assigned.</li>\n </ul>\n <p> <strong> </strong> <strong>Years of Experience Experience Details</strong></p> \n <ul>\n  <li>5+ years related work experience or equivalent combination of transferable experience and education</li> \n  <li>IT development/programming/coding professional work experience</li> \n  <li>Specific Tools/Languages Required:</li> \n  <li>HADOOP</li> \n  <li>Spark</li> \n  <li>Experience with Agile Methodology</li>\n </ul>\n <p> <strong> </strong> <strong>Comments for Suppliers: </strong></p> \n <p> <strong>- Manager is look for someone with 3-4 year experience with Hadoop/Spark ETL</strong></p> \n <p> <strong>- Experienced in Agile methodologies</strong></p> \n <p> <strong>- Healthcare experience is strongly preferred</strong></p> \n <p> <strong> </strong> <strong>Additional Required Qualifications:</strong></p> \n <ul>\n  <li>Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures</li> \n  <li>Proficiency using versioning tools</li> \n  <li>Thorough knowledge of Information Technology fields and computer systems</li> \n  <li>Demonstrated organizational, analytical and interpersonal skills</li> \n  <li>Flexible team player</li> \n  <li>Ability to manage tasks independently and take ownership of responsibilities</li> \n  <li>Ability to learn from mistakes and apply constructive feedback to improve performance</li> \n  <li>Must demonstrate initiative and effective independent decision-making skills</li> \n  <li>Ability to communicate technical information clearly and articulately</li> \n  <li>Ability to adapt to a rapidly changing environment</li> \n  <li>In-depth understanding of the systems development life cycle</li> \n  <li>Proficiency programming in more than one object oriented programming language</li> \n  <li>Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio</li> \n  <li>Proficiency using debugging tools</li> \n  <li>High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy</li>\n </ul>\n <p> <strong>Thanks &amp; Regards</strong></p> \n <p> <strong> </strong> <strong>Gireesh| Technical Recruiter</strong></p> \n <p>E: O: EXT 147</p> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Agfq-HtjR5aO0ymFr-ZARA",
    "url": "https://jobmote.com/job/51116/aws-big-data-consultant-remote-europe-us-east-coast/",
    "title": "AWS Big Data Consultant - Remote (Europe / US East Coast)",
    "tags": [
      "DBG:surround``2N(work,remot) 9W OR(travel,visit)",
      "DBG:surround``3N( 2N(work,remot), OR(us,across,globe,world,planet,100,set 3W hour) )",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=8, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "50% remote",
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "INTUITIVE TECHNOLOGY PARTNERS, INC.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:07:27 PM",
    "validThrough": "Jul 21, 2019 10:07:27 PM",
    "crawled": "Jul 19, 2019 3:06:25 AM",
    "content": "<div>\n <p>Role: Senior Consultant</p> \n <p>Specialization: Big Data &amp; Analytics</p> \n <p>Location: East Hanover, NJ. Ideally the Consultant is required in Europe, however any location in East Coast, US will work.</p> \n <p>Remote: 100%. Although this position is remote work, the consultant is required to travel for team meetings and client location as required.</p> \n <p>Start date: ASAP</p> \n <p>Duration: Available at least 3 days a week till end of December 2019.</p> \n <p>Requirement description:</p> \n <p>- Big Data specialty (AWS and 3pty), at least 3 years in the role (Consultant, Solution Architect, Big Data Engineer, Big Data SME, or similar) <br>- At least 3 years of experience with AWS services (within AWS, partner or another company) <br>- Based in EMEA or US East Coast <br>- Track record of delivering complex big data project similar in size (at least 1 good reference) <br>- Experience in Pharma industry or similar <br>- Databricks know-how is a big plus</p> \n <p> </p> - provided by Dice\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "rNoOUkRQQRO8sG1YrG74lQ",
    "url": "https://stackoverflow.com/jobs/282724/software-engineers-research-security-grammatech-inc?a=1wOE0QGlt6Io",
    "title": "Software Engineers - Research (Security) at GrammaTech, Inc. (Ithaca, NY) ",
    "tags": [
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG:surround``remot 9W 4N( OR(offic,onsit), time)",
      "DBG_TECH1:k/t/w:arm/embedded/8",
      "DBG_TECH1:k/t/w:c++/c/24",
      "DBG_TECH1:k/t/w:keras/bigdata-ml/8",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:sonarqube/java/8",
      "DBG_TECH1:techWeightMap:{python=11, other=0, dotnet=0, c=24, mobile=0, go=0, nodejs=0, bigdata-ml=18, ruby=0, apple=0, java=8, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/c",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "c"
    ],
    "hiringOrganization": {
      "name": "GrammaTech, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 19, 2019 12:06:25 AM",
    "validThrough": "Jul 26, 2019 12:06:25 AM",
    "crawled": "Jul 19, 2019 12:06:25 AM",
    "content": "<h3><span>Software Engineers - Research (Security)</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior, Lead</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Desktop Developer</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Computer Software, Cybersecurity, Security Software</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: GrammaTech, Inc. | Ithaca, NY\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-05:00) Eastern Time </span> \n  </div> \n  <div> \n   <span>Office Location:</span> \n   <span>Ithaca, NY.</span> \n   <span>Employees can also work full time from this office.</span> \n  </div> \n  <div> \n   <span>Visa Sponsorship:</span> \n   <span>Yes</span> \n  </div> \n  <div> \n   <span>Relocation Assistance:</span> \n   <span>Yes</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n c++\n</div>\n<div>\n python\n</div>\n<div>\n git\n</div>\n<div>\n docker\n</div>\n<div>\n static-analysis\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Overivew:</strong></p>\n <p>Are you ready to be challenged, right from the interview process?&nbsp; Are you looking to work with a highly intelligent but humble team? Do you want to work on cutting-edge cyber security problems and have the background to do it? Well then, this role may be for you.</p>\n <p>GrammaTech is looking for software engineers at varying levels of experience to perform advanced software development. Build new components and extend existing tooling to meet project needs. Implement both exploratory research prototypes and high-quality products. Significant experience contributing to large projects, developing software, with focus on C++ and Python.&nbsp;</p>\n <p><strong>REMOTE EMPLOYEES WILL BE CONSIDERED IF SKILLS AND EXPERIENCE MATCH.</strong></p>\n <p><strong>Responsibilities:</strong></p>\n <p>A research-oriented software engineer is expected to:&nbsp;</p>\n <ul>\n  <li>Study and implement approaches drawn from academic literature or in-house design</li>\n  <li>Evaluate the resulting prototype implementation to test its value in addressing the research goals</li>\n  <li>Report results to the PI and respond by adapting the prototype to better address research goals</li>\n  <li>Contribute to presentations and written reports to keep research sponsors up to date on project progress</li>\n  <li>Prepare prototypes for demonstrations and evaluations by research sponsors</li>\n  <li>Transition prototypes into deployable products&nbsp;</li>\n </ul>\n <p><strong>Qualifications:</strong> Required:</p>\n <ul>\n  <li>BS in Computer Science or equivalent with a minimum of 3+ years demonstrated experience working in software development in C++ and Python. Knowledge of other languages is a plus.</li>\n  <li>Experience in development activities on large code bases with software design, build, and test from scratch</li>\n  <li>Familiarity with common software architectures, design patterns, and software development life cycle practices including effectively using revision control systems (git) and container technology (docker)</li>\n  <li>Knowledge of security and bug finding, capability of finding problems within software code</li>\n </ul>\n <p>Preferred:</p>\n <ul>\n  <li>MS or PhD in computer science or equivalent</li>\n  <li>Experience in using Machine Learning Frameworks like scikit-learn, TensorFlow, Keras, etc.</li>\n  <li>Knowledge of machine code, such as ARM, x86, or x86-64</li>\n  <li>Static analysis for binaries and/or source code</li>\n  <li>Experience with fuzzing and sandboxing</li>\n  <li>Compiler design, compiler front-end integration, parsers</li>\n  <li>Dynamic analysis, program instrumentation, and profiling</li>\n  <li>System-administration experience, especially related to security</li>\n  <li>Malware-analysis techniques</li>\n </ul>\n <p><strong><em>About the Company:</em></strong></p>\n <p><em>We have offices in Ithaca, NY and Madison, WI — but will consider remote employees when there is a strong match of skills and experience.</em></p>\n <p>Innovation is at the heart of GrammaTech. We are constantly pushing the boundaries of software research and development – from software assurance and software integrity to cyber-security threat mitigation and autonomic computing.&nbsp;</p>\n <p>GrammaTech was founded over 30 years ago, with a firmly-grounded purpose to help organizations develop tomorrow’s software.&nbsp; Given the ever-increasing dependence of software in today’s connected world, our staff is able to focus on the most challenging software issues through a constant stream of highly innovative research and commercial development programs – focused on the evolving cyber-security landscape, software hardening and intelligent systems. &nbsp;Within these projects, GrammaTech employees have the opportunity to work with industry, academic, and government experts, significantly advancing their skills in engineering, research, marketing, or sales.</p>\n <p><em>GrammaTech, Inc. is an Equal Opportunity/Affirmative Action employer.&nbsp;</em></p>\n <p><em>Members of underrepresented groups are encouraged to apply, please call 607-273-7340 if assistance is needed.</em></p> \n</div> \n<div> \n <span>Apply now</span>\n</div> \n<h4>About GrammaTech, Inc.</h4> \n<div>\n <p>GrammaTech has two distinct business development units, the Product Team and the Research Team. Information on both can be found on the company website but this position is on the Research Team and some of our past projects can be found on our website,&nbsp;<a href='https://www.grammatech.com/sponsored-research' rel='nofollow'>https://www.grammatech.com/sponsored-research</a>.</p>\n <p>The <strong>Product Team</strong> focuses on our Code Sonar product line:</p>\n <p>CodeSonar employs a unified dataflow and symbolic execution analysis that examines the computation of the complete application. By not relying on pattern matching or similar approximations, CodeSonar's static analysis engine is extraordinarily deep, finding 3-5 times more defects on average than other static analysis tools.</p>\n <p>Unlike many software development tools, such as testing tools, compilers, configuration management, etc., SAST tools can be integrated into a team's development process at any time with ease. SAST technologies like CodeSonar simply attach to your existing build environments to add analysis information to your verification process.</p>\n <p>The <strong>Research Team </strong>responds to Request for Proposals from government and other sponsors:</p>\n <p>Our expertise in software analysis and binary transformation comes from decades of experience of high-tech research with the U.S. government and other organizations. Over the past two decades, we have partnered with several groups to help solve some of the most complex software challenges that impact devices' resiliency, safety, and security. Our work has been focused in three areas:</p>\n <ul>\n  <li><strong>Software Assurance:</strong>&nbsp;new techniques and technologies for analyzing and correcting software to ensure runtime integrity and prevent unplanned system breaches and failures.</li>\n  <li><strong>Software Hardening:</strong>&nbsp;technologies solely focused on system resiliency.</li>\n  <li><strong>Autonomic Computing:</strong>&nbsp;providing software systems with the ability to ‘self-protect’</li>\n </ul> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Competitive base salaries - whether in Ithaca, Madison or remote!</span> </li> \n <li> <span></span> <span>Flex Time - flexible hours, ample vacation time, available day one</span> </li> \n <li> <span></span> <span>Floating Holidays - flexible holidays can be taken on any day</span> </li> \n <li> <span></span> <span>Healthcare -health, dental, &amp; vision; covered day one</span> </li> \n <li> <span></span> <span>Annual bonuses and raises - above cost of living increases</span> </li> \n <li> <span></span> <span>Generous pension plan - after 13 months of employment</span> </li> \n <li> <span></span> <span>SNACKS - plenty of free snacks!</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "E_8GV6D3T7G_CCu-xIIASg",
    "url": "https://stackoverflow.com/jobs/282710/data-engineer-scala-spark-remote-semanticbits?a=1wOlXRkOeIyA",
    "title": "Data Engineer (Scala/Spark) - Remote at SemanticBits  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(eastern, east, est, edt, newyork) 3W OR(time,timezon)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:angular/frontend/8",
      "DBG_TECH1:k/t/w:coffeescript/frontend/1",
      "DBG_TECH1:k/t/w:coffeescript/nodejs/1",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:scala/java/15",
      "DBG_TECH1:k/t/w:spring-boot/java/8",
      "DBG_TECH1:k/t/w:spring/java/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=1, bigdata-ml=42, ruby=0, apple=0, java=33, gamedev=0, php=0, embedded=0, frontend=9}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/America/East"
    ],
    "tagsNames1": [
      "US East time zone"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "SemanticBits",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 10:30:26 PM",
    "validThrough": "Jul 25, 2019 10:30:26 PM",
    "crawled": "Jul 18, 2019 10:30:26 PM",
    "content": "<h3><span>Data Engineer (Scala/Spark) - Remote</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Digital Health</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>51–200 people</span> \n  </div> \n </div> \n</div> \n<div>\n Company: SemanticBits | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-05:00) Eastern Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n scala\n</div>\n<div>\n apache-spark\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p>SemanticBits is looking for a talented Data Engineer who is eager to apply computer science, software engineering, databases, and distributed/parallel processing frameworks to prepare big data for the use of data analysts and data scientists. You will deliver data acquisition, transformations, cleansing, conversion, compression, and loading of data into data and analytics models. You will work in partnership with data scientists and analysts to understand use cases, data needs, and outcome objectives. You are a practitioner of advanced data modeling and optimization of data and analytics solutions at scale. Expert in data management, data access (big data, data marts, etc.), programming, and data modeling; and familiar with analytic algorithms and applications (like machine learning).</p>\n <p>SemanticBits is a leading company specializing in the design and development of digital health services, and the work we do is just as unique as the culture we’ve created. We develop cutting-edge solutions to complex problems for commercial, academic, and government organizations. The systems we develop are used in finding cures for deadly diseases, improving the quality of healthcare delivered to millions of people, and revolutionizing the healthcare industry on a nationwide scale. There is a meaningful connection between our work and the real people who benefit from it; and, as such, we create an environment in which new ideas and innovative strategies are encouraged. We are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional success every day.</p>\n <p>Requirements:</p>\n <ul>\n  <li>Bachelor’s degree in Computer Science (or a related field)</li>\n  <li>Three or more years in data engineering</li>\n  <li>At least two years working with Scala and Spark</li>\n  <li>Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases (SQL and relational design), networking</li>\n  <li>Demonstrable experience engineering scalable data processing pipelines.</li>\n  <li>Demonstrable expertise with Scala, Spark, and wrangling of various data formats - Parquet, CSV, XML, JSON.</li>\n  <li>Experience with the following technologies is highly desirable: Teradata, AWS EMR, AWS EC2, AWS S3, Airflow, SAS, Hadoop, Java, Spring Boot, Angular</li>\n  <li>Experience with Agile methodology, using test-driven development.</li>\n  <li>Excellent command of written and spoken English</li>\n  <li>Self-driven problem solver</li>\n </ul>\n <p>Benefits:</p>\n <ul>\n  <li>Generous base salary</li>\n  <li>Three weeks of PTO</li>\n  <li>Excellent health benefits program (Medical, dental and vision)</li>\n  <li>Education and conference reimbursement</li>\n  <li>401k retirement plan. We contribute 3% of base salary irrespective of employee's contribution</li>\n  <li>100% paid short-term and long-term disability</li>\n  <li>100% paid life insurance</li>\n  <li>Flexible Spending Account (FSA)</li>\n  <li>Casual working environment</li>\n  <li>Flexible working hours</li>\n </ul>\n <p>SemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.</p> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282710?reset=False&amp;ra=1wOlXRkOeIyA&amp;oqs=a%3D1wOlXRkOeIyA' rel='nofollow'>Apply now</a>\n</div> \n<h4>About SemanticBits</h4> \n<div>\n <p>SemanticBits is a leading company specializing in the design and development of digital health services, and the work we do is just as unique as the culture we’ve created. We develop cutting-edge solutions to complex problems for commercial, academic, and government organizations. The systems we develop are used in finding cures for deadly diseases, improving the quality of healthcare delivered to millions of people, and revolutionizing the healthcare industry on a nationwide scale. There is a meaningful connection between our work and the real people who benefit from it; and, as such, we create an environment in which new ideas and innovative strategies are encouraged. We are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional success every day.</p>\n <p><strong>Salary &amp; Benefits</strong></p>\n <ul>\n  <li>Generous base salary</li>\n  <li>Three weeks of PTO</li>\n  <li>Excellent health benefits program (Medical, dental and vision)</li>\n  <li>Education and conference reimbursement</li>\n  <li>401k retirement plan. We contribute 3% of base salary irrespective of employee's contribution</li>\n  <li>100% paid short-term and long-term disability</li>\n  <li>100% paid life insurance</li>\n  <li>FSA</li>\n  <li>Casual Working Environment</li>\n  <li>Flexible Office Hours</li>\n </ul>\n <p>SemanticBits, LLC is an equal opportunity, affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other characteristic protected by law. We are also a veteran-friendly employer.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Medical, dental, vision, life, disability</span> </li> \n <li> <span></span> <span>Matched 401K plan</span> </li> \n <li> <span></span> <span>Generous vacation allowances, floating holidays, and sick leave</span> </li> \n <li> <span></span> <span>Continued Education Reimbursement</span> </li> \n <li> <span></span> <span>Free coffee and snacks</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "x79qXzSkQ1OR1_Jb992Rkw",
    "url": "https://stackoverflow.com/jobs/282404/senior-data-engineer-data-architect-do-good-literacypro-systems-inc?a=1wHZtWK5Suf6",
    "title": "Senior Data Engineer / Data Architect - Do Good. Do Well. Have Fun Doing It. at LiteracyPro ...",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "LiteracyPro Systems, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 200000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 200k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 9:30:23 PM",
    "validThrough": "Jul 25, 2019 9:30:23 PM",
    "crawled": "Jul 18, 2019 9:30:24 PM",
    "content": "<h3><span>Senior Data Engineer / Data Architect - Do Good. Do Well. Have Fun Doing It.</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Database Administrator</span> \n  </div> \n </div> \n</div> \n<div>\n Company: LiteracyPro Systems, Inc. | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-07:00) Mountain Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div>\n etl\n</div>\n<div>\n sql\n</div>\n<div>\n pentaho\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Type: </strong></p>\n <p>Contract position for approximately 3 months. Will be able to start project within a week.</p>\n <p><strong>Brief Job Description:</strong> &nbsp;</p>\n <p>LiteracyPro creates software for social good. Our data collection and reporting software helps government and community-based organizations help hundreds of thousands of disadvantaged people improve their opportunities to get jobs with sustainable, living wages for themselves and their families. Enjoy being part of a fun group of bright, passionate folks, in a great working environment, with generous salary &amp; benefits while helping those who help others.</p>\n <p>Our newest product, CommunityPro Suite (CPS), is a growing SaaS case management, referral, reporting and analysis enterprise application that enables hundreds of agencies to securely match, consolidate and share data in real time. The purpose of the software is to reduce organizational friction by helping local agencies better collaborate to help people achieve economic self-sufficiency for themselves and their families. The end-goal of CPS is to play an important role in helping to create healthy, vibrant communities in this country and the world.</p>\n <p>Our Company is experiencing explosive growth due to increasing national demand for our software, and we’re looking for that rare, accomplished data analyst who wants to do good, get paid well and have fun doing it. We’re seeking someone with an energizing leadership style, and who has the smarts, passion and people skills to guide our efforts on all aspects of the data management process, including: on-boarding; acquisition; attribution; transformation; and reporting of newly acquired data sets to provide high-quality data supporting analytics and our clients’ needs in a timely fashion.</p>\n <p>Given the highly execution-focused nature of the work, the ideal candidate will roll up their sleeves to ensure that their projects meet deadlines and will always look for ways to optimize processes in future cycles.</p>\n <p><strong>Responsibilities:</strong></p>\n <p>This position has the primary responsibility for the acquisition, transformation, and maintenance of data for our primary SAAS application. This data is interchanged from and returned to an increasingly diverse set of third-party source systems.</p>\n <ul>\n  <li>Conduct in-depth data profiling and data quality assessments of data received from multiple source systems to determine the current level of data accuracy, conformation to standards, reporting requirements, etc.</li>\n  <li>Investigate data flow issues by discovering system states that prevent successful job completion (source systems, infrastructure, etc.).</li>\n  <li>Identify and analyze the errors/inconsistencies in the data; provide timely resolutions for data lineage and data cleansing.</li>\n  <li>Build and validate a data quality framework with alerts for data discrepancies.</li>\n  <li>Work with the product owner/system owner, development, and QA teams to ensure alignment and proper interpretation of complex data requirements.</li>\n  <li>Develop technical documentation, including requirements documents, process overviews, data models, data flow, and ETL jobs.</li>\n </ul>\n <p><strong>Experience and Qualifications:</strong></p>\n <ul>\n  <li>6+ years performing analysis and building data processes.</li>\n  <li>6+ years of experience with ETL tasks such as reviewing business requirements, developing and troubleshooting data cleansing and loading solutions, preparing solution documentation, data dictionaries, metadata repositories, and database security.</li>\n  <li>6+ years of industry experience with the development and implementation of enterprise-level data warehousing and supporting business intelligence initiatives, particularly focused on star schema data modeling.</li>\n  <li>6+ years of experience with database design, including mastery of complex report queries and SQL optimization.</li>\n  <li>Experience with MySQL, Amazon Web Services, Microsoft Azure. Experience with Pentaho CE a plus!</li>\n  <li>Familiarity with the data security and privacy requirements of FERPA, HIPPA, SOC2 and related industry and legal standards</li>\n </ul>\n <ul>\n  <li>Degree in Computer Science, Information Systems, Mathematics, or equivalent quantitative field</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282404?reset=False&amp;ra=1wHZtWK5Suf6&amp;oqs=a%3D1wHZtWK5Suf6' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About LiteracyPro Systems, Inc.</h4> \n<div>\n <p><strong>Our Mission</strong></p>\n <p><em>“To be a powerful force of good in the world by creating revolutionary tools for those serving humanity.”</em></p>\n <p><strong>Our Culture</strong></p>\n <ul>\n  <li>Aptitude to thrive in a pioneering environment and successfully manage multiple priorities and projects with critical deadlines.</li>\n  <li>Insanely curious, naturally approaches challenges with energy and positivity.</li>\n  <li>Your word is your bond. Your sincerity and honesty easily generate a deep sense of admiration and loyalty in your team.</li>\n  <li>You’re an exceptional listener; you ask lots of questions to better understand complex problems and interpersonal matters.</li>\n  <li>You can laugh at yourself; you’re only human and make mistakes like the rest of us.</li>\n </ul>\n <p><strong>Our Core Values:</strong></p>\n <p>The very core of LiteracyPro Systems is our genuine belief in, and adherence to, the company’s six core values:</p>\n <ul>\n  <li>Honesty and ethical behavior above all else</li>\n  <li>Teamwork—we sink or swim together</li>\n  <li>Work hard, have fun</li>\n  <li>Passion for excellence—second best will never suffice</li>\n  <li>We follow through on our commitments—we mean what we say and we say what we mean</li>\n  <li>Service to our community</li>\n </ul>\n <p>These six core values guide us in everything we do—from the commitments we make and the execution of our business plan, to the way we treat each other on a daily basis. Our values foster a deep sense of responsibility to our customers, vendors, and investors as well as to fellow team members. We are driven by the satisfaction of excellence.</p>\n <p><strong>Please send a cover letter and your resume to: David Miller, <a href='mailto:dhmiller@literacypro.com' rel='nofollow'>dhmiller@literacypro.com</a><br></strong></p> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "eakN1ON_RPmVpf89_B2-GA",
    "url": "https://stackoverflow.com/jobs/282622/r-developer-yougov?a=1wMwwd9rlHhe",
    "title": "R Developer at YouGov  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W OR(germani, unitedkingdom, austria, croatia, hrvatska, denmark, franc, ireland, netherland, spain, sweden, switzerland)",
      "DBG:surround``OR(locat, anywher, base, resid) 7W usa",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/16",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/2",
      "DBG_TECH1:k/t/w:python-developer/python/13",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:techWeightMap:{python=15, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=1, bigdata-ml=18, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/python",
      "TITLE1/dev",
      "TZ/America"
    ],
    "tagsNames1": [
      "American time zones"
    ],
    "tagsNames2": [
      "bigdata-ml",
      "python"
    ],
    "hiringOrganization": {
      "name": "YouGov",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 3:06:25 PM",
    "validThrough": "Jul 25, 2019 3:06:25 PM",
    "crawled": "Jul 18, 2019 3:06:25 PM",
    "content": "<h3><span>R Developer</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Industry: </span> \n   <span>Market research, Web Technology</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Company size: </span> \n   <span>501–1k people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: YouGov | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-06:00) Central Time +/- 4 hours</span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div></div>\n<div>\n r\n</div>\n<div>\n shiny\n</div>\n<div>\n python\n</div>\n<div>\n etl\n</div>\n<div>\n Pawel 88 1 6\n</div>\n<div>\n mnowotka Backend Team Lead 6.7k 11 62 110\n</div>\n<div>\n Xbito 1.3k 1 8 8\n</div>\n<div>\n Andy Wong 1\n</div> \n<h4>Job description</h4> \n<div>\n <p><span>Crunch.io, part of the YouGov PLC, is seeking a talented, motivated, and versatile human to help lead the development of our R data science products. Crunch provides a modern platform for survey data analysis, and a central feature of our product is the ability to manipulate and analyze datasets stored in the cloud using R. As senior R developer, you will have three main responsibilities. First, you will work with the rest of our team to design and implement novel features that deliver real value and change our clients’ workflows for the better. Second, as the primary point of contact between our R user community and the development team, you will serve as their voice in product development. And third, you will often directly help clients manipulate and explore data using Crunch, including helping clients design and implement workflows that incorporate Crunch.&nbsp;&nbsp;</span></p>\n <p><strong>Key responsibilities:</strong></p>\n <ul>\n  <li><span>Teaching users how to work with the library through documentation and direct conversations.</span></li>\n  <li><span>Writing scripts that help clients implement Crunch and make it a part of their workflow, including ETL, data analysis, and outputs.&nbsp;&nbsp;</span></li>\n  <li><span>Developing and maintaining our core R packages, including new feature design, comprehensive testing, and documentation</span></li>\n  <li><span>Supporting our community of R users by responding to feature requests and triaging bug reports</span></li>\n  <li><span>Evangelizing our product and educating our R user base by contributing to our technical blog and helping enrich our support documentation</span></li>\n  <li><span>Translating API speak to R that feels natural and native</span></li>\n  <li><span>Engaging with and contributing to the broader open source R ecosystem</span></li>\n </ul>\n <p><span>Depending on your interests and skills, there are opportunities to get involved in:</span></p>\n <ul>\n  <li><span>API design: developing good conventions that enable our platform to scale and make it easy for client applications to consume them</span></li>\n  <li><span>JavaScript development, helping our frontend developers implement features you've utilized in R</span></li>\n  <li><span>Product management, building on your interactions with our users to shape our product roadmap and feature design</span></li>\n  <li><span>Python development, ranging from implementing APIs you need for the R packages, to&nbsp; statistical modeling, numerical computing, machine learning, and natural language processing</span></li>\n </ul>\n <p><span>In any given week, you might implement an R interface for a new API our backend has added, write a blog post introducing that new feature, track down a bug report from a user, write a test that reproduces the issue, and assist customers in implementing Crunch via the Crunch R packages.&nbsp;</span></p>\n <p><strong>Qualifications:</strong></p>\n <ul>\n  <li><span>Expert-level skills in R, including experience delivering code that others rely on to do their work. Prior experience creating and maintaining R packages is highly valued.</span></li>\n  <li><span>Serious commitment to high development standards, including comprehensive testing, in whatever language you're working</span></li>\n  <li><span>Demonstrated ability to work with a team of peers, understanding and respecting the responsibilities and expertise developers, designers, QA folks, and others bring to the project</span></li>\n  <li><span>Eagerness to take ownership of projects and deliver results on schedule</span></li>\n  <li><span>Experience in a &quot;data science&quot;, such as social science, market research, or data visualization, is a plus.</span></li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282622?reset=False&amp;ra=1wMwwd9rlHhe&amp;oqs=a%3D1wMwwd9rlHhe' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About YouGov</h4> \n<div>\n <p>YouGov works with the world's leading brands and organisations to understand what people think.</p>\n <p><strong>Powered&nbsp;by Digital Development</strong></p>\n <p>Our Global Dev group is a tight group of seven teams comprised of about 40 developers based globally in the UK, Poland, USA and beyond.</p>\n <p>The teams coordinate on efforts to build applications and innovate in data collection, survey authoring, profile data management, integration, data analytics, content management, and other areas.</p>\n <p>These applications drive the&nbsp;opinion data engine of YouGov; empowering the biggest and the best organisations around the world with accurate information about what the world thinks. Enabling these organisations to make effective predictions based on what their audience or stakeholders think.</p>\n <p>We believe the more people are able to participate in the decisions made by the institutions that serve them, the better those decisions will be.</p>\n <p><strong>Diverse as the Audience we work with</strong></p>\n <p>YouGov is part of Stonewall's Global Diversity Champions Framework.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Flexibility</span> </li> \n <li> <span></span> <span>Best Equipment</span> </li> \n <li> <span></span> <span>Salary + Bonus</span> </li> \n <li> <span></span> <span>Well-being at Work</span> </li> \n <li> <span></span> <span>Various lifestyle benefits</span> </li> \n <li> <span></span> <span>Culture of Learning</span> </li> \n <li> <span></span> <span>Pension (401K in the USA)</span> </li> \n <li> <span></span> <span>Employee Assistance</span> </li> \n <li> <span></span> <span>Games and Social Events</span> </li> \n <li> <span></span> <span>Good Holiday allowance</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "S-wavKvQRWCyIVsc9y4wmg",
    "url": "https://remoteok.io/jobs/73979",
    "title": "Software Engineer",
    "tags": [
      "DBG:surround``remot 2W work W experi",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=8, ruby=2, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "AlphaSights",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "ETB",
      "minValue": 75000,
      "maxValue": 75000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserLargeText",
      "isEquity": false,
      "formatted": "ETB 75k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 2:13:18 AM",
    "validThrough": "Jul 25, 2019 2:13:18 AM",
    "crawled": "Jul 18, 2019 3:06:30 AM",
    "content": "<span></span> \n<span><h4>AlphaSights</h4></span> \n<br> \n<h3>Software Engineer</h3> \n<span></span> \n<span>verified</span> \n<br> \n<span>Brazil</span> \n<div> \n <div>\n   *[Disclaimer: we are targeting experienced engineers based in Brazil]* \n  <br> \n  <br>At AlphaSights, we search through more than 500 million professionals working in the world today to find the small handful of experts qualified to answer our clients needs. They use these insights to drive amazing progress within their organizations. Our mission is to provide access to dispersed, hidden, and underutilized knowledge. \n  <br> \n  <br>We’ve made terrific progress working in this new space, but there is still an incredible amount of work to do. We’ve only just scratched the surface on how we can apply technology to this problem. \n  <br> \n  <br>AlphaSights' Engineers build features across our ecosystem of products and services, both internal and client facing. As a Fullstack engineer you will remove pain-points, optimize workflows, and enhance the intelligence and capabilities of our systems. You'll work closely with a variety of people in the business to arrive at the best solution, immediately see the impact of your work, and get feedback directly from users. \n  <br> \n  <br>We're looking for people who are interested in building software systems to an incredibly high standard, comfortable working across multiple languages, and learn quickly when new technologies are introduced. \n  <br> \n  <br>We care more about your engineering skill versus your deep knowledge of a particular language or framework. \n  <br> \n  <br>**You will:** \n  <br> \n  <br>* Build and technically own large areas of our product and service ecosystem \n  <br>* Improve the performance of our applications \n  <br>* Improve developer tooling and processes \n  <br>* Work in small, nimble teams \n  <br>* Contribute with our growing Open Source efforts \n  <br>* Understand our business context deeply and leverage your engineering knowledge to propose creative solutions to problems \n  <br> \n  <br>**You might be a fit if you:** \n  <br> \n  <br>Don't worry if your experience or background doesn't match all of these areas, we believe a broad spectrum of experience provides a great perspective on solving problems in new and innovative ways and we’d love to hear from you. \n  <br> \n  <br>* Have at least 6 years of professional experience, and have served as tech lead for a specific application, product area, or infrastructure \n  <br>* You’re an expert in at least one programming Language. Ruby, Java or Python experience would be a plus. \n  <br>* Enjoy mentoring other team members, including code reviews and tech talks \n  <br>* Can balance deep work with cross-team collaboration \n  <br>* Constantly learn from and mentor other engineers \n  <br>* See yourself as an entrepreneur as well as an engineer \n  <br>* Are interested in working in a team applying data science to solve challenging business problems \n  <br>* Previous remote working experience is a plus \n  <br> \n  <br>**You might work on:** \n  <br> \n  <br>* Automate the detection and mitigation of risk in real-time \n  <br>* Propose and deliver a new product initiative to production \n  <br>* Democratize data within the organization \n  <br>* Optimizing and scaling our overall platform architecture \n  <br>* Build tools to schedule multi-party communication with heavy constraints \n  <br>* Help pick and define our tools \n  <br> \n  <br>**Who you would work with:** \n  <br> \n  <br>* You would join a dynamic, multinational, and diverse team who enjoy solving interesting problems in a collaborative environment \n  <br>* We have self-taught engineers as well as graduates from top Computer Science and Engineering schools \n  <br>* Your co-workers will include motivated recent graduates as well as experienced industry leaders from companies such as Google and Amazon \n  <br> \n  <br>Find out more: http://engineering.alphasights.com \n  <br> \n  <br>#Salary \n  <br>$75,000 \n  <br> \n  <br> \n  <br>#Location \n  <br>- Brazil \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "0y8YFCtCTGGW3SW5O_hG2A",
    "url": "https://jobmote.com/job/50290/azure-big-data-engineer-remote-flexible/",
    "title": "Azure Big Data Engineer (Remote Flexible)",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=1, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=5, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Nigel Frank International US",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 10:07:21 PM",
    "validThrough": "Jul 20, 2019 10:07:21 PM",
    "crawled": "Jul 18, 2019 3:06:25 AM",
    "content": "<div>\n Azure Big Data Engineer (Remote Flexibility)\n <br> My client is looking to have a strong Azure Data Engineer to join their creative team! As a part of the engineering team you will be responsible for developing and designing high-quality applications for transforming and analyzing large amounts of data collected from applications that include: audience data and location data. You will also be testing and prototyping services and products for certain clients while using ETL and visualization tools.\n <br> *AZURE EXPERIENCE REQUIRED\n <br> Skills:\n <ul>\n  <li>Experience using languages like Python, Scala, and Java</li>\n  <li>Experience hands-on using Cloud technologies like Azure (Data Factory, Data Bricks, Data Warehouse, HD Insight)</li>\n  <li>Experience with ETL tools like SSIS, SSAS, SSRS</li>\n  <li>Some familiarity with Microsoft BI and Power BI is great as well</li>\n  <li>Experience with data pipeline and workflow management tools</li>\n </ul>Benefits:\n <ul>\n  <li>Medical</li>\n  <li>Dental</li>\n  <li>Vision</li>\n  <li>Family leave</li>\n  <li>PTO</li>\n  <li>Retirement Plan</li>\n  <li>Remote options</li>\n </ul>For all inquiries, I can be contacted at [Click Here to Email Your Resum?] or by calling (ext1220). I'm looking forward to helping you get a great career!\n <br> What's in it for you?\n <br> Nigel Frank International is the global leader in Microsoft Technology recruitment-it's all we do. With a multilingual network of consultants across nine worldwide locations, we place more skilled Microsoft Dynamics, Azure and Stack professionals with Microsoft Partners and end-users worldwide than any other recruitment business. I recruit for our permanent Azure division, working exclusively with Big Data professionals in Pennsylvania. By focusing exclusively on Microsoft recruitment, we've been able to build relationships with some of the biggest Microsoft customers, partners, and ISVs, giving us exclusive access to some of the best jobs on the market. For more information on available Azure Big Data Jobs please contact me or see for more information.\n <br>\n <br>\n <b>More details concerning my client will be provided for applicants who show interest and who are qualified for the position.</b>\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "fzYytK21QeiJoECPRV6bAQ",
    "url": "https://jobmote.com/job/50283/aws-big-data-engineer-hadoop-python-remote/",
    "title": "AWS Big Data Engineer - Hadoop, Python - remote",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/4",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/40",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:k/t/w:shell/other/2",
      "DBG_TECH1:techWeightMap:{python=6, other=2, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=76, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 10:07:21 PM",
    "validThrough": "Jul 20, 2019 10:07:21 PM",
    "crawled": "Jul 18, 2019 3:06:25 AM",
    "content": "<div>\n AWS Big Data Engineer - Hadoop, Python\n <br>\n <br>AWS Big Data Engineer\n <br>\n <br>Description:\n <br>\n <br>My client in Rockville, MD is looking to bring on a Big Data Engineer to lead the department for the full life cycle of a data migration project. The client is actively interviewing as the project is set to begin the first of September and they are looking to on board their senior leads in advance.\n <br>\n <br>This candidate will be able to manage their own team, participate in the full lifecycle of the migration, and help build out the organizations engineering department.\n <br>\n <br>Role &amp; Responsibilities:\n <ul>\n  <li>Closely working with cross-functional teams.</li>\n  <li>Building fact tables to facilitate quicker and easier data access.</li>\n  <li>Building indices at elastic Search to support real-time dash boards at Kabana, and building predictive models to support AI/ML.</li>\n </ul>Requirements:\n <ul>\n  <li>3+ years of relevant work experience </li>\n  <li>Working experience of Scala, Spark, building ATL query models.</li>\n  <li>Developing shell scripts and running Oozie/spark jobs on Hadoop platform</li>\n  <li>Hadoop platform work using Big Data tools.</li>\n  <li>Working experience on ElasticSearch and Kibana</li>\n </ul>Hadoop, Python\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "r0GqSZ7DQu2XkW7pVu5x9Q",
    "url": "https://remoteok.io/jobs/73976",
    "title": "Data Engineer",
    "tags": [
      "DBG:surround``4N( OR(virtual,distribut,scatter), OR(compani,team,OR(organ,organis)))",
      "DBG:surround``4W( OR(fulltim,work,talent), anywher)",
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:apache-storm/java/8",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:golang/go/16",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/2",
      "DBG_TECH1:k/t/w:javascript/nodejs/2",
      "DBG_TECH1:k/t/w:maven/java/13",
      "DBG_TECH1:k/t/w:npm/nodejs/5",
      "DBG_TECH1:k/t/w:perl/other/20",
      "DBG_TECH1:k/t/w:python/python/8",
      "DBG_TECH1:k/t/w:ruby/ruby/2",
      "DBG_TECH1:k/t/w:rubygems/ruby/8",
      "DBG_TECH1:techWeightMap:{python=8, other=20, dotnet=0, c=0, mobile=1, go=16, nodejs=7, bigdata-ml=32, ruby=10, apple=0, java=23, gamedev=0, php=0, embedded=0, frontend=2}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TECH1/java",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml",
      "java"
    ],
    "hiringOrganization": {
      "name": "ActiveState Software ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 18, 2019 12:57:11 AM",
    "validThrough": "Jul 25, 2019 12:57:11 AM",
    "crawled": "Jul 18, 2019 1:06:30 AM",
    "content": "<span></span> \n<span><h4>ActiveState Software</h4>&nbsp;</span> \n<br> \n<h3>Data Engineer</h3> \n<div> \n <div> \n  <br>If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it! \n  <br> \n  <br>This position is open to full-time telecommuters anywhere in North America. You can also choose to work from our headquarters in beautiful Vancouver, BC. \n  <br> \n  <br>This position is open to both junior (including fresh out of school) and senior applicants. The salary for this position will be commensurate with your experience. \n  <br> \n  <br>What You’ll be Doing \n  <br> \n  <br>As a Data Engineer, you will create and maintain a data processing pipeline to feed our automated build systems with information about various open source languages and package updates. This work includes automating processing of open source package update feeds from language repositories including PyPI (Python), CPAN (Perl), Maven (Java), NPM (JavaScript), RubyGems. You will also be creating web crawlers for eco-systems without well defined APIs. \n  <br> \n  <br>Our day to day work practices are centered around GitHub, pull requests, code review, CI for testing, and agile development with Pivotal Tracker as our project management tool. We’re always looking to improve our practices and we expect you to help us to do so. \n  <br> \n  <br>We’re a polyglot company building our system using Golang, Python, Elm, Javascript, Perl, Docker, Kubernetes, DCOS, CircleCI, and other modern tools. Quality is as important as speed. We’re building for the long run, so you’ll need to enjoy writing tests and documentation too. \n  <br> \n  <br>Our team is scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Highfive for video calls and screen sharing, Pivotal Tracker, and Google Drive. \n  <br> \n  <br>We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code. \n  <br> \n  <br>Working at ActiveState \n  <br> \n  <br>ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all of us. \n  <br> \n  <br>Our company is a team of 40+ and growing, with 2/3rds of the positions in technical roles&nbsp; including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events. \n  <br> \n  <br>Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches. \n  <br> \n  <br>What’s in it for You \n  <br> \n  <br> \n  <br>* Working for a stable and growing company that offers the environment and personal growth potential of a start-up. \n  <br> \n  <br>* The chance to work with a smart, passionate team of people. \n  <br> \n  <br>* The chance to work on a project that will change the work lives of developers around the world. \n  <br> \n  <br>* Competitive salary, bonus, and stock option plan. \n  <br> \n  <br>* Comprehensive benefits package and health/wellness credit program. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Requirements \n  <br> \n  <br> \n  <br>* Experience creating and maintaining complex software systems along with the ability to design non-trivial applications and components from scratch. \n  <br> \n  <br>* The ability to write clean, well-tested code with clear documentation. \n  <br> \n  <br>* Deep experience with at least one programming language, and shallow experience with several. \n  <br> \n  <br>* Excellent written and spoken skills, both technical and non-technical. You’ll need to work closely with your developer teammates, as well as be able to have coherent conversations with people from QA, sales, marketing, and other parts of the company. \n  <br> \n  <br>* A willingness to engage in the process of defining our work through conversations with product management, other engineering teams, and the rest of the company. \n  <br> \n  <br>* The ability to help others on the team become better at their jobs through mentoring, thoughtful code reviews, and generally being a team player. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Assets \n  <br> \n  <br>If you have experience with any of the following please make sure to highlight it in your cover letter: \n  <br> \n  <br> \n  <br>* Data processing technologies, including but not limited to Kafka, Hadoop, Hive, Presto, Luigi, Airflow, Storm, etc. \n  <br> \n  <br>* Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI. \n  <br> \n  <br>* Golang code, especially large code bases. \n  <br> \n  <br>* Microservices and message queues. \n  <br> \n  <br>* Docker and Kubernetes. \n  <br> \n  <br>* Perl, Python, Tcl, or Ruby, especially an understanding of their respective language communities and toolchains. \n  <br> \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "vxcYyV4uRiyPKMSTkiRY_g",
    "url": "https://remoteok.io/jobs/73971",
    "title": "Data Scientist",
    "tags": [
      "DBG:surround``2N(remot, posit)",
      "DBG:surround``posit 5W 2N(from,anywher)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/4",
      "DBG_TECH1:k/t/w:python/python/2",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=2, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=28, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blue Orange Digital ",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 8:58:15 PM",
    "validThrough": "Jul 24, 2019 8:58:15 PM",
    "crawled": "Jul 17, 2019 9:30:31 PM",
    "content": "<span></span> \n<span><h4>Blue Orange Digital</h4>&nbsp;</span> \n<br> \n<h3>Data Scientist</h3> \n<div> \n <div> \n  <br>Job Description \n  <br> \n  <br> \n  <br> \n  <br>You will be joining a highly talented team of engineers working on a custom hiring and talent mapping application. We are helping a large company leverage their data to find the perfect candidates. This ranges from predictive models to answering other very open-ended questions. We have a range of projects from&nbsp; \n  <br> \n  <br>This is a remote position that can be done from anywhere.&nbsp; \n  <br> \n  <br>Responsibilities: \n  <br> \n  <br> \n  <br>* Use statistical, algorithmic, data mining, and visualization techniques to model complex problems, identify opportunities, discover solutions, and deliver actionable business insights. \n  <br> \n  <br>* Own your projects and use this autonomy to find creative and innovative ways of solving problems and delivering solutions. \n  <br> \n  <br>* Handle both parts of the Research &amp; Development process, including clean, rigorous implementations of devised models inside our Analytics system. \n  <br> \n  <br>* Communicate data-driven insights and recommendations to key stakeholders. \n  <br> \n  <br>* Be in constant communication with team members and other relevant parties and convey results efficiently and clearly. \n  <br> \n  <br> \n  <br> \n  <br> \n  <br>Requirements: \n  <br> \n  <br> \n  <br>* A strong background in advanced mathematics, in particular in probability theory and statistics, data mining, and machine learning. \n  <br> \n  <br>* Comfortable working with messy structured data sets and turning them into machine learning products \n  <br> \n  <br>* Experience in Natural Language Processing (keyword extraction and sentiment analysis) \n  <br> \n  <br>* You must be able to think critically, to look at the big picture and spot what is missing, taking advantage of it to propose improvements and deliver business insights. \n  <br> \n  <br>* 4+ years of professional experience in data science, doing exploratory data analysis, testing hypothesis, and building predictive models. \n  <br> \n  <br>* Ability to quickly and accurately understand complex new concepts. \n  <br> \n  <br>* Proficiency in Python and previous experience efficiently conducting research and creating ad hoc reports. \n  <br> \n  <br>* Familiarity with Scala/Spark a plus \n  <br> \n  <br>* Be excited about collaborating daily with your team and other groups while working via a distributed model. \n  <br> \n  <br>* Be eager to help your teammates, share your knowledge with them, and learn from them. \n  <br> \n  <br> \n  <br> \n </div> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "acjP204cSuGGf7dg9XbNNA",
    "url": "https://stackoverflow.com/jobs/282404/senior-data-analyst-do-good-do-well-have-fun-literacypro-systems-inc?a=1wHZtWK5Suf6",
    "title": "Senior Data Analyst - Do Good. Do Well. Have Fun Doing It. at LiteracyPro Systems, Inc.  ",
    "tags": [
      "DBG:surround``OR(countri, locat) 3W OR(remot,flexibl)",
      "DBG:surround``remot 16W timezon",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/40",
      "DBG_TECH1:k/t/w:windows-ce/embedded/8",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=8, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "LiteracyPro Systems, Inc.",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 200000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 200k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 9:30:26 PM",
    "validThrough": "Jul 24, 2019 9:30:26 PM",
    "crawled": "Jul 17, 2019 9:30:26 PM",
    "content": "<h3><span>Senior Data Analyst - Do Good. Do Well. Have Fun Doing It.</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Contract</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n</div> \n<div>\n Company: LiteracyPro Systems, Inc. | No office location\n <br>\n</div> \n<h4>Remote details</h4> \n<div> \n <div> \n  <div> \n   <span>Preferred Timezone:</span> \n   <span>(GMT-07:00) Mountain Time </span> \n  </div> \n </div> \n</div> \n<h4>Technologies</h4>\n<div>\n etl\n</div>\n<div>\n sql\n</div>\n<div>\n pentaho\n</div>\n<div>\n amazon-web-services\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Title: </strong></p>\n <p>Senior ETL/Data Analyst (Contractor or Contract-to-Hire Position - we're open to both)</p>\n <p><strong>Brief Job Description:</strong> &nbsp;</p>\n <p>LiteracyPro creates software for social good. Our data collection and reporting software helps government and community-based organizations help hundreds of thousands of disadvantaged people improve their opportunities to get jobs with sustainable, living wages for themselves and their families. Enjoy being part of a fun group of bright, passionate folks, in a great working environment, with generous salary &amp; benefits while helping those who help others.</p>\n <p>Our newest product, CommunityPro Suite (CPS), is a growing SaaS case management, referral, reporting and analysis enterprise application that enables hundreds of agencies to securely match, consolidate and share data in real time. The purpose of the software is to reduce organizational friction by helping local agencies better collaborate to help people achieve economic self-sufficiency for themselves and their families. The end-goal of CPS is to play an important role in helping to create healthy, vibrant communities in this country and the world.</p>\n <p>Our Company is experiencing explosive growth due to increasing national demand for our software, and we’re looking for that rare, accomplished data analyst who wants to do good, get paid well and have fun doing it. We’re seeking someone with an energizing leadership style, and who has the smarts, passion and people skills to guide our efforts on all aspects of the data management process, including: on-boarding; acquisition; attribution; transformation; and reporting of newly acquired data sets to provide high-quality data supporting analytics and our clients’ needs in a timely fashion.</p>\n <p>Given the highly execution-focused nature of the work, the ideal candidate will roll up their sleeves to ensure that their projects meet deadlines and will always look for ways to optimize processes in future cycles.</p>\n <p><strong>Responsibilities:</strong></p>\n <p>This position has the primary responsibility for the acquisition, transformation, and maintenance of data for our primary SAAS application. This data is interchanged from and returned to an increasingly diverse set of third-party source systems.</p>\n <ul>\n  <li>Conduct in-depth data profiling and data quality assessments of data received from multiple source systems to determine the current level of data accuracy, conformation to standards, reporting requirements, etc.</li>\n  <li>Investigate data flow issues by discovering system states that prevent successful job completion (source systems, infrastructure, etc.).</li>\n  <li>Identify and analyze the errors/inconsistencies in the data; provide timely resolutions for data lineage and data cleansing.</li>\n  <li>Build and validate a data quality framework with alerts for data discrepancies.</li>\n  <li>Work with the product owner/system owner, development, and QA teams to ensure alignment and proper interpretation of complex data requirements.</li>\n  <li>Develop technical documentation, including requirements documents, process overviews, data models, data flow, and ETL jobs.</li>\n </ul>\n <p><strong>Experience and Qualifications:</strong></p>\n <ul>\n  <li>6+ years performing analysis and building data processes.</li>\n  <li>6+ years of experience with ETL tasks such as reviewing business requirements, developing and troubleshooting data cleansing and loading solutions, preparing solution documentation, data dictionaries, metadata repositories, and database security.</li>\n  <li>6+ years of industry experience with the development and implementation of enterprise-level data warehousing and supporting business intelligence initiatives, particularly focused on star schema data modeling.</li>\n  <li>6+ years of experience with database design, including mastery of complex report queries and SQL optimization.</li>\n  <li>Experience with MySQL, Amazon Web Services, Microsoft Azure. Experience with Pentaho CE a plus!</li>\n  <li>Familiarity with the data security and privacy requirements of FERPA, HIPPA, SOC2 and related industry and legal standards</li>\n </ul>\n <ul>\n  <li>Degree in Computer Science, Information Systems, Mathematics, or equivalent quantitative field</li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282404?reset=False&amp;ra=1wHZtWK5Suf6&amp;oqs=a%3D1wHZtWK5Suf6' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About LiteracyPro Systems, Inc.</h4> \n<div>\n <p><strong>Our Mission</strong></p>\n <p><em>“To be a powerful force of good in the world by creating revolutionary tools for those serving humanity.”</em></p>\n <p><strong>Our Culture</strong></p>\n <ul>\n  <li>Aptitude to thrive in a pioneering environment and successfully manage multiple priorities and projects with critical deadlines.</li>\n  <li>Insanely curious, naturally approaches challenges with energy and positivity.</li>\n  <li>Your word is your bond. Your sincerity and honesty easily generate a deep sense of admiration and loyalty in your team.</li>\n  <li>You’re an exceptional listener; you ask lots of questions to better understand complex problems and interpersonal matters.</li>\n  <li>You can laugh at yourself; you’re only human and make mistakes like the rest of us.</li>\n </ul>\n <p><strong>Our Core Values:</strong></p>\n <p>The very core of LiteracyPro Systems is our genuine belief in, and adherence to, the company’s six core values:</p>\n <ul>\n  <li>Honesty and ethical behavior above all else</li>\n  <li>Teamwork—we sink or swim together</li>\n  <li>Work hard, have fun</li>\n  <li>Passion for excellence—second best will never suffice</li>\n  <li>We follow through on our commitments—we mean what we say and we say what we mean</li>\n  <li>Service to our community</li>\n </ul>\n <p>These six core values guide us in everything we do—from the commitments we make and the execution of our business plan, to the way we treat each other on a daily basis. Our values foster a deep sense of responsibility to our customers, vendors, and investors as well as to fellow team members. We are driven by the satisfaction of excellence.</p>\n <p><strong>Please send a cover letter and your resume to: David Miller, <a href='mailto:dhmiller@literacypro.com' rel='nofollow'>dhmiller@literacypro.com</a><br></strong></p> \n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "kHmR47GmT3CuALK49GvnUA",
    "url": "https://stackoverflow.com/jobs/282320/data-scientist-blue-orange-digital?a=1wGfc0ESu9ig",
    "title": "Data Scientist at Blue Orange Digital  ",
    "tags": [
      "DBG:surround``posit 5W 2N(from,anywher)",
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/32",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/8",
      "DBG_TECH1:k/t/w:python/python/4",
      "DBG_TECH1:k/t/w:scala/java/3",
      "DBG_TECH1:techWeightMap:{python=4, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=40, ruby=0, apple=0, java=3, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Blue Orange Digital",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "USD",
      "minValue": 150000,
      "maxValue": 180000,
      "info": "",
      "unit": "YEAR",
      "parser": "SalaryParserDefaultImpl",
      "isEquity": false,
      "formatted": "USD 150k - 180k /Year"
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 3:06:55 PM",
    "validThrough": "Jul 24, 2019 3:06:55 PM",
    "crawled": "Jul 17, 2019 3:06:55 PM",
    "content": "<h3><span>Data Scientist</span> </h3> \n<h4>About this job</h4> \n<div> \n <div> \n  <div> \n   <span>Job type: </span> \n   <span>Full-time</span> \n  </div> \n  <div> \n   <span>Experience level: </span> \n   <span>Mid-Level, Senior</span> \n  </div> \n  <div> \n   <span>Role: </span> \n   <span>Data Scientist</span> \n  </div> \n </div> \n <div> \n  <div> \n   <span>Industry: </span> \n   <span>Data Analysis, Financial Technology, Machine Learning</span> \n  </div> \n  <div> \n   <span>Company size: </span> \n   <span>11–50 people</span> \n  </div> \n  <div> \n   <span>Company type: </span> \n   <span>Private</span> \n  </div> \n </div> \n</div> \n<div>\n Company: Blue Orange Digital | No office location\n <br>\n</div>\n<h4>Technologies</h4>\n<div></div>\n<div>\n machine-learning\n</div>\n<div>\n r\n</div>\n<div>\n python\n</div>\n<div>\n apache-spark\n</div>\n<div>\n nlp\n</div> \n<h4>Job description</h4> \n<div>\n <p><strong>Job Description</strong><span><br><br></span></p>\n <p><span>You will be joining a highly talented team of engineers working on a custom hiring and talent mapping application. We are helping a large company leverage their data to find the perfect candidates. This ranges from predictive models to answering other very open-ended questions. We have a range of projects from&nbsp;</span></p>\n <p><span>This is a remote position that can be done from anywhere.&nbsp;</span></p>\n <p><span>Responsibilities:</span></p>\n <ul>\n  <li><span>Use statistical, algorithmic, data mining, and visualization techniques to model complex problems, identify opportunities, discover solutions, and deliver actionable business insights.</span></li>\n  <li><span>Own your projects and use this autonomy to find creative and innovative ways of solving problems and delivering solutions.</span></li>\n  <li><span>Handle both parts of the Research &amp; Development process, including clean, rigorous implementations of devised models inside our Analytics system.</span></li>\n  <li><span>Communicate data-driven insights and recommendations to key stakeholders.</span></li>\n  <li><span>Be in constant communication with team members and other relevant parties and convey results efficiently and clearly.</span></li>\n </ul>\n <p><span>Requirements:</span></p>\n <ul>\n  <li><span>A strong background in advanced mathematics, in particular in probability theory and statistics, data mining, and machine learning.</span></li>\n  <li><span>Comfortable working with messy structured data sets and turning them into machine learning products</span></li>\n  <li><span>Experience in Natural Language Processing (keyword extraction and sentiment analysis)</span></li>\n  <li><span>You must be able to think critically, to look at the big picture and spot what is missing, taking advantage of it to propose improvements and deliver business insights.</span></li>\n  <li><span>4+ years of professional experience in data science, doing exploratory data analysis, testing hypothesis, and building predictive models.</span></li>\n  <li><span>Ability to quickly and accurately understand complex new concepts.</span></li>\n  <li><span>Proficiency in Python and previous experience efficiently conducting research and creating ad hoc reports.</span></li>\n  <li><span>Familiarity with Scala/Spark a plus</span></li>\n  <li><span>Be excited about collaborating daily with your team and other groups while working via a distributed model.</span></li>\n  <li><span>Be eager to help your teammates, share your knowledge with them, and learn from them.</span></li>\n </ul> \n</div> \n<div> \n <a href='https://stackoverflow.com/jobs/apply/282320?reset=False&amp;ra=1wGfc0ESu9ig&amp;oqs=a%3D1wGfc0ESu9ig' rel='nofollow'>Apply now</a>\n</div>\n<div> \n</div> \n<h4>About Blue Orange Digital</h4> \n<div>\n <p>Founded by engineers, Blue Orange Digital wanted to bring an engineering-first approach to the development agency model. We aim to work on projects that use the latest and greatest technologies. We care about the products we build and only work with clients who understand that good applications come from happy engineers. We’re headquartered in NYC and DC with additional remote engineers across the US.</p> \n</div> \n<h4>Benefits</h4> \n<ul> \n <li> <span></span> <span>Competitive Salaries</span> </li> \n <li> <span></span> <span>Health/Vision/Dental</span> </li> \n <li> <span></span> <span>401k</span> </li> \n <li> <span></span> <span>Awesome people</span> </li> \n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "Z6kXWBzTSr2ui78QIW9Ysw",
    "url": "https://jobmote.com/job/50143/senior-aws-data-engineer-utah-remote-flex-135k-bonus/",
    "title": "Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus",
    "tags": [
      "DBG:surround``remot 3N ( OR(employe,develop,engin,team,role,employment,workmat) OR compani OR worldwide)",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/24",
      "DBG_TECH1:techWeightMap:{python=0, other=0, dotnet=0, c=0, mobile=0, go=0, nodejs=0, bigdata-ml=24, ruby=0, apple=0, java=0, gamedev=0, php=0, embedded=0, frontend=0}",
      "REMOTE1/100",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "Jefferson Frank",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 16, 2019 10:07:21 PM",
    "validThrough": "Jul 19, 2019 10:07:21 PM",
    "crawled": "Jul 17, 2019 3:06:25 AM",
    "content": "<div>\n Senior AWS Data Engineer- Utah-Remote Flex- $135K +Bonus \n <br> A SaaS based organization that has a product hosted on AWS and looking to hire for a senior level AWS Engineer. The company has their own product to help companies with supply chain, sales, planning and other operations\n <br> Product is hosted on AWS - have developers internally writing the code, they deploy it, use a lot of different open source technologies, all of which is hosted on EC2 instances, they use Amazon built in offerings for RDS and elasticash to use their Redis instances.\n <br> Main requirement is that candidates must understand the business side of the data and load it into their tool for these companies for their behalf. \n <br> AWS Requirements:\n <ul>\n  <li>Redshift</li>\n  <li>EC2</li>\n  <li>S3</li>\n  <li>Hive</li>\n  <li>Lambda</li>\n  <li>EMR</li>\n  <li>DynamoDB</li>\n  <li>Kinesis</li>\n  <li>Glue</li>\n  <li>Athena</li>\n  <li>SQL</li>\n </ul> If you or someone you know is interested in this position, please send your resume directly to [Click Here to Email Your Resum?] or call .\n <br>\n <br>Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professionals on the planet. Backed by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.\n <br>\n <br>At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivalled customer experience. Work with us and you'll get the personalized experience you deserve - one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.\n <br>\n <br>Utah/Big Data/ Engineering/ SaaS/ Analytics/ AWS/ Amazon web Services/ Remote/ Data/ Salt Lake Ciity/ Highland/ Provo/ Lehi\n <br>\n</div>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  },
  {
    "id": "UBpwZkJGQx60dEwHydKoeg",
    "url": "https://newyork.craigslist.org/mnh/sof/d/new-york-city-data-scientist-with/6935550355.html",
    "title": "Data Scientist with a rebellious spirit (SoHo)",
    "tags": [
      "DBG:surround``fulltim 4N telecommut",
      "DBG_TECH1:k/t/w:artificial-intelligence/bigdata-ml/2",
      "DBG_TECH1:k/t/w:bash/other/1",
      "DBG_TECH1:k/t/w:c++/c/8",
      "DBG_TECH1:k/t/w:clojure/other/5",
      "DBG_TECH1:k/t/w:data-science/bigdata-ml/48",
      "DBG_TECH1:k/t/w:hadoop/bigdata-ml/8",
      "DBG_TECH1:k/t/w:java/java/2",
      "DBG_TECH1:k/t/w:java/mobile/1",
      "DBG_TECH1:k/t/w:javascript/frontend/1",
      "DBG_TECH1:k/t/w:javascript/nodejs/1",
      "DBG_TECH1:k/t/w:machine-learning/bigdata-ml/6",
      "DBG_TECH1:k/t/w:numpy/python/5",
      "DBG_TECH1:k/t/w:pandas/python/5",
      "DBG_TECH1:k/t/w:python/python/6",
      "DBG_TECH1:k/t/w:scikit-learn/bigdata-ml/8",
      "DBG_TECH1:k/t/w:scikit-learn/python/5",
      "DBG_TECH1:k/t/w:scipy/python/5",
      "DBG_TECH1:techWeightMap:{python=26, other=6, dotnet=0, c=8, mobile=1, go=0, nodejs=1, bigdata-ml=72, ruby=0, apple=0, java=2, gamedev=0, php=0, embedded=0, frontend=1}",
      "REMOTE1/50",
      "TECH1/bigdata-ml",
      "TITLE1/dev",
      "TZ/unknown"
    ],
    "tagsNames1": [
      "50% remote"
    ],
    "tagsNames2": [
      "bigdata-ml"
    ],
    "hiringOrganization": {
      "name": "UNSET",
      "sameAs": "UNSET"
    },
    "salary": {
      "currency": "UNSET",
      "minValue": 0,
      "maxValue": 0,
      "info": "",
      "unit": "UNSET",
      "parser": "SalaryParserWithNoiseImpl",
      "isEquity": false,
      "formatted": ""
    },
    "employmentType": "UNSET",
    "published": "Jul 17, 2019 12:00:06 AM",
    "validThrough": "Jul 24, 2019 12:00:06 AM",
    "crawled": "Jul 17, 2019 1:07:18 AM",
    "content": "<span><span>Data Scientist with a rebellious spirit</span><small> (SoHo)</small> </span>\n<div>\n <div> \n  <div></div> \n  <p> <small> (<a href='https://www.google.com/maps/preview/@40.725500,-73.998300,16z' rel='nofollow'>google map</a>) </small> </p>\n </div> \n <p> <span>compensation: <b>market</b></span> <br> <span>employment type: <b>full-time</b></span> <br> <span>telecommuting okay</span> <br> </p> \n</div> “What we need is more people who specialize in the impossible.”\n<br>Theodor Roethke\n<br>\n<br>Founded in 2015, we are a fully funded data and analytics company in\n<br>New York City. We have people from SoFi, Fortress Capital, Credit Suisse and Bank of America.\n<br>\n<br>A TASTE OF WHAT WE DO\n<br>See if you enjoy these questions:\n<br>• If political views in a neighborhood begin to shift, how would it affect demand for mortgages?\n<br>• If you had data on all student loans in the United States, how could you use it to make money?\n<br>• Imagine you have an incredible 99% accurate model predicting defaults on unsecured loans, but it\n<br>is mostly relying on age, race, and gender of the applicant, which would be illegal. Can you still do\n<br>something useful with the model?\n<br>• A model takes 3 days to train, but you must tune it to get improvement in one week to impress\n<br>investors. What would you do?\n<br>• A partner company gave you a proprietary dataset for which we have paid $100k, yet the target\n<br>column has 50% missing values, rendering the whole project unfeasible. How would you\n<br>communicate this situation to your colleagues? What should be the next step?\n<br>• Is the python expression (lambda x: x) in {lambda x: x} true or false?\n<br>OUR GOAL is to become the modern-day “Village Banker”. The traditional Village Banker conducted\n<br>business through relationships and deep knowledge of the end customer’s true financial situation and\n<br>behavioral characteristics. We are doing the same using modern machine learning and data analytics.\n<br>OUR PROPRIETARY risk engine is in production with a top 10 U.S. bank originating over $100 MILLION\n<br>of loans every MONTH!\n<br>\n<br>OUR VALUES\n<br>• COLLABORATIVE – but we respect your autonomy!\n<br>• CURIOUS – new solutions are better than the status quo.\n<br>• RESULTS – we embrace “what works”. Elegant software design is not a priority.\n<br>• AMBIGUITY – we often make decisions based on imperfect information.\n<br>• COMMITTED – once we make a commitment, we see the project to the completion.\n<br>\n<br>POSITION SUMMARY\n<br>The data scientist will develop advanced machine-learning models. Yet it is not about tuning a model from\n<br>98% to 99%; we target problems with no state-of-the-art solution, and no guarantee that a solution exists.\n<br>The business aspect is just as important as the data science one. Expect messy proprietary datasets with\n<br>little or no documentation, arcane compliance requirements, and calculated risk-taking when you only have\n<br>1-2 chances for your model to perform well, or else it risks being discarded.\n<br>\n<br>PRIMARY RESPONSIBILITIES\n<br>• (Help) develop and optimize new models using multiple data sources of varying quality.\n<br>• (Help) manage and monitor existing models.\n<br>• Assist with infrastructure improvements, if you are interested in this direction.\n<br>• Conduct and interpret experiments, conduct R&amp;D. You can typically choose the direction, and it\n<br>can be as math- and CS-heavy as you want!\n<br>• Participate in business-related discussions and build an understanding of the overall context.\n<br>• Be a proactive and enthusiastic team member, as cheesy as it sounds!\n<br>• You must be open to learning.\n<br>\n<br>REQUIRED SKILLS/EXPERIENCE\n<br>• Solid programming fundamentals. You should be able to get an entry-level software position at\n<br>Google or Facebook.\n<br>• Knowledge of Python. Note that R, Java, C++, Clojure, or Javascript do not count.\n<br>• Solid intuition in any of math / physics / computer science / accounting / engineering / law / ...\n<br>• Knowledge of basic statistics.\n<br>• Academic or industry examples of previously built machine learning models are a must. Kaggle\n<br>competitions and personal projects also qualify.\n<br>• Desire to learn more about business and finance.\n<br>• Financial knowledge not required.\n<br>• BS/BA in a highly quantitative field is expected, but we are happy to consider exceptions.\n<br>\n<br>PREFERRED SKILLS/EXPERIENCE\n<br>• Ability to communicate your opinion.\n<br>• Hand-on experience with unclean, semi-structured or unstructured data sets.\n<br>• Proficient in math / statistics.\n<br>• Experience working in teams of analysts, data engineers, statisticians, and data scientists.\n<br>• Experience using Git, pandas/numpy/scipy/scikit-learn/jupyter, bash.\n<br>• Knowledge of Linux, AWS or another cloud, Spark, Hadoop, H2O, Airflow or Luigi.\n<br>• M.S./Ph.D. in a highly quantitative field is preferred, but we care more about what you can do.\n<br>You will be working alongside a 10-year consumer lending veteran who created strategies for Citibank\n<br>and Bank of America, a 10-year recommendation systems expert who taught graduate-level Python\n<br>courses, a Harvard grad with experience in Ethereum smart contracts and litigation analytics, an ACM\n<br>ICPC World Champion with a successful AI startup exit, and several other experts in compliance,\n<br>mortgage industry, capital markets, who know their respective fields inside out.\n<br>\n<br>WHAT WE OFFER\n<br>• Competitive market-based salary with a potential for a bonus or equity options, in case of\n<br>exceptional performance.\n<br>• Position based in New York, NY. Some work from home allowed if you can deliver results.\n<br>• Periodic travel if this is something you are interested in.\n<br>• Informal, caring, open culture with zero bureaucracy. (Well, a tiny bit!)\n<br>• Opportunity to learn and grow. If you are interested in growing in a particular direction (e.g. data\n<br>engineering, more advanced data science, finance, interviewing future candidates, compliance,\n<br>project management, business negotiation), we will come up with a plan and make sure you stay\n<br>on track.\n<br>• Easy access to and regular mentorship from the CEO and other senior team members.\n<br>• Medical insurance: United HealthCare Standard with no annual deductible (100% employer paid)\n<br>for individual employee and family.\n<br>• Dental: MetLife Enhanced (100% employer paid) — annual deductible of $50 (individual) &amp; $150\n<br>(family).\n<br>• 401 (K): 3% employer match.\n<br>• Group Term Life Insurance (up to 2x annual salary).\n<br>• Short-Term and Long-Term Disability insurance\n<br>\n<br>* Occasional telecommuting is fine if you live near NYC. Part-time can be discussed for the right candidate. \n<ul> \n <li>OK for recruiters to contact this job poster.</li> \n <li>do NOT contact us with unsolicited services or offers</li>\n</ul>",
    "place1": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    },
    "place2": {
      "locality": "UNSET",
      "region": "UNSET",
      "country": "UNSET"
    }
  }
]
}
